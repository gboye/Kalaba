{
 "metadata": {
  "name": "",
  "signature": "sha256:db959315a447c11afd244e49ea93884f5cdc58211d0c0d53a30783cc0536eaf1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf8 -*-\n",
      "repertoire=\"Kalaba-Test\"\n",
      "serie=repertoire+\"/\"\n",
      "#########################IMPORTS############################################\n",
      "import codecs, optparse\n",
      "import re, random\n",
      "import sys,os,time\n",
      "import string\n",
      "import yaml\n",
      "import ParFuMor as PFM\n",
      "from ParFuMor import *\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################VARIABLES##########################################\n",
      "version=os.path.basename(\"__file__\")\n",
      "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
      "debug=0\n",
      "debug_now=0\n",
      "print_no=False\n",
      "print_coffee=False\n",
      "print_commands=True\n",
      "print_phrases=True\n",
      "print_glose=1\n",
      "print_lexique=True\n",
      "print_cloze=False\n",
      "print_racines=False\n",
      "no_form=\"***\"\n",
      "# no_grapho=['dormir', 'lit']\n",
      "# no_phono=['gros', 'coussin']\n",
      "no_grapho=['petit','Nabil',\"sur\"]\n",
      "no_phono=[\"grand\",\"autruche\",'dans']\n",
      "phono_no=u\"XXXXX\"\n",
      "grapho_no=u\"XXXXX\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
      "    gloses=yaml.load(stream)\n",
      "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
      "    phonology=yaml.load(stream)\n",
      "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
      "    morphosyntax=yaml.load(stream)\n",
      "with open(serie+\"Tableaux.yaml\", 'r') as stream:\n",
      "    tableaux=yaml.load(stream)\n",
      "with open(serie+\"Hierarchie.pkl\", 'rb') as input:\n",
      "   PFM.hierarchieCF = pickle.load(input)\n",
      "with open(serie+\"Lexique.pkl\", 'rb') as input:\n",
      "   PFM.lexique = pickle.load(input)\n",
      "with open(serie+\"Regles.pkl\", 'rb') as input:\n",
      "   PFM.regles = pickle.load(input)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1208
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####D\u00e9finition des ent\u00eates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################CONSTANTS##########################################\n",
      "head = [\n",
      "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
      "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
      "\"Mot & Roman & Glose  \\\\\\\\\",\n",
      "\"\\\\hline\\\\strutgh{14pt}%\"\n",
      "]\n",
      "head_n = [\n",
      "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
      "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
      "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
      "\"\\\\hline\\\\strutgh{14pt}%\"\n",
      "]\n",
      "head_v = [\n",
      "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
      "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
      "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
      "\"\\\\hline\\\\strutgh{14pt}%\"\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tail = [\n",
      "\"\\\\hline\"\n",
      "\"\\\\end{tabular}\\\\\\\\\"\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1210
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####D\u00e9finition des structures pour impression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exemples=[]\n",
      "accumulateur=[]\n",
      "vocabulaire=[]\n",
      "def accumulerMots(mot):\n",
      "    accumulateur.append(mot)\n",
      "    return\n",
      "def ajouterExemple(exemple,printBool=False):\n",
      "    if printBool:\n",
      "        print exemple\n",
      "    exemples.append(exemple.strip())\n",
      "    del accumulateur[:]\n",
      "    return\n",
      "def ajouterVocabulaire(terme,printBool=False):\n",
      "    if printBool:\n",
      "        print terme\n",
      "    vocabulaire.append(terme.strip())\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1211
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####D\u00e9finition des segments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "consonnes=phonology[\"consonnes\"]\n",
      "voyelles=phonology[\"voyelles\"]\n",
      "gabarits=phonology[\"gabarits\"]\n",
      "derives=phonology[\"derives\"]\n",
      "nom_classe=phonology[\"nom_classe\"]\n",
      "nom_apo=phonology[\"apophonies\"]\n",
      "\n",
      "nom_mut=phonology[\"mutations\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1212
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####D\u00e9finition des cat\u00e9gories"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres=gloses[\"N\"][\"Genre\"]\n",
      "types=gloses[\"V\"][\"Type\"]\n",
      "i=2\n",
      "verbe_forme={}\n",
      "for forme in morphosyntax[\"V\"][\"FormesBase\"]:\n",
      "    verbe_forme[i]=forme\n",
      "    i+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def recoder(chaine,table):\n",
      "    if type(chaine)==str:\n",
      "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
      "        result=temp.encode('utf8')\n",
      "    elif type(chaine)==unicode:\n",
      "        result=chaine.translate(table)\n",
      "    return result\n",
      "\n",
      "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
      "deaccentIn = [ord(char) for char in accentedIn]\n",
      "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
      "deaccent = dict(zip(deaccentIn, deaccentOut))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syntagmes=morphosyntax[\"Syntagmes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contractions=morphosyntax[\"Contractions\"]\n",
      "for contraction in contractions:\n",
      "    temp=[]\n",
      "    for element in contractions[contraction]:\n",
      "        if isinstance(element,unicode):\n",
      "            temp.append(element.encode(\"utf8\"))\n",
      "        else:\n",
      "            temp.append(element)\n",
      "    contractions[contraction]=temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syllabes=phonology[\"syllabes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def taches(chaine):\n",
      "    result=[]\n",
      "    choix=random.sample([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\"],len(chaine)//2+len(chaine)%2)\n",
      "    for n in range(0, len(chaine), 2):\n",
      "        result.append(\"\\\\cache%s{%s}\" % (choix[n//2],chaine[n:n+2]))\n",
      "    return \"\".join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
      "    if len(tableau)==0: return\n",
      "    comment=tab[2]\n",
      "    for element in tab[0]:\n",
      "        ajouterVocabulaire(comment+element)\n",
      "    for element in tableau:\n",
      "        ajouterVocabulaire(comment+element)\n",
      "    for element in tab[1]:\n",
      "        ajouterVocabulaire(comment+element)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_tableaux(cols,tableau,texte=\"\",debut=0,tab=(head,tail,\"\")):\n",
      "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
      "    if texte!=\"\":\n",
      "        table=filtrer_tableau(tableau,texte)\n",
      "    else:\n",
      "        table=tableau\n",
      "    chunk=(len(table)-debut*cols)/cols+1\n",
      "    faire_tableaux(table,debut,cols,tab)\n",
      "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
      "    reste=[]\n",
      "    if debug: print nombre,debut,tableau\n",
      "    if debut!=0:\n",
      "        for i in range(nombre):\n",
      "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
      "        table=tableau[debut*nombre:]\n",
      "    else:\n",
      "        table=tableau\n",
      "    longueur=len(table)\n",
      "    chunk=longueur/nombre+1\n",
      "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
      "    if chunk<48:\n",
      "        chunks=chunk\n",
      "    else:\n",
      "        chunks=48\n",
      "        reste=table[48*nombre:]\n",
      "    if debug: print \"RESTE : \", chunk, reste\n",
      "    for i in range(nombre):\n",
      "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
      "    if reste:\n",
      "        faire_tableaux(reste,0,nombre,tab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filtrer_tableau(tableau,filtre):\n",
      "    result=[]\n",
      "    for line in tableau:\n",
      "        elements=line.split(\" \")\n",
      "        if elements[0] in filtre: result.append(line)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_gn(depart,cas):\n",
      "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
      "    if debug: print \"groupe depart :\", depart\n",
      "    groupe_nom=[]\n",
      "    groupe_nom.append(depart[0])\n",
      "    if debug: print depart[0]\n",
      "    for mot in depart[1:]:\n",
      "        if debug: print mot\n",
      "        groupe_nom.extend(etendre_contraction([mot]))\n",
      "    if debug: print \"groupe nom :\", groupe_nom\n",
      "    mots=[]\n",
      "    det=[]\n",
      "    adj=[]\n",
      "    nom=[]\n",
      "    gp=[]\n",
      "    tete=\"\"\n",
      "    nombre=\"\"\n",
      "    reste=0\n",
      "    for mot in groupe_nom:\n",
      "        if reste==0:\n",
      "            if mot==\"deux\":\n",
      "                nombre=\"DU\"\n",
      "                if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
      "            else:\n",
      "                nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
      "                categorie=PFM.lexique.lexemes[nomLexeme].classe\n",
      "                if debug: \n",
      "                    print \"mot\",[mot]\n",
      "                    print \"vedette\",PFM.lexique.formeLexeme[mot][0],categorie\n",
      "                    print \"categories\",PFM.hierarchieCF.classes[\"N\"]\n",
      "                if PFM.hierarchieCF.getCategory(categorie)==\"N\":\n",
      "                    tete=categorie\n",
      "                    if debug: print \"t\u00eate :\", tete\n",
      "                    tampon=tete.split('.')\n",
      "                    classe=tampon[0]\n",
      "                    try:\n",
      "                        typeMot=tampon[1]\n",
      "                    except IndexError:\n",
      "                        typeMot=''\n",
      "                    if mot[len(mot)-1]=='s':\n",
      "                        if nombre==\"\": nombre=\"PL\"\n",
      "                    else:\n",
      "                        if nombre==\"\": nombre=\"SG\"\n",
      "                    nom.append(PFM.lexique.formeLexeme[mot][0])\n",
      "                    cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
      "                    if cas==\"ERG\":\n",
      "                        erg_genre=classe\n",
      "                        erg_nombre=nombre\n",
      "                    elif cas==\"ABS\":\n",
      "                        abs_genre=classe\n",
      "                        abs_nombre=nombre\n",
      "                elif categorie in [\"DET\"]:\n",
      "                    det.append(PFM.lexique.formeLexeme[mot][0])\n",
      "                elif categorie in PFM.hierarchieCF.classes[\"ADJ\"]:\n",
      "                    adj.append(PFM.lexique.formeLexeme[mot][0])\n",
      "                elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
      "                    gp.append(mot)\n",
      "                    reste=1\n",
      "        else:\t\t\t\t\t\t\t#On a trouv\u00e9 une PREP, toute la suite va dans DP\n",
      "            gp.append(mot)\n",
      "    if debug: print \"accord :\", tete\n",
      "    if reste==1: gp=faire_gp(gp)\n",
      "    if debug: print \"GP dans le GN : \", gp\n",
      "    if debug: print \"GN sans det ? \", det\n",
      "    if not det: det.append(\"IND\")\n",
      "    for mot in det:\n",
      "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
      "        ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent).upper()+nombre.capitalize()+cas.capitalize()\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "    for mot in gp: mots.append(mot)\n",
      "    for mot in adj:\n",
      "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
      "        ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent).lower()+classe.capitalize()+nombre.capitalize()\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "    for mot in nom:\n",
      "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
      "        if mot.istitle():\n",
      "            ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent)+cellule\n",
      "        else:\n",
      "            ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent).lower()+cellule\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "    return mots"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_gp(groupe_prep):\n",
      "    mots=[]\n",
      "    groupe_prep=etendre_contraction(groupe_prep)\n",
      "    if debug: print \"faire_gp\", groupe_prep\n",
      "    preposition=groupe_prep[0]\n",
      "    if preposition!=\"\u00e0\" :\n",
      "        if debug: print \"PREP!=\u00e0\",[groupe_prep[0],\"\u00e0\"]\n",
      "        ref=\"\\\\\"+recoder(groupe_prep[0],deaccent).upper()\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "        if debug:\n",
      "            print \"groupe prep :\", groupe_prep\n",
      "            print ref\n",
      "        if len(groupe_prep)>1:\n",
      "            groupe_nom=groupe_prep[1:]\n",
      "            mots.insert(0,faire_gn(groupe_nom,\"OBL\"))\n",
      "        return mots\n",
      "    else:\n",
      "        groupe_nom=groupe_prep[1:]\n",
      "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,\"DAT\")\n",
      "        mots.append(faire_gn(groupe_nom,\"DAT\"))\n",
      "        return mots"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def etendre_contraction(liste):\n",
      "    result=[]\n",
      "    if liste[0] in contractions.keys():\n",
      "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
      "        result.extend(contractions[liste[0]])\n",
      "        result.extend(liste[1:])\n",
      "    else:\n",
      "        result=liste\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
      "    if debug: print \"printflat\", liste\n",
      "    if not isinstance(liste, basestring):\n",
      "        for element in liste:\n",
      "            accumulerMots(prefixe)\n",
      "            printflat(element,suffixe)\n",
      "    else: \n",
      "        accumulerMots(prefixe)\n",
      "        accumulerMots(liste+suffixe)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#######################\n",
      "#\n",
      "#\tINITIALISATION DES VARIABLES\n",
      "#\n",
      "#######################\n",
      "\n",
      "try:\n",
      "    __IPYTHON__ \n",
      "    ipython=True\n",
      "except: \n",
      "    ipython=False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################\n",
      "#\n",
      "# LECTURE DU FICHIER DE LEXEMES\n",
      "#\n",
      "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
      "#\n",
      "################\n",
      "print \"%% version : \"+version\n",
      "print \"%% traitement : \"+time_stamp\n",
      "\n",
      "if ipython or True:\n",
      "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
      "    phrase_nom=serie+\"Phrases.txt\"\n",
      "else:\n",
      "    parser=optparse.OptionParser()\n",
      "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
      "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
      "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
      "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
      "\n",
      "    (options, args) = parser.parse_args()\n",
      "    lexeme_nom=args[0]\n",
      "    phrase_nom=args[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "%% version : __file__\n",
        "%% traitement : 140915-2300\n"
       ]
      }
     ],
     "prompt_number": 1228
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Ouverture du fichier lexique"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Ouverture du fichier phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    phrase_file = codecs.open(phrase_nom,\"r\",\"utf-8\")\n",
      "except IOError:\n",
      "    print 'I could not open the sentence file', phrase_nom\n",
      "    sys.exit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def recoder(chaine,table):\n",
      "    if type(chaine)==str:\n",
      "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
      "        result=temp.encode('utf8')\n",
      "    elif type(chaine)==unicode:\n",
      "        result=chaine.translate(table)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
      "deaccentIn = [ord(char) for char in accentedIn]\n",
      "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
      "deaccent = dict(zip(deaccentIn, deaccentOut))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
      "ipaIn = [ord(char) for char in tipaIn]\n",
      "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
      "toipa = dict(zip(ipaIn, ipaOut))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#################################################\n",
      "#################################################\n",
      "#################################################\n",
      "##\n",
      "##\n",
      "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
      "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
      "##\n",
      "##\n",
      "#################################################\n",
      "################################################\n",
      "#\n",
      "#\n",
      "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
      "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
      "#\n",
      "#\n",
      "################################################\n",
      "texte=[]\n",
      "#graphies={}\n",
      "#abs_genre=\"\"\n",
      "#abs_nombre=\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if print_phrases:\n",
      "    comment=\"\"\n",
      "else:\n",
      "    comment=\"%\"\n",
      "ajouterExemple(comment+\"\\\\begin{exe}\")\n",
      "for line in phrase_file:\n",
      "    phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
      "    tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").encode(\"utf8\").split(\"\\t\")\n",
      "    if not tampon[0].startswith(\"#\"):\n",
      "        verbe=tampon[1].split(\" \")\n",
      "        verbeForme=verbe[0]\n",
      "        if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
      "            print \"FORME AMBIGU\u00cb\"\n",
      "        verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
      "        (formeCitation,typeVerbe)=verbeLexeme.split(\".\")\n",
      "        verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
      "        verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
      "        if debug: print \"verbe :\", verbe\n",
      "        if verbeLexeme.endswith(\"VI\"):\n",
      "            suj_cas=\"ABS\"\n",
      "        else:\n",
      "            suj_cas=\"ERG\"\n",
      "            obj_cas=\"ABS\"\n",
      "        suj_genre=\"A\"\n",
      "        suj_nombre=\"SG\"\n",
      "        obj_genre=\"A\"\n",
      "        obj_nombre=\"SG\"\n",
      "        sujet=tampon[0].strip().split(\" \")\n",
      "        phrase[syntagmes['Phrase'].index('SUJ')]=faire_gn(sujet,suj_cas)\n",
      "        if debug: print \"sujet :\",phrase[1]\n",
      "        if len(tampon)>=3:\n",
      "            objet=tampon[2].split(\" \")\n",
      "            if debug: print \"objet : \",objet\n",
      "            if objet!=['']: phrase[syntagmes['Phrase'].index('OBJ')]=faire_gn(objet,obj_cas)\n",
      "        if len(tampon)>=4:\n",
      "            indirect=tampon[3].split(\" \")\n",
      "            if debug: print \"indirect : \",indirect\n",
      "            if indirect!=['']: phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect)\n",
      "        if len(tampon)>=5:\n",
      "            ajout=tampon[4].split(\" \")\n",
      "            phrase[syntagmes['Phrase'].index('AJOUT')]=faire_gp(ajout)\n",
      "        glose=\"\\\\\"+recoder(verbeLemme,deaccent)+morphosyntax[\"V\"][\"FormesBase\"][verbeFormeIndex].capitalize()+abs_genre.capitalize()+abs_nombre.capitalize()\n",
      "        phrase[syntagmes['Phrase'].index('V')]=glose\n",
      "        texte.append(glose)\n",
      "        if print_glose:\n",
      "            ajouterExemple(comment+\"\\\\ex\\\\glll\")\n",
      "        else:\n",
      "            ajouterExemple(comment+\"\\\\ex\\\\gll\")\n",
      "        print comment,\n",
      "        for mot in phrase:\n",
      "            if mot!=0:\n",
      "                printflat(mot,\"{}\")\n",
      "        ajouterExemple(\" \".join(accumulateur)+\"\\\\\\\\\")\n",
      "        print comment,\n",
      "        for mot in phrase:\n",
      "            if mot!=0:\n",
      "                printflat(mot,\"P{}\")\n",
      "        ajouterExemple(\" \".join(accumulateur)+\"\\\\\\\\\")\n",
      "        if print_glose:\n",
      "            print comment,\n",
      "            for mot in phrase:\n",
      "                if mot!=0:\n",
      "                    printflat(mot,\"G{}\")\n",
      "            ajouterExemple(\" \".join(accumulateur)+\"\\\\\\\\\")\n",
      "        traduction=(line.strip().rstrip('.')).split()\n",
      "        start=1\n",
      "        accumulerMots(comment)\n",
      "        for element in traduction:\t\t\t# convertir les S majuscules \u00e0 la finale des mots en minuscules\n",
      "            if element!=\"\":\n",
      "                if start:\n",
      "                    start=0\n",
      "                    element=element.capitalize()\n",
      "                caracteres=list(element)\n",
      "                if caracteres[len(caracteres)-1]=='S':\n",
      "                    caracteres[len(caracteres)-1]='s'\n",
      "                accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
      "        ajouterExemple(\" \".join(accumulateur))\n",
      "        del accumulateur[:]\n",
      "        if print_coffee and random.randint(1,6)==1:\n",
      "            stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
      "            alpha=random.random()/1.5\n",
      "            angle=random.randint(0,360)\n",
      "            xoff=random.randint(-200,0)\n",
      "            ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
      "ajouterExemple(comment+\"\\\\end{exe}\")\n",
      "    \n",
      "phrase_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "too many values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1234-c31700ac77e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"FORME AMBIGU\u00cb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mverbeLexeme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformeLexeme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mverbeForme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mformeCitation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypeVerbe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbeLexeme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mverbeLemme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%s%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformeCitation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypeVerbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mverbeFormeIndex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexemes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mverbeLexeme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbeForme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
       ]
      }
     ],
     "prompt_number": 1234
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#################################################\n",
      "if ('options' in globals() and options.print_cloze) or print_racines:\n",
      "    tableau_racines_n=[]\n",
      "    tableau_racines_v=[]\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RACINES%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tNOMS\"\n",
      "    print\n",
      "    for element in sorted(radical_n.keys()):\n",
      "        tableau_racines_n.append(\"%s & %s & \\\\textipa{%s} & \\\\textipa{%s} \\\\\\\\\" % (element, radical_n[element][2], radical_n[element][0], radical_n[element][1]))\n",
      "    print_tableaux(2,tableau_racines_n,\"\",0,(head_n,tail,\"%\"))\t\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tVERBES\"\t\n",
      "    print\n",
      "    for element in sorted(radical_v.keys()):\n",
      "        tableau_racines_v.append(\"%s & %s & \\\\textipa{%s} \\\\\\\\\" % (element, radical_v[element][1], radical_v[element][0]))\n",
      "    print_tableaux(2,tableau_racines_v,\"\",0,(head_v,tail,\"%\"))\t"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if ('options' in globals() and options.print_cloze) or print_lexique:\n",
      "    tab=(head,tail,\"\")\n",
      "else:\n",
      "    tab=(head,tail,\"%\")\n",
      "ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
      "ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
      "print_tableaux(2,tableaux[\"N\"],texte,8,tab)\n",
      "ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
      "print_tableaux(3,tableaux[\"ADJ\"],texte,11,tab)\n",
      "ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
      "print_tableaux(2,tableaux[\"V\"],texte,35,tab)\n",
      "ajouterVocabulaire(tab[2]+\"\\\\item D\u00c9TERMINANTS\\\\\\\\[-3ex]\")\n",
      "print_tableaux(3,tableaux[\"DET\"],texte,12,tab)\n",
      "ajouterVocabulaire(tab[2]+\"\\\\item PR\u00c9POSITIONS\\\\\\\\[-3ex]\")\n",
      "print_tableaux(3,tableaux[\"PREP\"],texte,0,tab)\n",
      "ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "if ('options' in globals() and options.print_cloze) or print_cloze:\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%CLOZE%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tNOMS\"\t\n",
      "    for element in cloze_noms:\n",
      "        print \"% \", element[0].translate(toipa)+\";\"+element[1]\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tVERBES\"\t\n",
      "    for element in cloze_verbes:\n",
      "        print \"% \", element[0].translate(toipa)+\";\"+element[1]\t\t"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(serie+\"Exemples.tex\", 'wb') as output:\n",
      "    for exemple in exemples:\n",
      "        output.write(exemple+\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(serie+\"Vocabulaire.tex\", 'wb') as output:\n",
      "    for vocable in vocabulaire:\n",
      "        output.write(vocable+\"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}