{
 "metadata": {
  "name": "",
  "signature": "sha256:04952d535498e52106b207ad360ff67ef6f7d182d831a49e7383cd29e28fea73"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf8 -*-\n",
      "\n",
      "#########################IMPORTS############################################\n",
      "import codecs, optparse\n",
      "import re, random\n",
      "import sys,os,time\n",
      "import string\n",
      "import yaml\n",
      "import ParFuMor as PFM\n",
      "from ParFuMor import *\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################VARIABLES##########################################\n",
      "version=os.path.basename(\"__file__\")\n",
      "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
      "debug=0\n",
      "debug_now=0\n",
      "print_no=False\n",
      "print_coffee=True\n",
      "print_commands=True\n",
      "print_phrases=True\n",
      "print_glose=0\n",
      "print_lexique=False\n",
      "print_cloze=False\n",
      "print_racines=False\n",
      "no_form=\"***\"\n",
      "genre=[u'M',u'F',u'A', u'I']\n",
      "classe=[u'H',u'NH']\n",
      "nombre=[u'SG',u'DU',u'PL',u'NSG']\n",
      "nombre_sdp=[u'SG',u'DU',u'PL']\n",
      "nombre_sp=[u'SG',u'NSG']\n",
      "cas=[u'',u'ERG',u'ABS']\n",
      "# no_grapho=['dormir', 'lit']\n",
      "# no_phono=['gros', 'coussin']\n",
      "no_grapho=['petit','Nabil',\"sur\"]\n",
      "no_phono=[\"grand\",\"autruche\",'dans']\n",
      "phono_no=u\"XXXXX\"\n",
      "grapho_no=u\"XXXXX\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"Kalaba-Phonology.yaml\", 'r') as stream:\n",
      "    phonology=yaml.load(stream)\n",
      "with open(\"Kalaba-MorphoSyntax.yaml\", 'r') as stream:\n",
      "    morphosyntax=yaml.load(stream)\n",
      "with open('PFM-Hierarchie.pkl', 'rb') as input:\n",
      "   PFM.hierarchieCF = pickle.load(input)\n",
      "with open('PFM-Lexique.pkl', 'rb') as input:\n",
      "   PFM.lexique = pickle.load(input)\n",
      "with open('PFM-Regles.pkl', 'rb') as input:\n",
      "   PFM.regles = pickle.load(input)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexemes=[]\n",
      "graphies={}\n",
      "lexique={}\n",
      "base={}\n",
      "categorie_v={}\n",
      "temps_v={}\n",
      "radical_n={}\n",
      "radical_v={}\n",
      "noms=[]\n",
      "cloze_noms=[]\n",
      "tableau_noms=[]\n",
      "verbes=[]\n",
      "cloze_verbes=[]\n",
      "tableau_verbes=[]\n",
      "determinants=[]\n",
      "tableau_determinants=[]\n",
      "prepositions=[]\n",
      "tableau_prepositions=[]\n",
      "adjectifs=[]\n",
      "tableau_adjectifs=[]\n",
      "francais=[]\n",
      "kalaba=[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####D\u00e9finition des ent\u00eates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#########################CONSTANTS##########################################\n",
      "head = [\n",
      "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
      "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
      "\"Mot & Roman & Glose  \\\\\\\\\",\n",
      "\"\\\\hline\\\\strutgh{14pt}%\"\n",
      "]\n",
      "head_n = [\n",
      "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
      "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
      "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
      "\"\\\\hline\\\\strutgh{14pt}%\"\n",
      "]\n",
      "head_v = [\n",
      "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
      "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
      "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
      "\"\\\\hline\\\\strutgh{14pt}%\"\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tail = [\n",
      "\"\\\\hline\"\n",
      "\"\\\\end{tabular}\\\\\\\\\"\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####D\u00e9finition des segments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "consonnes=phonology[\"consonnes\"]\n",
      "voyelles=phonology[\"voyelles\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gabarits=phonology[\"gabarits\"]\n",
      "derives=phonology[\"derives\"]\n",
      "nom_classe=phonology[\"nom_classe\"]\n",
      "nom_apo=phonology[\"apophonies\"]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nom_mut=phonology[\"mutations\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nom_nombre=morphosyntax[\"N\"][\"Nombre\"]\n",
      "nom_cas=morphosyntax[\"N\"][\"Cas\"]\n",
      "verbe_classe=morphosyntax[\"V\"][\"Type\"]\n",
      "verbe_genre=morphosyntax[\"V\"][\"Genre-Abs\"]\n",
      "verbe_nombre=morphosyntax[\"V\"][\"Nombre-Abs\"]\n",
      "verbe_temps=morphosyntax[\"V\"][\"Temps\"]\n",
      "i=2\n",
      "verbe_forme={}\n",
      "for forme in morphosyntax[\"V\"][\"FormesBase\"]:\n",
      "    verbe_forme[i]=forme\n",
      "    i+=1\n",
      "det_nb=morphosyntax[\"DET\"][\"Nombre\"]\n",
      "det_cas=morphosyntax[\"DET\"][\"Cas\"]\n",
      "adjectif_genre=morphosyntax[\"ADJ\"][\"Genre\"]\n",
      "adjectif_nb=morphosyntax[\"ADJ\"][\"Nombre\"]\n",
      "adj_types_nombre=morphosyntax[\"ADJ\"][\"CF\"][\"Nombre\"]\n",
      "adj_types_genre=morphosyntax[\"ADJ\"][\"CF\"][\"Genre\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syntagmes=morphosyntax[\"Syntagmes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contractions=morphosyntax[\"Contractions\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syllabes=phonology[\"syllabes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def taches(chaine):\n",
      "    result=[]\n",
      "    choix=random.sample([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\"],len(chaine)//2+len(chaine)%2)\n",
      "    for n in range(0, len(chaine), 2):\n",
      "        result.append(\"\\\\cache%s{%s}\" % (choix[n//2],chaine[n:n+2]))\n",
      "    return \"\".join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
      "    if len(tableau)==0: return\n",
      "    comment=tab[2]\n",
      "    for element in tab[0]:\n",
      "        print comment+element\n",
      "    for element in tableau:\n",
      "        print comment+element\n",
      "    for element in tab[1]:\n",
      "        print comment+element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_tableaux(cols,tableau,texte=\"\",debut=0,tab=(head,tail,\"\")):\n",
      "    print tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\"\n",
      "    if texte!=\"\":\n",
      "        table=filtrer_tableau(tableau,texte)\n",
      "    else:\n",
      "        table=tableau\n",
      "    chunk=(len(table)-debut*cols)/cols+1\n",
      "    faire_tableaux(table,debut,cols,tab)\n",
      "    print tab[2]+\"\\\\end{multicols}\"\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#def faire_tableaux(tableau,taille=16,debut=16,nombre=0):\n",
      "#\tfor i in range(nombre):\n",
      "#\t\tfaire_tableau(tableau[debut*i:debut*(i+1)])\n",
      "#\tlongueur=len(tableau)-nombre*debut\n",
      "#\tchunks=longueur/taille\n",
      "##\tprint longueur, taille, chunks\n",
      "#\tfor i in range(chunks+1):\n",
      "##\t\tprint i\n",
      "#\t\tfaire_tableau(tableau[nombre*debut+taille*i:nombre*debut+taille*(i+1)])\n",
      "\n",
      "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
      "    reste=[]\n",
      "    if debug: print nombre,debut,tableau\n",
      "    if debut!=0:\n",
      "        for i in range(nombre):\n",
      "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
      "        table=tableau[debut*nombre:]\n",
      "    else:\n",
      "        table=tableau\n",
      "    longueur=len(table)\n",
      "    chunk=longueur/nombre+1\n",
      "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
      "    if chunk<48:\n",
      "        chunks=chunk\n",
      "    else:\n",
      "        chunks=48\n",
      "        reste=table[48*nombre:]\n",
      "    if debug: print \"RESTE : \", chunk, reste\n",
      "#\tprint longueur, taille, chunks\n",
      "    for i in range(nombre):\n",
      "#\t\tprint i\n",
      "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
      "    if reste:\n",
      "        faire_tableaux(reste,0,nombre,tab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filtrer_tableau(tableau,filtre):\n",
      "    result=[]\n",
      "    for line in tableau:\n",
      "        elements=line.split(\" \")\n",
      "        if elements[0] in filtre: result.append(line)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_gn(depart,cas):\n",
      "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
      "    if debug: print \"groupe depart :\", depart\n",
      "    groupe_nom=[]\n",
      "    groupe_nom.append(depart[0])\n",
      "    if debug: print depart[0]\n",
      "    for mot in depart[1:]:\n",
      "        if debug: print mot\n",
      "        groupe_nom.extend(etendre_contraction([mot]))\n",
      "    if debug: print \"groupe nom :\", groupe_nom\n",
      "    mots=[]\n",
      "    det=[]\n",
      "    adj=[]\n",
      "    nom=[]\n",
      "    gp=[]\n",
      "    tete=\"\"\n",
      "    nombre=\"\"\n",
      "    reste=0\n",
      "    for mot in groupe_nom:\n",
      "        if reste==0:\n",
      "            if mot==\"deux\":\n",
      "                nombre=\"DU\"\n",
      "                if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
      "            else:\n",
      "                if debug:\n",
      "                    print mot,\n",
      "                    print PFM.lexique.formeLexeme[mot][0],\n",
      "                    print PFM.lexique.formeLexeme[mot][0]\n",
      "                nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
      "                categorie=PFM.lexique.lexemes[nomLexeme].classe\n",
      "                if categorie in genres:\n",
      "                    tete=categorie\n",
      "                    if debug: print \"t\u00eate :\", tete\n",
      "                    tampon=tete.split('.')\n",
      "                    classe=tampon[0]\n",
      "                    try:\n",
      "                        type=tampon[1]\n",
      "                    except IndexError:\n",
      "                        type=''\n",
      "                    if mot[len(mot)-1]=='s':\n",
      "                        if nombre==\"\": nombre=\"PL\"\n",
      "                    else:\n",
      "                        if nombre==\"\": nombre=\"SG\"\n",
      "                    nom.append(PFM.lexique.formeLexeme[mot][0])\n",
      "                    cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
      "                    if cas==\"ERG\":\n",
      "                        erg_genre=classe\n",
      "                        erg_nombre=nombre\n",
      "                    elif cas==\"ABS\":\n",
      "                        abs_genre=classe\n",
      "                        abs_nombre=nombre\n",
      "                elif categorie in [\"DEF\",\"DEM\",\"IND\"]:\n",
      "                    det.append(categorie)\n",
      "                elif categorie.startswith(\"ADJ\"):\n",
      "                    adj.append(PFM.lexique.formeLexeme[mot][0])\n",
      "                elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
      "                    gp.append(mot)\n",
      "                    reste=1\n",
      "        else:\t\t\t\t\t\t\t#On a trouv\u00e9 une PREP, toute la suite va dans DP\n",
      "            gp.append(mot)\n",
      "    if debug: print \"accord :\", tete\n",
      "    if reste==1: gp=faire_gp(gp)\n",
      "    if debug: print \"GP dans le GN : \", gp\n",
      "    if debug: print \"GN sans det ? \", det\n",
      "    if not det: det.append(\"IND\")\n",
      "    for mot in det:\n",
      "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
      "        ref=\"\\\\\"+mot.lower()+nombre.capitalize()+cas.capitalize()\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "    for mot in gp: mots.append(mot)\n",
      "    for mot in adj:\n",
      "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
      "        ref=\"\\\\\"+mot.lower()+nombre.capitalize()+classe.capitalize()\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "    for mot in nom:\n",
      "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
      "        if mot.istitle():\n",
      "            ref=\"\\\\\"+mot+cellule\n",
      "        else:\n",
      "            ref=\"\\\\\"+mot.lower()+cellule\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "    return mots"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def faire_gp(groupe_prep):\n",
      "    mots=[]\n",
      "    groupe_prep=etendre_contraction(groupe_prep)\n",
      "    if debug: print \"faire_gp\", groupe_prep\n",
      "    if groupe_prep[0]!=u\"\u00e0\" :\n",
      "        if debug: print \"PREP!=\u00e0\"\n",
      "        ref=\"\\\\\"+groupe_prep[0].upper()\n",
      "        mots.append(ref)\n",
      "        texte.append(ref)\n",
      "        if debug:\n",
      "            print \"groupe prep :\", groupe_prep\n",
      "            print ref\n",
      "        if len(groupe_prep)>1:\n",
      "            groupe_nom=groupe_prep[1:]\n",
      "            mots.insert(0,faire_gn(groupe_nom,\"OBL\"))\n",
      "        return mots\n",
      "    else:\n",
      "        groupe_nom=groupe_prep[1:]\n",
      "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,\"DAT\")\n",
      "        mots.append(faire_gn(groupe_nom,\"DAT\"))\n",
      "        return mots"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def etendre_contraction(liste):\n",
      "    result=[]\n",
      "    if liste[0] in contractions.keys():\n",
      "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
      "        result.extend(contractions[liste[0]])\n",
      "        result.extend(liste[1:])\n",
      "    else:\n",
      "        result=liste\n",
      "    #for element in liste:\n",
      "    #\tif element in contractions.keys(): result.extend(contractions[element])\n",
      "    #\telse: result.append(element)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
      "    if debug: print \"printflat\", liste\n",
      "    if not isinstance(liste, basestring):\n",
      "        for element in liste:\n",
      "            print prefixe,\n",
      "            printflat(element,suffixe)\n",
      "    else: print prefixe,liste+suffixe,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#######################\n",
      "#\n",
      "#\tINITIALISATION DES VARIABLES\n",
      "#\n",
      "#######################\n",
      "\n",
      "genres=nom_classe.keys()\n",
      "types=verbe_classe.keys()\n",
      "nombres=nom_nombre.keys()\n",
      "cases=nom_cas.keys()\n",
      "temps=verbe_temps.keys()\n",
      "\n",
      "try:\n",
      "    __IPYTHON__ \n",
      "    ipython=True\n",
      "except: \n",
      "    ipython=False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################\n",
      "#\n",
      "# LECTURE DU FICHIER DE LEXEMES\n",
      "#\n",
      "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
      "#\n",
      "################\n",
      "print \"%% version : \"+version\n",
      "print \"%% traitement : \"+time_stamp\n",
      "\n",
      "if ipython:\n",
      "    lexeme_nom=\"lexemes.txt\"\n",
      "    phrase_nom=\"phrases.txt\"\n",
      "else:\n",
      "    parser=optparse.OptionParser()\n",
      "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
      "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
      "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
      "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
      "\n",
      "    (options, args) = parser.parse_args()\n",
      "    lexeme_nom=args[0]\n",
      "    phrase_nom=args[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "%% version : __file__\n",
        "%% traitement : 140913-1433\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Ouverture du fichier lexique"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Ouverture du fichier phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    phrase_file = codecs.open(phrase_nom,\"r\",\"utf-8\")\n",
      "except IOError:\n",
      "    print 'I could not open the sentence file', phrase_nom\n",
      "    sys.exit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def recoder(chaine,table):\n",
      "    if type(chaine)==str:\n",
      "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
      "        result=temp.encode('utf8')\n",
      "    elif type(chaine)==unicode:\n",
      "        result=chaine.translate(table)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
      "deaccentIn = [ord(char) for char in accentedIn]\n",
      "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
      "deaccent = dict(zip(deaccentIn, deaccentOut))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
      "ipaIn = [ord(char) for char in tipaIn]\n",
      "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
      "toipa = dict(zip(ipaIn, ipaOut))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexemes=[]\n",
      "graphies={}\n",
      "noms=[]\n",
      "tableau_noms=[]\n",
      "verbes=[]\n",
      "tableau_verbes=[]\n",
      "determinants=[]\n",
      "tableau_determinants=[]\n",
      "prepositions=[]\n",
      "tableau_prepositions=[]\n",
      "adjectifs=[]\n",
      "tableau_adjectifs=[]\n",
      "francais=[]\n",
      "kalaba=[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#################################################\n",
      "#################################################\n",
      "#################################################\n",
      "##\n",
      "##\n",
      "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
      "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
      "##\n",
      "##\n",
      "#################################################\n",
      "################################################\n",
      "#\n",
      "#\n",
      "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
      "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
      "#\n",
      "#\n",
      "################################################\n",
      "texte=[]\n",
      "graphies={}\n",
      "abs_genre=\"\"\n",
      "abs_nombre=\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PFM.lexique.formeLexeme"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "{'DEF': ['DEF'],\n",
        " 'DEM': ['DEM'],\n",
        " 'IND': ['IND'],\n",
        " 'Katisha': ['Katisha.A'],\n",
        " 'Katishas': ['Katisha.A'],\n",
        " 'Nabil': ['Nabil.D'],\n",
        " 'Nabils': ['Nabil.D'],\n",
        " 'Nicole': ['Nicole.B'],\n",
        " 'Nicoles': ['Nicole.B'],\n",
        " 'achetaient': ['acheter.VT'],\n",
        " 'achetait': ['acheter.VT'],\n",
        " 'acheter': ['acheter.VT'],\n",
        " 'ach\\xc3\\xa8te': ['acheter.VT'],\n",
        " 'ach\\xc3\\xa8tent': ['acheter.VT'],\n",
        " 'arrivaient': ['arriver.VI'],\n",
        " 'arrivait': ['arriver.VI'],\n",
        " 'arrive': ['arriver.VI'],\n",
        " 'arrivent': ['arriver.VI'],\n",
        " 'arriver': ['arriver.VI'],\n",
        " 'autruche': ['autruche.B'],\n",
        " 'autruches': ['autruche.B'],\n",
        " 'avec': ['avec'],\n",
        " 'balai': ['balai.A'],\n",
        " 'balais': ['balai.A'],\n",
        " 'bas': ['bas.1'],\n",
        " 'basse': ['bas.1'],\n",
        " 'basses': ['bas.1'],\n",
        " 'blanc': ['blanc.1'],\n",
        " 'blanche': ['blanc.1'],\n",
        " 'blanches': ['blanc.1'],\n",
        " 'blancs': ['blanc.1'],\n",
        " 'boire': ['boire.VT'],\n",
        " 'boit': ['boire.VT'],\n",
        " 'boivent': ['boire.VT'],\n",
        " 'buvaient': ['boire.VT'],\n",
        " 'buvait': ['boire.VT'],\n",
        " 'caf\\xc3\\xa9': ['caf\\xc3\\xa9.C'],\n",
        " 'caf\\xc3\\xa9s': ['caf\\xc3\\xa9.C'],\n",
        " 'ce': ['DEM'],\n",
        " 'ces': ['DEM'],\n",
        " 'cet': ['DEM'],\n",
        " 'cette': ['DEM'],\n",
        " 'chambre': ['chambre.B'],\n",
        " 'chambres': ['chambre.B'],\n",
        " 'chassaient': ['chasser.VT'],\n",
        " 'chassait': ['chasser.VT'],\n",
        " 'chasse': ['chasser.VT'],\n",
        " 'chassent': ['chasser.VT'],\n",
        " 'chasser': ['chasser.VT'],\n",
        " 'chasseur': ['chasseur.C'],\n",
        " 'chasseurs': ['chasseur.C'],\n",
        " 'chat': ['chat.D'],\n",
        " 'chats': ['chat.D'],\n",
        " 'chatte': ['chat.D'],\n",
        " 'chattes': ['chat.D'],\n",
        " 'coussin': ['coussin.B'],\n",
        " 'coussins': ['coussin.B'],\n",
        " 'coyote': ['coyote.C'],\n",
        " 'coyotes': ['coyote.C'],\n",
        " 'cuisine': ['cuisine.D'],\n",
        " 'cuisines': ['cuisine.D'],\n",
        " 'd': ['de'],\n",
        " 'dans': ['dans'],\n",
        " 'de': ['de'],\n",
        " 'des': ['IND'],\n",
        " 'devant': ['devant'],\n",
        " 'donnaient': ['donner.VD'],\n",
        " 'donnait': ['donner.VD'],\n",
        " 'donne': ['donner.VD'],\n",
        " 'donnent': ['donner.VD'],\n",
        " 'donner': ['donner.VD'],\n",
        " 'dormaient': ['dormir.VI'],\n",
        " 'dormait': ['dormir.VI'],\n",
        " 'dorment': ['dormir.VI'],\n",
        " 'dormir': ['dormir.VI'],\n",
        " 'dort': ['dormir.VI'],\n",
        " 'entraient': ['entrer.VI'],\n",
        " 'entrait': ['entrer.VI'],\n",
        " 'entre': ['entrer.VI'],\n",
        " 'entrent': ['entrer.VI'],\n",
        " 'entrer': ['entrer.VI'],\n",
        " 'fille': ['fille.C'],\n",
        " 'filles': ['fille.C'],\n",
        " 'fruit': ['fruit.A'],\n",
        " 'fruits': ['fruit.A'],\n",
        " 'gar\\xc3\\xa7on': ['gar\\xc3\\xa7on.D'],\n",
        " 'gar\\xc3\\xa7ons': ['gar\\xc3\\xa7on.D'],\n",
        " 'grand': ['grand.1'],\n",
        " 'grande': ['grand.1'],\n",
        " 'grandes': ['grand.1'],\n",
        " 'grands': ['grand.1'],\n",
        " 'gros': ['gros.2'],\n",
        " 'grosse': ['gros.2'],\n",
        " 'grosses': ['gros.2'],\n",
        " 'infirmi\\xc3\\xa8re': ['infirmi\\xc3\\xa8re.A'],\n",
        " 'infirmi\\xc3\\xa8res': ['infirmi\\xc3\\xa8re.A'],\n",
        " 'jaune': ['jaune.2'],\n",
        " 'jaunes': ['jaune.2'],\n",
        " 'l': ['DEF'],\n",
        " 'la': ['DEF'],\n",
        " 'lance': ['lancer.VD'],\n",
        " 'lancent': ['lancer.VD'],\n",
        " 'lancer': ['lancer.VD'],\n",
        " 'lan\\xc3\\xa7aient': ['lancer.VD'],\n",
        " 'lan\\xc3\\xa7ait': ['lancer.VD'],\n",
        " 'le': ['DEF'],\n",
        " 'les': ['DEF'],\n",
        " 'lit': ['lit.D'],\n",
        " 'lits': ['lit.D'],\n",
        " 'maigre': ['maigre.2'],\n",
        " 'maigres': ['maigre.2'],\n",
        " 'maison': ['maison.D'],\n",
        " 'maisons': ['maison.D'],\n",
        " 'mange': ['manger.VT'],\n",
        " 'mangeaient': ['manger.VT'],\n",
        " 'mangeait': ['manger.VT'],\n",
        " 'mangent': ['manger.VT'],\n",
        " 'manger': ['manger.VT'],\n",
        " 'montraient': ['montrer.VD'],\n",
        " 'montrait': ['montrer.VD'],\n",
        " 'montre': ['montrer.VD'],\n",
        " 'montrent': ['montrer.VD'],\n",
        " 'montrer': ['montrer.VD'],\n",
        " 'noir': ['noir.1'],\n",
        " 'noire': ['noir.1'],\n",
        " 'noires': ['noir.1'],\n",
        " 'noirs': ['noir.1'],\n",
        " 'oeuf': ['oeuf.C'],\n",
        " 'oeufs': ['oeuf.C'],\n",
        " 'offraient': ['offrir.VD'],\n",
        " 'offrait': ['offrir.VD'],\n",
        " 'offre': ['offrir.VD'],\n",
        " 'offrent': ['offrir.VD'],\n",
        " 'offrir': ['offrir.VD'],\n",
        " 'petit': ['petit.1'],\n",
        " 'petite': ['petit.1'],\n",
        " 'petites': ['petit.1'],\n",
        " 'petits': ['petit.1'],\n",
        " 'plaine': ['plaine.A'],\n",
        " 'plaines': ['plaine.A'],\n",
        " 'pour': ['pour'],\n",
        " 'quatre': ['quatre.2'],\n",
        " 'rouge': ['rouge.2'],\n",
        " 'rouges': ['rouge.2'],\n",
        " 'souriS': ['souriS.B'],\n",
        " 'souris': ['souriS.B'],\n",
        " 'sous': ['sous'],\n",
        " 'supportaient': ['supporter.VT'],\n",
        " 'supportait': ['supporter.VT'],\n",
        " 'supporte': ['supporter.VT'],\n",
        " 'supportent': ['supporter.VT'],\n",
        " 'supporter': ['supporter.VT'],\n",
        " 'sur': ['sur'],\n",
        " 'table': ['table.D'],\n",
        " 'tables': ['table.D'],\n",
        " 'th\\xc3\\xa9': ['th\\xc3\\xa9.B'],\n",
        " 'th\\xc3\\xa9s': ['th\\xc3\\xa9.B'],\n",
        " 'tombaient': ['tomber.VI'],\n",
        " 'tombait': ['tomber.VI'],\n",
        " 'tombe': ['tomber.VI'],\n",
        " 'tombent': ['tomber.VI'],\n",
        " 'tomber': ['tomber.VI'],\n",
        " 'trois': ['trois.2'],\n",
        " 'un': ['IND'],\n",
        " 'une': ['IND'],\n",
        " 'viande': ['viande.A'],\n",
        " 'viandes': ['viande.A'],\n",
        " 'village': ['village.C'],\n",
        " 'villages': ['village.C'],\n",
        " '\\xc3\\xa0': ['\\xc3\\xa0']}"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if print_phrases:\n",
      "    comment=\"\"\n",
      "else:\n",
      "    comment=\"%\"\n",
      "print comment+\"\\\\begin{exe}\"\n",
      "for line in phrase_file:\n",
      "    phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
      "    #\n",
      "    # Insertion du replace(\"'\",\" \") pour la gestion des articles \u00e9lid\u00e9s en fran\u00e7ais\n",
      "    #\n",
      "    tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").split(\"\\t\")\n",
      "    if not tampon[0].startswith(\"#\"):\n",
      "        verbe=tampon[1].split(\" \")\n",
      "        if debug: print \"verbe :\", verbe\n",
      "        if PFM.lexique.formeLexeme[verbe[0]][0].endswith(\"VI\"):\n",
      "            suj_cas=\"ABS\"\n",
      "        else:\n",
      "            suj_cas=\"ERG\"\n",
      "            obj_cas=\"ABS\"\n",
      "        suj_genre=\"A\"\n",
      "        suj_nombre=\"SG\"\n",
      "        obj_genre=\"A\"\n",
      "        obj_nombre=\"SG\"\n",
      "        sujet=tampon[0].strip().split(\" \")\n",
      "        phrase[syntagmes['Phrase'].index('SUJ')]=faire_gn(sujet,suj_cas)\n",
      "        if debug: print \"sujet :\",phrase[1]\n",
      "# \t\tverbe=tampon[1].split(\" \")\n",
      "# \t\tif debug: print \"verbe :\", verbe\n",
      "        if len(tampon)>=3:\n",
      "            objet=tampon[2].split(\" \")\n",
      "            if debug: print \"objet : \",objet\n",
      "            if objet!=['']: phrase[syntagmes['Phrase'].index('OBJ')]=faire_gn(objet,obj_cas)\n",
      "        if len(tampon)>=4:\n",
      "            indirect=tampon[3].split(\" \")\n",
      "            if debug: print \"indirect : \",indirect\n",
      "            if indirect!=['']: phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect)\n",
      "        #if len(tampon)>=4:\n",
      "        #\tindirect=tampon[3].split(\" \")\n",
      "        #\tif indirect!=['']: phrase[2]=faire_gp(indirect)\n",
      "        if len(tampon)>=5:\n",
      "            ajout=tampon[4].split(\" \")\n",
      "            phrase[syntagmes['Phrase'].index('AJOUT')]=faire_gp(ajout)\n",
      "#\t\tglose=faire_glose(base[verbe[0]],suj_genre,suj_num)\n",
      "#\t\tif debug: print verbe[0],categorie_v[verbe[0]], temps_v[verbe[0]], suj_genre, suj_nombre\n",
      "#\t\tglose=\"\\\\\"+base[verbe[0]]+categorie_v[verbe[0]].capitalize()+temps_v[verbe[0]].capitalize()+suj_genre.capitalize()+suj_nombre.capitalize()\n",
      "#  \t\tif categorie_v[verbe[0]] == \"VI\":\n",
      "#  \t\t\tglose=\"\\\\\"+base[verbe[0]]+categorie_v[verbe[0]].capitalize()+temps_v[verbe[0]].capitalize()+suj_genre.capitalize()+suj_nombre.capitalize()\n",
      "#  \t\telse:\n",
      "        glose=\"\\\\\"+base[verbe[0]]+categorie_v[verbe[0]].capitalize()+temps_v[verbe[0]].capitalize()+abs_genre.capitalize()+abs_nombre.capitalize()\n",
      "        phrase[syntagmes['Phrase'].index('V')]=glose\n",
      "        texte.append(glose)\n",
      "        if print_glose:\n",
      "            print comment+\"\\\\ex\\\\glll\"\n",
      "        else:\n",
      "            print comment+\"\\\\ex\\\\gll\"\n",
      "        print comment,\n",
      "        for mot in phrase:\n",
      "            if mot!=0:\n",
      "                printflat(mot,\"{}\")\n",
      "        print \"\\\\\\\\\"\n",
      "        print comment,\n",
      "        for mot in phrase:\n",
      "            if mot!=0:\n",
      "                printflat(mot,\"P{}\")\n",
      "        print \"\\\\\\\\\"\n",
      "        if print_glose:\n",
      "            print comment,\n",
      "            for mot in phrase:\n",
      "                if mot!=0:\n",
      "                    printflat(mot,\"G{}\")\n",
      "            print \"\\\\\\\\\"\n",
      "        traduction=(line.strip().rstrip('.')).split()\n",
      "        start=1\n",
      "        sys.stdout.write(comment)\n",
      "        for element in traduction:\t\t\t# convertir les S majuscules \u00e0 la finale des mots en minuscules\n",
      "            if element!=\"\":\n",
      "                if start:\n",
      "                    start=0\n",
      "                    element=element.capitalize()\n",
      "                else:\n",
      "                    sys.stdout.write(' ')\n",
      "                caracteres=list(element)\n",
      "                if caracteres[len(caracteres)-1]=='S':\n",
      "                    caracteres[len(caracteres)-1]='s'\n",
      "                sys.stdout.write(\"\".join(caracteres))\n",
      "        sys.stdout.write('.\\r')\n",
      "        if print_coffee and random.randint(1,6)==1:\n",
      "            stain=random.choice([\"A\",\"B\"])\n",
      "            alpha=random.random()/1.5\n",
      "            angle=random.randint(0,360)\n",
      "            xoff=random.randint(-200,0)\n",
      "            sys.stdout.write('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
      "print comment+\"\\\\end{exe}\"\n",
      "    \n",
      "phrase_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\\begin{exe}\n"
       ]
      },
      {
       "ename": "KeyError",
       "evalue": "u'infirmi\\xe8re'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-95-0e905cd83bb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mindirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtampon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"indirect : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mindirect\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msyntagmes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IND'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaire_gp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#if len(tampon)>=4:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#       indirect=tampon[3].split(\" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-81-5bbe876a314c>\u001b[0m in \u001b[0;36mfaire_gp\u001b[0;34m(groupe_prep)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroupe_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mgroupe_nom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroupe_prep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfaire_gn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroupe_nom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"OBL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-94-10fcecd86813>\u001b[0m in \u001b[0;36mfaire_gn\u001b[0;34m(depart, cas)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0mPFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformeLexeme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0;32mprint\u001b[0m \u001b[0mPFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformeLexeme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mnomLexeme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformeLexeme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mcategorie\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexemes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnomLexeme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcategorie\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: u'infirmi\\xe8re'"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#################################################\n",
      "if ('options' in globals() and options.print_cloze) or print_racines:\n",
      "    tableau_racines_n=[]\n",
      "    tableau_racines_v=[]\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RACINES%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tNOMS\"\n",
      "    print\n",
      "    for element in sorted(radical_n.keys()):\n",
      "        tableau_racines_n.append(\"%s & %s & \\\\textipa{%s} & \\\\textipa{%s} \\\\\\\\\" % (element, radical_n[element][2], radical_n[element][0], radical_n[element][1]))\n",
      "    print_tableaux(2,tableau_racines_n,\"\",0,(head_n,tail,\"%\"))\t\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tVERBES\"\t\n",
      "    print\n",
      "    for element in sorted(radical_v.keys()):\n",
      "        tableau_racines_v.append(\"%s & %s & \\\\textipa{%s} \\\\\\\\\" % (element, radical_v[element][1], radical_v[element][0]))\n",
      "    print_tableaux(2,tableau_racines_v,\"\",0,(head_v,tail,\"%\"))\t"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "if ('options' in globals() and options.print_cloze) or print_lexique:\n",
      "    tab=(head,tail,\"\")\n",
      "else:\n",
      "    tab=(head,tail,\"%\")\n",
      "print tab[2]+\"\\\\begin{itemize}\"\n",
      "print tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\"\n",
      "print_tableaux(2,tableaux[\"N\"],texte,21,tab)\n",
      "print tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\"\n",
      "print_tableaux(3,tableaux[\"ADJ\"],texte,4,tab)\n",
      "print tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\"\n",
      "print_tableaux(2,tableaux[\"V\"],texte,35,tab)\n",
      "print tab[2]+\"\\\\item DETERMINANTS\\\\\\\\[-3ex]\"\n",
      "print_tableaux(3,tableaux[\"DET\"],texte,12,tab)\n",
      "print tab[2]+\"\\\\item PREPOSITIONS\\\\\\\\[-3ex]\"\n",
      "print_tableaux(3,tableaux[\"PREP\"],texte,0,tab)\n",
      "print tab[2]+\"\\\\end{itemize}\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "if ('options' in globals() and options.print_cloze) or print_cloze:\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%CLOZE%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tNOMS\"\t\n",
      "    for element in cloze_noms:\n",
      "        print \"% \", element[0].translate(toipa)+\";\"+element[1]\n",
      "    print\n",
      "    print\n",
      "    print\n",
      "    print \"%\t\t\t\t\t\t\t\t\t\tVERBES\"\t\n",
      "    for element in cloze_verbes:\n",
      "        print \"% \", element[0].translate(toipa)+\";\"+element[1]\t\t"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}