{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/16-K5\"\n",
    "serie=repertoire+\"/\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debug=0\n",
    "print_glose=True\n",
    "print_cloze=True\n",
    "print_radicaux=True\n",
    "numeros={'1':'Un','2':'Deux','3':'Trois','4':'Quatre','5':'Cinq'}\n",
    "personnes={'1sg':'UnSg','2sg':'DeuxSg','3sg':'TroisSg','1du':'UnDu','2du':'DeuxDu','3du':'TroisDu','1pl':'UnPl','2pl':'DeuxPl','3pl':'TroisPl'}\n",
    "\n",
    "commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}\\\\grapho{%s}}\"\n",
    "#commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}{\\\\dn %s}}\"\n",
    "#commandGrapho=u\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}{%s}}\"\n",
    "commandPhono=u\"\\\\newcommand{\\\\%sP}{\\\\textipa{%s}}\"\n",
    "commandGlose=u\"\\\\newcommand{\\\\%sG}{\\\\textGlose{%s}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k, DET, IND\n",
       "\t\tk :\n",
       "\t\t\tDET, Nombre=Sg, Cas=Erg:\ttekuk\t\\cacherGloses{Erg-}\\cacherGloses{Sg-}IND\tte-ku-k\tteku\\textRadical{k}\n",
       "\t\t\tDET, Nombre=Sg, Cas=Abs:\tpikuk\t\\cacherGloses{Abs-}\\cacherGloses{Sg-}IND\tpi-ku-k\tpiku\\textRadical{k}\n",
       "\t\t\tDET, Nombre=Sg, Cas=Dat:\tkukna\t\\cacherGloses{Sg-}IND\\cacherGloses{-Dat}\tku-k-na\tku\\textRadical{k}na\n",
       "\t\t\tDET, Nombre=Sg, Cas=Obl:\tkuk\t\\cacherGloses{Sg-}IND\tku-k\tku\\textRadical{k}\n",
       "\t\t\tDET, Nombre=Du, Cas=Erg:\ttekab\t\\cacherGloses{Erg-}IND\\cacherGloses{-Du}\tte-k-ab\tte\\textRadical{k}ab\n",
       "\t\t\tDET, Nombre=Du, Cas=Abs:\tpikab\t\\cacherGloses{Abs-}IND\\cacherGloses{-Du}\tpi-k-ab\tpi\\textRadical{k}ab\n",
       "\t\t\tDET, Nombre=Du, Cas=Dat:\tkabna\tIND\\cacherGloses{-Du}\\cacherGloses{-Dat}\tk-ab-na\t\\textRadical{k}abna\n",
       "\t\t\tDET, Nombre=Du, Cas=Obl:\tkab\tIND\\cacherGloses{-Du}\tk-ab\t\\textRadical{k}ab\n",
       "\t\t\tDET, Nombre=Pl, Cas=Erg:\ttedok\t\\cacherGloses{Erg-}\\cacherGloses{Pl-}IND\tte-do-k\ttedo\\textRadical{k}\n",
       "\t\t\tDET, Nombre=Pl, Cas=Abs:\tpidok\t\\cacherGloses{Abs-}\\cacherGloses{Pl-}IND\tpi-do-k\tpido\\textRadical{k}\n",
       "\t\t\tDET, Nombre=Pl, Cas=Dat:\tdokna\t\\cacherGloses{Pl-}IND\\cacherGloses{-Dat}\tdo-k-na\tdo\\textRadical{k}na\n",
       "\t\t\tDET, Nombre=Pl, Cas=Obl:\tdok\t\\cacherGloses{Pl-}IND\tdo-k\tdo\\textRadical{k}"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFM.lexique.lexemes[u'IND']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "nom_mut=phonology[\"mutations\"]\n",
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention aux correspondances pour les syllabes\n",
    "YAML interprète la clé no comme False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_grapho(graphie):\n",
    "#    chunks=re.findall(r\"([ptkbdgmnNfsSvzjrlyv]?[aeiou]?)|[aeiou]|[ptkbdgmnNfsSvzjrlyv]|[.…,;!?:—–()\\[\\]\\/# \"\"«»<>]\", graphie)\n",
    "#    chunks=re.findall(r\"([ptkbdgmnNfsSvzZjwrlyv]?[aeiou]?|[.…,;!?:—–()\\[\\]\\/#\"\"«»<>]+|.*)\", graphie,re.U)\n",
    "    chunks=re.findall(ur\"\\s+|[ptkbdgmnNfsSvzZjwrlyv]?[aeiou]?\", graphie,re.U)\n",
    "    result=[]\n",
    "#    print chunks\n",
    "    for chunk in chunks:\n",
    "#        print [chunk],syllabes.keys()\n",
    "        if chunk in syllabes.keys():\n",
    "            result.append(syllabes[chunk])\n",
    "        else:\n",
    "            result.append(chunk)\n",
    "    return \"\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_cloze(glose):\n",
    "    if debug: print [glose]\n",
    "    chunks=re.findall(r\"\\\\cacherGloses{([^}]*)?}|(\\w+)\", glose,re.UNICODE)\n",
    "    result=[]\n",
    "    for chunk in chunks:\n",
    "        result.extend([x for x in chunk if x!=\"\"])\n",
    "    return u\"%s;\"%len(result)+\";\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grapho=recoder(\"SviNaNeNNoNN\",translit)\n",
    "#grapho,parse_grapho(grapho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep]\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"]\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "glosePREP={x:u\"%s%s\"%(x.upper(),cacherGloses(\"[\"+casPreposition[x].strip(\"+\").capitalize()+\"]\")) for x in casPreposition if \"+\" in casPreposition[x]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'apr\\xe8s': u'APR\\xc8S\\\\cacherGloses{[Obl]}',\n",
       " 'avec': u'AVEC\\\\cacherGloses{[Obl]}',\n",
       " 'dans': u'DANS\\\\cacherGloses{[Obl]}',\n",
       " 'de': u'DE\\\\cacherGloses{[Obl]}',\n",
       " u'derri\\xe8re': u'DERRI\\xc8RE\\\\cacherGloses{[Obl]}',\n",
       " 'devant': u'DEVANT\\\\cacherGloses{[Obl]}',\n",
       " 'entre': u'ENTRE\\\\cacherGloses{[Obl]}',\n",
       " 'sur': u'SUR\\\\cacherGloses{[Obl]}',\n",
       " 'vers': u'VERS\\\\cacherGloses{[Obl]}',\n",
       " u'\\xe0': u'\\xc0\\\\cacherGloses{[Obl]}'}"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glosePREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%% version : __file__\n",
      "%% traitement : 160708-1835\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False\n",
    "\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "print \"%% version : \"+version\n",
    "print \"%% traitement : \"+time_stamp\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=\"lexemes.txt\"\n",
    "#    phrase_nom=\"phrases.txt\"\n",
    "    pass\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table,boolUTF8=True):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    if boolUTF8:\n",
    "        return result\n",
    "    else:\n",
    "        return result.encode(\"utf8\")\n",
    "#translit=string.maketrans(u'iueoaftgzZvjkSpN',u'tgazpHTGZJVkXyxI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonoIn =  unicode(phonology[\"translations\"][\"grapho\"][\"in\"])\n",
    "graphoIn = [ord(char) for char in phonoIn]\n",
    "graphoOut = unicode(phonology[\"translations\"][\"grapho\"][\"out\"])\n",
    "translit = dict(zip(graphoIn, graphoOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#translit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tableaux={}\n",
    "gloseClozes={}\n",
    "declarations=[]\n",
    "for categorie in PFM.lexique.catLexeme:\n",
    "    if not categorie in tableaux:\n",
    "        tableaux[categorie]=set()\n",
    "        gloseClozes[categorie]=[]\n",
    "    if verbose: print categorie\n",
    "    for lexeme in PFM.lexique.catLexeme[categorie]:\n",
    "        if verbose: print PFM.lexique.lexemes[lexeme]\n",
    "        for case in PFM.lexique.lexemes[lexeme].paradigme.cases:\n",
    "            caseGlose=case.glose\n",
    "            if categorie in PFM.categoriesMajeures:\n",
    "                nom=PFM.lexique.lexemes[lexeme].nom\n",
    "            else:\n",
    "                nom=PFM.lexique.lexemes[lexeme].nom.upper()\n",
    "                gloseCase=case.glose\n",
    "                if categorie==\"PREP\" and gloseCase in glosePREP:\n",
    "                    caseGlose=glosePREP[gloseCase]\n",
    "                elif categorie==\"PREP\":\n",
    "                    caseGlose=caseGlose.upper()\n",
    "#                print caseGlose\n",
    "            ref=PFM.modifierGlose(nom,case.sigma,\"ref\")\n",
    "            ref=recoder(ref,deaccent)\n",
    "            for ligature in deligatures:\n",
    "                ref=ref.replace(ligature,deligatures[ligature])\n",
    "            for pers in personnes:\n",
    "                ref=ref.replace(pers,personnes[pers])\n",
    "            for num in numeros:\n",
    "                ref=ref.replace(num,numeros[num])\n",
    "#            phono=case.forme\n",
    "#            print (\"lexeme\",lexeme)\n",
    "            grapho=chaine2utf8(re.sub(ur\"\\s+\",ur\"\",recoder(parse_grapho(case.forme),translit)))\n",
    "            if print_radicaux:\n",
    "                phono=case.detoure.replace(\" \",\"\")\n",
    "            else:\n",
    "                phono=case.forme.replace(\" \",\"\")\n",
    "#            print [ref,grapho]\n",
    "            declarations.append(commandGrapho%(ref,grapho))\n",
    "            declarations.append(commandPhono%(ref,phono))\n",
    "            declarations.append(commandGlose%(ref,caseGlose))\n",
    "            if print_glose:\n",
    "                tableaux[categorie].add(\"\\\\\"+ref+\" & \\\\\"+ref+\"P & \\\\\"+ref+\"G \\\\\\\\\")\n",
    "            else:\n",
    "                tableaux[categorie].add(\"\\\\\"+ref+\" & \\\\\"+ref+\"P & \\\\blanc{\\\\\"+ref+\"G} \\\\\\\\\")\n",
    "            if print_cloze:\n",
    "                vedette=nom.split(\".\")[0]\n",
    "                gloses=parse_cloze(case.glose)\n",
    "                if debug: print [grapho, recoder(phono,toipa)]\n",
    "                try:\n",
    "                    cloze=u\";\".join([ref,vedette,categorie,recoder(phono,toipa),recoder(case.decoupe,toipa),case.sigma,gloses])\n",
    "                except NameError:\n",
    "                    cloze=u\";\".join([ref,vedette,categorie,recoder(phono,toipa),gloses])\n",
    "                gloseClozes[categorie].append(cloze)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if print_radicaux:\n",
    "    nomDeclaration=\"Declarations-Radicaux.tex\"\n",
    "    nomTableaux=\"Tableaux-Radicaux.yaml\"\n",
    "else:\n",
    "    nomDeclaration=\"Declarations.tex\"\n",
    "    nomTableaux=\"Tableaux.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(serie+nomDeclaration, 'wb', encoding='utf8') as output:\n",
    "    for declaration in declarations:\n",
    "#        print type(declaration),declaration\n",
    "        output.write(declaration+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not print_radicaux:\n",
    "    with codecs.open(serie+\"Clozes.txt\", 'wb', encoding='utf8') as output:\n",
    "        for categorie in gloseClozes:\n",
    "            output.write(\"#\\t\"+categorie+\"\\n#\\n#\\n\")\n",
    "            for cloze in gloseClozes[categorie]:\n",
    "                output.write(cloze+\"\\n\")\n",
    "            output.write(\"#\\n#\\n#\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yaml.safe_dump(tableaux, file(serie+nomTableaux, 'w'), encoding='utf-8', allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gloseClozes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#declarations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
