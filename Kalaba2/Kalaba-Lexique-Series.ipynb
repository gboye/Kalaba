{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "#########################IMPORTS############################################\n",
    "from os.path import expanduser\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, YamlDuplicates\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/17-K1/\n",
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/17-K2/\n",
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/17-K3/\n",
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/17-K4/\n",
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/17-K5/\n"
     ]
    }
   ],
   "source": [
    "home = expanduser(\"~\")\n",
    "repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/\"\n",
    "annee=\"17\"\n",
    "numerosKalabas=[1,2,3,4,5]\n",
    "#numerosKalabas=[3]\n",
    "nomKalabas=[repertoire+annee+\"-K%d/\"%num for num in numerosKalabas]\n",
    "\n",
    "#nomKalabas=[home+\"/Dropbox/Partage-Broadway/GAM/Caches/NosCaches/Kalabas/K2-Kalaba0304/\"]\n",
    "\n",
    "print \"\\n\".join(nomKalabas)\n",
    "\n",
    "lexiqueTestPrep=u\"dans\"\n",
    "lexiqueTestNoun=u\"loups\"\n",
    "lexiqueTestHyper=u\"villagEOIs\"\n",
    "\n",
    "nomDeclarationRad=\"Declarations-Radicaux.tex\"\n",
    "nomTableauxRad=\"Tableaux-Gloses.yaml\"\n",
    "nomDeclaration=\"Declarations.tex\"\n",
    "nomTableaux=\"Tableaux.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalaba-Lexique-Series\n"
     ]
    }
   ],
   "source": [
    "print(theNotebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug=0\n",
    "print_glose=True\n",
    "print_cloze=True\n",
    "print_radicaux=False\n",
    "cloze_expanded=True\n",
    "numeros={'1':'Un','2':'Deux','3':'Trois','4':'Quatre','5':'Cinq'}\n",
    "personnes={'1sg':'UnSg','2sg':'DeuxSg','3sg':'TroisSg','1du':'UnDu','2du':'DeuxDu','3du':'TroisDu','1pl':'UnPl','2pl':'DeuxPl','3pl':'TroisPl'}\n",
    "\n",
    "commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{%s}}\"\n",
    "#commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}{\\\\dn %s}}\"\n",
    "#commandGrapho=u\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}{%s}}\"\n",
    "commandPhono=u\"\\\\newcommand{\\\\%sP}{\\\\textipa{%s}}\"\n",
    "commandGlose=u\"\\\\newcommand{\\\\%sG}{\\\\textGlose{%s}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_grapho(graphie):\n",
    "    def change_bigrams(chaine):\n",
    "        result=\"\"\n",
    "        for monogramme in chaine:\n",
    "            if monogramme in bigrammes:\n",
    "                result+=bigrammes[monogramme]\n",
    "            else:\n",
    "                result+=monogramme\n",
    "        return result\n",
    "    \n",
    "    chunks=re.findall(ur\"\\s+|[ptkqbdgmnNfTsSvDzZjwRrlLyv]?[aeiouAEIUO]?\", graphie,re.U)\n",
    "    result=[]\n",
    "    if debug: print graphie\n",
    "    for chunk in chunks:\n",
    "        if debug: print chunk,\n",
    "        #ATTENTION : YAML interprète \"no\" comme FALSE\n",
    "        if chunk in syllabes.keys():\n",
    "            result.append(syllabes[chunk])\n",
    "        else:\n",
    "            result.append(chunk)\n",
    "    if debug: print\n",
    "    return change_bigrams(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_cloze(glose):\n",
    "    if debug: print [glose]\n",
    "    chunks=re.findall(r\"\\\\cacherGloses{([^}]*)?}|(\\w+)\", glose,re.UNICODE)\n",
    "    result=[]\n",
    "    for chunk in chunks:\n",
    "        result.extend([x for x in chunk if x!=\"\"])\n",
    "    return (u\"%s;\"%len(result)+\";\".join(result),\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table,boolUTF8=True):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    if boolUTF8:\n",
    "        return result\n",
    "    else:\n",
    "        return result.encode(\"utf8\")\n",
    "#translit=string.maketrans(u'iueoaftgzZvjkSpN',u'tgazpHTGZJVkXyxI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération lexique : 17-K1 07:02:53\n",
      "Génération lexique : 17-K2 07:02:54\n",
      "Génération lexique : 17-K3 07:02:56\n",
      "Génération lexique : 17-K4 07:03:04\n",
      "Génération lexique : 17-K5 07:03:07\n",
      "Génération terminée : 07:03:09\n"
     ]
    }
   ],
   "source": [
    "for serie in nomKalabas:\n",
    "    print \"Génération lexique :\",serie.split(\"/\")[-2], time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "    '''\n",
    "    Lecture des fichiers de paramètres\n",
    "     1) Phonology.yaml pour \n",
    "         - les voyelles, les consonnes\n",
    "         - la correspondance pour l'écrit (symbole => lettre, syllabe => lettres)\n",
    "         - la correspondance pour l'oral\n",
    "         - la désaccentuation et les déligatures du français\n",
    "         - les gabarits ?\n",
    "         - l'apophonie, les mutations consonantiques\n",
    "     2) Stems.yaml pour\n",
    "         - les catégories et les classes\n",
    "         - les radicaux et les formes correspondantes\n",
    "             - la première forme sert de forme de citation\n",
    "     3) MorphoSyntax.yaml pour\n",
    "         - définition de la valeur des formes verbales du français\n",
    "         - définition des attributs de chaque catégorie\n",
    "         - valeur par défaut pour chaque attribut\n",
    "         - définition des cas pour SUJ, OBJ, IND et PREP\n",
    "         - .../...\n",
    "         - définition des constituants et de l'ordre dans les syntagmes\n",
    "         - définition des contractions du français (du => de le, etc.)\n",
    "    '''\n",
    "    with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "        phonology=yaml.load(stream)\n",
    "    with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "        stems=yaml.load(stream)\n",
    "    with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "        morphosyntax=yaml.load(stream)\n",
    "        \n",
    "    '''\n",
    "    Récupération des données du ParFuMor\n",
    "    '''\n",
    "    with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "       PFM.hierarchieCF = pickle.load(input)\n",
    "    with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "       PFM.lexique = pickle.load(input)\n",
    "    with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "       PFM.regles = pickle.load(input)\n",
    "\n",
    "    if debug: print PFM.lexique.lexemes[lexiqueTestPrep]\n",
    "\n",
    "    consonnes=phonology[\"consonnes\"]\n",
    "    voyelles=phonology[\"voyelles\"]\n",
    "    gabarits=phonology[\"gabarits\"]\n",
    "    derives=phonology[\"derives\"]\n",
    "    nom_classe=phonology[\"nom_classe\"]\n",
    "    nom_apo=phonology[\"apophonies\"]\n",
    "    nom_mut=phonology[\"mutations\"]\n",
    "    syllabes=phonology[\"syllabes\"]\n",
    "\n",
    "    if \"Cas\" in morphosyntax:\n",
    "        casSyntagmes=morphosyntax[\"Cas\"]\n",
    "    else:\n",
    "        casSyntagmes=\"\"\n",
    "    lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "    casPreposition={}\n",
    "    for preposition in lexiquePrepositions:\n",
    "        prep=preposition.upper()\n",
    "        if casSyntagmes and prep in casSyntagmes:\n",
    "            casPreposition[preposition]=casSyntagmes[prep]\n",
    "        elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "            casPreposition[preposition]=casSyntagmes[\"PREP\"]\n",
    "        else:\n",
    "            casPreposition[preposition]=\"\"\n",
    "    glosePREP={x:u\"%s%s\"%(x.upper(),cacherGloses(\"[\"+casPreposition[x].strip(\"+\").capitalize()+\"]\")) for x in casPreposition if \"+\" in casPreposition[x]}\n",
    "\n",
    "    try:\n",
    "        __IPYTHON__ \n",
    "        ipython=True\n",
    "    except: \n",
    "        ipython=False\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Constitution d'un entête pour les fichiers TEX en sortie\n",
    "        - nom du script\n",
    "        - date du run\n",
    "    '''\n",
    "    texHeader=[]\n",
    "    version=theNotebook\n",
    "    texHeader.append(\"%% script : \"+version)\n",
    "    texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "    if debug: print \"\\n\".join(texHeader)\n",
    "    \n",
    "    if ipython or True:\n",
    "    #    lexeme_nom=\"lexemes.txt\"\n",
    "    #    phrase_nom=\"phrases.txt\"\n",
    "        pass\n",
    "    else:\n",
    "        parser=optparse.OptionParser()\n",
    "        parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "        parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "        parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "        parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "        (options, args) = parser.parse_args()\n",
    "        lexeme_nom=args[0]\n",
    "        phrase_nom=args[1]\n",
    "\n",
    "    phonoIn =  unicode(phonology[\"translations\"][\"grapho\"][\"in\"])\n",
    "    graphoIn = [ord(char) for char in phonoIn]\n",
    "    graphoOut = unicode(phonology[\"translations\"][\"grapho\"][\"out\"])\n",
    "    translit = dict(zip(graphoIn, graphoOut))\n",
    "    bigrammes = phonology[\"translations\"][\"bigrammes\"]\n",
    "\n",
    "    accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "    deaccentIn = [ord(char) for char in accentedIn]\n",
    "    deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "    deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "    deligatures=phonology[\"translations\"][\"deligatures\"]\n",
    "\n",
    "    tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "    ipaIn = [ord(char) for char in tipaIn]\n",
    "    ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "    toipa = dict(zip(ipaIn, ipaOut))\n",
    "\n",
    "    tableaux={}\n",
    "    tableauxGloses={}\n",
    "    gloseClozes={}\n",
    "    declarations=[]\n",
    "    declarationsRad=[]\n",
    "    \n",
    "    '''\n",
    "    Pour chaque catégorie\n",
    "    '''\n",
    "    for categorie in PFM.lexique.catLexeme:\n",
    "        '''\n",
    "        si la catégorie n'est pas dans le tableau, il faut l'ajouter dans les trois structures :\n",
    "            tableaux : les lignes à ajouter à la fin du document LaTeX sans les gloses\n",
    "            tableauxGloses : les lignes à ajouter à la fin du document LaTeX avec les gloses\n",
    "            gloseClozes : les informations sur les mots pour les questions CLOZE \n",
    "        '''\n",
    "        if not categorie in tableaux:\n",
    "            tableaux[categorie]=set()\n",
    "            tableauxGloses[categorie]=set()\n",
    "            gloseClozes[categorie]=[]\n",
    "        if verbose: print categorie\n",
    "        '''\n",
    "        pour chaque lexème de la catégorie\n",
    "        '''\n",
    "        for lexeme in PFM.lexique.catLexeme[categorie]:\n",
    "            if verbose: print PFM.lexique.lexemes[lexeme]\n",
    "            '''\n",
    "            pour chaque case du paradigme du lexème\n",
    "            '''\n",
    "            for case in PFM.lexique.lexemes[lexeme].paradigme.cases:\n",
    "                caseGlose=case.glose\n",
    "                '''\n",
    "                Les éléments des catégories majeures (N,V,Adj) sont représentés en minuscules\n",
    "                    => les noms propres commencent par une capitale\n",
    "                Les éléments grammaticaux sont représentés en majuscules\n",
    "                '''\n",
    "                if categorie in PFM.categoriesMajeures:\n",
    "                    nom=PFM.lexique.lexemes[lexeme].nom\n",
    "                else:\n",
    "                    nom=PFM.lexique.lexemes[lexeme].nom.upper()\n",
    "                    gloseCase=case.glose\n",
    "                    if categorie==\"PREP\" and gloseCase in glosePREP:\n",
    "                        caseGlose=glosePREP[gloseCase]\n",
    "                    elif categorie==\"PREP\":\n",
    "                        caseGlose=caseGlose.upper()\n",
    "                ref=PFM.modifierGlose(nom,case.sigma,\"ref\")\n",
    "                ref=recoder(ref,deaccent)\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                Dealing with LaTeX names format for commands\n",
    "                \n",
    "                 1) no ligatures\n",
    "                 2) no numbers\n",
    "                '''\n",
    "                \n",
    "                for ligature in deligatures:\n",
    "                    ref=ref.replace(ligature,deligatures[ligature])\n",
    "                for pers in personnes:\n",
    "                    ref=ref.replace(pers,personnes[pers])\n",
    "                for num in numeros:\n",
    "                    ref=ref.replace(num,numeros[num])\n",
    "                    \n",
    "                grapho=chaine2utf8(re.sub(ur\"\\s+\",ur\"\",parse_grapho(recoder(case.forme,translit))))\n",
    "                phonoRad=case.detoure.replace(\" \",\"\")\n",
    "                phono=case.forme.replace(\" \",\"\")\n",
    "\n",
    "                '''\n",
    "                Creating the DECLARATIONS TEX contents\n",
    "                '''\n",
    "                \n",
    "                declarations.append(commandGrapho%(ref,grapho))\n",
    "                declarations.append(commandPhono%(ref,phono))\n",
    "                declarations.append(commandGlose%(ref,caseGlose))\n",
    "                declarationsRad.append(commandGrapho%(ref,grapho))\n",
    "                declarationsRad.append(commandPhono%(ref,phonoRad))\n",
    "                declarationsRad.append(commandGlose%(ref,caseGlose))\n",
    "                \n",
    "                '''\n",
    "                Creating the TABLEAUX TEX contents\n",
    "                '''\n",
    "                \n",
    "                tableauxGloses[categorie].add(\"\\\\\"+ref+\" & \\\\\"+ref+\"P & \\\\\"+ref+\"G \\\\\\\\\")\n",
    "                tableaux[categorie].add(\"\\\\\"+ref+\" & \\\\\"+ref+\"P & \\\\blanc{\\\\\"+ref+\"G} \\\\\\\\\")\n",
    "                \n",
    "                '''\n",
    "                Creating the CLOZE CSV contents\n",
    "                '''\n",
    "                \n",
    "                vedette=nom.split(\".\")[0]\n",
    "                gloses,strGlose=parse_cloze(case.glose)\n",
    "#                print gloses,case.decoupe,case.detoure\n",
    "                phono=case.forme.replace(\" \",\"\")\n",
    "                if debug: print [grapho, recoder(phono,toipa)]\n",
    "                if cloze_expanded:\n",
    "                    try:\n",
    "                        cloze=u\";\".join([ref,vedette,\n",
    "                                         categorie,\n",
    "                                         recoder(case.radical,toipa),recoder(case.racine,toipa),\n",
    "                                         recoder(phono,toipa),recoder(case.decoupe,toipa),\n",
    "                                         case.sigma,\n",
    "                                         strGlose,\n",
    "                                         gloses])\n",
    "                    except NameError:\n",
    "                        cloze=u\";\".join([ref,vedette,\n",
    "                                         categorie,\n",
    "                                         recoder(case.radical,toipa),recoder(case.racine,toipa),\n",
    "                                         recoder(phono,toipa),\n",
    "                                         strGlose,\n",
    "                                         gloses])\n",
    "                else:\n",
    "                    try:\n",
    "                        cloze=u\";\".join([ref,vedette,categorie,recoder(phono,toipa),recoder(case.decoupe,toipa),case.sigma,gloses])\n",
    "                    except NameError:\n",
    "                        cloze=u\";\".join([ref,vedette,categorie,recoder(phono,toipa),gloses])\n",
    "                gloseClozes[categorie].append(cloze)\n",
    "\n",
    "        '''\n",
    "        Écriture des fichiers en sortie\n",
    "         1) déclarations sans les radicaux\n",
    "         2) déclarations avec les radicaux\n",
    "         3) données pour les questions CLOZE\n",
    "         4) tableaux de vocabulaire avec gloses\n",
    "         5) tableaux de vocabulaire sans gloses\n",
    "        '''\n",
    "        with codecs.open(serie+nomDeclaration, 'wb', encoding='utf8') as output:\n",
    "            for declaration in texHeader+declarations:\n",
    "        #        print type(declaration),declaration\n",
    "                output.write(declaration+\"\\n\")\n",
    "\n",
    "        with codecs.open(serie+nomDeclarationRad, 'wb', encoding='utf8') as output:\n",
    "            for declaration in texHeader+declarationsRad:\n",
    "        #        print type(declaration),declaration\n",
    "                output.write(declaration+\"\\n\")\n",
    "\n",
    "        with codecs.open(serie+\"Clozes.txt\", 'wb', encoding='utf8') as output:\n",
    "            for categorie in gloseClozes:\n",
    "                output.write(\"#\\t\"+categorie+\"\\n#\\n#\\n\")\n",
    "                for cloze in gloseClozes[categorie]:\n",
    "                    output.write(cloze+\"\\n\")\n",
    "                output.write(\"#\\n#\\n#\\n\")\n",
    "\n",
    "        yaml.safe_dump(tableauxGloses, file(serie+nomTableauxRad, 'w'), encoding='utf-8', allow_unicode=True)\n",
    "        yaml.safe_dump(tableaux, file(serie+nomTableaux, 'w'), encoding='utf-8', allow_unicode=True)\n",
    "\n",
    "print u\"Génération terminée :\", time.strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': '.d',\n",
       " 'N': 'h',\n",
       " 'S': '.s',\n",
       " 'T': '.t',\n",
       " 'Z': '.g',\n",
       " 'ii': 'I',\n",
       " 'iu': 'Iyu',\n",
       " 'ui': 'Uwi',\n",
       " 'uu': 'U'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\\\newcommand{\\\\passerViPrsTroisSgA}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttUp}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgAP}{\\\\textipa{fefaTiddeb}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgAG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.A}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgB}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttip}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgBP}{\\\\textipa{fefaTiddub}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgBG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.B}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgC}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttap}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgCP}{\\\\textipa{fefaTiddab}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgCG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.C}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgD}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttUp}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgDP}{\\\\textipa{fefaTiddeb}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisSgDG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.D}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuA}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttU}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuAP}{\\\\textipa{fefaTidde}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuAG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.A}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuB}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.dutti}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuBP}{\\\\textipa{fefaTiddu}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuBG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.B}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuC}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.dutta}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuCP}{\\\\textipa{fefaTidda}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuCG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.C}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuD}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttU}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuDP}{\\\\textipa{fefaTidde}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisDuDG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.D}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlA}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttUf}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlAP}{\\\\textipa{fefaTiddeZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlAG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.A}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlB}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttif}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlBP}{\\\\textipa{fefaTidduZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlBG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.B}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlC}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttaf}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlCP}{\\\\textipa{fefaTiddaZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlCG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.C}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlD}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{vUva.duttUf}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlDP}{\\\\textipa{fefaTiddeZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPrsTroisPlDG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xV2.PRS}\\\\cacherGloses{-V2.D}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgA}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datUp}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgAP}{\\\\textipa{gefaTadeb}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgAG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.A}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgB}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datip}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgBP}{\\\\textipa{gefaTadub}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgBG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.B}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgC}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datap}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgCP}{\\\\textipa{gefaTadab}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgCG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.C}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgD}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datUp}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgDP}{\\\\textipa{gefaTadeb}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisSgDG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.D}\\\\cacherGloses{-V2.3Sg}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuA}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datU}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuAP}{\\\\textipa{gefaTade}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuAG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.A}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuB}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.dati}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuBP}{\\\\textipa{gefaTadu}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuBG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.B}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuC}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.data}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuCP}{\\\\textipa{gefaTada}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuCG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.C}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuD}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datU}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuDP}{\\\\textipa{gefaTade}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisDuDG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.D}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlA}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datUf}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlAP}{\\\\textipa{gefaTadeZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlAG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.A}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlB}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datif}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlBP}{\\\\textipa{gefaTaduZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlBG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.B}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlC}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.dataf}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlCP}{\\\\textipa{gefaTadaZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlCG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.C}\\\\cacherGloses{-V2.3Pl}}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlD}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{kUva.datUf}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlDP}{\\\\textipa{gefaTadeZ}}',\n",
       " u'\\\\newcommand{\\\\passerViPstTroisPlDG}{\\\\textGlose{passer\\\\cacherGloses{.VI.V2}\\\\cacherGloses{xPST}\\\\cacherGloses{-V2.D}\\\\cacherGloses{-V2.3Pl}}}']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l for l in declarations if \"passer\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse .tofutfi\n",
      "parse, recoder .dIvidvu\n",
      "recoder DIvidvu\n",
      "recoder, parse .dIvidvu\n",
      ".d.tdt\n"
     ]
    }
   ],
   "source": [
    "chaine=\"Tofutfi\"\n",
    "print \"parse\", parse_grapho(chaine)\n",
    "print \"parse, recoder\",recoder(parse_grapho(chaine),translit)\n",
    "print \"recoder\", recoder(chaine,translit)\n",
    "print \"recoder, parse\",parse_grapho(recoder(chaine,translit))\n",
    "print parse_grapho(\"DTdt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
