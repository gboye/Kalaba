{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "repertoire=home+\"/Copy/Cours/Bordeaux/L1-UE1/Kalaba-15/02-PseudoLatin\"\n",
    "serie=repertoire+\"/\"\n",
    "variante=\"\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=1\n",
    "print_no=False\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_phrases=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False\n",
    "print_lexique=False\n",
    "print_cloze=False\n",
    "print_racines=False\n",
    "no_form=\"***\"\n",
    "# no_grapho=['dormir', 'lit']\n",
    "# no_phono=['gros', 'coussin']\n",
    "no_grapho=['petit','Nabil',\"sur\"]\n",
    "no_phono=[\"grand\",\"autruche\",'dans']\n",
    "phono_no=u\"XXXXX\"\n",
    "grapho_no=u\"XXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        \"Graphie & Prononciation & Glose \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.load(stream)\n",
    "with open(serie+\"Tableaux.yaml\", 'r') as stream:\n",
    "    tableaux=yaml.load(stream)\n",
    "with open(serie+\"Hierarchie.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\xe0', 'devant', 'avec', 'de', 'pour', 'sous', 'sur', 'dans']"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\\\\\\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}\n",
    "\n",
    "#types=gloses[\"V\"][\"CF\"]\n",
    "casSyntagmes=morphosyntax[\"Cas\"]\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep]\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"]\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"V\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#casSyntagmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element.encode(\"utf8\"))\n",
    "        else:\n",
    "            temp.append(element)\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def taches():\n",
    "    seuil=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<7:\n",
    "            return \"\"\n",
    "        elif n<=seuil:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_tableaux(cols,tableau,texte=\"\",debut=0,tab=(head,tail,\"\")):\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "    if texte!=\"\":\n",
    "        (table,reste)=filtrer_tableau(tableau,texte)\n",
    "    else:\n",
    "        table=tableau\n",
    "        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip()\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<48:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=48\n",
    "        reste=table[48*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        if elements[0] in filtre: \n",
    "            presents.append(line)\n",
    "        else:\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_gn(depart,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom=[]\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    reste=0\n",
    "    for mot in groupe_nom:\n",
    "        if reste==0:\n",
    "#            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "            if mot==\"deux\" and \"Du\" in valAttribut[\"Nombre\"]:\n",
    "                nombre=\"DU\"\n",
    "                if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "            else:\n",
    "                nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                if debug: \n",
    "                    print \"mot\",[mot]\n",
    "                    print \"vedette\",PFM.lexique.formeLexeme[mot][0],categorie\n",
    "                    print \"categories\",PFM.hierarchieCF.classes[\"N\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                if PFM.hierarchieCF.getCategory(categorie)==\"N\":\n",
    "                    tete=categorie\n",
    "                    if debug: print \"tête :\", tete\n",
    "                    tampon=tete.split('.')\n",
    "                    classe=tampon[0]\n",
    "                    try:\n",
    "                        typeMot=tampon[1]\n",
    "                    except IndexError:\n",
    "                        typeMot=''\n",
    "                    if mot[len(mot)-1]=='s':\n",
    "                        if nombre==\"\": nombre=\"PL\"\n",
    "                    else:\n",
    "                        if nombre==\"\": nombre=\"SG\"\n",
    "                    nom.append(PFM.lexique.formeLexeme[mot][0])\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "                    if not boolAttribut[\"N\"][\"Cas\"]:\n",
    "                        cas=\"\"\n",
    "#                    else:\n",
    "                    cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                    if cas==\"ERG\":\n",
    "                        erg_genre=classe\n",
    "                        erg_nombre=nombre\n",
    "                        if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                    elif cas==\"ABS\":\n",
    "                        abs_genre=classe\n",
    "                        abs_nombre=nombre\n",
    "                        if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                elif categorie in [\"DET\"]:\n",
    "                    det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                elif categorie in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                    gp.append(mot)\n",
    "                    reste=1\n",
    "        else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "            gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det: det.append(\"IND\")\n",
    "    tempSyntagme=[]\n",
    "    for mot in det:\n",
    "        if not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent).upper()+classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "#        mots.append(ref)\n",
    "#        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),\" \".join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        if not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "        ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent).lower()+classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "#        mots.append(ref)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        if mot.istitle():\n",
    "            ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(mot.split(\".\")[0],deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"N\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"N\"),structureSyntagme[\"N\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    return listeMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", groupe_prep\n",
    "    preposition=groupe_prep[0]\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not boolAttribut[\"N\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "        if casPreposition and preposition in casPreposition:\n",
    "            cas=casPreposition[preposition]\n",
    "            ref=\"\\\\\"+recoder(groupe_prep[0],deaccent).upper()\n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            cas=\"\"\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print ref\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),faire_gn(groupe_nom,cas))\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        mots.append(faire_gn(groupe_nom,cas))\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else: \n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%% version : __file__\n",
      "%% traitement : 150922-1504\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "print \"%% version : \"+version\n",
    "print \"%% traitement : \"+time_stamp\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+variante+\"Phrases.csv\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Ouverture du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    phrase_file = codecs.open(phrase_nom,\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                               \n"
     ]
    }
   ],
   "source": [
    "if print_phrases:\n",
    "    comment=\"\"\n",
    "else:\n",
    "    comment=\"%\"\n",
    "ajouterExemple(comment+\"\\\\begin{exe}\")\n",
    "for line in phrase_file:\n",
    "    phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "    tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").split(\"\\t\")\n",
    "#    print tampon[0],type(tampon[0])\n",
    "    if not tampon[0].startswith(\"#\"):\n",
    "        verbe=tampon[1].split(\" \")\n",
    "        verbeForme=verbe[0]\n",
    "        if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "            print \"FORME AMBIGUË\"\n",
    "        verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "        temp=verbeLexeme.split(\".\")\n",
    "        formeCitation=temp[0]\n",
    "        typeVerbe=temp[1]\n",
    "#        print verbeLexeme, formeCitation,typeVerbe\n",
    "        verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "        verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "        if debug: print \"verbe :\", verbe\n",
    "#        if verbeLexeme.endswith(\"VI\"):\n",
    "        if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "            if \".VI\" in verbeLexeme:            \n",
    "                suj_cas=\"Abs\"\n",
    "            else:\n",
    "                suj_cas=\"Erg\"\n",
    "                obj_cas=\"Erg\"\n",
    "        elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "            suj_cas=casSyntagmes[\"SUJ\"]\n",
    "            obj_cas=casSyntagmes[\"OBJ\"]\n",
    "        else:\n",
    "            suj_cas=\"\"\n",
    "            obj_cas=\"\"\n",
    "        suj_genre=valAttribut[\"Genre\"][0]\n",
    "        suj_nombre=valAttribut[\"Nombre\"][0]\n",
    "        obj_genre=valAttribut[\"Genre\"][0]\n",
    "        obj_nombre=valAttribut[\"Nombre\"][0]\n",
    "        abs_genre=valAttribut[\"Genre\"][0]\n",
    "        abs_nombre=valAttribut[\"Nombre\"][0]\n",
    "        sujet=tampon[0].strip().split(\" \")\n",
    "        phrase[syntagmes['Phrase'].index('SUJ')]=faire_gn(sujet,suj_cas)\n",
    "        if debug: print \"sujet :\",phrase[1]\n",
    "        if len(tampon)>=3:\n",
    "            objet=tampon[2].split(\" \")\n",
    "            if debug: print \"objet : \",objet\n",
    "            if objet!=['']: phrase[syntagmes['Phrase'].index('OBJ')]=faire_gn(objet,obj_cas)\n",
    "        if len(tampon)>=4:\n",
    "            indirect=tampon[3].split(\" \")\n",
    "            if debug: print \"indirect : \",indirect\n",
    "            if indirect!=['']: phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "        if len(tampon)>=5:\n",
    "            comp=tampon[4].split(\" \")\n",
    "            if comp!=['']:\n",
    "                phrase[syntagmes['Phrase'].index('COMP')]=faire_gp(comp)\n",
    "        if len(tampon)>=6:\n",
    "            ajout=tampon[5].split(\" \")\n",
    "            phrase[syntagmes['Phrase'].index('AJOUT')]=faire_gp(ajout)\n",
    "#        if typeCas==\"NoCas\":\n",
    "        if not boolAttribut[\"N\"][\"Cas\"] or suj_cas==\"Nom\":\n",
    "            glose=\"\\\\\"+recoder(formeCitation,deaccent)+morphosyntax[\"V\"][\"FormesBase\"][verbeFormeIndex].capitalize()+morphosyntax[\"V\"][\"FormesPers\"][verbeFormeIndex] \n",
    "        else:\n",
    "            glose=\"\\\\\"+recoder(formeCitation,deaccent)+morphosyntax[\"V\"][\"FormesBase\"][verbeFormeIndex].capitalize()+abs_genre.capitalize()+\"Trois\"+abs_nombre.capitalize()\n",
    "        phrase[syntagmes['Phrase'].index('V')]=glose\n",
    "        texte.append(glose)\n",
    "        if print_glose:\n",
    "            ajouterExemple(comment+\"\\\\ex\\\\glll\")\n",
    "        else:\n",
    "            ajouterExemple(comment+\"\\\\ex\\\\gll\")\n",
    "        print comment,\n",
    "        for mot in phrase:\n",
    "            if mot!=0:\n",
    "                printflat(mot,\"{}\")\n",
    "        ajouterExemple(\" \".join(accumulateur)+\"\\\\\\\\\")\n",
    "        print comment,\n",
    "        for mot in phrase:\n",
    "            if mot!=0:\n",
    "                printflat(mot,\"P{}\")\n",
    "        ajouterExemple(\" \".join(accumulateur)+\"\\\\\\\\\")\n",
    "        if print_glose:\n",
    "            print comment,\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            ajouterExemple(\" \".join(accumulateur)+\"\\\\\\\\\")\n",
    "        traduction=(line.strip().rstrip('.')).split()\n",
    "        start=1\n",
    "#        accumulerMots(comment)\n",
    "        for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "            if element!=\"\":\n",
    "                if start:\n",
    "                    start=0\n",
    "                    element=element.capitalize()\n",
    "                caracteres=list(element)\n",
    "                if caracteres[len(caracteres)-1]=='S':\n",
    "                    caracteres[len(caracteres)-1]='s'\n",
    "                accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "        ajouterExemple(taches()+\" \".join(accumulateur))\n",
    "        del accumulateur[:]\n",
    "        if print_coffee and random.randint(1,4)==1:\n",
    "            stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "            alpha=random.random()/1.5\n",
    "            angle=random.randint(0,360)\n",
    "            xoff=random.randint(-200,0)\n",
    "            ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "    if comment==\"%\": ajouterExemple(\"\\\\\\\\\")\n",
    "ajouterExemple(comment+\"\\\\end{exe}\")\n",
    "    \n",
    "phrase_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PFM.hierarchieCF.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "    tab=(head,tail,\"\")\n",
    "else:\n",
    "    tab=(head,tail,\"%\")\n",
    "prononciationExtrait=[]\n",
    "ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "print_tableaux(2,tableaux[\"N\"],texte,8,tab)\n",
    "ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "print_tableaux(3,tableaux[\"ADJ\"],texte,11,tab)\n",
    "ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "print_tableaux(2,tableaux[\"V\"],texte,35,tab)\n",
    "ajouterVocabulaire(tab[2]+\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "print_tableaux(3,tableaux[\"DET\"],texte,12,tab)\n",
    "ajouterVocabulaire(tab[2]+\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "print_tableaux(3,tableaux[\"PREP\"],texte,0,tab)\n",
    "ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if ('options' in globals() and options.print_cloze) or print_cloze:\n",
    "    print\n",
    "    print\n",
    "    print\n",
    "    print \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%CLOZE%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\n",
    "    print\n",
    "    print\n",
    "    print\n",
    "    print \"%\t\t\t\t\t\t\t\t\t\tNOMS\"\t\n",
    "    for element in cloze_noms:\n",
    "        print \"% \", element[0].translate(toipa)+\";\"+element[1]\n",
    "    print\n",
    "    print\n",
    "    print\n",
    "    print \"%\t\t\t\t\t\t\t\t\t\tVERBES\"\t\n",
    "    for element in cloze_verbes:\n",
    "        print \"% \", element[0].translate(toipa)+\";\"+element[1]\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+variante+\"Exemples.tex\", 'wb') as output:\n",
    "    for exemple in exemples:\n",
    "        output.write(exemple+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+variante+\"Vocabulaire.tex\", 'wb') as output:\n",
    "    for vocable in vocabulaire:\n",
    "        output.write(vocable+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+variante+\"Prononciation.tex\", 'wb') as output:\n",
    "    for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "        output.write(ligne+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
