{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParFuMor (version YAML & Objets)\n",
    "\n",
    "- Ajout d'un %store pour la gestion des numéros de kanoniks (16/04/20)\n",
    "\n",
    "- Attention les règles qui ne changent pas le radical donnent lieu à des mauvais découpages des formes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import itertools\n",
    "import yaml,YamlDuplicates\n",
    "from yaml.constructor import ConstructorError\n",
    "import warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle\n",
    "from IPython.display import HTML, display\n",
    "#import cellbell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter\n",
    "\n",
    "le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\n",
      "Stored 'numerosKalaba' (list)\n",
      "Stored 'typeKalaba' (str)\n"
     ]
    }
   ],
   "source": [
    "%store -r numerosKalaba typeKalaba\n",
    "numerosKalaba=[1,2,3,4,5]\n",
    "numerosKalaba=[18]\n",
    "print numerosKalaba\n",
    "typeKalaba=\"Kanonik\"\n",
    "%store numerosKalaba \n",
    "%store typeKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "\n",
    "if typeKalaba!=\"Kanonik\":\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/\"\n",
    "    serie=repertoire+\"22-\"\n",
    "    nomsKalabas=[serie+\"K%d/\"%num for num in numerosKalaba]\n",
    "else:\n",
    "    repertoire=home+\"/Library/Mobile Documents/com~apple~CloudDocs/Downloads/\"\n",
    "    serie=repertoire+\"23-Kanoniks/\"\n",
    "    nomsKalabas=[serie+\"Kanonik-%02d-ok/\"%num for num in numerosKalaba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExemple(lDict):\n",
    "    exKey=lDict.keys()[0]\n",
    "    if isinstance(lDict[exKey],dict):\n",
    "        result=getExemple(lDict[exKey])\n",
    "    elif isinstance(lDict[exKey],list):\n",
    "        result=lDict[exKey][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/gilles/Library/Mobile Documents/com~apple~CloudDocs/Downloads/23-Kanoniks/Kanonik-18-ok/\n",
      "NOM : Genre Nombre\n",
      "VER : Temps Pers Genre\n",
      "ADJ : Genre Nombre\n",
      "PRO : Genre Nombre\n",
      "DET : Genre Nombre\n",
      "head stems\n",
      "head stems,NOM\n"
     ]
    }
   ],
   "source": [
    "PFM.duplicateErrors=[]\n",
    "for serie in nomsKalabas:\n",
    "    print\n",
    "    print serie\n",
    "\n",
    "    with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "        gloses=yaml.safe_load(stream)\n",
    "        PFM.gloses=gloses\n",
    "    with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "        try:\n",
    "            stems=yaml.safe_load(stream)\n",
    "            PFM.stems=stems\n",
    "        except ConstructorError,msg:\n",
    "            print msg\n",
    "            continue\n",
    "    \n",
    "    lexiqueTestPrep=getExemple(stems[\"PREP\"]).lower()\n",
    "    lexiqueTestNoun=getExemple(stems[\"NOM\"]).lower()\n",
    "    lexiqueTestHyper=getExemple(stems[\"ADJ\"]).lower()\n",
    "    \n",
    "    with open(serie+\"Blocks.yaml\", 'r') as stream:\n",
    "        blocks=yaml.safe_load(stream)\n",
    "        PFM.blocks=blocks\n",
    "    with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "        phonology=yaml.safe_load(stream)\n",
    "        PFM.phonology=phonology\n",
    "    with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "        morphosyntax=yaml.safe_load(stream)\n",
    "        PFM.morphosyntax=morphosyntax\n",
    "\n",
    "        \n",
    "    for cat in morphosyntax[\"Attributs\"]:\n",
    "        if sorted(morphosyntax[\"Attributs\"][cat])!=sorted(gloses[cat].keys()):\n",
    "            warnings.warn(\"\\n\"+serie+\"\\nLes attributs de %s ne sont pas cohérents\\nMorphosyntax => %s\\nGloses => %s\"%(cat,\", \".join(morphosyntax[\"Attributs\"][cat]),\", \".join(gloses[cat].keys())))\n",
    "    \n",
    "    regles=Regles()\n",
    "    PFM.regles=regles\n",
    "    for categorie in blocks:\n",
    "        regles.addBlocs(categorie,blocks[categorie])\n",
    "\n",
    "\n",
    "    paradigmes=Paradigmes()\n",
    "    PFM.paradigmes=paradigmes\n",
    "\n",
    "    hierarchieCF=HierarchieCF()\n",
    "    PFM.hierarchieCF=hierarchieCF\n",
    "    lexique=Lexique()\n",
    "    PFM.lexique=lexique\n",
    "\n",
    "\n",
    "    for cat in gloses:\n",
    "    #    print cat\n",
    "        attributes=[]\n",
    "        if gloses[cat]:\n",
    "            if set(gloses[cat].keys())==set(morphosyntax[\"Attributs\"][cat]):\n",
    "                features=morphosyntax[\"Attributs\"][cat]\n",
    "    #            print \"inhérent\",features\n",
    "            else:\n",
    "                features=gloses[cat].keys()\n",
    "    #            print \"contextuel\",features\n",
    "            for attribute in features:\n",
    "                attributes.append(gloses[cat][attribute])\n",
    "            nuplets=(itertools.product(*attributes))\n",
    "            for nuplet in nuplets:\n",
    "                proprietes=[cat]\n",
    "                for element in range(len(nuplet)):\n",
    "                    proprietes.append(u\"%s=%s\"%(features[element],nuplet[element]))\n",
    "                paradigmes.addForme(cat,proprietes)\n",
    "\n",
    "    analyserGloses(gloses)\n",
    "    analyserStems(stems)\n",
    "        \n",
    "    with open(serie+\"Hierarchie-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(hierarchieCF, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(serie+\"Lexique-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(lexique, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(serie+\"Regles-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(regles, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    PFM.lexique.lexemes[lexiqueTestPrep]\n",
    "\n",
    "    mot=lexiqueTestNoun\n",
    "    # classesNom=PFM.lexique.formeLexeme[mot.lower()][0].split('.')[1:]\n",
    "    # [classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]]\n",
    "\n",
    "    PFM.lexique.formeLexeme[lexiqueTestHyper][0]\n",
    "\n",
    "if PFM.duplicateErrors:\n",
    "    print\n",
    "    print \"=======ERREURS========\"\n",
    "    print\n",
    "    for ligne in PFM.duplicateErrors:\n",
    "        print ligne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ani': {'belu': ['mammouth', 'mammouths'],\n",
       "  'den': ['tortue'],\n",
       "  'imat': ['poisson', 'poissons'],\n",
       "  'liru': ['licorne'],\n",
       "  'rita': ['oiseau', 'oiseaux'],\n",
       "  'tud': ['lapin']},\n",
       " 'Hum': {'Subo': ['chevalier', 'chevaliers'],\n",
       "  'almel': ['Almael'],\n",
       "  'anok': ['Anouk'],\n",
       "  'god': ['fille', 'filles'],\n",
       "  'letun': ['magicien'],\n",
       "  'lom': [u'L\\xe9ina'],\n",
       "  'men': ['enfant', 'enfants']},\n",
       " 'Ina': {'Nis': ['vent'],\n",
       "  'Sogi': ['tartine', 'tartines'],\n",
       "  'Zepu': ['pomme', 'pommes'],\n",
       "  'Zili': ['maison'],\n",
       "  'bod': ['grotte'],\n",
       "  'bul': ['cri', 'cris'],\n",
       "  'dero': [u'cr\\xe2ne', u'cr\\xe2nes'],\n",
       "  'dodr': ['orage'],\n",
       "  'finov': ['Afior'],\n",
       "  'fisn': ['os', 'oS'],\n",
       "  'fite': ['aile', 'ailes'],\n",
       "  'gef': [u'oxyg\\xe8ne'],\n",
       "  'gone': ['lueur'],\n",
       "  'kar': ['ciel'],\n",
       "  'kubl': ['stylo'],\n",
       "  'log': ['rambarde'],\n",
       "  'lole': [u'obscurit\\xe9'],\n",
       "  'maf': [u'rivi\\xe8re'],\n",
       "  'mig': ['caillou', 'cailloux'],\n",
       "  'muvin': ['soleil'],\n",
       "  'nak': ['baguette'],\n",
       "  'put': ['pelle'],\n",
       "  'rasa': ['lunette', 'lunettes'],\n",
       "  'rev': ['escalier'],\n",
       "  'ril': [u'\\xe9toile', u'\\xe9toiles'],\n",
       "  'ruvo': ['lasagne', 'lasagnes'],\n",
       "  'sak': ['lave'],\n",
       "  'sega': ['feu'],\n",
       "  'suN': [u'plan\\xe8te', u'plan\\xe8tes'],\n",
       "  'tuv': ['feuille'],\n",
       "  'veli': ['formule']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems[\"NOM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanc\n",
      "sur\n"
     ]
    }
   ],
   "source": [
    "print PFM.lexique.formeLexeme[lexiqueTestHyper][0]\n",
    "# print PFM.lexique.formeLexeme[lexiqueTestNoun][0]\n",
    "print PFM.lexique.formeLexeme[lexiqueTestPrep][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'VER, Temps=PRS, Pers=3Sg, Genre=Ani',\n",
       " u'VER, Temps=PRS, Pers=3Sg, Genre=Ina',\n",
       " u'VER, Temps=PRS, Pers=3Sg, Genre=Hum',\n",
       " u'VER, Temps=PRS, Pers=3Du, Genre=Ani',\n",
       " u'VER, Temps=PRS, Pers=3Du, Genre=Ina',\n",
       " u'VER, Temps=PRS, Pers=3Du, Genre=Hum',\n",
       " u'VER, Temps=PRS, Pers=3Pl, Genre=Ani',\n",
       " u'VER, Temps=PRS, Pers=3Pl, Genre=Ina',\n",
       " u'VER, Temps=PRS, Pers=3Pl, Genre=Hum',\n",
       " u'VER, Temps=FUT, Pers=3Sg, Genre=Ani',\n",
       " u'VER, Temps=FUT, Pers=3Sg, Genre=Ina',\n",
       " u'VER, Temps=FUT, Pers=3Sg, Genre=Hum',\n",
       " u'VER, Temps=FUT, Pers=3Du, Genre=Ani',\n",
       " u'VER, Temps=FUT, Pers=3Du, Genre=Ina',\n",
       " u'VER, Temps=FUT, Pers=3Du, Genre=Hum',\n",
       " u'VER, Temps=FUT, Pers=3Pl, Genre=Ani',\n",
       " u'VER, Temps=FUT, Pers=3Pl, Genre=Ina',\n",
       " u'VER, Temps=FUT, Pers=3Pl, Genre=Hum']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.getSigmas([\"VER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF=\n",
      "['CF=N1', 'CF=N2']\n",
      "does not apply\n"
     ]
    }
   ],
   "source": [
    "case=\"CF=N3\"\n",
    "m=re.match(ur\"(.*=)(.*)\",\"CF=N1|N2\")\n",
    "if m:\n",
    "    altTrait=m.group(1)\n",
    "    altValeurs=m.group(2).split(\"|\")\n",
    "    print altTrait\n",
    "    altTraits=[altTrait+v for v in altValeurs]\n",
    "    print altTraits\n",
    "    if any(t == case for t in altTraits):\n",
    "        print \"applies\"\n",
    "    else:\n",
    "        print \"does not apply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regles.getRules(\"VER\",'CF=V1, Temps=PRS, Pers=3PL')\n",
    "# regles.getRules(\"PRO\",\"Nombre=Du, Genre=C\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test=Lexeme(\"ganav\",\"VER\",\"croc\").getParadigm(lignes=[\"Genre\"],colonne=[\"Pers\",\"Temps\"])\n",
    "test=Lexeme(\"ganav\",\"NOM\",\"croc\").getParadigm(lignes=[\"Nombre\"],colonne=[\"Cas\"])\n",
    "\n",
    "# test=Lexeme(\"RAD\",\"DET\",\"croc\").getParadigm(lignes=[\"Genre\"],colonne=[\"Nombre\",\"Cas\"])\n",
    "test\n",
    "#test.index.sortlevel(0,ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lignes=[\"Temps\",\"Pers\",\"Trans\"]\n",
    "colonne=[\"Genre\"]\n",
    "lignes=[\"Genre\",\"Nombre\"]\n",
    "colonne=[\"Cas\"]\n",
    "for cf in [\"N%d\"%(i+1) for i in range(4)]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Erg\",\"Abs\",\"Dat\",\"Obl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)\n",
    "\n",
    "lignes=[\"Cas\",\"Genre\"]\n",
    "colonne=[\"Nombre\"]\n",
    "for cf in [\"A%d\"%(i+1) for i in range(2)]:\n",
    "#for cf in [\"DET\"]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "#    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)\n",
    "\n",
    "lignes=[\"Genre\"]\n",
    "colonne=[\"Nombre\"]\n",
    "for cf in [\"DET\"]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat=\"N\"\n",
    "triLex={}\n",
    "for element in PFM.lexique.lexemes:\n",
    "#    print element\n",
    "    elementElts=element.split(\".\")\n",
    "    nom=elementElts[0]\n",
    "    if len(elementElts)==3:\n",
    "        if elementElts[1].startswith(cat):\n",
    "            if not elementElts[2] in triLex:\n",
    "                triLex[elementElts[2]]=set()\n",
    "            triLex[elementElts[2]].add((PFM.lexique.lexemes[element].stem,nom))            \n",
    "triLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stylo.Ina kubl\n",
      "Anouk.Hum anok\n",
      "PRO kad\n",
      "planète.Ina suN\n",
      "poisson.Ani imat\n",
      "tartine.Ina Sogi\n",
      "baguette.Ina nak\n",
      "pomme.Ina Zepu\n",
      "oiseau.Ani rita\n",
      "jouer vub\n",
      "être pofl\n",
      "DEM r\n",
      "enfant.Hum men\n",
      "aile.Ina fite\n",
      "Afior.Ina finov\n",
      "aider duta\n",
      "découvrir mon\n",
      "DEF f\n",
      "blanc tof\n",
      "étoile.Ina ril\n",
      "transformer givu\n",
      "oxygène.Ina gef\n",
      "noir neg\n",
      "caillou.Ina mig\n",
      "devenir bud\n",
      "lasagne.Ina ruvo\n",
      "fille.Hum god\n",
      "manger fesna\n",
      "avec tuk\n",
      "pousser tave\n",
      "grotte.Ina bod\n",
      "long zlu\n",
      "en pod\n",
      "casser kagu\n",
      "magicien.Hum letun\n",
      "os.Ina fisn\n",
      "sur daf\n",
      "atterrir vekoz\n",
      "vent.Ina Nis\n",
      "briller getek\n",
      "Almael.Hum almel\n",
      "obscurité.Ina lole\n",
      "chevalier.Hum Subo\n",
      "escalier.Ina rev\n",
      "gros Nud\n",
      "feu.Ina sega\n",
      "vert lidmu\n",
      "grand moke\n",
      "feuille.Ina tuv\n",
      "maison.Ina Zili\n",
      "rambarde.Ina log\n",
      "voir ekat\n",
      "devant Nis\n",
      "lunette.Ina rasa\n",
      "sombre dev\n",
      "orage.Ina dodr\n",
      "cri.Ina bul\n",
      "mammouth.Ani belu\n",
      "crâne.Ina dero\n",
      "de plok\n",
      "lapin.Ani tud\n",
      "Léina.Hum lom\n",
      "prendre kunoso\n",
      "sous lap\n",
      "rivière.Ina maf\n",
      "longer teke\n",
      "capturer nap\n",
      "licorne.Ani liru\n",
      "regarder ponb\n",
      "lave.Ina sak\n",
      "ciel.Ina kar\n",
      "à gum\n",
      "tortue.Ani den\n",
      "magique poS\n",
      "pour vri\n",
      "écrire mud\n",
      "bleu grak\n",
      "formule.Ina veli\n",
      "pelle.Ina put\n",
      "IND s\n",
      "dans so\n",
      "lancer batt\n",
      "lueur.Ina gone\n",
      "soleil.Ina muvin\n"
     ]
    }
   ],
   "source": [
    "for l in PFM.lexique.lexemes:\n",
    "    print l,PFM.lexique.lexemes[l].stem"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp=test.reset_index()\n",
    "temp[\"Nombre\"]=pd.Categorical(temp[\"Nombre\"],categories=[\"Sg\",\"Du\",\"Pl\"],ordered=True)\n",
    "temp.sort_values(\"Nombre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
