{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParFuMor (version YAML & Objets)\n",
    "\n",
    "- Ajout d'un %store pour la gestion des numéros de kanoniks (16/04/20)\n",
    "\n",
    "- Attention les règles qui ne changent pas le radical donnent lieu à des mauvais découpages des formes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import itertools\n",
    "import yaml,YamlDuplicates\n",
    "from yaml.constructor import ConstructorError\n",
    "import warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle\n",
    "from IPython.display import HTML, display\n",
    "#import cellbell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter\n",
    "\n",
    "le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "Stored 'numerosKalaba' (list)\n"
     ]
    }
   ],
   "source": [
    "%store -r numerosKalaba\n",
    "numerosKalaba=[1,2,3,4,5]\n",
    "numerosKalaba=[2]\n",
    "print numerosKalaba\n",
    "%store numerosKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/\"\n",
    "serie=repertoire+\"20-\"\n",
    "nomsKalabas=[serie+\"K%d/\"%num for num in numerosKalaba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExemple(lDict):\n",
    "    exKey=lDict.keys()[0]\n",
    "    if isinstance(lDict[exKey],dict):\n",
    "        result=getExemple(lDict[exKey])\n",
    "    elif isinstance(lDict[exKey],list):\n",
    "        result=lDict[exKey][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/20-K1/\n",
      "VER : Temps Pers\n",
      "NOM : Genre Nombre\n",
      "DET : Genre Nombre\n",
      "ADJ : Genre Nombre\n",
      "head stems\n",
      "head stems,VER\n",
      "head stems,NOM\n"
     ]
    }
   ],
   "source": [
    "PFM.duplicateErrors=[]\n",
    "for serie in nomsKalabas:\n",
    "    print\n",
    "    print serie\n",
    "\n",
    "    with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "        gloses=yaml.safe_load(stream)\n",
    "        PFM.gloses=gloses\n",
    "    with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "        try:\n",
    "            stems=yaml.safe_load(stream)\n",
    "            PFM.stems=stems\n",
    "        except ConstructorError,msg:\n",
    "            print msg\n",
    "            continue\n",
    "    lexiqueTestPrep=getExemple(stems[\"PREP\"])\n",
    "    lexiqueTestNoun=getExemple(stems[\"NOM\"])\n",
    "    lexiqueTestHyper=getExemple(stems[\"ADJ\"])\n",
    "    with open(serie+\"Blocks.yaml\", 'r') as stream:\n",
    "        blocks=yaml.safe_load(stream)\n",
    "        PFM.blocks=blocks\n",
    "    with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "        phonology=yaml.safe_load(stream)\n",
    "        PFM.phonology=phonology\n",
    "    with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "        morphosyntax=yaml.safe_load(stream)\n",
    "        PFM.morphosyntax=morphosyntax\n",
    "\n",
    "        \n",
    "    for cat in morphosyntax[\"Attributs\"]:\n",
    "        if sorted(morphosyntax[\"Attributs\"][cat])!=sorted(gloses[cat].keys()):\n",
    "            warnings.warn(\"\\n\"+serie+\"\\nLes attributs de %s ne sont pas cohérents\\nMorphosyntax => %s\\nGloses => %s\"%(cat,\", \".join(morphosyntax[\"Attributs\"][cat]),\", \".join(gloses[cat].keys())))\n",
    "    \n",
    "    regles=Regles()\n",
    "    PFM.regles=regles\n",
    "    for categorie in blocks:\n",
    "        regles.addBlocs(categorie,blocks[categorie])\n",
    "\n",
    "\n",
    "    paradigmes=Paradigmes()\n",
    "    PFM.paradigmes=paradigmes\n",
    "\n",
    "    hierarchieCF=HierarchieCF()\n",
    "    PFM.hierarchieCF=hierarchieCF\n",
    "    lexique=Lexique()\n",
    "    PFM.lexique=lexique\n",
    "\n",
    "\n",
    "    for cat in gloses:\n",
    "    #    print cat\n",
    "        attributes=[]\n",
    "        if gloses[cat]:\n",
    "            if set(gloses[cat].keys())==set(morphosyntax[\"Attributs\"][cat]):\n",
    "                features=morphosyntax[\"Attributs\"][cat]\n",
    "    #            print \"inhérent\",features\n",
    "            else:\n",
    "                features=gloses[cat].keys()\n",
    "    #            print \"contextuel\",features\n",
    "            for attribute in features:\n",
    "                attributes.append(gloses[cat][attribute])\n",
    "            nuplets=(itertools.product(*attributes))\n",
    "            for nuplet in nuplets:\n",
    "                proprietes=[cat]\n",
    "                for element in range(len(nuplet)):\n",
    "                    proprietes.append(u\"%s=%s\"%(features[element],nuplet[element]))\n",
    "                paradigmes.addForme(cat,proprietes)\n",
    "\n",
    "    analyserGloses(gloses)\n",
    "    analyserStems(stems)\n",
    "        \n",
    "    with open(serie+\"Hierarchie-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(hierarchieCF, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(serie+\"Lexique-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(lexique, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(serie+\"Regles-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(regles, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    PFM.lexique.lexemes[lexiqueTestPrep]\n",
    "\n",
    "    mot=lexiqueTestNoun\n",
    "    classesNom=PFM.lexique.formeLexeme[mot][0].split('.')[1:]\n",
    "    [classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]]\n",
    "\n",
    "    PFM.lexique.formeLexeme[lexiqueTestHyper][0]\n",
    "\n",
    "if PFM.duplicateErrors:\n",
    "    print\n",
    "    print \"=======ERREURS========\"\n",
    "    print\n",
    "    for ligne in PFM.duplicateErrors:\n",
    "        print ligne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENTRE'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getExemple(stems[\"PREP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gros\n",
      "villageoise.F\n",
      "ENTRE\n"
     ]
    }
   ],
   "source": [
    "print PFM.lexique.formeLexeme[lexiqueTestHyper][0]\n",
    "print PFM.lexique.formeLexeme[lexiqueTestNoun][0]\n",
    "print PFM.lexique.formeLexeme[lexiqueTestPrep][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DET, Genre=M, Nombre=Sg',\n",
       " u'DET, Genre=M, Nombre=Du',\n",
       " u'DET, Genre=M, Nombre=Pl',\n",
       " u'DET, Genre=F, Nombre=Sg',\n",
       " u'DET, Genre=F, Nombre=Du',\n",
       " u'DET, Genre=F, Nombre=Pl',\n",
       " u'DET, Genre=N, Nombre=Sg',\n",
       " u'DET, Genre=N, Nombre=Du',\n",
       " u'DET, Genre=N, Nombre=Pl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.getSigmas([\"DET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF=\n",
      "['CF=N1', 'CF=N2']\n",
      "does not apply\n"
     ]
    }
   ],
   "source": [
    "case=\"CF=N3\"\n",
    "m=re.match(ur\"(.*=)(.*)\",\"CF=N1|N2\")\n",
    "if m:\n",
    "    altTrait=m.group(1)\n",
    "    altValeurs=m.group(2).split(\"|\")\n",
    "    print altTrait\n",
    "    altTraits=[altTrait+v for v in altValeurs]\n",
    "    print altTraits\n",
    "    if any(t == case for t in altTraits):\n",
    "        print \"applies\"\n",
    "    else:\n",
    "        print \"does not apply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regles.getRules(\"NOM\",'CF=N3, Genre=C, Nombre=Du, Cas=Acc')\n",
    "regles.getRules(\"VER\",\"Pers=3Pau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Nombre</th>\n",
       "      <th>Du</th>\n",
       "      <th>Pl</th>\n",
       "      <th>Sg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>RAD-u-s</td>\n",
       "      <td>RAD-u-t</td>\n",
       "      <td>RAD-u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>RAD-e-s</td>\n",
       "      <td>RAD-e-t</td>\n",
       "      <td>RAD-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>RAD-a-s</td>\n",
       "      <td>RAD-a-t</td>\n",
       "      <td>RAD-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Nombre       Du       Pl     Sg\n",
       "Genre                          \n",
       "F       RAD-u-s  RAD-u-t  RAD-u\n",
       "M       RAD-e-s  RAD-e-t  RAD-e\n",
       "N       RAD-a-s  RAD-a-t  RAD-a"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=Lexeme(\"RAD\",\"DET\",\"croc\").getParadigm(lignes=[\"Genre\"],colonne=[\"Nombre\"])\n",
    "#test=Lexeme(\"RAD\",\"DET\",\"croc\").getParadigm(lignes=[\"Genre\"],colonne=[\"Nombre\",\"Cas\"])\n",
    "test\n",
    "#test.index.sortlevel(0,ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "lignes=[\"Temps\",\"Pers\",\"Trans\"]\n",
    "colonne=[\"Genre\"]\n",
    "lignes=[\"Genre\",\"Nombre\"]\n",
    "colonne=[\"Cas\"]\n",
    "for cf in [\"N%d\"%(i+1) for i in range(4)]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Erg\",\"Abs\",\"Dat\",\"Obl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)\n",
    "\n",
    "lignes=[\"Cas\",\"Genre\"]\n",
    "colonne=[\"Nombre\"]\n",
    "for cf in [\"A%d\"%(i+1) for i in range(2)]:\n",
    "#for cf in [\"DET\"]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "#    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)\n",
    "\n",
    "lignes=[\"Genre\"]\n",
    "colonne=[\"Nombre\"]\n",
    "for cf in [\"DET\"]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat=\"N\"\n",
    "triLex={}\n",
    "for element in PFM.lexique.lexemes:\n",
    "#    print element\n",
    "    elementElts=element.split(\".\")\n",
    "    nom=elementElts[0]\n",
    "    if len(elementElts)==3:\n",
    "        if elementElts[1].startswith(cat):\n",
    "            if not elementElts[2] in triLex:\n",
    "                triLex[elementElts[2]]=set()\n",
    "            triLex[elementElts[2]].add((PFM.lexique.lexemes[element].stem,nom))            \n",
    "triLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "envahir.V1 keZuNup\n",
      "transformer.V2 sevuT\n",
      "acheter.V1 bagan\n",
      "sortir.V1 Dadejar\n",
      "souffrance.F TiledaS\n",
      "donner.V2 zibudel\n",
      "rouge rumiT\n",
      "Nicole.F nikol\n",
      "noir kizow\n",
      "être.V2 toZumet\n",
      "quatre sejin\n",
      "coup.N fezil\n",
      "colère.F Sagobul\n",
      "différent Sozup\n",
      "sur zeDun\n",
      "vers tan\n",
      "apporter.V2 NabiS\n",
      "ENTRE DiNe\n",
      "serpent.F pevur\n",
      "de kum\n",
      "cuisine.N lunegik\n",
      "bas baZowaN\n",
      "enfant.hyper.F sadimel\n",
      "villageois.M NoTeN\n",
      "lance.N DotoSut\n",
      "blessé wibam\n",
      "loup.M TeniS\n",
      "chef.F mugat\n",
      "disparaître.V1 sowuD\n",
      "lune.M benov\n",
      "souris.M palek\n",
      "Violette.F vjolet\n",
      "ombre.N bibuS\n",
      "enfant.M duZen\n",
      "furieux poleS\n",
      "rêvasser.V1 nivap\n",
      "fuir.V1 deven\n",
      "profond jemibot\n",
      "maigre gadin\n",
      "DEM b\n",
      "cri.N mubeD\n",
      "chatte.F piZov\n",
      "chasseur.M soNom\n",
      "DEF l\n",
      "boire.V1 Tizok\n",
      "thé.M judog\n",
      "arriver.V1 poSob\n",
      "nuit.M vidon\n",
      "courageux joZogiN\n",
      "chercher.V2 NunaDas\n",
      "poisson.M wunozol\n",
      "coussin.F gaZur\n",
      "infirmière.F dozut\n",
      "jeter.V2 gumaZ\n",
      "dévorer.V1 mawes\n",
      "parler.V2 Zebuf\n",
      "fruit.N DomeZ\n",
      "sauter.V1 Neranuf\n",
      "village.N tuvej\n",
      "Nabil.M nabil\n",
      "coyote.F Togoniw\n",
      "couteau.N wabaj\n",
      "voir.V1 marufil\n",
      "courir.V1 Nivumil\n",
      "à ToT\n",
      "lueur.M divuS\n",
      "viande.M TezuT\n",
      "terrible Sogeges\n",
      "IND k\n",
      "louve.F TiniSum\n",
      "chat.M guwir\n",
      "tomber.V1 juNoleg\n",
      "soeur.F vegevuj\n",
      "forêt.M Dazep\n",
      "café.N fovub\n",
      "approcher.V2 riwefit\n",
      "fille.F duzunuT\n",
      "démon.M nugek\n",
      "chasser.V2 vaZiT\n",
      "manger.V2 Tuseg\n",
      "blanc nemiT\n",
      "entrer.V1 SoDim\n",
      "dormir.V2 SejuT\n",
      "avec Sif\n",
      "après zizo\n",
      "maison.F kaDaN\n",
      "œuf.N gijeN\n",
      "villageoise.F NoTim\n",
      "mort.N vudogab\n",
      "prendre.V2 puwekuf\n",
      "aller.V1 DuZob\n",
      "blessure.N nijeT\n",
      "sort.N pejis\n",
      "protéger.V2 sudubam\n",
      "Katisha.F katiSa\n",
      "croc.M muZapuj\n",
      "montrer.V1 Dojaf\n",
      "arbre.N foZiDos\n",
      "devant laj\n",
      "balai.N rofejis\n",
      "pousser.V2 jaZap\n",
      "homme.M modes\n",
      "dans sep\n",
      "pour duS\n",
      "chambre.N madot\n",
      "sous Zuru\n",
      "derrière waTo\n",
      "Mahira.F maira\n",
      "corps.M liNoT\n",
      "petit ruzet\n",
      "combat.N muliT\n",
      "planter.V2 nuZufik\n",
      "suivant webinur\n",
      "supporter.V2 daTaS\n",
      "garçon.M ZegoN\n",
      "jaune foder\n",
      "rejoindre.V1 vitural\n",
      "autruche.F rejav\n",
      "table.F Duvop\n",
      "visage.N bovos\n",
      "grand milapeS\n",
      "milieu.N viwet\n",
      "gorge.M figoT\n",
      "plaine.N jebif\n",
      "Kaleb.M kaleb\n",
      "combattant.M jorut\n",
      "gros guNomaS\n",
      "offrir.V2 NeZoro\n",
      "recouvrir.V2 duwun\n",
      "trois vojuN\n",
      "lit.F Dafib\n",
      "lancer.V2 seDap\n",
      "main.N Negegiz\n",
      "transpercer.V1 viDibaN\n",
      "effrayé kavijot\n",
      "passer.V1 Nawazut\n"
     ]
    }
   ],
   "source": [
    "for l in PFM.lexique.lexemes:\n",
    "    print l,PFM.lexique.lexemes[l].stem"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp=test.reset_index()\n",
    "temp[\"Nombre\"]=pd.Categorical(temp[\"Nombre\"],categories=[\"Sg\",\"Du\",\"Pl\"],ordered=True)\n",
    "temp.sort_values(\"Nombre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py27)",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
