{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParFuMor (version YAML & Objets)\n",
    "\n",
    "- Ajout d'un %store pour la gestion des numéros de kanoniks (16/04/20)\n",
    "\n",
    "- Attention les règles qui ne changent pas le radical donnent lieu à des mauvais découpages des formes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import itertools\n",
    "import yaml,YamlDuplicates\n",
    "from yaml.constructor import ConstructorError\n",
    "import warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle\n",
    "from IPython.display import HTML, display\n",
    "#import cellbell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter\n",
    "\n",
    "le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "Stored 'numerosKalaba' (list)\n",
      "Stored 'typeKalaba' (str)\n"
     ]
    }
   ],
   "source": [
    "%store -r numerosKalaba typeKalaba\n",
    "numerosKalaba=[1,2,3,4,5]\n",
    "numerosKalaba=[2]\n",
    "print numerosKalaba\n",
    "typeKalaba=\"Kanonik\"\n",
    "%store numerosKalaba \n",
    "%store typeKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "\n",
    "if typeKalaba!=\"Kanonik\":\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/\"\n",
    "    serie=repertoire+\"21-\"\n",
    "    nomsKalabas=[serie+\"K%d/\"%num for num in numerosKalaba]\n",
    "else:\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-UE4-Morphologie/\"\n",
    "    serie=repertoire+\"K-22/\"\n",
    "    nomsKalabas=[serie+\"Kanonik-%02d/\"%num for num in numerosKalaba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExemple(lDict):\n",
    "    exKey=lDict.keys()[0]\n",
    "    if isinstance(lDict[exKey],dict):\n",
    "        result=getExemple(lDict[exKey])\n",
    "    elif isinstance(lDict[exKey],list):\n",
    "        result=lDict[exKey][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-UE4-Morphologie/K-22/Kanonik-02/\n",
      "NOM : Genre Nombre\n",
      "VER : Temps Pers\n",
      "ADJ : Genre Nombre\n",
      "PRO : Genre Nombre\n",
      "DET : Genre Nombre\n",
      "head stems\n",
      "head stems,NOM\n",
      "head stems,NOM,N1\n",
      "head stems,NOM,N2\n",
      "head stems,DET\n"
     ]
    }
   ],
   "source": [
    "PFM.duplicateErrors=[]\n",
    "for serie in nomsKalabas:\n",
    "    print\n",
    "    print serie\n",
    "\n",
    "    with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "        gloses=yaml.safe_load(stream)\n",
    "        PFM.gloses=gloses\n",
    "    with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "        try:\n",
    "            stems=yaml.safe_load(stream)\n",
    "            PFM.stems=stems\n",
    "        except ConstructorError,msg:\n",
    "            print msg\n",
    "            continue\n",
    "    lexiqueTestPrep=getExemple(stems[\"PREP\"])\n",
    "    lexiqueTestNoun=getExemple(stems[\"NOM\"])\n",
    "    lexiqueTestHyper=getExemple(stems[\"ADJ\"])\n",
    "    with open(serie+\"Blocks.yaml\", 'r') as stream:\n",
    "        blocks=yaml.safe_load(stream)\n",
    "        PFM.blocks=blocks\n",
    "    with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "        phonology=yaml.safe_load(stream)\n",
    "        PFM.phonology=phonology\n",
    "    with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "        morphosyntax=yaml.safe_load(stream)\n",
    "        PFM.morphosyntax=morphosyntax\n",
    "\n",
    "        \n",
    "    for cat in morphosyntax[\"Attributs\"]:\n",
    "        if sorted(morphosyntax[\"Attributs\"][cat])!=sorted(gloses[cat].keys()):\n",
    "            warnings.warn(\"\\n\"+serie+\"\\nLes attributs de %s ne sont pas cohérents\\nMorphosyntax => %s\\nGloses => %s\"%(cat,\", \".join(morphosyntax[\"Attributs\"][cat]),\", \".join(gloses[cat].keys())))\n",
    "    \n",
    "    regles=Regles()\n",
    "    PFM.regles=regles\n",
    "    for categorie in blocks:\n",
    "        regles.addBlocs(categorie,blocks[categorie])\n",
    "\n",
    "\n",
    "    paradigmes=Paradigmes()\n",
    "    PFM.paradigmes=paradigmes\n",
    "\n",
    "    hierarchieCF=HierarchieCF()\n",
    "    PFM.hierarchieCF=hierarchieCF\n",
    "    lexique=Lexique()\n",
    "    PFM.lexique=lexique\n",
    "\n",
    "\n",
    "    for cat in gloses:\n",
    "    #    print cat\n",
    "        attributes=[]\n",
    "        if gloses[cat]:\n",
    "            if set(gloses[cat].keys())==set(morphosyntax[\"Attributs\"][cat]):\n",
    "                features=morphosyntax[\"Attributs\"][cat]\n",
    "    #            print \"inhérent\",features\n",
    "            else:\n",
    "                features=gloses[cat].keys()\n",
    "    #            print \"contextuel\",features\n",
    "            for attribute in features:\n",
    "                attributes.append(gloses[cat][attribute])\n",
    "            nuplets=(itertools.product(*attributes))\n",
    "            for nuplet in nuplets:\n",
    "                proprietes=[cat]\n",
    "                for element in range(len(nuplet)):\n",
    "                    proprietes.append(u\"%s=%s\"%(features[element],nuplet[element]))\n",
    "                paradigmes.addForme(cat,proprietes)\n",
    "\n",
    "    analyserGloses(gloses)\n",
    "    analyserStems(stems)\n",
    "        \n",
    "    with open(serie+\"Hierarchie-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(hierarchieCF, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(serie+\"Lexique-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(lexique, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(serie+\"Regles-S2.pkl\", 'wb') as output:\n",
    "       pickle.dump(regles, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    PFM.lexique.lexemes[lexiqueTestPrep]\n",
    "\n",
    "    mot=lexiqueTestNoun\n",
    "    classesNom=PFM.lexique.formeLexeme[mot][0].split('.')[1:]\n",
    "    [classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]]\n",
    "\n",
    "    PFM.lexique.formeLexeme[lexiqueTestHyper][0]\n",
    "\n",
    "if PFM.duplicateErrors:\n",
    "    print\n",
    "    print \"=======ERREURS========\"\n",
    "    print\n",
    "    for ligne in PFM.duplicateErrors:\n",
    "        print ligne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Zik': ['sur'],\n",
       " 'akad': ['pendant'],\n",
       " 'beN': ['entre'],\n",
       " 'fu': ['vers'],\n",
       " 'gopun': [u'apr\\xe8s'],\n",
       " 'lal': ['pour'],\n",
       " 'mileb': ['avec'],\n",
       " 'ne': ['en'],\n",
       " 'ni': [u'\\xe0'],\n",
       " 'po': ['dans'],\n",
       " 'toS': ['de']}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems[\"PREP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouveau\n",
      "morceau.N1.F\n",
      "pour\n"
     ]
    }
   ],
   "source": [
    "print PFM.lexique.formeLexeme[lexiqueTestHyper][0]\n",
    "print PFM.lexique.formeLexeme[lexiqueTestNoun][0]\n",
    "print PFM.lexique.formeLexeme[lexiqueTestPrep][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'VER, Temps=PRS, Pers=3Sg',\n",
       " u'VER, Temps=PRS, Pers=3Pau',\n",
       " u'VER, Temps=PRS, Pers=3Pl',\n",
       " u'VER, Temps=PST, Pers=3Sg',\n",
       " u'VER, Temps=PST, Pers=3Pau',\n",
       " u'VER, Temps=PST, Pers=3Pl']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.getSigmas([\"VER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF=\n",
      "['CF=N1', 'CF=N2']\n",
      "does not apply\n"
     ]
    }
   ],
   "source": [
    "case=\"CF=N3\"\n",
    "m=re.match(ur\"(.*=)(.*)\",\"CF=N1|N2\")\n",
    "if m:\n",
    "    altTrait=m.group(1)\n",
    "    altValeurs=m.group(2).split(\"|\")\n",
    "    print altTrait\n",
    "    altTraits=[altTrait+v for v in altValeurs]\n",
    "    print altTraits\n",
    "    if any(t == case for t in altTraits):\n",
    "        print \"applies\"\n",
    "    else:\n",
    "        print \"does not apply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X+a', 'Temps=PRS')]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regles.getRules(\"VER\",'CF=V1, Temps=PRS, Pers=3PL')\n",
    "# regles.getRules(\"PRO\",\"Nombre=Du, Genre=C\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# test=Lexeme(\"ganav\",\"VER\",\"croc\").getParadigm(lignes=[\"Genre\"],colonne=[\"Pers\",\"Temps\"])\n",
    "test=Lexeme(\"ganav\",\"NOM\",\"croc\").getParadigm(lignes=[\"Nombre\"],colonne=[\"Cas\"])\n",
    "\n",
    "# test=Lexeme(\"RAD\",\"DET\",\"croc\").getParadigm(lignes=[\"Genre\"],colonne=[\"Nombre\",\"Cas\"])\n",
    "test\n",
    "#test.index.sortlevel(0,ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "lignes=[\"Temps\",\"Pers\",\"Trans\"]\n",
    "colonne=[\"Genre\"]\n",
    "lignes=[\"Genre\",\"Nombre\"]\n",
    "colonne=[\"Cas\"]\n",
    "for cf in [\"N%d\"%(i+1) for i in range(4)]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Erg\",\"Abs\",\"Dat\",\"Obl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)\n",
    "\n",
    "lignes=[\"Cas\",\"Genre\"]\n",
    "colonne=[\"Nombre\"]\n",
    "for cf in [\"A%d\"%(i+1) for i in range(2)]:\n",
    "#for cf in [\"DET\"]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "#    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)\n",
    "\n",
    "lignes=[\"Genre\"]\n",
    "colonne=[\"Nombre\"]\n",
    "for cf in [\"DET\"]:\n",
    "    test=Lexeme(\"RAD\",cf,\"croc\").getParadigm(lignes=lignes,colonne=colonne)\n",
    "    test=test.reset_index().groupby(by=[\"Sg\",\"Du\",\"Pl\"]).agg(lambda x: \", \".join(set(x))).reset_index().set_index(lignes)\n",
    "    print cf\n",
    "    display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'F': {('Sonizi', u'fl\\xe8che'),\n",
       "  ('bagape', u'arbre'),\n",
       "  ('bizili', u'jumelle'),\n",
       "  ('bokenuN', u'aventure'),\n",
       "  ('buriza', u'livre'),\n",
       "  ('dasetu', u'l\\xe9gende'),\n",
       "  ('fevegi', u'feu'),\n",
       "  ('fivuS', u'd\\xe9sert'),\n",
       "  ('geSiso', u'histoire'),\n",
       "  ('kaSeZu', u'pause'),\n",
       "  ('kurige', u'guerri\\xe8re'),\n",
       "  ('mopinu', u'tr\\xe9sor'),\n",
       "  ('razebu', u'voyage'),\n",
       "  ('segika', u'dessin'),\n",
       "  ('sekuZi', u'repas'),\n",
       "  ('tapilu', u'morceau'),\n",
       "  ('telofi', u'tellaufi'),\n",
       "  ('tizer', u'cit\\xe9'),\n",
       "  ('voseda', u'grotte')},\n",
       " u'M': {('Sigolo', u'parchemin'),\n",
       "  ('Zezame', u'nom'),\n",
       "  ('arutur', u'Arthur'),\n",
       "  ('bodola', u'fl\\xfbte'),\n",
       "  ('dezato', u'village'),\n",
       "  ('faduNe', u'pi\\xe8ge'),\n",
       "  ('firule', u'lunette'),\n",
       "  ('gurusu', u'bouche'),\n",
       "  ('lubrik', u'chef'),\n",
       "  ('muSula', u'dragon'),\n",
       "  ('paterik', u'Patrick'),\n",
       "  ('rorapo', u'dinosaure'),\n",
       "  ('rutoza', u'pomme'),\n",
       "  ('satame', u'tronc'),\n",
       "  ('tomoda', u'amiti\\xe9'),\n",
       "  ('vegalum', u'chemin'),\n",
       "  ('vosegaN', u'entr\\xe9e'),\n",
       "  ('vozubli', u'gar\\xe7on'),\n",
       "  ('zaNir', u'Zagnir')},\n",
       " u'N': {('Seteruk', u'force'),\n",
       "  ('fonuNe', u'ouverture'),\n",
       "  ('foreSu', u'recherche'),\n",
       "  ('gedala', u'serpent'),\n",
       "  ('kagumi', u'fond'),\n",
       "  ('kinude', u'enfant'),\n",
       "  ('kunati', u'troupe'),\n",
       "  ('leNafe', u'sauveur'),\n",
       "  ('lepuruSo', u'lutin'),\n",
       "  ('lutoga', u'jour'),\n",
       "  ('modaSi', u'ami'),\n",
       "  ('mufele', u'milieu'),\n",
       "  ('neZofi', u'aide'),\n",
       "  ('savomu', u'qu\\xeate'),\n",
       "  ('tuboca', u'bout')}}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat=\"N\"\n",
    "triLex={}\n",
    "for element in PFM.lexique.lexemes:\n",
    "#    print element\n",
    "    elementElts=element.split(\".\")\n",
    "    nom=elementElts[0]\n",
    "    if len(elementElts)==3:\n",
    "        if elementElts[1].startswith(cat):\n",
    "            if not elementElts[2] in triLex:\n",
    "                triLex[elementElts[2]]=set()\n",
    "            triLex[elementElts[2]].add((PFM.lexique.lexemes[element].stem,nom))            \n",
    "triLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "désert.N1.F fivuS\n",
      "reconnaître bolat\n",
      "entrée.N1.M vosegaN\n",
      "disparaître turbul\n",
      "enflammé potika\n",
      "parchemin.N1.M Sigolo\n",
      "livre.N2.F buriza\n",
      "Zagnir.N2.M zaNir\n",
      "ouvrir tubop\n",
      "flèche.N2.F Sonizi\n",
      "force.N1.N Seteruk\n",
      "mettre taZm\n",
      "rencontrer mobid\n",
      "vers fu\n",
      "montrer elets\n",
      "de toS\n",
      "pomme.N2.M rutoza\n",
      "trouver mimuz\n",
      "IND.ART Ze\n",
      "perdu ferla\n",
      "tronc.N2.M satame\n",
      "voir iSdif\n",
      "nouveau niNu\n",
      "piège.N1.M faduNe\n",
      "reposer bukr\n",
      "partir gotop\n",
      "morceau.N1.F tapilu\n",
      "ancien moldu\n",
      "voler flup\n",
      "histoire.N1.F geSiso\n",
      "en ne\n",
      "souffler venom\n",
      "dans po\n",
      "bouche.N2.M gurusu\n",
      "revoir fidj\n",
      "chef.N2.M lubrik\n",
      "raconter kaNil\n",
      "chemin.N1.M vegalum\n",
      "englouti glabo\n",
      "dévoiler magob\n",
      "sur Zik\n",
      "quête.N1.N savomu\n",
      "sauveur.N2.N leNafe\n",
      "féliciter Zizel\n",
      "pendant akad\n",
      "DEF.ART nu\n",
      "village.N1.M dezato\n",
      "tellaufi.N1.F telofi\n",
      "à ni\n",
      "être vokel\n",
      "lunette.N2.M firule\n",
      "voyage.N1.F razebu\n",
      "pause.N1.F kaSeZu\n",
      "lutin.N2.N lepuruSo\n",
      "aventure.N1.F bokenuN\n",
      "sept geZo\n",
      "trésor.N2.F mopinu\n",
      "fond.N1.N kagumi\n",
      "détruire Zupet\n",
      "garçon.N1.M vozubli\n",
      "recherche.N1.N foreSu\n",
      "cité.N1.F tizer\n",
      "bloquer kolb\n",
      "troupe.N2.N kunati\n",
      "avec mileb\n",
      "parler tSaper\n",
      "après gopun\n",
      "envoyer tuvak\n",
      "futur zimoke\n",
      "nom.N1.M Zezame\n",
      "bout.N2.N tuboca\n",
      "DEM.DEM or\n",
      "dinosaure.N2.M rorapo\n",
      "chanter lestikr\n",
      "quatre teserako\n",
      "former maZik\n",
      "Arthur.N2.M arutur\n",
      "jour.N1.N lutoga\n",
      "pour lal\n",
      "expliquer potir\n",
      "arbre.N2.F bagape\n",
      "petit ʃoli\n",
      "enfant.N2.N kinude\n",
      "il g\n",
      "flûte.N2.M bodola\n",
      "dragon.N2.M muSula\n",
      "jumelle.N2.F bizili\n",
      "six zoru\n",
      "arrêter labr\n",
      "légende.N1.F dasetu\n",
      "ami.N2.N modaSi\n",
      "aide.N1.N neZofi\n",
      "deux viotse\n",
      "grand blinu\n",
      "amitié.N1.M tomoda\n",
      "serpent.N2.N gedala\n",
      "cinq pendi\n",
      "dessin.N1.F segika\n",
      "Patrick.N2.M paterik\n",
      "gros Somaso\n",
      "milieu.N1.N mufele\n",
      "trois klimo\n",
      "entre beN\n",
      "guerrière.N2.F kurige\n",
      "repas.N1.F sekuZi\n",
      "grotte.N2.F voseda\n",
      "feu.N1.F fevegi\n",
      "rechercher serS\n",
      "mortel rotela\n",
      "ouverture.N1.N fonuNe\n",
      "avancer nirol\n"
     ]
    }
   ],
   "source": [
    "for l in PFM.lexique.lexemes:\n",
    "    print l,PFM.lexique.lexemes[l].stem"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp=test.reset_index()\n",
    "temp[\"Nombre\"]=pd.Categorical(temp[\"Nombre\"],categories=[\"Sg\",\"Du\",\"Pl\"],ordered=True)\n",
    "temp.sort_values(\"Nombre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
