{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "#########################IMPORTS############################################\n",
    "from os.path import expanduser\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, YamlDuplicates\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle\n",
    "#from cellbell import ding\n",
    "\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalaba3-Lexique-Series\n"
     ]
    }
   ],
   "source": [
    "print(theNotebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter\n",
    "\n",
    "le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Kanonik\n"
     ]
    }
   ],
   "source": [
    "%store -r numerosKalaba typeKalaba\n",
    "# numerosKalaba=[4]\n",
    "print numerosKalaba, typeKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "devnag=False\n",
    "# devnag=True\n",
    "\n",
    "kalabaVoyelles=u\"ieaou\"\n",
    "kalabaConsonnes=u\"ptkbdgmnNfTsSvDzZrljw\"\n",
    "kalabaIPA=[u\"ʃ\",u\"ʒ\",u\"ŋ\",u\"θ\", u\"ð\"]\n",
    "fixedPhonInventory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = expanduser(\"~\")\n",
    "\n",
    "if typeKalaba!=\"Kanonik\":\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/\"\n",
    "    serie=repertoire+\"21-\"\n",
    "    nomsKalabas=[serie+\"K%d/\"%num for num in numerosKalaba]\n",
    "else:\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-UE4-Morphologie/\"\n",
    "    serie=repertoire+\"K-22/\"\n",
    "    nomsKalabas=[serie+\"Kanonik-%02d/\"%num for num in numerosKalaba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "if devnag:\n",
    "    declarationsExt=\"dn\"\n",
    "else:\n",
    "    declarationsExt=\"tex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExemple(lDict):\n",
    "    exKey=lDict.keys()[0]\n",
    "    if isinstance(lDict[exKey],dict):\n",
    "        result=getExemple(lDict[exKey])\n",
    "    elif isinstance(lDict[exKey],list):\n",
    "        result=lDict[exKey][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomDeclaration=\"Declarations.%s\"%declarationsExt\n",
    "nomDeclarationRad=\"Declarations-Radicaux.%s\"%declarationsExt\n",
    "nomDeclarationDec=\"Declarations-Decoupages.%s\"%declarationsExt\n",
    "nomTableauxRad=\"Tableaux-Gloses.yaml\"\n",
    "nomTableaux=\"Tableaux.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=0\n",
    "print_glose=True\n",
    "print_cloze=True\n",
    "print_radicaux=True\n",
    "cloze_expanded=True\n",
    "numeros={'1':'Un','2':'Deux','3':'Trois','4':'Quatre','5':'Cinq'}\n",
    "personnes={'1sg':'UnSg','2sg':'DeuxSg','3sg':'TroisSg',\n",
    "           '1du':'UnDu','2du':'DeuxDu','3du':'TroisDu',\n",
    "           '1pau':'UnPau','2pau':'DeuxPau','3pau':'TroisPau',\n",
    "           '1pl':'UnPl','2pl':'DeuxPl','3pl':'TroisPl'}\n",
    "\n",
    "if devnag:\n",
    "    commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\grapho{\\\\dn %s}}\"    \n",
    "    #commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{\\\\dn %s}}\"    \n",
    "    #commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}{\\\\dn %s}}\"\n",
    "else:\n",
    "    commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\grapho{%s}}\"    \n",
    "    #commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{\\\\graphoSkip}\\\\grapho{%s}}\"    \n",
    "    #commandGrapho=\"\\\\newcommand{\\\\%s}{\\\\strutgb{0pt}{%s}}\"\n",
    "\n",
    "commandPhono=u\"\\\\newcommand{\\\\%sP}{\\\\textipa{%s}}\"\n",
    "commandPhonoDecoupe=u\"\\\\newcommand{\\\\%sD}{\\\\textipa{%s}}\"\n",
    "commandGlose=u\"\\\\newcommand{\\\\%sG}{\\\\textGlose{%s}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grapho(graphie):\n",
    "    def change_monograms(chaine):\n",
    "        result=\"\"\n",
    "        for monogramme in chaine:\n",
    "            if monogramme in monogrammes:\n",
    "                result+=monogrammes[monogramme]\n",
    "            else:\n",
    "                result+=monogramme\n",
    "        return result\n",
    "\n",
    "    def change_bigrams(chaine):\n",
    "        if monogrammes:\n",
    "            result=change_monograms(chaine)\n",
    "        else:\n",
    "            result=chaine\n",
    "        if bigrammes:\n",
    "            regexBigrammes=\"|\".join(bigrammes.keys())\n",
    "            changements=re.findall(regexBigrammes,result)\n",
    "            for bigramme in changements:\n",
    "                result=result.replace(bigramme,bigrammes[bigramme])\n",
    "        return result\n",
    "    \n",
    "    def change_vocmods(chaine):\n",
    "        result=chaine\n",
    "        if len(chaine)==2:\n",
    "            cons=chaine[:-1]\n",
    "            voc=chaine[-1]\n",
    "            if voc in vocmods:\n",
    "                result=u\"\\\\\"+vocmods[voc]+\"{%s}\"%cons\n",
    "#         print result\n",
    "        return result\n",
    "        \n",
    "    ######\n",
    "    #\n",
    "    # Changer la regexp pour s'adapter à phonology.yaml\n",
    "    #\n",
    "    ######\n",
    "    \n",
    "    chunks=re.findall(ur\"\\s+|[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]?[aeiouAEIUO]?\", graphie,re.U)\n",
    "    result=[]\n",
    "    if debug: print graphie\n",
    "    for chunk in chunks:\n",
    "        if debug: print chunk,\n",
    "        #ATTENTION : YAML interprète \"no\" comme FALSE\n",
    "        if chunk in syllabes.keys():\n",
    "            lSyllabe=syllabes[chunk]\n",
    "            result.append(syllabes[chunk])\n",
    "        else:\n",
    "            lSyllabe=chunk\n",
    "        if vocmods:\n",
    "            lSyllabe=change_vocmods(lSyllabe)\n",
    "        result.append(lSyllabe)\n",
    "    if debug: print\n",
    "    return change_bigrams(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cloze(glose):\n",
    "    if debug: print [glose]\n",
    "    chunks=re.findall(r\"\\\\cacherGloses{([^}]*)?}|(\\w+)\", glose,re.UNICODE)\n",
    "    result=[]\n",
    "    for chunk in chunks:\n",
    "        result.extend([x for x in chunk if x!=\"\"])\n",
    "    return (u\"%s;\"%len(result)+\";\".join(result),\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table,boolUTF8=True):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    if boolUTF8:\n",
    "        return result\n",
    "    else:\n",
    "        return result.encode(\"utf8\")\n",
    "#translit=string.maketrans(u'iueoaftgzZvjkSpN',u'tgazpHTGZJVkXyxI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escapeGabarit(forme):\n",
    "    result=forme\n",
    "    for i in \"123\":\n",
    "#         result=result.replace(i,\"\\\\textnormal{C}$_{%s}$\"%i)\n",
    "#         result=result.replace(str(int(i)+3),\"\\\\textnormal{C}$_{%s}^{m}$\"%i)\n",
    "        result=result.replace(i,\"\\\\*C\\\\textsubscript{\\\\*%s}\"%i)\n",
    "        result=result.replace(str(int(i)+3),\"\\\\*C\\\\textsubscript{\\\\*%s\\\\textsuperscript{m}}\"%i)\n",
    "#     result=result.replace(\"V\",\"\\\\textnormal{V}\")        \n",
    "#     result=result.replace(\"A\",\"\\\\textnormal{V}$_{\\\\textnormal{\\\\tiny apo}}$\")        \n",
    "    result=result.replace(\"A\",\"\\\\*V\\\\textsubscript{apo}\")        \n",
    "\n",
    "    return result\n",
    "\n",
    "def escapeRacine(forme):\n",
    "    m=re.match(ur\"(.*)racine\\(([^)]+)\\)x(.*)\",forme)\n",
    "    if m:\n",
    "        prefixe=m.group(1)\n",
    "        if debug: print prefixe\n",
    "        racine=\"\\\\racine{%s}\"%m.group(2)\n",
    "        if debug: print racine\n",
    "        suffixe=m.group(3)\n",
    "        suffixes=re.split(ur\"([-+])\",suffixe)\n",
    "        gabarit=\"$\\\\times$\\\\gabarit{%s}\"%escapeGabarit(suffixes[0])\n",
    "        terminaison=\"\".join(suffixes[1:])\n",
    "        return prefixe+racine+gabarit+terminaison\n",
    "    else:\n",
    "        return forme\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolPhonInventory(forme,consonnes,voyelles):\n",
    "    lForme=forme\n",
    "    for c in kalabaIPA:\n",
    "        lForme=lForme.replace(c,\"\")\n",
    "    return re.findall(ur\"[^%s%s]\"%(consonnes,voyelles),lForme)\n",
    "    \n",
    "def boolHiatus(forme,voyelles):\n",
    "    return re.findall(ur\"(?=([%s][%s]))\"%(voyelles,voyelles),forme)\n",
    "    \n",
    "def boolVoyelleInitiale(forme,voyelles):\n",
    "    if forme[0] in voyelles:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bilanVoyellesInitiales(voc,cons,label,cat,thresh=0.1):\n",
    "    nbVoc=len(voc)\n",
    "    nbCons=len(cons)\n",
    "    nbTot=nbVoc+nbCons\n",
    "    ratio=float(nbVoc)/nbTot\n",
    "    if ratio>=thresh and cat not in \"PREP DET\".split():\n",
    "        print \"\\t\",cat,label,\"Voyelles initiales\",float(nbVoc)/nbTot\n",
    "        ding()\n",
    "    return\n",
    "\n",
    "def pourcent(nombre):\n",
    "    return u\"%2.0f%%\"%(100*nombre)\n",
    "\n",
    "def bilanPhon(cat,thresh=0.1):\n",
    "    nbVocStems=len(vocRad)\n",
    "    nbConsStems=len(consRad)\n",
    "    nbStems=nbVocStems+nbConsStems\n",
    "    ratioVocStems=float(nbVocStems)/nbStems\n",
    "    nbVocForms=len(vocForm)\n",
    "    nbConsForms=len(consForm)\n",
    "    nbForms=nbVocForms+nbConsForms\n",
    "    ratioVocForms=float(nbVocForms)/nbForms\n",
    "    nbHiatus=len(hiatusForm)\n",
    "    ratioHiatus=float(nbHiatus)/nbForms\n",
    "    nbHorsInv=len(horsPhon)\n",
    "    if ratioVocForms>=thresh and cat not in \"PREP DET\".split():\n",
    "        print \"\\t\",cat,\"Formes\",\"Voyelles initiales\",pourcent(ratioVocForms),nbForms\n",
    "        ding()\n",
    "    elif ratioVocStems>=thresh and cat not in \"PREP DET\".split():\n",
    "        print \"\\t\",cat,\"Radicaux\",\"Voyelles initiales\",pourcent(ratioVocStems),nbStems\n",
    "        ding()\n",
    "    if ratioHiatus>=thresh and cat not in \"PREP DET\".split():\n",
    "        print \"\\t\",cat,\"hiatus\",pourcent(ratioHiatus),nbForms\n",
    "    if nbHorsInv>0:\n",
    "        print \"\\t\",\", \".join(horsPhon)\n",
    "    return\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolPhonInventory(u\"teiuoit\",kalabaConsonnes,kalabaVoyelles)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp=u\"mu-racine(releD)x1V2a3a-t-i\"\n",
    "escapeRacine(temp)\n",
    "print case.radical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération lexique : Kanonik-02 16:43:06\n",
      "\ttubocasif, tubocabar, tubocaluv\n",
      "Génération terminée : 16:43:07\n"
     ]
    }
   ],
   "source": [
    "for serie in nomsKalabas:\n",
    "    print \"Génération lexique :\",serie.split(\"/\")[-2], time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "    '''\n",
    "    Lecture des fichiers de paramètres\n",
    "     1) Phonology.yaml pour \n",
    "         - les voyelles, les consonnes\n",
    "         - la correspondance pour l'écrit (symbole => lettre, syllabe => lettres)\n",
    "         - la correspondance pour l'oral\n",
    "         - la désaccentuation et les déligatures du français\n",
    "         - les gabarits ?\n",
    "         - l'apophonie, les mutations consonantiques\n",
    "     2) Stems.yaml pour\n",
    "         - les catégories et les classes\n",
    "         - les radicaux et les formes correspondantes\n",
    "             - la première forme sert de forme de citation\n",
    "     3) MorphoSyntax.yaml pour\n",
    "         - définition de la valeur des formes verbales du français\n",
    "         - définition des attributs de chaque catégorie\n",
    "         - valeur par défaut pour chaque attribut\n",
    "         - définition des cas pour SUJ, OBJ, IND et PREP\n",
    "         - .../...\n",
    "         - définition des constituants et de l'ordre dans les syntagmes\n",
    "         - définition des contractions du français (du => de le, etc.)\n",
    "    '''\n",
    "    with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "        phonology=yaml.safe_load(stream)\n",
    "    with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "        stems=yaml.safe_load(stream)\n",
    "    lexiqueTestPrep=getExemple(stems[\"PREP\"])\n",
    "    lexiqueTestNoun=getExemple(stems[\"NOM\"])\n",
    "    lexiqueTestHyper=getExemple(stems[\"ADJ\"])\n",
    "    lexiqueTestVerbe=getExemple(stems[\"VER\"])\n",
    "    \n",
    "    with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "        morphosyntax=yaml.safe_load(stream)\n",
    "        \n",
    "    '''\n",
    "    Récupération des données du ParFuMor\n",
    "    '''\n",
    "    with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "       PFM.hierarchieCF = pickle.load(input)\n",
    "    with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "       PFM.lexique = pickle.load(input)\n",
    "    with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "       PFM.regles = pickle.load(input)\n",
    "\n",
    "    if debug: print \"Test PREP\"; PFM.lexique.lexemes[lexiqueTestPrep]\n",
    "\n",
    "    if fixedPhonInventory:\n",
    "        consonnes=kalabaConsonnes\n",
    "        voyelles=kalabaVoyelles\n",
    "    else:\n",
    "        consonnes=phonology[\"consonnes\"]\n",
    "        voyelles=phonology[\"voyelles\"]\n",
    "    gabarits=phonology[\"gabarits\"]\n",
    "    derives=phonology[\"derives\"]\n",
    "    nom_classe=phonology[\"nom_classe\"]\n",
    "    nom_apo=phonology[\"apophonies\"]\n",
    "    nom_mut=phonology[\"mutations\"]\n",
    "    syllabes=phonology[\"syllabes\"]\n",
    "\n",
    "    if \"Cas\" in morphosyntax:\n",
    "        casSyntagmes=morphosyntax[\"Cas\"]\n",
    "    else:\n",
    "        casSyntagmes=\"\"\n",
    "    lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "    casPreposition={}\n",
    "    for preposition in lexiquePrepositions:\n",
    "        prep=preposition.upper()\n",
    "        if casSyntagmes and prep in casSyntagmes:\n",
    "            casPreposition[preposition]=casSyntagmes[prep]\n",
    "        elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "            casPreposition[preposition]=casSyntagmes[\"PREP\"]\n",
    "        else:\n",
    "            casPreposition[preposition]=\"\"\n",
    "    glosePREP={x:u\"%s%s\"%(x.upper(),cacherGloses(\"[\"+casPreposition[x].strip(\"+\").capitalize()+\"]\")) for x in casPreposition if \"+\" in casPreposition[x]}\n",
    "\n",
    "    try:\n",
    "        __IPYTHON__ \n",
    "        ipython=True\n",
    "    except: \n",
    "        ipython=False\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Constitution d'un entête pour les fichiers TEX en sortie\n",
    "        - nom du script\n",
    "        - date du run\n",
    "    '''\n",
    "    texHeader=[]\n",
    "    version=theNotebook\n",
    "    texHeader.append(\"%% script : \"+version)\n",
    "    texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "    if devnag:\n",
    "        texHeader.append('@hindi')\n",
    "    if debug: print \"\\n\".join(texHeader)\n",
    "    \n",
    "    if ipython or True:\n",
    "    #    lexeme_nom=\"lexemes.txt\"\n",
    "    #    phrase_nom=\"phrases.txt\"\n",
    "        pass\n",
    "    else:\n",
    "        parser=optparse.OptionParser()\n",
    "        parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "        parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "        parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "        parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "        (options, args) = parser.parse_args()\n",
    "        lexeme_nom=args[0]\n",
    "        phrase_nom=args[1]\n",
    "\n",
    "    phonoIn =  unicode(phonology[\"translations\"][\"grapho\"][\"in\"])\n",
    "    graphoIn = [ord(char) for char in phonoIn]\n",
    "    graphoOut = unicode(phonology[\"translations\"][\"grapho\"][\"out\"])\n",
    "    translit = dict(zip(graphoIn, graphoOut))\n",
    "    if \"monogrammes\" in phonology[\"translations\"]:\n",
    "        monogrammes = phonology[\"translations\"][\"monogrammes\"]\n",
    "    else:\n",
    "        monogrammes = {}\n",
    "    bigrammes = phonology[\"translations\"][\"bigrammes\"]\n",
    "    if \"vocmods\" in phonology[\"translations\"]:\n",
    "        vocmods=phonology[\"translations\"][\"vocmods\"]\n",
    "    else: vocmods=None\n",
    "\n",
    "    accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "    deaccentIn = [ord(char) for char in accentedIn]\n",
    "    deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "    deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "    deligatures=phonology[\"translations\"][\"deligatures\"]\n",
    "\n",
    "    tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "    ipaIn = [ord(char) for char in tipaIn]\n",
    "    ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "    toipa = dict(zip(ipaIn, ipaOut))\n",
    "\n",
    "    tableaux={}\n",
    "    tableauxGloses={}\n",
    "    gloseClozes={}\n",
    "    declarations=[]\n",
    "    declarationsRad=[]\n",
    "    declarationsDec=[]\n",
    "    vocRatio={}\n",
    "    hiatusRatio={}\n",
    "    \n",
    "    '''\n",
    "    Pour chaque catégorie\n",
    "    '''\n",
    "    for categorie in PFM.lexique.catLexeme:\n",
    "        '''\n",
    "        compter le nombre de radicaux et de formes qui commencent par une voyelle et par une consonne\n",
    "        compter le nombre de hiatus dans les formes\n",
    "        '''\n",
    "        vocRad=[]\n",
    "        consRad=[]\n",
    "        vocForm=[]\n",
    "        consForm=[]\n",
    "        hiatusForm=[]\n",
    "        hiatusCounts={}\n",
    "        horsPhon=[]\n",
    "        '''\n",
    "        si la catégorie n'est pas dans le tableau, il faut l'ajouter dans les trois structures :\n",
    "            tableaux : les lignes à ajouter à la fin du document LaTeX sans les gloses\n",
    "            tableauxGloses : les lignes à ajouter à la fin du document LaTeX avec les gloses\n",
    "            gloseClozes : les informations sur les mots pour les questions CLOZE \n",
    "        '''\n",
    "        if not categorie in tableaux:\n",
    "            tableaux[categorie]=set()\n",
    "            tableauxGloses[categorie]=set()\n",
    "            gloseClozes[categorie]=[]\n",
    "        if debug: print categorie\n",
    "        '''\n",
    "        pour chaque lexème de la catégorie\n",
    "        '''\n",
    "        for lexeme in PFM.lexique.catLexeme[categorie]:\n",
    "            stemLexeme=PFM.lexique.lexemes[lexeme].stem\n",
    "            if boolVoyelleInitiale(stemLexeme,voyelles):\n",
    "                vocRad.append(stemLexeme)\n",
    "            else:\n",
    "                consRad.append(stemLexeme)\n",
    "            if debug: print \"lexeme,PFM.lexique.lexemes[lexeme]\",lexeme,PFM.lexique.lexemes[lexeme].stem\n",
    "            '''\n",
    "            pour chaque case du paradigme du lexème\n",
    "            '''\n",
    "            for case in PFM.lexique.lexemes[lexeme].paradigme.cases:\n",
    "                formLexeme=case.forme\n",
    "                if boolVoyelleInitiale(formLexeme,voyelles):\n",
    "                    vocForm.append(formLexeme)\n",
    "                else:\n",
    "                    consForm.append(formLexeme)\n",
    "                if boolHiatus(formLexeme,voyelles):\n",
    "                    hiatusForm.append(formLexeme)\n",
    "                if boolPhonInventory(formLexeme,consonnes,voyelles):\n",
    "                    horsPhon.append(formLexeme)\n",
    "                if debug: print \"case\", case\n",
    "                caseGlose=case.glose\n",
    "                '''\n",
    "                Les éléments des catégories majeures (N,V,Adj) sont représentés en minuscules\n",
    "                    => les noms propres commencent par une capitale\n",
    "                Les éléments grammaticaux sont représentés en majuscules\n",
    "                '''\n",
    "                if categorie in PFM.categoriesMajeures:\n",
    "                    nom=PFM.lexique.lexemes[lexeme].nom\n",
    "                else:\n",
    "                    nom=PFM.lexique.lexemes[lexeme].nom.upper()\n",
    "                    gloseCase=case.glose\n",
    "                    if categorie==\"PREP\" and gloseCase in glosePREP:\n",
    "                        caseGlose=glosePREP[gloseCase]\n",
    "                    elif categorie==\"PREP\":\n",
    "                        caseGlose=caseGlose.upper()\n",
    "                ref=nom.replace(\"-\",\"\")\n",
    "                ref=PFM.modifierGlose(ref,case.sigma,\"ref\")\n",
    "                ref=recoder(ref,deaccent)\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                Dealing with LaTeX names format for commands\n",
    "                \n",
    "                 1) no ligatures\n",
    "                 2) no numbers\n",
    "                '''\n",
    "                \n",
    "                for ligature in deligatures:\n",
    "                    ref=ref.replace(ligature,deligatures[ligature])\n",
    "                for pers in personnes:\n",
    "                    ref=ref.replace(pers,personnes[pers])\n",
    "                for num in numeros:\n",
    "                    ref=ref.replace(num,numeros[num])\n",
    "                \n",
    "                    \n",
    "                grapho=chaine2utf8(re.sub(ur\"\\s+\",ur\"\",parse_grapho(recoder(case.forme,translit))))\n",
    "                phonoRad=case.detoure.replace(\" \",\"\")\n",
    "                phonoDec=escapeRacine(case.decoupe)\n",
    "                if debug: print \"phono Rad\", phonoRad\n",
    "                phono=case.forme.replace(\" \",\"\")\n",
    "\n",
    "                '''\n",
    "                Creating the DECLARATIONS TEX contents\n",
    "                '''\n",
    "                \n",
    "                declarations.append(commandGrapho%(ref,grapho))\n",
    "                declarations.append(commandPhono%(ref,phono))\n",
    "                declarations.append(commandGlose%(ref,caseGlose))\n",
    "                declarationsRad.append(commandGrapho%(ref,grapho))\n",
    "                declarationsRad.append(commandPhono%(ref,phonoRad))\n",
    "                declarationsRad.append(commandPhonoDecoupe%(ref,phonoDec))\n",
    "                declarationsRad.append(commandGlose%(ref,caseGlose))\n",
    "                declarationsDec.append(commandGrapho%(ref,grapho))\n",
    "                declarationsDec.append(commandPhono%(ref,phonoDec))\n",
    "                declarationsDec.append(commandGlose%(ref,caseGlose))\n",
    "                \n",
    "                '''\n",
    "                Creating the TABLEAUX TEX contents\n",
    "                '''\n",
    "                \n",
    "                tableauxGloses[categorie].add(\"\\\\\"+ref+\" & \\\\\"+ref+\"P & \\\\\"+ref+\"G \\\\\\\\\")\n",
    "                tableaux[categorie].add(\"\\\\\"+ref+\" & \\\\\"+ref+\"P & \\\\blanc{\\\\\"+ref+\"G} \\\\\\\\\")\n",
    "                \n",
    "                '''\n",
    "                Creating the CLOZE CSV contents\n",
    "                '''\n",
    "                \n",
    "                vedette=nom.split(\".\")[0]\n",
    "                gloses,strGlose=parse_cloze(case.glose)\n",
    "#                print gloses,case.decoupe,case.detoure\n",
    "                phono=case.forme.replace(\" \",\"\")\n",
    "                if debug: print \"grapho, recoder(phono,toipa)\", [grapho, recoder(phono,toipa)]\n",
    "                if cloze_expanded:\n",
    "                    try:\n",
    "                        if debug: print ref\n",
    "                        cloze=u\";\".join([ref,vedette,\n",
    "                                         categorie,\n",
    "                                         recoder(case.radical,toipa),recoder(case.racine,toipa),\n",
    "                                         recoder(phono,toipa),recoder(case.decoupe,toipa),\n",
    "                                         case.sigma,\n",
    "                                         strGlose,\n",
    "                                         gloses])\n",
    "                    except NameError:\n",
    "                        print ref\n",
    "                        cloze=u\";\".join([ref,vedette,\n",
    "                                         categorie,\n",
    "                                         recoder(case.radical,toipa),recoder(case.racine,toipa),\n",
    "                                         recoder(phono,toipa),\n",
    "                                         strGlose,\n",
    "                                         gloses])\n",
    "                else:\n",
    "                    try:\n",
    "                        print ref\n",
    "                        cloze=u\";\".join([ref,vedette,categorie,recoder(phono,toipa),recoder(case.decoupe,toipa),case.sigma,gloses])\n",
    "                    except NameError:\n",
    "                        print ref\n",
    "                        cloze=u\";\".join([ref,vedette,categorie,recoder(phono,toipa),gloses])\n",
    "                gloseClozes[categorie].append(cloze)\n",
    "#         bilanVoyellesInitiales(vocRad,consRad,\"Radicaux\",categorie)\n",
    "#         bilanVoyellesInitiales(vocForm,consForm,\"Formes\",categorie)\n",
    "        bilanPhon(categorie)\n",
    "        '''\n",
    "        Écriture des fichiers en sortie\n",
    "         1) déclarations sans les radicaux\n",
    "         2) déclarations avec les radicaux\n",
    "         3) données pour les questions CLOZE\n",
    "         4) tableaux de vocabulaire avec gloses\n",
    "         5) tableaux de vocabulaire sans gloses\n",
    "        '''\n",
    "        with codecs.open(serie+nomDeclaration, 'wb', encoding='utf8') as output:\n",
    "            for declaration in texHeader+declarations:\n",
    "        #        print type(declaration),declaration\n",
    "                output.write(declaration+\"\\n\")\n",
    "\n",
    "        with codecs.open(serie+nomDeclarationRad, 'wb', encoding='utf8') as output:\n",
    "            for declaration in texHeader+declarationsRad:\n",
    "        #        print type(declaration),declaration\n",
    "                output.write(declaration+\"\\n\")\n",
    "\n",
    "#         with codecs.open(serie+nomDeclarationDec, 'wb', encoding='utf8') as output:\n",
    "#             for declaration in texHeader+declarationsDec:\n",
    "#                 print type(declaration),declaration\n",
    "#                 output.write(declaration+\"\\n\")\n",
    "\n",
    "        with codecs.open(serie+\"Clozes.txt\", 'wb', encoding='utf8') as output:\n",
    "            for categorie in gloseClozes:\n",
    "                output.write(\"#\\t\"+categorie+\"\\n#\\n#\\n\")\n",
    "                for cloze in gloseClozes[categorie]:\n",
    "                    output.write(cloze+\"\\n\")\n",
    "                output.write(\"#\\n#\\n#\\n\")\n",
    "\n",
    "        yaml.safe_dump(tableauxGloses, file(serie+nomTableauxRad, 'w'), encoding='utf-8', allow_unicode=True)\n",
    "        yaml.safe_dump(tableaux, file(serie+nomTableaux, 'w'), encoding='utf-8', allow_unicode=True)\n",
    "        if devnag:\n",
    "            os.system('devnag %s'%(serie+nomDeclaration))\n",
    "            os.system('devnag %s'%(serie+nomDeclarationRad))\n",
    "            os.system('devnag %s'%(serie+nomDeclarationDec))    \n",
    "print u\"Génération terminée :\", time.strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Arthur': [u'Arthur.N2.M'],\n",
       " u'DEF': [u'DEF.ART'],\n",
       " u'DEM': [u'DEM.DEM'],\n",
       " u'IND': [u'IND.ART'],\n",
       " u'Patrick': [u'Patrick.N2.M'],\n",
       " u'Zagnir': [u'Zagnir.N2.M'],\n",
       " u'aide': [u'aide.N1.N'],\n",
       " u'ami': [u'ami.N2.N'],\n",
       " u'amis': [u'ami.N2.N'],\n",
       " u'amiti\\xe9': [u'amiti\\xe9.N1.M'],\n",
       " u'ancien': [u'ancien'],\n",
       " u'anciens': [u'ancien'],\n",
       " u'apr\\xe8s': [u'apr\\xe8s'],\n",
       " u'arbre': [u'arbre.N2.F'],\n",
       " u'arbres': [u'arbre.N2.F'],\n",
       " u'arr\\xeataient': [u'arr\\xeater'],\n",
       " u'arr\\xeatait': [u'arr\\xeater'],\n",
       " u'arr\\xeate': [u'arr\\xeater'],\n",
       " u'arr\\xeatent': [u'arr\\xeater'],\n",
       " u'arr\\xeater': [u'arr\\xeater'],\n",
       " u'avance': [u'avancer'],\n",
       " u'avancent': [u'avancer'],\n",
       " u'avancer': [u'avancer'],\n",
       " u'avanc\\xe8rent': [u'avancer'],\n",
       " u'avan\\xe7a': [u'avancer'],\n",
       " u'avec': [u'avec'],\n",
       " u'aventure': [u'aventure.N1.F'],\n",
       " u'aventures': [u'aventure.N1.F'],\n",
       " u'bloquaient': [u'bloquer'],\n",
       " u'bloquait': [u'bloquer'],\n",
       " u'bloque': [u'bloquer'],\n",
       " u'bloquent': [u'bloquer'],\n",
       " u'bloquer': [u'bloquer'],\n",
       " u'bouche': [u'bouche.N2.M'],\n",
       " u'bout': [u'bout.N2.N'],\n",
       " u'ce': [u'DEM.DEM'],\n",
       " u'ces': [u'DEM.DEM'],\n",
       " u'cet': [u'DEM.DEM'],\n",
       " u'cette': [u'DEM.DEM'],\n",
       " u'chanta': [u'chanter'],\n",
       " u'chante': [u'chanter'],\n",
       " u'chantent': [u'chanter'],\n",
       " u'chanter': [u'chanter'],\n",
       " u'chant\\xe8rent': [u'chanter'],\n",
       " u'chef': [u'chef.N2.M'],\n",
       " u'chefs': [u'chef.N2.M'],\n",
       " u'chemin': [u'chemin.N1.M'],\n",
       " u'cinq': [u'cinq'],\n",
       " u'cit\\xe9': [u'cit\\xe9.N1.F'],\n",
       " u'd': [u'IND.ART'],\n",
       " u'dE': [u'IND.ART'],\n",
       " u'dans': [u'dans'],\n",
       " u'de': [u'de'],\n",
       " u'des': [u'IND.ART'],\n",
       " u'dessin': [u'dessin.N1.F'],\n",
       " u'deux': [u'deux'],\n",
       " u'dinosaure': [u'dinosaure.N2.M'],\n",
       " u'disparaissent': [u'dispara\\xeetre'],\n",
       " u'dispara\\xeet': [u'dispara\\xeetre'],\n",
       " u'dispara\\xeetre': [u'dispara\\xeetre'],\n",
       " u'disparurent': [u'dispara\\xeetre'],\n",
       " u'disparut': [u'dispara\\xeetre'],\n",
       " u'dragon': [u'dragon.N2.M'],\n",
       " u'd\\xe9sert': [u'd\\xe9sert.N1.F'],\n",
       " u'd\\xe9serts': [u'd\\xe9sert.N1.F'],\n",
       " u'd\\xe9truire': [u'd\\xe9truire'],\n",
       " u'd\\xe9truisent': [u'd\\xe9truire'],\n",
       " u'd\\xe9truisirent': [u'd\\xe9truire'],\n",
       " u'd\\xe9truisit': [u'd\\xe9truire'],\n",
       " u'd\\xe9truit': [u'd\\xe9truire'],\n",
       " u'd\\xe9voilaient': [u'd\\xe9voiler'],\n",
       " u'd\\xe9voilait': [u'd\\xe9voiler'],\n",
       " u'd\\xe9voile': [u'd\\xe9voiler'],\n",
       " u'd\\xe9voilent': [u'd\\xe9voiler'],\n",
       " u'd\\xe9voiler': [u'd\\xe9voiler'],\n",
       " u'elle': [u'il'],\n",
       " u'elles': [u'il'],\n",
       " u'en': [u'en'],\n",
       " u'enfant': [u'enfant.N2.N'],\n",
       " u'enflamm\\xe9': [u'enflamm\\xe9'],\n",
       " u'enflamm\\xe9es': [u'enflamm\\xe9'],\n",
       " u'englouti': [u'englouti'],\n",
       " u'engloutie': [u'englouti'],\n",
       " u'entre': [u'entre'],\n",
       " u'entr\\xe9e': [u'entr\\xe9e.N1.M'],\n",
       " u'envoie': [u'envoyer'],\n",
       " u'envoient': [u'envoyer'],\n",
       " u'envoyaient': [u'envoyer'],\n",
       " u'envoyait': [u'envoyer'],\n",
       " u'envoyer': [u'envoyer'],\n",
       " u'est': [u'\\xeatre'],\n",
       " u'eux': [u'il'],\n",
       " u'expliquaient': [u'expliquer'],\n",
       " u'expliquait': [u'expliquer'],\n",
       " u'explique': [u'expliquer'],\n",
       " u'expliquent': [u'expliquer'],\n",
       " u'expliquer': [u'expliquer'],\n",
       " u'feu': [u'feu.N1.F'],\n",
       " u'fl\\xe8che': [u'fl\\xe8che.N2.F'],\n",
       " u'fl\\xe8ches': [u'fl\\xe8che.N2.F'],\n",
       " u'fl\\xfbte': [u'fl\\xfbte.N2.M'],\n",
       " u'fond': [u'fond.N1.N'],\n",
       " u'force': [u'force.N1.N'],\n",
       " u'forces': [u'force.N1.N'],\n",
       " u'forma': [u'former'],\n",
       " u'forme': [u'former'],\n",
       " u'forment': [u'former'],\n",
       " u'former': [u'former'],\n",
       " u'form\\xe8rent': [u'former'],\n",
       " u'futur': [u'futur'],\n",
       " u'f\\xe9licita': [u'f\\xe9liciter'],\n",
       " u'f\\xe9licite': [u'f\\xe9liciter'],\n",
       " u'f\\xe9licitent': [u'f\\xe9liciter'],\n",
       " u'f\\xe9liciter': [u'f\\xe9liciter'],\n",
       " u'f\\xe9licit\\xe8rent': [u'f\\xe9liciter'],\n",
       " u'gar\\xe7on': [u'gar\\xe7on.N1.M'],\n",
       " u'gar\\xe7ons': [u'gar\\xe7on.N1.M'],\n",
       " u'grand': [u'grand'],\n",
       " u'grande': [u'grand'],\n",
       " u'gros': [u'gros'],\n",
       " u'grotte': [u'grotte.N2.F'],\n",
       " u'guerri\\xe8re': [u'guerri\\xe8re.N2.F'],\n",
       " u'guerri\\xe8res': [u'guerri\\xe8re.N2.F'],\n",
       " u'histoire': [u'histoire.N1.F'],\n",
       " u'il': [u'il'],\n",
       " u'ils': [u'il'],\n",
       " u'jour': [u'jour.N1.N'],\n",
       " u'jumelle': [u'jumelle.N2.F'],\n",
       " u'jumelles': [u'jumelle.N2.F'],\n",
       " u'l': [u'DEF.ART'],\n",
       " u'la': [u'DEF.ART'],\n",
       " u'le': [u'DEF.ART'],\n",
       " u'les': [u'DEF.ART'],\n",
       " u'livre': [u'livre.N2.F'],\n",
       " u'lui': [u'il'],\n",
       " u'lunette': [u'lunette.N2.M'],\n",
       " u'lunettes': [u'lunette.N2.M'],\n",
       " u'lutin': [u'lutin.N2.N'],\n",
       " u'l\\xe9gende': [u'l\\xe9gende.N1.F'],\n",
       " u'met': [u'mettre'],\n",
       " u'mettent': [u'mettre'],\n",
       " u'mettre': [u'mettre'],\n",
       " u'milieu': [u'milieu.N1.N'],\n",
       " u'mirent': [u'mettre'],\n",
       " u'mit': [u'mettre'],\n",
       " u'montra': [u'montrer'],\n",
       " u'montre': [u'montrer'],\n",
       " u'montrent': [u'montrer'],\n",
       " u'montrer': [u'montrer'],\n",
       " u'montr\\xe8rent': [u'montrer'],\n",
       " u'morceau': [u'morceau.N1.F'],\n",
       " u'morceaux': [u'morceau.N1.F'],\n",
       " u'mortel': [u'mortel'],\n",
       " u'mortels': [u'mortel'],\n",
       " u'nom': [u'nom.N1.M'],\n",
       " u'nouveau': [u'nouveau'],\n",
       " u'nouveaux': [u'nouveau'],\n",
       " u'ouverture': [u'ouverture.N1.N'],\n",
       " u'ouvraient': [u'ouvrir'],\n",
       " u'ouvrait': [u'ouvrir'],\n",
       " u'ouvre': [u'ouvrir'],\n",
       " u'ouvrent': [u'ouvrir'],\n",
       " u'ouvrir': [u'ouvrir'],\n",
       " u'parchemin': [u'parchemin.N1.M'],\n",
       " u'parchemins': [u'parchemin.N1.M'],\n",
       " u'parlaient': [u'parler'],\n",
       " u'parlait': [u'parler'],\n",
       " u'parle': [u'parler'],\n",
       " u'parlent': [u'parler'],\n",
       " u'parler': [u'parler'],\n",
       " u'part': [u'partir'],\n",
       " u'partaient': [u'partir'],\n",
       " u'partait': [u'partir'],\n",
       " u'partent': [u'partir'],\n",
       " u'partir': [u'partir'],\n",
       " u'pause': [u'pause.N1.F'],\n",
       " u'pendant': [u'pendant'],\n",
       " u'perdu': [u'perdu'],\n",
       " u'perdus': [u'perdu'],\n",
       " u'petit': [u'petit'],\n",
       " u'pi\\xe8ge': [u'pi\\xe8ge.N1.M'],\n",
       " u'pi\\xe8ges': [u'pi\\xe8ge.N1.M'],\n",
       " u'pomme': [u'pomme.N2.M'],\n",
       " u'pommes': [u'pomme.N2.M'],\n",
       " u'pour': [u'pour'],\n",
       " u'quatre': [u'quatre'],\n",
       " u'qu\\xeate': [u'qu\\xeate.N1.N'],\n",
       " u'racontaient': [u'raconter'],\n",
       " u'racontait': [u'raconter'],\n",
       " u'raconte': [u'raconter'],\n",
       " u'racontent': [u'raconter'],\n",
       " u'raconter': [u'raconter'],\n",
       " u'recherchE': [u'rechercher'],\n",
       " u'recherchaient': [u'rechercher'],\n",
       " u'recherchait': [u'rechercher'],\n",
       " u'recherche': [u'recherche.N1.N'],\n",
       " u'recherchent': [u'rechercher'],\n",
       " u'rechercher': [u'rechercher'],\n",
       " u'reconnaissent': [u'reconna\\xeetre'],\n",
       " u'reconna\\xeet': [u'reconna\\xeetre'],\n",
       " u'reconna\\xeetre': [u'reconna\\xeetre'],\n",
       " u'reconnurent': [u'reconna\\xeetre'],\n",
       " u'reconnut': [u'reconna\\xeetre'],\n",
       " u'rencontraient': [u'rencontrer'],\n",
       " u'rencontrait': [u'rencontrer'],\n",
       " u'rencontre': [u'rencontrer'],\n",
       " u'rencontrent': [u'rencontrer'],\n",
       " u'rencontrer': [u'rencontrer'],\n",
       " u'repaS': [u'repas.N1.F'],\n",
       " u'repas': [u'repas.N1.F'],\n",
       " u'reposaient': [u'reposer'],\n",
       " u'reposait': [u'reposer'],\n",
       " u'repose': [u'reposer'],\n",
       " u'reposent': [u'reposer'],\n",
       " u'reposer': [u'reposer'],\n",
       " u'revirent': [u'revoir'],\n",
       " u'revit': [u'revoir'],\n",
       " u'revoient': [u'revoir'],\n",
       " u'revoir': [u'revoir'],\n",
       " u'revoit': [u'revoir'],\n",
       " u'sauveur': [u'sauveur.N2.N'],\n",
       " u'sauveurs': [u'sauveur.N2.N'],\n",
       " u'sept': [u'sept'],\n",
       " u'serpent': [u'serpent.N2.N'],\n",
       " u'serpents': [u'serpent.N2.N'],\n",
       " u'six': [u'six'],\n",
       " u'sont': [u'\\xeatre'],\n",
       " u'soufflaient': [u'souffler'],\n",
       " u'soufflait': [u'souffler'],\n",
       " u'souffle': [u'souffler'],\n",
       " u'soufflent': [u'souffler'],\n",
       " u'souffler': [u'souffler'],\n",
       " u'sur': [u'sur'],\n",
       " u'tellaufi': [u'tellaufi.N1.F'],\n",
       " u'trois': [u'trois'],\n",
       " u'tronc': [u'tronc.N2.M'],\n",
       " u'troupe': [u'troupe.N2.N'],\n",
       " u'trouva': [u'trouver'],\n",
       " u'trouve': [u'trouver'],\n",
       " u'trouvent': [u'trouver'],\n",
       " u'trouver': [u'trouver'],\n",
       " u'trouv\\xe8rent': [u'trouver'],\n",
       " u'tr\\xe9sor': [u'tr\\xe9sor.N2.F'],\n",
       " u'tr\\xe9sors': [u'tr\\xe9sor.N2.F'],\n",
       " u'un': [u'IND.ART'],\n",
       " u'une': [u'IND.ART'],\n",
       " u'vers': [u'vers'],\n",
       " u'village': [u'village.N1.M'],\n",
       " u'villages': [u'village.N1.M'],\n",
       " u'voient': [u'voir'],\n",
       " u'voir': [u'voir'],\n",
       " u'voit': [u'voir'],\n",
       " u'vola': [u'voler'],\n",
       " u'vole': [u'voler'],\n",
       " u'volent': [u'voler'],\n",
       " u'voler': [u'voler'],\n",
       " u'vol\\xe8rent': [u'voler'],\n",
       " u'voyage': [u'voyage.N1.F'],\n",
       " u'voyaient': [u'voir'],\n",
       " u'voyait': [u'voir'],\n",
       " u'\\xe0': [u'\\xe0'],\n",
       " u'\\xe9taient': [u'\\xeatre'],\n",
       " u'\\xe9tait': [u'\\xeatre'],\n",
       " u'\\xeatre': [u'\\xeatre']}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chaine=\"dolutakeZi\"\n",
    "print \"parse\", parse_grapho(chaine)\n",
    "print \"parse, recoder\",recoder(parse_grapho(chaine),translit)\n",
    "print \"recoder\", recoder(chaine,translit)\n",
    "print \"recoder, parse\",parse_grapho(recoder(chaine,translit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREP\n"
     ]
    }
   ],
   "source": [
    "print case.sigma"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ref=PFM.lexique.lexemes['enfant.hyper.B.N1'].nom\n",
    "ref=PFM.lexique.lexemes['pleurer-act.VI.V1'].nom\n",
    "ref=ref.replace(\"-\",\"\")\n",
    "print ref\n",
    "PFM.modifierGlose(ref,case.sigma,\"ref\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lexeme='PRO'\n",
    "for case in PFM.lexique.lexemes[lexeme].paradigme.cases:\n",
    "    print case.sigma\n",
    "    ref=PFM.lexique.lexemes[lexeme].nom\n",
    "    ref=ref.replace(\"-\",\"\")\n",
    "    print ref,\n",
    "    print PFM.modifierGlose(ref,case.sigma,\"ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
