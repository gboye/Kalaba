{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problèmes et Extensions\n",
    "\n",
    "## Problèmes\n",
    "- javascript runs fail\n",
    "- faire de nouvelles sorties pour les kalabas sans séparateurs de mots\n",
    " - radicaux seuls\n",
    " - découpage en syntagmes pour l'exercice sur l'ordre des syntagmes\n",
    "\n",
    "## Extensions\n",
    "- traitement du paucal\n",
    " - 2,3,4,5 ou suffixe P sur le nom sans numéral\n",
    "- ajout des compléments/ajouts multiples\n",
    " - séparation par ;\n",
    " - gestion des dislocations gauches dans les multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "#from cellbell import ding\n",
    "from itertools import groupby\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle,copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(theNotebook)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gestion partagée des numéros à traiter & gestion des variantes\n",
    "\n",
    "Le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable\n",
    "\n",
    "Après la réussite de la variante de base, on change automatiquement la variante à -Corr pour générer les fichiers de solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Corr\n",
      "[5] Kalaba\n"
     ]
    }
   ],
   "source": [
    "# numerosKalaba=[5]\n",
    "# %store numerosKalaba\n",
    "%store -r numerosKalaba typeKalaba\n",
    "variante=\"\"\n",
    "if 'nextVariante' in globals():\n",
    "    variante=nextVariante\n",
    "print variante\n",
    "print numerosKalaba, typeKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/23-K5/\n"
     ]
    }
   ],
   "source": [
    "home = expanduser(\"~\")\n",
    "\n",
    "if typeKalaba!=\"Kanonik\":\n",
    "    numeroKalaba=\"23-K%d/\"%numerosKalaba[0]\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/\"\n",
    "    serie=repertoire+numeroKalaba\n",
    "else:\n",
    "    repertoire=home+\"/Library/Mobile Documents/com~apple~CloudDocs/Downloads/\"\n",
    "    serie=repertoire+\"23-Kanoniks/\"\n",
    "    serie=serie+\"Kanonik-%02d-ok/\"%numerosKalaba[0]\n",
    "print serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')\n",
    "    \n",
    "    \n",
    "complementPhrases=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Kalaba 3 et 5\n",
    "Pour le kalaba 3 et le 5, pas de séparateur entre les mots\n",
    "Pour le kalaba 5, mettre Mahira dans Mots.csv et Agathos dans Phrases.csv (pour la gestion du puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "séparateur  \n"
     ]
    }
   ],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=0\n",
    "\n",
    "#casNombreDet=True\n",
    "RightLeft=True\n",
    "\n",
    "if (numerosKalaba[0] in [3,5]) and variante==\"\" and typeKalaba!=\"Kanonik\":\n",
    "    separateurPhonoCloze=\"\"\n",
    "else:\n",
    "    separateurPhonoCloze=\" \"\n",
    "# separateurPhonoCloze=\" \"    \n",
    "separateurMots=separateurPhonoCloze\n",
    "print \"séparateur\",separateurMots\n",
    "#separateurMots=\" \"\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False        #False\n",
    "print_radicaux=False     #False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.safe_load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.safe_load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.safe_load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.safe_load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Gloses.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\columnbreak\\\\vfill\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Nom\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cas', 'Genre', 'Nombre', 'Pers', 'Temps'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOM', 'VER', 'ADJ', 'PRO', 'DET']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'DET': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'NOM': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'PRO': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'VER': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': False,\n",
       "  'Pers': True,\n",
       "  'Temps': True}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'IND', 'AJOUT', 'OBJ', 'COMP', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'GP', 'DET']}\n"
     ]
    }
   ],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]\n",
    "syntagmesLR=copy.deepcopy(syntagmes)\n",
    "print syntagmesLR\n",
    "syntagmesRL=copy.deepcopy(syntagmes)\n",
    "for element in syntagmesRL:\n",
    "    syntagmesRL[element].reverse()\n",
    "nomFonctions=syntagmes[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LR',\n",
       " {'GADJ': ['ADV', 'ADJ', 'GP'],\n",
       "  'GN': ['GADJ', 'NOM', 'GP', 'DET'],\n",
       "  'GP': ['GN', 'PREP'],\n",
       "  'Phrase': ['VER', 'IND', 'AJOUT', 'OBJ', 'COMP', 'SUJ']},\n",
       " 'RL',\n",
       " {'GADJ': ['GP', 'ADJ', 'ADV'],\n",
       "  'GN': ['DET', 'GP', 'NOM', 'GADJ'],\n",
       "  'GP': ['PREP', 'GN'],\n",
       "  'Phrase': ['SUJ', 'COMP', 'OBJ', 'AJOUT', 'IND', 'VER']})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"LR\",syntagmesLR, \"RL\",syntagmesRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS', 'PST', '3Sg', '3Pau', '3Pl', 'A', 'B', 'C', 'D']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tableaux des formes utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellules={c:set() for c in \"NOM VER ADJ DET PRO\".split(\" \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Introduire les pronoms kalaba\n",
    "- identifier qu'il s'agit d'un pronom\n",
    "- parser le référent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounNumber(nom,nombre):\n",
    "    if nom[len(nom)-1] in [\"s\",\"x\"]:\n",
    "        if nombre==\"\": nombre=\"PL\"\n",
    "    elif nom[len(nom)-1] in [\"P\",\"D\"]:\n",
    "        if nombre==\"\": \n",
    "            if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"PAU\"\n",
    "            elif \"Du\" in valAttributs[\"Nombre\"] and nom[len(nom)-1]==\"D\":\n",
    "                nombre=\"DU\"\n",
    "            else:\n",
    "                nombre=\"PL\"\n",
    "    else:\n",
    "        if nombre==\"\": nombre=\"SG\"\n",
    "    return nombre\n",
    "\n",
    "def getNounGender(ref):\n",
    "    nom=ref.rstrip(\"P\").rstrip(\"D\")\n",
    "    nomLexeme=PFM.lexique.formeLexeme[nom][0]\n",
    "    classesNom=nomLexeme.split('.')[1:]\n",
    "    print classesNom\n",
    "    proGender=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "    return proGender, classesNom\n",
    "\n",
    "\n",
    "def getRef(pronom):\n",
    "    m=re.match(\"^(.*)#(.*)#\",pronom)\n",
    "    if m:\n",
    "        pro=m.group(1)\n",
    "        ref=m.group(2)\n",
    "    else:\n",
    "        print \"mauvaise notation pour un pronom\"\n",
    "        pro=\"\"\n",
    "        ref=\"\"\n",
    "    return pro,ref"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "pro,ref=getRef(u\"elles#fillesD#\")\n",
    "proNum=getNounNumber(ref,nombre=\"\")\n",
    "proGen,proClasse=getNounGender(ref)\n",
    "nomLexeme=PFM.lexique.formeLexeme[pro][0]\n",
    "print pro, nomLexeme, proNum, ref, proNum, proGen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Traitement des GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_gn(departP,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe departP :\", departP\n",
    "    groupe_nom=[]\n",
    "    if departP[0]==\"de\" and departP[1]==\"les\":\n",
    "        depart=[\"des\"]+departP[2:]\n",
    "    else:\n",
    "        depart=departP\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        if not \"#\" in mot:\n",
    "            groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    pro=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    if len(groupe_nom)==1:\n",
    "#         print \"Pronom ?\",groupe_nom\n",
    "        nomSeul=groupe_nom[0]\n",
    "        boolPro=(\"#\" in nomSeul)\n",
    "    else:\n",
    "        boolPro=False\n",
    "    if boolPro:\n",
    "        proForm,proRef=getRef(nomSeul)\n",
    "        nomLexeme=PFM.lexique.formeLexeme[proForm][0]\n",
    "        print \"ref nomSeul\",proForm,proRef\n",
    "        nombre=getNounNumber(proRef,nombre=\"\")\n",
    "        classe,classesNom=getNounGender(proRef)\n",
    "        pro.append(nomLexeme)\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "#                    else:\n",
    "        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "        cellules[\"PRO\"].add(\".\".join([nomLexeme,classe.capitalize(),nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "        if debug or 0:\n",
    "            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "        if cas==\"ERG\":\n",
    "            erg_genre=classe\n",
    "            erg_nombre=nombre\n",
    "            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "        elif cas==\"ABS\":\n",
    "            abs_genre=classe\n",
    "            abs_nombre=nombre\n",
    "            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for mot in groupe_nom:\n",
    "            if reste==0:\n",
    "    #            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "                if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                    nombre=\"DU\"\n",
    "                    if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                else:\n",
    "                    if \"Pau\" in valAttributs[\"Nombre\"] and mot in \"deux trois quatre cinq\".split():\n",
    "                        nombre=\"PAU\"\n",
    "                        if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                    if mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot[:-1]][0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                        except:\n",
    "                            nomLexeme=PFM.lexique.formeLexeme[mot.lower()][0]\n",
    "                    categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                    if debug or 0: \n",
    "                        print \"mot\",[mot]\n",
    "                        print \"vedette\",nomLexeme,categorie\n",
    "                        print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                    if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                        tete=categorie\n",
    "                        if debug or 0: print \"tête :\", tete\n",
    "                        tampon=tete.split('.')\n",
    "    #                    classe=tampon[0]\n",
    "                        classesNom=nomLexeme.split('.')[1:]\n",
    "                        if debug or 0: print \"classesNom\",classesNom \n",
    "                        classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                        if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                        try:\n",
    "                            typeMot=tampon[1]\n",
    "                        except IndexError:\n",
    "                            typeMot=''\n",
    "                        # modif pour les mots à pluriels en x\n",
    "                        # 23/11/19\n",
    "                        #\n",
    "                        nombre=getNounNumber(mot,nombre)\n",
    "#                         if mot[len(mot)-1] in [\"s\",\"x\"]:\n",
    "#                             if nombre==\"\": nombre=\"PL\"\n",
    "#                         elif mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "#                             if nombre==\"\":\n",
    "#                                 # modif pour permettre le pluriel dans les cas où il n'y a pas de paucal.\n",
    "#                                 # 30/5/21\n",
    "#                                 #\n",
    "#                                 if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "#                                     nombre=\"PAU\"\n",
    "#                                 elif \"Du\" in valAttributs[\"Nombre\"] and mot[len(mot)-1]==\"D\":\n",
    "#                                     nombre=\"DU\"\n",
    "#                                 else:\n",
    "#                                     nombre=\"PL\"\n",
    "#                         else:\n",
    "#                             if nombre==\"\": nombre=\"SG\"\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre\n",
    "\n",
    "                        nom.append(nomLexeme)\n",
    "    #                    if typeCas==\"NoCas\":\n",
    "    #                        cas=\"\"\n",
    "                        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                            cas=\"\"\n",
    "    #                    else:\n",
    "                        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                        cellules[\"NOM\"].add(\".\".join([nomLexeme,nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "                        if cas==\"ERG\":\n",
    "                            erg_genre=classe\n",
    "                            erg_nombre=nombre\n",
    "                            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                        elif cas==\"ABS\":\n",
    "                            abs_genre=classe\n",
    "                            abs_nombre=nombre\n",
    "                            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"DET\"]:\n",
    "#\n",
    "# Modif pour accepter les majuscules en début de phrase\n",
    "#\n",
    "#                         det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                        det.append(nomLexeme)\n",
    "\n",
    "    #                elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"]:\n",
    "#\n",
    "# Modif pour accepter les majuscules en début de phrase\n",
    "#\n",
    "#                         adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                        adj.append(nomLexeme)\n",
    "\n",
    "                    elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                        gp.append(mot)\n",
    "                        reste=1\n",
    "            else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "                gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det and not boolPro: \n",
    "        if nom[0][0]==nom[0][0].upper():\n",
    "            det.append(PFM.lexique.formeLexeme[\"les\"][0])\n",
    "        else:\n",
    "            det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "\n",
    "    tempSyntagme=[]\n",
    "\n",
    "    if pro:\n",
    "        for mot in pro:\n",
    "    #\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "            noligMot=mot.split(\".\")[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            #\n",
    "            # traitement des noms propres avec tiret\n",
    "            # traitement des noms paucals sans ordinaux\n",
    "            #\n",
    "            if \"-\" in noligMot:\n",
    "                noLigs=noligMot.split(\"-\")\n",
    "                if len(noLigs)>1:\n",
    "                    noligMot=noLigs[0]+\"\".join([c for c in noLigs[1:]])\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "            print ref\n",
    "    #        mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot)\n",
    "            texte.append(ref)\n",
    "            tempSyntagme.append(ref)\n",
    "        structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "        mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "        \n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            print \"pas de nombre\"\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "#             print mot,casDet,nombreDet\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        cellules[\"DET\"].add(\".\".join([mot,classeDet,nombreDet,casDet]).strip(\".\"))\n",
    "\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        cellules[\"ADJ\"].add(\".\".join([mot,classeAdj,nombreAdj,casAdj]).strip(\".\"))\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        #\n",
    "        # traitement des noms propres avec tiret\n",
    "        # traitement des noms paucals sans ordinaux\n",
    "        #\n",
    "        if \"-\" in noligMot:\n",
    "            noLigs=noligMot.split(\"-\")\n",
    "            if len(noLigs)>1:\n",
    "                noligMot=noLigs[0]+\"\".join([c.lower() for c in noLigs[1:]])\n",
    "#         noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        if noligMot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    if debug or 0:\n",
    "        print \"fin faire_gn\",listeMots\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/14529523/python-split-for-lists\n",
    "\n",
    "l = [\"data\",\"more data\",\";\",\"data 2\",\"more data 2\",\"danger\",\";\",\"date3\",\"lll\"]\n",
    "[list(group) for k, group in groupby(l, lambda x: x == \";\") if not k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Traitement des GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplier_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    lGroupes=[list(group) for k, group in groupby(groupe_prep, lambda x: x == \";\") if not k]\n",
    "    if len(lGroupes)>1:\n",
    "        print lGroupes\n",
    "    for lGp in lGroupes:\n",
    "        mots.extend(faire_gp(lGp,fonction))\n",
    "    return mots\n",
    "    \n",
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", \" \".join(groupe_prep), \"fonction\",fonction\n",
    "    formePreposition=groupe_prep[0]\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "    if debug: print formePreposition, preposition\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        # noligMot=groupe_prep[0]\n",
    "        noligMot=preposition\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        \n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                lexemesLocaux.add(noligMot.upper())\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print \"ref\",ref,noligMot\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Traitement des contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['une', 'jeune', 'princesse', 'mari\\xc3\\xa9e']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etendre_contraction(\"une jeune princesse mariée\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else:\n",
    "#        if \"{preview}\" in liste:\n",
    "#            print \"preview\",prefixe,liste,suffixe\n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Traitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "texHeader=[]\n",
    "if \"theNotebook\" in globals():\n",
    "    version=theNotebook\n",
    "    texHeader.append(\"%% script : \"+version)\n",
    "texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    ecriture_nom=serie+complementPhrases+\"Ecrit.csv\"\n",
    "    ordre_nom=serie+complementPhrases+\"Ordre.csv\"\n",
    "    mots_nom=serie+complementPhrases+\"Mots.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\"\n",
    "    if len(args)>=4:\n",
    "        ecriture_nom=args[3]\n",
    "    else:\n",
    "        ecriture_nom=\"\"\n",
    "    if len(args)>=5:\n",
    "        ordre_nom=args[4]\n",
    "    else:\n",
    "        ordre_nom=\"\"\n",
    "    if len(args)>=6:\n",
    "        mots_nom=args[5]\n",
    "    else:\n",
    "        mots_nom=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrerCloze(filtre):\n",
    "    result=[]\n",
    "    for ligne in clozeLines:\n",
    "        if type(ligne)==str:\n",
    "            ligne=unicode(ligne.decode('utf8'))\n",
    "        ligne=ligne.strip()\n",
    "        if not ligne.startswith(\"#\"):\n",
    "            clozeElements=ligne.split(\";\")\n",
    "            if clozeElements[1] in filtre:\n",
    "                result.append(ligne)\n",
    "        else:\n",
    "            result.append(ligne)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if not isinstance(item, basestring):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewerBegin=\"\\\\begin{preview}\\\\begin{flushleft}\"\n",
    "previewerEnd=\"\\\\end{flushleft}\\\\end{preview}\"\n",
    "\n",
    "def latex2ipa(mot):\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLignePreview=\"\\\\end{preview}\"\n",
    "    if \" \" in mot:\n",
    "        result=[]\n",
    "        for element in mot.split():\n",
    "            result.append(latex2ipa(element))\n",
    "        return separateurMots.join(result)\n",
    "    else:\n",
    "        mot=mot.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "    #    print mot\n",
    "        mot=mot.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "    #    print mot\n",
    "        element=mot.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "    #    print element\n",
    "        cleElement=element.strip().strip(\"\\\\{}\")\n",
    "    #    print cleElement\n",
    "        if element==\"\\\\ex\": cleElement=\"\"\n",
    "        if cleElement:\n",
    "            if not cleElement in traductions:\n",
    "                print mot\n",
    "                print cleElement\n",
    "                print traductions\n",
    "                warnings.warn(\"pas de transcription pour %s\"%cleElement)\n",
    "                return None\n",
    "            else:\n",
    "                return traductions[cleElement]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex2ipa(\"\\\\begin{preview}\\\\DEFMSg{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previewer(chaine,numLignesVides=0,suffixe=\"\"):\n",
    "    flatChaine=[mot+suffixe for mot in list(flatten(chaine))]\n",
    "    result=previewerBegin+separateurMots.join(flatChaine)+\"\\\\\\\\\"*numLignesVides+previewerEnd\n",
    "    return [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "texteMots=set()\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.lexemes[\"construire\"].formes.index(\"construisit\")\n",
    "valAttributs[\"Genre\"]\n",
    "localClasses=[\"N\"]\n",
    "[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "localCas=\"Nom\"\n",
    "not localCas or localCas in sujetVerbe\n",
    "sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliserMajusculesMinuscules(mot):\n",
    "    result=mot\n",
    "    if \"'\" in mot:\n",
    "        lMots=mot.split(\"'\")\n",
    "        result=\"'\".join([normaliserMajusculesMinuscules(m) for m in lMots])\n",
    "    elif len(mot)>1 and mot!=mot.lower() and mot!=mot.capitalize():\n",
    "        result=mot[0]+mot[1:].lower()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"d'E-st'Ogm\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliserMajusculesMinuscules(u\"d'E-St'OGM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Introduire les pronoms dans les phrases\n",
    "\n",
    "- clitiques verbaux entre dièses pour permettre l'inclusion en français et l'exclusion en kalaba\n",
    "  - Marie TAB #les# voyait TAB ,les enfants TAB TAB dans la cour\n",
    "    - FR: Les enfants, Marie les voyait dans la cour.\n",
    "    - KB: Marie voyait les enfants dans la cour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFr(line):\n",
    "    result=line\n",
    "    m=re.search(ur\"((\\w+)#\\S+#)\",result)\n",
    "    if m:\n",
    "        result=result.replace(m.group(1),m.group(2))\n",
    "        result=cleanFr(result)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'elles pensent \\xe0 lui'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFr(u\"elles#sorcières# pensent à lui#garçon#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Assemblage des phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Niveau phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortie=\"latex\"):\n",
    "    print sortie\n",
    "    phrasesLocales=phrase_file.readlines()\n",
    "    syntagmesLocaux=[]\n",
    "    numLignes=len(phrasesLocales)\n",
    "    numImages=1\n",
    "    numLignesVides=0\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    elif sortie==\"images\":\n",
    "        numImages=1\n",
    "        numLignesVides=0\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "        numLignesVides=0\n",
    "\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLigneNoPreview=\"\\\\\\\\\"*numLignesVides\n",
    "    finLignePreview=\"\\\\\\\\\"*numLignesVides+\"\\\\end{preview}\"\n",
    "    numLignes=(len(phrasesLocales)//numImages)*numImages\n",
    "\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrasesLocales[:numLignes]):\n",
    "        if debug: print nPhrase,line\n",
    "        #phrase contient une position par fonction\n",
    "        #pour accueillir les équivalents kalabas des chunks français\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").replace(u\"’\",\" \").split(\"\\t\")\n",
    "        tampon=[t.strip() for t in tampon]\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug: \n",
    "            print \"===========================================\"            \n",
    "            print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "#             print nPhrase,tampon\n",
    "            #\n",
    "            # Introduire les clitiques non-traités\n",
    "            # \n",
    "            # #les# voit \n",
    "            #\n",
    "            m=re.search(ur\"#.*#\\s*(.*)\",tampon[1])\n",
    "            if m:\n",
    "                verbe=m.group(1).split(\" \")\n",
    "            else:\n",
    "                verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            tempVerbe=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print tempVerbe\n",
    "            formeCitation=tempVerbe[0]\n",
    "            lexemesLocaux.add(formeCitation)\n",
    "            for element in tempVerbe[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            if len(tempVerbe)>1:\n",
    "                typeVerbe=tempVerbe[1]\n",
    "            else: \n",
    "                typeVerbe=\"\"\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    frObjetCas=\"\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            if debug: print (frSujetCas,frObjetCas,klbSujet)\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (\"FAIRE_GN SUJET\",localMots,(localClasses,localNombre,localCas))\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas,localNombre,localClasses,sujetVerbe\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            ########################\n",
    "            #\n",
    "            # Modification pour permettre les accords par défaut\n",
    "            # avec des verbes transitifs sans objet pour les systèmes ergatifs\n",
    "            #\n",
    "            ########################\n",
    "            if klbSujet==\"OBJ\" and len(tampon)<3:\n",
    "                tampon.append(\"\")\n",
    "            if len(tampon)>=3:\n",
    "                if tampon[2] and tampon[2].startswith(\",\"):\n",
    "                    tampon[2]=tampon[2][1:]\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "                    # pourquoi un traitement spécial pour sortie==\"mots\"\n",
    "#                     elif sortie==\"mots\": print \"objet\",objet\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe and localCas!=\"Nom\":\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    print \"verbe ergatif sans objet\",[objet]\n",
    "                    print tampon\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                if tampon[3] and tampon[3].startswith(\",\"):\n",
    "                    tampon[3]=tampon[3][1:]\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=previewer(faire_gp(indirect,\"IND\"),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            ###################\n",
    "            #\n",
    "            # Modification pour ajouts multiples séparés par ;\n",
    "            # 24/11/19\n",
    "            #\n",
    "            ###################\n",
    "            if len(tampon)>=5:\n",
    "                if tampon[4] and tampon[4].startswith(\",\"):\n",
    "                    tampon[4]=tampon[4][1:]\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=previewer(multiplier_gp(comp),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=multiplier_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                if tampon[5] and tampon[5].startswith(\",\"):\n",
    "                    tampon[5]=tampon[5][1:]\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                if sortie==\"ordre\":\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=previewer(multiplier_gp(ajout),suffixe=\"{}\")\n",
    "                else:\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=multiplier_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "            noligFormeCitation=noligFormeCitation.replace(\"-\",\"\")\n",
    "            \n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent).lower()\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            cellules[\"VER\"].add(\".\".join([verbeLexeme,morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize(),nombrePersonne,classeVerbe,nombreVerbe]).strip(\".\"))\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=previewer([glose],suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            lexemesLocaux.add(noligFormeCitation)\n",
    "            texte.append(glose)\n",
    "            if sortie in [\"latex\",\"traductions\"]: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            syntagmesBruts=[]\n",
    "            syntagmesEtiquetes=[]\n",
    "            for nMot,mot in enumerate(phrase):\n",
    "                if mot!=0:\n",
    "                    \n",
    "                    if isinstance(mot,basestring):\n",
    "                        syntagmeLocal=latex2ipa(mot)\n",
    "                    else:\n",
    "                        interFlat=[]\n",
    "                        for m in flatten(mot):\n",
    "                            mList=re.findall(ur\"\\\\[^{]+{}\",m)\n",
    "                            if mList:\n",
    "                                interFlat.extend(mList)\n",
    "                            else:\n",
    "                                interFlat.append(m)\n",
    "                        if debug: print \"interFlat\",interFlat\n",
    "                        if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                            interFlat.reverse()\n",
    "                        syntagmeLocal=separateurMots.join([latex2ipa(f) for f in interFlat])\n",
    "                    syntagmesBruts.append(syntagmeLocal)\n",
    "                    syntagmesEtiquetes.append(syntagmeLocal)\n",
    "                    if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                        syntagmesEtiquetes.append(syntagmes[\"Phrase\"][nMot])\n",
    "                    else:\n",
    "                        syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "#                    syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "                    printflat(mot,\"{}\")\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts[::-1])+\";\"+\" \".join(syntagmesEtiquetes[::-1])\n",
    "            else:\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            print ligneSyntagmesLocaux\n",
    "            syntagmesLocaux.append(ligneSyntagmesLocaux)\n",
    "            localAccumulateur=[accu for accu in accumulateur if accu!=\"\"]\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "                if sortie==\"images\":\n",
    "                    if nPhrase%numImages==0:\n",
    "                        prefixe=\"\\\\begin{preview}\"\n",
    "                    else:\n",
    "                        prefixe=\"\"\n",
    "                    if nPhrase%numImages==numImages-1:\n",
    "                        finLigne=finLignePreview\n",
    "                    else:\n",
    "                        finLigne=finLigneNoPreview\n",
    "                elif sortie==\"mots\":\n",
    "                    localAccumulateur=[debutLignePreview+accu+finLignePreview for accu in accumulateur if accu!=\"\"]\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(localAccumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\" and separateurMots==\"\":\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur[::-1])+finLigne)\n",
    "            else:\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortie in [\"latex\",\"traductions\"]:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortie in [\"latex\",\"traductions\"]: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            ##############\n",
    "            #\n",
    "            # Modification pour ajouts multiples\n",
    "            # suppression des ; de séparation dans la traduction\n",
    "            #\n",
    "            ##############\n",
    "            if \",\" in line:\n",
    "                consts=line.split(\"\\t\")\n",
    "                disloc=[]\n",
    "                canon=[]\n",
    "                for const in consts:\n",
    "                    if const.startswith(\",\"):\n",
    "                        if \";\" in const:\n",
    "                            subConsts=const.split(\";\")\n",
    "                            print \"############## ; ##########@\"\n",
    "                            print subConsts\n",
    "                            disloc.append(subConsts[0][1:])\n",
    "                            for subConst in subConsts[1:]:\n",
    "                                canon.append(subConst.lstrip())\n",
    "                        else:\n",
    "                            disloc.append(const[1:])\n",
    "                    else:\n",
    "                        canon.append(const)\n",
    "                line=\",\\t\".join(disloc).strip()+\", \"+\"\\t\".join(canon)\n",
    "            if \" ; \" in line:\n",
    "                line=line.replace(\" ; \",\" \")\n",
    "            line=cleanFr(line)            \n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                if element==u\"À\":element=u\"à\"\n",
    "                if element==\"Au\":element=\"au\"\n",
    "                if element==\"Aux\":element=\"aux\"\n",
    "                element=element.strip(\"#\").replace(u\"’\",\"'\")\n",
    "                #\n",
    "                # Modification pour accepter les suffixes P et D à la fin des noms\n",
    "                # 31/5/21\n",
    "                #\n",
    "                if element[-2:] in [\"sP\",\"sD\"]:\n",
    "                    element=element[:-1]\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=normaliserMajusculesMinuscules(element)\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(caracteres)\n",
    "            if sortie==\"latex\": \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            elif sortie==\"images\":\n",
    "                ajouterExemple(marqueurCommentaire+\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "            elif sortie in [\"ordre\",\"mots\"]:\n",
    "                ajouterExemple(\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "                #if sortie==\"mots\": ajouterExemple(\"\\\\begin{preview}\"+\".\"+\"\\\\end{preview}\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortie==\"latex\" and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRONOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PRO\"][\"cols\"],tableaux[\"PRO\"],texte,dimensionsTableaux[\"PRO\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"PRO\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "            with codecs.open(serie+complementPhrases+\"Syntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in syntagmesLocaux:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "        elif (sortie==\"traductions\" and variante==\"-Corr\"):\n",
    "            with codecs.open(serie+complementPhrases+\"Traductions\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")            \n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "#    elif sortie==\"images\":\n",
    "#        with codecs.open(serie+complementPhrases+\"Images\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "#            for exemple in exemples:\n",
    "#                output.write(exemple+\"\\n\")\n",
    "    elif sortie in [\"images\",\"ordre\",\"mots\"]:\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "            for texHead in texHeader:\n",
    "                output.write(texHead+\"\\n\")\n",
    "            for exemple in exemples:\n",
    "                output.write(exemple+\"\\n\")\n",
    "    if sortie in [\"images\",\"traductions\",\"ordre\",\"mots\"]:\n",
    "        if sortie==\"mots\":print\n",
    "        clozeTraductions=[]\n",
    "        clozeExemples=exemples[:]\n",
    "        filtreLignes=[\"\\\\begin{phrases}\",\"\\\\ex\",\"\\\\gloses\",\"\\\\end{phrases}\"]\n",
    "        if sortie==\"traductions\":\n",
    "            clozeExemples=[exemple for exemple in clozeExemples if (not exemple in filtreLignes) and not exemple.startswith(\"%\")]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(clozeExemples)]*3):\n",
    "            if sortie==\"traductions\" and 0:\n",
    "                print \"ortho\",orthoLigne\n",
    "                print \"phono\",phonoLigne\n",
    "                print \"trad\",tradLigne\n",
    "            phonoLigne=phonoLigne.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "            phonoLigne=phonoLigne.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "            phonoLigne=phonoLigne.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoMots=phonoLigne.strip(marqueurCommentaire).replace(finLignePreview,\"\").strip().split()\n",
    "            tradLigne=tradLigne.strip(marqueurCommentaire).replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")\n",
    "                if element==\"\\\\ex\": cleElement=\"\"\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print \"no key\", cleElement,phonoMots\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n",
    "        if sortie==\"ordre\" and separateurMots==\"\":\n",
    "            dictSyntagmes={}\n",
    "            dictTraductions={}\n",
    "            ordreCles=[]\n",
    "            for element in syntagmesLocaux:\n",
    "                clePhono,valSyntagmes=element.split(\";\")\n",
    "                dictSyntagmes[clePhono]=\" \".join([v for v in valSyntagmes.split() if not v in nomFonctions])\n",
    "                ordreCles.append(clePhono)\n",
    "            for element in clozeTraductions:\n",
    "                clePhono,valTrad,valMots=element.split(\";\")\n",
    "                dictTraductions[clePhono]=valTrad\n",
    "            morceauxPhrases=[\"%s;%s\"%(dictSyntagmes[c],dictTraductions[c]) for c in ordreCles]\n",
    "            with codecs.open(serie+complementPhrases+\"OrdreSyntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in morceauxPhrases:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'IND', 'AJOUT', 'OBJ', 'COMP', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'GP', 'DET']}\n"
     ]
    }
   ],
   "source": [
    "sortie=\"traductions\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if traduction_nom.endswith(\"csv\") and variante!=\"-Corr\":\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the translation file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,sortie=sortie)\n",
    "            traduction_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'COMP', 'OBJ', 'AJOUT', 'IND', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['DET', 'GP', 'NOM', 'GADJ']}\n",
      "latex\n",
      "[[u'dans', u'le', u'village', u'\\xe0', u'c\\xf4t\\xe9'], [u'avec', u'Clemencia']]\n",
      "############## ; ##########@\n",
      "[u',dans le village \\xe0 c\\xf4t\\xe9 ', u' avec Clemencia\\n']\n",
      "ref nomSeul ils enfantsP\n",
      "[u'C', u'N4']\n",
      "\\PROCPauErg\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les trois sorci\\xe8res', u'jardinaient', u'', u'', u'', u',\\xe0 c\\xf4t\\xe9 des crapauds du maraiS']\n",
      "[[u'dans', u'un', u'donjon', u'au', u'milieu', u'du', u'manoir'], [u'avec', u'trois', u'dragonsP', u'verts']]\n",
      "ref nomSeul ils dragonsP\n",
      "[u'D', u'N3']\n",
      "\\PRODPauErg\n",
      "ref nomSeul ils chasseurs\n",
      "[u'D', u'N3']\n",
      "\\PRODPlErg\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'A', u'N2']\n",
      "\\PROAPauErg\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'A', u'N2']\n",
      "\\PROAPauErg\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'Hoderi', u'\\xe9tait', u'', u'', u'dans ce manoir']\n",
      "ref nomSeul ils chasseursD\n",
      "[u'D', u'N3']\n",
      "\\PRODPauErg\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la nuit noire', u'\\xe9tait', u'', u'', u'sur le village']\n",
      "[[u'sur', u'le', u'b\\xfbcher'], [u'de', u'douleur']]\n",
      "############## ; ##########@\n",
      "[u',sur le b\\xfbcher ', u' de douleur\\n']\n",
      "ref nomSeul elles sorcièresD\n",
      "[u'A', u'N2']\n",
      "\\PROAPauErg\n",
      "ref nomSeul il villageoiS\n",
      "[u'C', u'N4']\n",
      "\\PROCSgAbs\n",
      "[[u'sur', u'la', u'place'], [u'au', u'milieu', u'du', u'village']]\n",
      "[[u'par', u'esprit', u'de', u'vengeance'], [u'pour', u'les', u'chasseurs']]\n",
      "ref nomSeul il chat\n",
      "[u'C', u'N3']\n",
      "\\PROCSgAbs\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les trois sorci\\xe8res', u'descendent', u'', u'', u'des balais', u'dans la nuit']\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'A', u'N2']\n",
      "\\PROAPauAbs\n",
      "[[u'en', u'balais'], [u'avec', u'des', u'l\\xe9gumes']]\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'A', u'N2']\n",
      "\\PROAPauErg\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'le vote des hommes', u'compte', u'', u'', u'', u'pour le village']\n",
      "[[u'pendant', u'cinq', u'nuits'], [u'dans', u'le', u'donjon']]\n",
      "############## ; ##########@\n",
      "[u',pendant cinq nuits ', u' dans le donjon\\n']\n",
      "ref nomSeul ils espritP\n",
      "[u'B', u'N2']\n",
      "\\PROBPauAbs\n",
      "ref nomSeul ils crapauds\n",
      "[u'B', u'N3']\n",
      "\\PROBPlErg\n",
      "[[u'dans', u'le', u'village'], [u'\\xe0', u'c\\xf4t\\xe9', u'du', u'grand', u'manoir']]\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'Mahira', u'chassait', u'', u'', u'', u'dans la for\\xeat ; avec la fille de Kaleb']\n",
      "[[u'dans', u'la', u'for\\xeat'], [u'avec', u'la', u'fille', u'de', u'Kaleb']]\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les deux filles effray\\xe9es', u'fuient', u'', u'', u'devant le corpS de ce villageoiS']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les villageois', u'fuyaient', u'', u'', u'vers le village']\n",
      "verbe ergatif sans objet [['']]\n",
      "[u'Violette', u'fuit', '']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la petite fille', u'fuit', u'', u'', u'vers les lueurs du village']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la louve', u'fuit', u'', u'', u'', u'avec cette petite fille entrE les crocs']\n"
     ]
    }
   ],
   "source": [
    "sortie=\"latex\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file,sortie=sortie)\n",
    "phrase_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"Phrases-Clozes\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'faisait',\n",
       " u'levers',\n",
       " u'pleur\\xe8rent',\n",
       " u'attrapa',\n",
       " u'poss\\xe8dent',\n",
       " u'corps',\n",
       " u'excusait',\n",
       " u'blanche',\n",
       " u'accueille',\n",
       " u'gar\\xe7ons',\n",
       " u'partent',\n",
       " u'reconna\\xeetre',\n",
       " u'descendait',\n",
       " u'tomba',\n",
       " u'b\\xfbcher',\n",
       " u'votes',\n",
       " u'prot\\xe9g\\xe8rent',\n",
       " u'survolait',\n",
       " u'corpS',\n",
       " u'souffrance',\n",
       " u'pass\\xe8rent',\n",
       " u'redeviennent',\n",
       " u'histoires',\n",
       " u'revenir',\n",
       " u'gargouille',\n",
       " u'br\\xfblAIT',\n",
       " u'jardiner',\n",
       " u'tournaient',\n",
       " u'vers',\n",
       " u'villagEOIs',\n",
       " u'plantent',\n",
       " u'villageoises',\n",
       " u's\\u0153ur',\n",
       " u'robes',\n",
       " u'enleva',\n",
       " u'changent',\n",
       " u'disparurent',\n",
       " u'couteaux',\n",
       " u'br\\xfblAIENT',\n",
       " u'voit',\n",
       " u'villageoise',\n",
       " u'voir',\n",
       " u'sont',\n",
       " u'allument',\n",
       " u'pleurent',\n",
       " u'yeux',\n",
       " u'transform\\xe8rent',\n",
       " u'villagEOIS',\n",
       " u'pla\\xe7a',\n",
       " u'br\\xfblA',\n",
       " u'illustr\\xe8rent',\n",
       " u'envahir',\n",
       " u'donjon',\n",
       " u'l\\xe9gende',\n",
       " u'lever',\n",
       " u'pleure',\n",
       " u'nouvelle-N',\n",
       " u'approchait',\n",
       " u'offrent',\n",
       " u'br\\xfbl\\xe8rent',\n",
       " u'd',\n",
       " u'chef',\n",
       " u'noient',\n",
       " u'pour',\n",
       " u'infirmi\\xe8res',\n",
       " u'manoirs',\n",
       " u'pleurE',\n",
       " u'eurent',\n",
       " u'\\xe9changea',\n",
       " u'pleurA',\n",
       " u'filles',\n",
       " u'rejoignit',\n",
       " u'manquer-Med',\n",
       " u'supporter',\n",
       " u'poussa',\n",
       " u'pr\\xe9parait',\n",
       " u'volENT',\n",
       " u'\\xe9changer',\n",
       " u'Violettes',\n",
       " u'br\\xfblent',\n",
       " u'dort',\n",
       " u'redevint',\n",
       " u'th\\xe9',\n",
       " u'reconnaissent',\n",
       " u'dernIERs',\n",
       " u'passait',\n",
       " u'accueillait',\n",
       " u'\\xe9tait',\n",
       " u'gorge',\n",
       " u'pr\\xe8s',\n",
       " u'ombres',\n",
       " u'planter',\n",
       " u'\\xe0',\n",
       " u'pleurAIENT',\n",
       " u'noya',\n",
       " u'voleuses',\n",
       " u'cette',\n",
       " u'grandes',\n",
       " u'changea',\n",
       " u'p\\xe8re',\n",
       " u'disparaissait',\n",
       " u'Nicole',\n",
       " u'poisson',\n",
       " u'IND',\n",
       " u'derni\\xe8res',\n",
       " u'changer',\n",
       " u'b\\xfbchers',\n",
       " u'vole',\n",
       " u'illustraient',\n",
       " u'sortil\\xe8ges',\n",
       " u'vola',\n",
       " u'recouvre',\n",
       " u'pr\\xe9parer',\n",
       " u'dormaient',\n",
       " u'parents',\n",
       " u'approcher',\n",
       " u'vit',\n",
       " u'vilain',\n",
       " u'lan\\xe7ait',\n",
       " u'pendait',\n",
       " u'allait',\n",
       " u'volE',\n",
       " u'voter',\n",
       " u'volA',\n",
       " u'd\\xe9vorent',\n",
       " u'tombaient',\n",
       " u'r\\xeavasser',\n",
       " u'transperc\\xe8rent',\n",
       " u'disparues',\n",
       " u'mort',\n",
       " u'morts',\n",
       " u'ressuscita',\n",
       " u'feu',\n",
       " u'viT',\n",
       " u'reconnaissait',\n",
       " u'voyait',\n",
       " u'cherch\\xe8rent',\n",
       " u'noyaient',\n",
       " u'sort',\n",
       " u'r\\xeavasse',\n",
       " u'tomb\\xe8rent',\n",
       " u'soeurs',\n",
       " u'dernI\\xc8RE',\n",
       " u'redevenir',\n",
       " u'nourrissait',\n",
       " u'lOUP',\n",
       " u'cailloux',\n",
       " u'l\\xe9gumes',\n",
       " u'ressuscit\\xe8rent',\n",
       " u'col\\xe8res',\n",
       " u'peaux',\n",
       " u'excuse',\n",
       " u'illustrer',\n",
       " u'excusa',\n",
       " u'br\\xfblait',\n",
       " u'coyote',\n",
       " u'sortit',\n",
       " u'fuient',\n",
       " u'sorT',\n",
       " u'donnent',\n",
       " u'devant',\n",
       " u'poissons',\n",
       " u'des',\n",
       " u'envahit',\n",
       " u'disparition',\n",
       " u'excusE',\n",
       " u'sous',\n",
       " u'envahissaient',\n",
       " u'derri\\xe8re',\n",
       " u'sortait',\n",
       " u'arrive',\n",
       " u'vivait',\n",
       " u'enfant',\n",
       " u'arriva',\n",
       " u'illustre',\n",
       " u'illustra',\n",
       " u'visage',\n",
       " u'serpent',\n",
       " u'feux',\n",
       " u'Elphaba',\n",
       " u'nuiT',\n",
       " u'manqua',\n",
       " u'dragons',\n",
       " u'dormait',\n",
       " u'comptent',\n",
       " u'poss\\xe9der',\n",
       " u'nuisait',\n",
       " u'femme',\n",
       " u'poussent',\n",
       " u'suivant',\n",
       " u'allaient',\n",
       " u'vert',\n",
       " u'vol\\xe8rent',\n",
       " u'manquaient',\n",
       " u'court',\n",
       " u'pr\\xe9sentent',\n",
       " u'transforment',\n",
       " u'enl\\xe8ve',\n",
       " u'coyotes',\n",
       " u'interrogeait',\n",
       " u'conna\\xeetre',\n",
       " u'pendaient',\n",
       " u'furieuse',\n",
       " u'achetait',\n",
       " u'donnaient',\n",
       " u'revinrent',\n",
       " u'recouvrit',\n",
       " u'matin',\n",
       " u'arrivent',\n",
       " u'demandent',\n",
       " u'volAIT',\n",
       " u'r\\xeavassaient',\n",
       " u'pendit',\n",
       " u'sorci\\xe8re',\n",
       " u'inqui\\xe9taient',\n",
       " u'oeuf',\n",
       " u'reconstruit',\n",
       " u'br\\xfblaient',\n",
       " u'petits',\n",
       " u'entrer',\n",
       " u'inqui\\xe8tent',\n",
       " u'chassaient',\n",
       " u'attrap\\xe8rent',\n",
       " u'autruches',\n",
       " u'leva',\n",
       " u'virent',\n",
       " u'a',\n",
       " u'gorges',\n",
       " u'Clemencia',\n",
       " u'cr\\xe9ature',\n",
       " u'trois',\n",
       " u'br\\xfbler-Med',\n",
       " u'nombreux',\n",
       " u'hurl\\xe8rent',\n",
       " u'd\\xe9mons',\n",
       " u'demandaient',\n",
       " u'dragon',\n",
       " u'enlev\\xe8rent',\n",
       " u'montraient',\n",
       " u'grande',\n",
       " u'donner',\n",
       " u'mange',\n",
       " u'jardinaient',\n",
       " u'manoir',\n",
       " u'noyer',\n",
       " u'six',\n",
       " u'diff\\xe9rents',\n",
       " u'furieuses',\n",
       " u'racontait',\n",
       " u'boire',\n",
       " u'obscurit\\xe9s',\n",
       " u'acheter',\n",
       " u'diff\\xe9rente',\n",
       " u'Katishas',\n",
       " u'sortir-Mov',\n",
       " u'vivent',\n",
       " u'd\\xe9couvrit',\n",
       " u'col\\xe8re',\n",
       " u'enfants',\n",
       " u'survolent',\n",
       " u'br\\xfblENT',\n",
       " u'tombait',\n",
       " u'disparaissent',\n",
       " u'chasser-Mov',\n",
       " u'chatte',\n",
       " u'alla',\n",
       " u'la',\n",
       " u'd\\xe9vorer',\n",
       " u'apporta',\n",
       " u'PRO',\n",
       " u'br\\xfbl\\xe8rENT',\n",
       " u'disparaissaient',\n",
       " u'nuits',\n",
       " u'r\\xeavassait',\n",
       " u'pend',\n",
       " u'eux',\n",
       " u'd\\xe9couvre',\n",
       " u'eut',\n",
       " u'prot\\xe8ge',\n",
       " u'hommes',\n",
       " u'nouvELLE',\n",
       " u'pleurENT',\n",
       " u'sortil\\xe8ge',\n",
       " u'vivre',\n",
       " u'enfermait',\n",
       " u'surplomb\\xe8rent',\n",
       " u'chassait',\n",
       " u'Nabils',\n",
       " u'cet',\n",
       " u'ces',\n",
       " u'enferma',\n",
       " u'reconstruisirent',\n",
       " u'dormir',\n",
       " u'donjons',\n",
       " u'villageois',\n",
       " u'compter',\n",
       " u'Katisha',\n",
       " u'apportaient',\n",
       " u'faire',\n",
       " u'd\\xe9teste',\n",
       " u'compt\\xe8rent',\n",
       " u'porte',\n",
       " u'd\\xe9testa',\n",
       " u'porta',\n",
       " u'survolaient',\n",
       " u'pr\\xe9paraient',\n",
       " u'crocs',\n",
       " u'ma\\xeetre',\n",
       " u'troisi\\xe8me',\n",
       " u'arrivaient',\n",
       " u'm\\xe9chant',\n",
       " u'ma\\xeetres',\n",
       " u'pendirent',\n",
       " u'embrassait',\n",
       " u'prenait',\n",
       " u'entraient',\n",
       " u'balais',\n",
       " u'chasseur',\n",
       " u'jours',\n",
       " u'cachaient',\n",
       " u'moururent',\n",
       " u'supportait',\n",
       " u'nourrissaient',\n",
       " u'reviennent',\n",
       " u'remercie',\n",
       " u'homme',\n",
       " u'partir',\n",
       " u'louves',\n",
       " u'apporter',\n",
       " u'rejoignent',\n",
       " u'supporte',\n",
       " u'racont\\xe8rent',\n",
       " u's\\u0153urs',\n",
       " u'prot\\xe9geait',\n",
       " u'offre',\n",
       " u'l\\xe8ve',\n",
       " u'pla\\xe7aient',\n",
       " u'd\\xe9couvrent',\n",
       " u'arrivait',\n",
       " u'cris',\n",
       " u'revenait',\n",
       " u'm\\xe9chante',\n",
       " u'jaunes',\n",
       " u'enfANTs',\n",
       " u'r\\xeavassent',\n",
       " u'alluma',\n",
       " u'nuit',\n",
       " u'ressusciter',\n",
       " u'allume',\n",
       " u'chass\\xe8rENT',\n",
       " u'font',\n",
       " u'placE',\n",
       " u'pendant',\n",
       " u'faisaient',\n",
       " u'enlever',\n",
       " u'fuiT',\n",
       " u'oeil',\n",
       " u'enfANT',\n",
       " u'enferment',\n",
       " u'basse',\n",
       " u'prot\\xe9gea',\n",
       " u'loup',\n",
       " u'surplombaient',\n",
       " u'terrible',\n",
       " u'revenaient',\n",
       " u'avait',\n",
       " u'all\\xe8rent',\n",
       " u'accueillirent',\n",
       " u'place',\n",
       " u'cacher',\n",
       " u'mourir',\n",
       " u'racontaient',\n",
       " u'volent',\n",
       " u'lances',\n",
       " u'tournent',\n",
       " u'nouvelles',\n",
       " u'for\\xeat',\n",
       " u'nourrirent',\n",
       " u'manger',\n",
       " u'votait',\n",
       " u'h\\xe9ro\\xefnes',\n",
       " u'Kaleb',\n",
       " u'arbres',\n",
       " u'excusaient',\n",
       " u'racontent',\n",
       " u'buvait',\n",
       " u'embrassaient',\n",
       " u'gros',\n",
       " u'vote',\n",
       " u'retourna',\n",
       " u'vota',\n",
       " u'conna\\xeet',\n",
       " u'retourne',\n",
       " u'blanc',\n",
       " u'passer',\n",
       " u'retournait',\n",
       " u'enfermaient',\n",
       " u'boit',\n",
       " u'plaine',\n",
       " u'avec',\n",
       " u'fait',\n",
       " u'pleura',\n",
       " u'h\\xe9ro\\xefne',\n",
       " u'jette',\n",
       " u'lueur',\n",
       " u'envahissent',\n",
       " u'combats',\n",
       " u'combattant',\n",
       " u'Kalebs',\n",
       " u'votE',\n",
       " u'changeaient',\n",
       " u'visages',\n",
       " u'nourrissent',\n",
       " u'lanc\\xe8rent',\n",
       " u'crapaud',\n",
       " u'histoire',\n",
       " u'arr\\xeat\\xe8rent',\n",
       " u'arr\\xeataient',\n",
       " u'troisi\\xe8mes',\n",
       " u'villages',\n",
       " u'partaient',\n",
       " u'peau',\n",
       " u'montrent',\n",
       " u'transperce',\n",
       " u'grands',\n",
       " u'prend',\n",
       " u'apportait',\n",
       " u'douleurs',\n",
       " u'br\\xfbla',\n",
       " u'attrapaient',\n",
       " u'prendre',\n",
       " u'verte',\n",
       " u'd\\xe9testent',\n",
       " u'dans',\n",
       " u'profonds',\n",
       " u'derniers',\n",
       " u'd\\xe9mon',\n",
       " u'\\u0153ufs',\n",
       " u'noyait',\n",
       " u'mangea',\n",
       " u'verts',\n",
       " u'ressuscitent',\n",
       " u'fruits',\n",
       " u'retournent',\n",
       " u'mourait',\n",
       " u'approchent',\n",
       " u'transper\\xe7ait',\n",
       " u'chats',\n",
       " u'aller',\n",
       " u'saute',\n",
       " u'pr\\xe9sente',\n",
       " u'maraiS',\n",
       " u'attrapent',\n",
       " u'pr\\xe9senta',\n",
       " u'souris',\n",
       " u'pr\\xe9par\\xe8rent',\n",
       " u'tourna',\n",
       " u'obscurit\\xe9',\n",
       " u'courageuse',\n",
       " u'infirmi\\xe8re',\n",
       " u'grimoire',\n",
       " u'm\\xe9chantes',\n",
       " u'fuyait',\n",
       " u'jaune',\n",
       " u'constructions',\n",
       " u'jour',\n",
       " u'jardine',\n",
       " u'tourne',\n",
       " u'interrogent',\n",
       " u'jardina',\n",
       " u'croc',\n",
       " u'lit',\n",
       " u'souriS',\n",
       " u'loups',\n",
       " u'maison',\n",
       " u'jardin',\n",
       " u'deux',\n",
       " u'reconstruire',\n",
       " u'suivante',\n",
       " u'sautaient',\n",
       " u'blancs',\n",
       " u'jardins',\n",
       " u'descendaient',\n",
       " u'descendit',\n",
       " u'tornade',\n",
       " u'chassa',\n",
       " u'buvaient',\n",
       " u'combat',\n",
       " u'chambres',\n",
       " u'Mahiras',\n",
       " u'retourner',\n",
       " u'hurlaient',\n",
       " u'parle',\n",
       " u'nuisent',\n",
       " u'tourner-Mov',\n",
       " u'pr\\xe9sentaient',\n",
       " u'plaines',\n",
       " u'poussait',\n",
       " u'envahissait',\n",
       " u'hurler',\n",
       " u'treize',\n",
       " u'pleurAIT',\n",
       " u'chassA',\n",
       " u'chassAIT',\n",
       " u'chassE',\n",
       " u'matins',\n",
       " u'nouvELLEs',\n",
       " u'mangent',\n",
       " u'fille',\n",
       " u'part',\n",
       " u'cachait',\n",
       " u'jeter',\n",
       " u'embrassa',\n",
       " u'entrait',\n",
       " u'entr\\xe8rent',\n",
       " u'noire',\n",
       " u'\\xe9chang\\xe8rent',\n",
       " u'vont',\n",
       " u'inqui\\xe9t\\xe8rent',\n",
       " u'coup',\n",
       " u'mains',\n",
       " u'vivaient',\n",
       " u'dormirent',\n",
       " u'redevenait',\n",
       " u'Hoderis',\n",
       " u'dispara\\xeetre',\n",
       " u'connut',\n",
       " u'pleurer-Act',\n",
       " u'noirs',\n",
       " u'\\xe9changeait',\n",
       " u'passe',\n",
       " u'mangeaient',\n",
       " u'fuyaient',\n",
       " u'noir',\n",
       " u'suivants',\n",
       " u'\\xe9changeaient',\n",
       " u'votent',\n",
       " u'remerciaient',\n",
       " u'cache',\n",
       " u'Mahira',\n",
       " u'cacha',\n",
       " u'diff\\xe9rentes',\n",
       " u'manquent',\n",
       " u'embrasse',\n",
       " u'noie',\n",
       " u'surplombent',\n",
       " u'diff\\xe9rent',\n",
       " u'recouvrent',\n",
       " u'dernI\\xc8REs',\n",
       " u'robe',\n",
       " u'nouvelle',\n",
       " u'plantaient',\n",
       " u'sur',\n",
       " u'courir',\n",
       " u'reconstruisait',\n",
       " u'villageoiS',\n",
       " u'demand\\xe8rent',\n",
       " u'lumi\\xe8res',\n",
       " u'montrer',\n",
       " u'changeait',\n",
       " u'nourriT',\n",
       " u'douleur',\n",
       " u'apporte',\n",
       " u'plac\\xe8rent',\n",
       " u'passent',\n",
       " u'\\xe9changent',\n",
       " u'coups',\n",
       " u'nouveau',\n",
       " u'h\\xe9ro\\xefques',\n",
       " u'bas',\n",
       " u'furent',\n",
       " u'pr\\xe9sent\\xe8rent',\n",
       " u'dE',\n",
       " u'courageuses',\n",
       " u'voler-Act',\n",
       " u'enlevaient',\n",
       " u'partit',\n",
       " u'voler',\n",
       " u'accueillir',\n",
       " u'blanches',\n",
       " u'bless\\xe9e',\n",
       " u'braS',\n",
       " u'h\\xe9ro\\xefque',\n",
       " u'volait',\n",
       " u'nouveaux',\n",
       " u'redevinrent',\n",
       " u'blessure',\n",
       " u'maigres',\n",
       " u'grosse',\n",
       " u'profond',\n",
       " u'courut',\n",
       " u'maigre',\n",
       " u'ressuscitaient',\n",
       " u'bless\\xe9s',\n",
       " u'rejoindre',\n",
       " u'd\\xe9couvrirent',\n",
       " u'entrent',\n",
       " u'recouvrir',\n",
       " u'souffrances',\n",
       " u'portent',\n",
       " u'tournait',\n",
       " u'reconstruisit',\n",
       " u'arbre',\n",
       " u'parent',\n",
       " u'remerci\\xe8rent',\n",
       " u'sorciers',\n",
       " u'retournaient',\n",
       " u'br\\xfblE',\n",
       " u'pousser',\n",
       " u'chass\\xe8rent',\n",
       " u'raconter',\n",
       " u'Agathos',\n",
       " u'chemin',\n",
       " u'accueillaient',\n",
       " u'avaient',\n",
       " u'lui',\n",
       " u'pleurer',\n",
       " u'femmes',\n",
       " u'volAIENT',\n",
       " u'coussins',\n",
       " u'rouges',\n",
       " u'raisons',\n",
       " u'c\\xf4t\\xe9s',\n",
       " u'jardinent',\n",
       " u'tables',\n",
       " u'derni\\xe8re',\n",
       " u'jeta',\n",
       " u'arriv\\xe8rent',\n",
       " u'Freja',\n",
       " u'boivent',\n",
       " u'transformait',\n",
       " u'vilaines',\n",
       " u'l\\xe9gume',\n",
       " u'pr\\xe9para',\n",
       " u'portaient',\n",
       " u'illustrait',\n",
       " u'rejoint',\n",
       " u'chercha',\n",
       " u'bras',\n",
       " u'meurt',\n",
       " u'voient',\n",
       " u'fit',\n",
       " u'recouvrait',\n",
       " u'viande',\n",
       " u'pr\\xe9pare',\n",
       " u'ach\\xe8te',\n",
       " u'gar\\xe7on',\n",
       " u'approche',\n",
       " u'les',\n",
       " u'ils',\n",
       " u'vilains',\n",
       " u'demander',\n",
       " u'demandes',\n",
       " u'pendent',\n",
       " u'd\\xe9testaient',\n",
       " u'pousse',\n",
       " u'reconnut',\n",
       " u'maisons',\n",
       " u'c\\xf4t\\xe9',\n",
       " u'approchaient',\n",
       " u'\\u0153uf',\n",
       " u'Nabil',\n",
       " u'harmonie',\n",
       " u'ce',\n",
       " u'allumer',\n",
       " u'lueurs',\n",
       " u'village',\n",
       " u'parlaient',\n",
       " u'table',\n",
       " u'd\\xe9g\\xe2ts',\n",
       " u'reconna\\xeet',\n",
       " u'ENTRE',\n",
       " u'redevient',\n",
       " u'nuisirent',\n",
       " u'jettent',\n",
       " u'autruche',\n",
       " u'l\\xe9gendes',\n",
       " u'revient',\n",
       " u'apr\\xe8s',\n",
       " u'bless\\xe9es',\n",
       " u'milieu',\n",
       " u'poss\\xe9daient',\n",
       " u'v\\xe9curent',\n",
       " u'change',\n",
       " u'portait',\n",
       " u'courent',\n",
       " u'coururent',\n",
       " u'surplombait',\n",
       " u'lumi\\xe8re',\n",
       " u'votaient',\n",
       " u'chasseurs',\n",
       " u'passa',\n",
       " u'profondes',\n",
       " u'disparitions',\n",
       " u'arr\\xeatent',\n",
       " u'chassAIENT',\n",
       " u'redevenaient',\n",
       " u'quatre',\n",
       " u'chattes',\n",
       " u'br\\xfbler',\n",
       " u'd\\xe9voraient',\n",
       " u'sautait',\n",
       " u'fut',\n",
       " u'main',\n",
       " u'v\\xe9cut',\n",
       " u'd\\xe9test\\xe8rent',\n",
       " u'port\\xe8rent',\n",
       " u'disparu',\n",
       " u'Hoderi',\n",
       " u'hurlement',\n",
       " u'revint',\n",
       " u'plante',\n",
       " u'rejoignaient',\n",
       " u'prot\\xe9ger',\n",
       " u'plantait',\n",
       " u'vilaine',\n",
       " u'ombre',\n",
       " u'couraient',\n",
       " u'terribles',\n",
       " u'va',\n",
       " u'sorts',\n",
       " u'reconstruisent',\n",
       " u'connaissait',\n",
       " u'l\\xe8vent',\n",
       " u'd\\xe9couvrait',\n",
       " u'recouvrirent',\n",
       " u'Violette',\n",
       " u'\\xe9taient',\n",
       " u'meurent',\n",
       " u'raison',\n",
       " u'soeur',\n",
       " u'donnait',\n",
       " u'cherchaient',\n",
       " u'dernIER',\n",
       " u'cuisine',\n",
       " u'par',\n",
       " u'pleur\\xc8RENT',\n",
       " u'il',\n",
       " u'cherchent',\n",
       " u'interroge',\n",
       " u'voyaient',\n",
       " u'montrait',\n",
       " u'lits',\n",
       " u'attrapait',\n",
       " u'harmonies',\n",
       " u'descend',\n",
       " u'allum\\xe8rent',\n",
       " u'grand',\n",
       " u'noy\\xe8rent',\n",
       " u'embrassent',\n",
       " u'cinq',\n",
       " u'lunes',\n",
       " u'coussin',\n",
       " u'livre',\n",
       " u'for\\xeats',\n",
       " u'entrE',\n",
       " u'grimoires',\n",
       " u'elle',\n",
       " u'sauter',\n",
       " u'transper\\xe7aient',\n",
       " u'tombe',\n",
       " u'fruit',\n",
       " u'nombreuses',\n",
       " u'connaissent',\n",
       " u'viandes',\n",
       " u'm\\xe8re',\n",
       " u'entra',\n",
       " u'ont',\n",
       " u'poss\\xe9d\\xe8rent',\n",
       " u'entre',\n",
       " u'donn\\xe8rent',\n",
       " u'petite',\n",
       " u'ma\\xeetresse',\n",
       " u'de',\n",
       " u'chasser',\n",
       " u'd\\xe9g\\xe2t',\n",
       " u'proximit\\xe9s',\n",
       " u'parler',\n",
       " u'marais',\n",
       " u'gargouilles',\n",
       " u'transforma',\n",
       " u'cuisines',\n",
       " u'lever-N',\n",
       " u'jardinait',\n",
       " u'partirent',\n",
       " u'pleurait',\n",
       " u'sautent',\n",
       " u'manquait',\n",
       " u'hurlements',\n",
       " u'accueillit',\n",
       " u'Elphabas',\n",
       " u'reconnurent',\n",
       " u'allumait',\n",
       " u'illustrent',\n",
       " u'prenaient',\n",
       " u'Nicoles',\n",
       " u'comptait',\n",
       " u'cherche',\n",
       " u'transformer',\n",
       " u'poss\\xe8de',\n",
       " u'effray\\xe9es',\n",
       " u'retourn\\xe8rent',\n",
       " u'd\\xe9vore',\n",
       " u'esprit',\n",
       " u'survoler',\n",
       " u'ma\\xeetresses',\n",
       " u'dispara\\xeet',\n",
       " u'accueillent',\n",
       " u'manqu\\xe8rent',\n",
       " u'nuisaient',\n",
       " u'attrape',\n",
       " u'basses',\n",
       " u'passaient',\n",
       " u'sortent',\n",
       " u'pr\\xe9sentait',\n",
       " u'demande',\n",
       " u'demanda',\n",
       " u'blessures',\n",
       " u'compte',\n",
       " u'sorci\\xe8res',\n",
       " u'compta',\n",
       " u'cachent',\n",
       " u'poss\\xe9da',\n",
       " u'cherchait',\n",
       " u'pendre',\n",
       " u'supportent',\n",
       " u'tomber',\n",
       " u'tombent',\n",
       " u'firent',\n",
       " u'excusent',\n",
       " u'bless\\xe9',\n",
       " u'demandE',\n",
       " u'donna',\n",
       " u'vengeances',\n",
       " u'rejoignait',\n",
       " u'offraient',\n",
       " u'apport\\xe8rent',\n",
       " u'dernier',\n",
       " u'survol\\xe8rent',\n",
       " u'transpercent',\n",
       " u'autres',\n",
       " u'l',\n",
       " u'transforme',\n",
       " u'h\\xe9roS',\n",
       " u'DEM',\n",
       " u'effray\\xe9',\n",
       " u'milieux',\n",
       " u'proximit\\xe9',\n",
       " u'arr\\xeatait',\n",
       " u'survole',\n",
       " u'DEF',\n",
       " u'Frejas',\n",
       " u'remerciait',\n",
       " u'br\\xfble',\n",
       " u'donne',\n",
       " u'transpercer',\n",
       " u'poss\\xe9dait',\n",
       " u'chasse',\n",
       " u'd\\xe9tester',\n",
       " u'h\\xe9ros',\n",
       " u'parl\\xe8rent',\n",
       " u'parla',\n",
       " u'serpents',\n",
       " u'jardin\\xe8rent',\n",
       " u'chasseuses',\n",
       " u'avoir',\n",
       " u'porter',\n",
       " u'descendre',\n",
       " u'disparut',\n",
       " u'connurent',\n",
       " u'dorment',\n",
       " u'disparus',\n",
       " u'allumaient',\n",
       " u'chefs',\n",
       " u'enferme',\n",
       " u'disparue',\n",
       " u'grosses',\n",
       " u'enferm\\xe8rent',\n",
       " u'descendirent',\n",
       " u'descendent',\n",
       " u'hurla',\n",
       " u'chemins',\n",
       " u'une',\n",
       " u'\\xeatre',\n",
       " u'jet\\xe8rent',\n",
       " u'prot\\xe9geaient',\n",
       " u'rejoignirent',\n",
       " u'courait',\n",
       " u'd\\xe9couvrir',\n",
       " u'le',\n",
       " u'dormit',\n",
       " u'vengeance',\n",
       " u'tornades',\n",
       " u'places',\n",
       " u'suivantes',\n",
       " u'Clemencias',\n",
       " u'remercient',\n",
       " u'cr\\xe9atures',\n",
       " u'sept',\n",
       " u'prennent',\n",
       " u'fuir',\n",
       " u'cach\\xe8rent',\n",
       " u'fuit',\n",
       " u'combattants',\n",
       " u'chang\\xe8rent',\n",
       " u'mang\\xe8rent',\n",
       " u'sorcier',\n",
       " u'couteau',\n",
       " u'cri',\n",
       " u'parlait',\n",
       " u'sortirent',\n",
       " u'lune',\n",
       " u'caf\\xe9',\n",
       " u'achetaient',\n",
       " u'tourn\\xe8rent',\n",
       " u'hurlent',\n",
       " u'interrogeaient',\n",
       " u'chasseuse',\n",
       " u'enfermer',\n",
       " u'interrog\\xe8rent',\n",
       " u'enlevait',\n",
       " u'vot\\xe8rent',\n",
       " u'crapauds',\n",
       " u'sortaient',\n",
       " u'mourut',\n",
       " u'manque',\n",
       " u'profonde',\n",
       " u'recouvraient',\n",
       " u'lev\\xe8rent',\n",
       " u'volaient',\n",
       " u'noires',\n",
       " u'jetait',\n",
       " u'comptaient',\n",
       " u'mangeait',\n",
       " u'AgathoS',\n",
       " u'nourrit',\n",
       " u'pleuraient',\n",
       " u'nourrir',\n",
       " u'ressuscite',\n",
       " u'offrit',\n",
       " u'lancer',\n",
       " u'lan\\xe7a',\n",
       " u'arr\\xeata',\n",
       " u'prirent',\n",
       " u'arr\\xeate',\n",
       " u'furieux',\n",
       " u'd\\xe9testait',\n",
       " u'fuirent',\n",
       " u'construction',\n",
       " u'embrasser',\n",
       " u'inqui\\xe9ter',\n",
       " u'petites',\n",
       " u'louve',\n",
       " u'demandait',\n",
       " u'hurlait',\n",
       " u'montre',\n",
       " u'en',\n",
       " u'inqui\\xe9tait',\n",
       " u'\\xe9change',\n",
       " u'placer',\n",
       " u'inqui\\xe9ta',\n",
       " u'hurle',\n",
       " u'levait',\n",
       " u'd\\xe9vorait',\n",
       " u'lOUPs',\n",
       " u'supportaient',\n",
       " u'levaient',\n",
       " u'cheffe',\n",
       " u'un',\n",
       " u'cheffes',\n",
       " u'prot\\xe8gent',\n",
       " u'excus\\xe8rent',\n",
       " u'poussaient',\n",
       " u'chassent',\n",
       " u'pr\\xe9senter',\n",
       " u'lan\\xe7aient',\n",
       " u'offrir',\n",
       " u'vol\\xe8rENT',\n",
       " u'courageux',\n",
       " u'chercher',\n",
       " u'petit',\n",
       " u'nuire',\n",
       " u'prit',\n",
       " u'jetaient',\n",
       " u'caf\\xe9s',\n",
       " u'embrass\\xe8rent',\n",
       " u'chambre',\n",
       " u'ach\\xe8tent',\n",
       " u'inqui\\xe8te',\n",
       " u'chat',\n",
       " u'survola',\n",
       " u'rouge',\n",
       " u'raconta',\n",
       " u'offrirent',\n",
       " u'remercia',\n",
       " u'raconte',\n",
       " u'chassENT',\n",
       " u'surplomba',\n",
       " u'elles',\n",
       " u'effray\\xe9s',\n",
       " ...]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFM.lexique.formeLexeme.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Fichiers secondaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'COMP', 'OBJ', 'AJOUT', 'IND', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['DET', 'GP', 'NOM', 'GADJ']}\n",
      "images\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la louve', u'est', u'', u'', u'avec le village']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les grandes souffrances', u'fuyaient', u'', u'', u'vers ces deux d\\xe9mons effray\\xe9s']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'Mahira', u'fuyait', u'', u'', u'avec les deux visages du d\\xe9mon']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la lune', u'fuyait', u'', u'', u'entrE les arbres', u'apr\\xe8s la nuit']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'le village effray\\xe9', u'fuit', u'', u'', u'devant les arbres furieux de la lance noire']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les loups', u'fuient', u'', u'', u'derri\\xe8re Mahira']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les deux arbres', u'fuyaient', u'', u'', u'sur les gorges de la for\\xeat']\n",
      "ref nomSeul ils lOUPsD\n",
      "[u'A', u'N3']\n",
      "\\PROAPauAbs\n",
      "ref nomSeul il chasseur\n",
      "[u'D', u'N3']\n",
      "\\PRODSgErg\n",
      "ref nomSeul elles sorcièresD\n",
      "[u'A', u'N2']\n",
      "\\PROAPauErg\n",
      "ref nomSeul il grimoire\n",
      "[u'B', u'N4']\n",
      "\\PROBSgErg\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'il#grimoire#', u'\\xe9tait', u'', u'', u'sur le c\\xf4t\\xe9 du jardin ; sous la cuisine']\n",
      "[[u'sur', u'le', u'c\\xf4t\\xe9', u'du', u'jardin'], [u'sous', u'la', u'cuisine']]\n",
      "[[u'en', u'crapaud'], [u'pour', u'la', u'nuit']]\n",
      "ref nomSeul elles sorcièresD\n",
      "[u'A', u'N2']\n",
      "\\PROAPauAbs\n",
      "ref nomSeul il dragon\n",
      "[u'D', u'N3']\n",
      "\\PRODSgErg\n",
      "ref nomSeul elle Clemencia\n",
      "[u'C', u'N1']\n",
      "\\PROCSgErg\n",
      "ref nomSeul il dragon\n",
      "[u'D', u'N3']\n",
      "\\PRODSgErg\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les sorci\\xe8res', u'sont', u'', u'', u'avec le village']\n"
     ]
    }
   ],
   "source": [
    "if typeKalaba!=\"Kanonik\":\n",
    "    sortie=\"images\"\n",
    "    if \"RightLeft\" in globals() and RightLeft:\n",
    "        syntagmes=syntagmesRL\n",
    "    else:\n",
    "        syntagmes=syntagmesLR\n",
    "    print syntagmes\n",
    "\n",
    "    lexemesLocaux=set()\n",
    "    if ecriture_nom.endswith(\"csv\"):\n",
    "        try:\n",
    "            ecriture_file = codecs.open(ecriture_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the file', ecriture_nom\n",
    "            sys.exit()      \n",
    "        else:\n",
    "            try:\n",
    "                cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "            except IOError:\n",
    "                print 'I could not open the cloze file', cloze_nom\n",
    "                sys.exit()\n",
    "            else:\n",
    "                ecriture={}\n",
    "                for line in cloze_file.readlines():\n",
    "                    line=line.strip()\n",
    "                    if not line.startswith(\"#\"):\n",
    "                        elementsCloze=line.split(\";\")\n",
    "                        ecriture[elementsCloze[0]]=elementsCloze[5]\n",
    "                cloze_file.close()\n",
    "                exemples=[]\n",
    "                accumulateur=[]\n",
    "                vocabulaire=[]\n",
    "    #            prononciationExtrait=[]\n",
    "                faire_phrases(ecriture_file,sortie=sortie)\n",
    "                ecriture_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'IND', 'AJOUT', 'OBJ', 'COMP', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'GP', 'DET']}\n",
      "ordre\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la louve', u'est', u'', u'', u'avec le village']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les grandes souffrances', u'fuyaient', u'', u'', u'vers ces deux d\\xe9mons effray\\xe9s']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'Mahira', u'fuyait', u'', u'', u'avec les deux visages du d\\xe9mon']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la lune', u'fuyait', u'', u'', u'entrE les arbres', u'apr\\xe8s la nuit']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'le village effray\\xe9', u'fuit', u'', u'', u'devant les arbres furieux de la lance noire']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les loups', u'fuient', u'', u'', u'derri\\xe8re Mahira']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les deux arbres', u'fuyaient', u'', u'', u'sur les gorges de la for\\xeat']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les s\\u0153urs de la ma\\xeetresse du donjon', u'jardinent', u'', u'', u'au milieu des l\\xe9gumes ; devant le manoir']\n",
      "[[u'au', u'milieu', u'des', u'l\\xe9gumes'], [u'devant', u'le', u'manoir']]\n"
     ]
    }
   ],
   "source": [
    "if typeKalaba!=\"Kanonik\":\n",
    "    sortie=\"ordre\"\n",
    "    syntagmes=syntagmesLR\n",
    "    print syntagmes\n",
    "\n",
    "    lexemesLocaux=set()\n",
    "    if ordre_nom.endswith(\"csv\"):\n",
    "        try:\n",
    "            ordre_file = codecs.open(ordre_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the file', ordre_nom\n",
    "            sys.exit()      \n",
    "        else:\n",
    "            try:\n",
    "                cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "            except IOError:\n",
    "                print 'I could not open the cloze file', cloze_nom\n",
    "                sys.exit()\n",
    "            else:\n",
    "                ordre={}\n",
    "                for line in cloze_file.readlines():\n",
    "                    line=line.strip()\n",
    "                    if not line.startswith(\"#\"):\n",
    "                        elementsCloze=line.split(\";\")\n",
    "                        ordre[elementsCloze[0]]=elementsCloze[5]\n",
    "                cloze_file.close()\n",
    "                exemples=[]\n",
    "                accumulateur=[]\n",
    "                vocabulaire=[]\n",
    "    #            prononciationExtrait=[]\n",
    "                faire_phrases(ordre_file,sortie=sortie)\n",
    "                ordre_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'COMP', 'OBJ', 'AJOUT', 'IND', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['DET', 'GP', 'NOM', 'GADJ']}\n",
      "mots\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la louve', u'est', u'', u'', u'avec le village']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les grandes souffrances', u'fuyaient', u'', u'', u'vers ces deux d\\xe9mons effray\\xe9s']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'Mahira', u'fuyait', u'', u'', u'avec les deux visages du d\\xe9mon']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'la lune', u'fuyait', u'', u'', u'entrE les arbres', u'apr\\xe8s la nuit']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'le village effray\\xe9', u'fuit', u'', u'', u'devant les arbres furieux de la lance noire']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les loups', u'fuient', u'', u'', u'derri\\xe8re Mahira']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les deux arbres', u'fuyaient', u'', u'', u'sur les gorges de la for\\xeat']\n",
      "verbe ergatif sans objet [[u'']]\n",
      "[u'les s\\u0153urs de la ma\\xeetresse du donjon', u'jardinent', u'', u'', u'au milieu des l\\xe9gumes ; devant le manoir']\n",
      "[[u'au', u'milieu', u'des', u'l\\xe9gumes'], [u'devant', u'le', u'manoir']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if typeKalaba!=\"Kanonik\":\n",
    "    sortie=\"mots\"\n",
    "    if \"RightLeft\" in globals() and RightLeft:\n",
    "        syntagmes=syntagmesRL\n",
    "    else:\n",
    "        syntagmes=syntagmesLR\n",
    "    print syntagmes\n",
    "\n",
    "    lexemesLocaux=set()\n",
    "    if mots_nom.endswith(\"csv\"):\n",
    "        try:\n",
    "            mots_file = codecs.open(mots_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the file', mots_nom\n",
    "            sys.exit()      \n",
    "        else:\n",
    "            try:\n",
    "                cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "            except IOError:\n",
    "                print 'I could not open the cloze file', cloze_nom\n",
    "                sys.exit()\n",
    "            else:\n",
    "                motsIsoles={}\n",
    "                for line in cloze_file.readlines():\n",
    "                    line=line.strip()\n",
    "                    if not line.startswith(\"#\"):\n",
    "                        elementsCloze=line.split(\";\")\n",
    "                        motsIsoles[elementsCloze[0]]=elementsCloze[5]\n",
    "                cloze_file.close()\n",
    "                exemples=[]\n",
    "                accumulateur=[]\n",
    "                vocabulaire=[]\n",
    "    #            prononciationExtrait=[]\n",
    "                faire_phrases(mots_file,sortie=sortie)\n",
    "                mots_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok pour cette étape\n"
     ]
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "if variante==\"\": \n",
    "    print \"faire la correction\"\n",
    "    nextVariante=\"-Corr\"\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "else:\n",
    "    print u\"ok pour cette étape\"\n",
    "    del nextVariante\n",
    "    ding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post-traitements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.formeLexeme[\"trois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yamlDump(nFile,content):\n",
    "    with open(nFile, 'w') as output:\n",
    "        yaml.dump(content, output, default_flow_style=False,allow_unicode=True)\n",
    "\n",
    "    with open(nFile, 'r') as input:\n",
    "        yamlLines=input.readlines()\n",
    "\n",
    "    yamlText=\"\".join(yamlLines)\n",
    "    yamlText=re.sub(r\"!!python/unicode\",\"\",yamlText)\n",
    "    yamlText=re.sub(r\"\\n\\s*-\\s*\",\", \",yamlText)\n",
    "    yamlText=re.sub(r\":,\\s*\",\": \",yamlText)\n",
    "    yamlText=re.sub(r\": *([^\\n]+)\",\": [\\g<1>]\",yamlText)\n",
    "\n",
    "\n",
    "    with open(nFile, 'w') as output:\n",
    "        output.write(yamlText)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': [u'gros.A1.A.SG.Dat',\n",
       "  u'jaune.A2.C.SG.obl',\n",
       "  u'furieux.A1.D.PL.obl',\n",
       "  u'courageux.A2.C.SG.Erg',\n",
       "  u'effray\\xe9.A2.A.SG.erg',\n",
       "  u'rouge.A1.A.SG.Erg',\n",
       "  u'petit.A1.D.SG.obl',\n",
       "  u'blanc.A1.D.SG.Erg',\n",
       "  u'grand.A2.A.PAU.Abs',\n",
       "  u'rouge.A1.C.SG.Abs',\n",
       "  u'profond.A2.A.SG.Erg',\n",
       "  u'blanc.A1.A.SG.Dat',\n",
       "  u'nombreux.A2.C.PL.Abs',\n",
       "  u'rouge.A1.C.SG.Erg',\n",
       "  u'effray\\xe9.A2.C.SG.Abs',\n",
       "  u'noir.A2.A.PAU.Abs',\n",
       "  u'terrible.A1.B.PAU.Erg',\n",
       "  u'effray\\xe9.A2.A.SG.Erg',\n",
       "  u'petit.A1.A.PAU.obl',\n",
       "  u'terrible.A1.D.PL.Abs',\n",
       "  u'jaune.A2.C.SG.Abs',\n",
       "  u'quatre.A1.C.PAU.Abs',\n",
       "  u'grand.A2.A.SG.Erg',\n",
       "  u'grand.A2.D.PL.Erg',\n",
       "  u'noir.A2.C.PL.Erg',\n",
       "  u'gros.A1.D.PL.Abs',\n",
       "  u'trois.A2.D.PAU.Abs',\n",
       "  u'bless\\xe9.A2.A.SG.Erg',\n",
       "  u'blanc.A1.C.PAU.Erg',\n",
       "  u'gros.A1.D.PAU.Abs',\n",
       "  u'petit.A1.C.PL.Abs',\n",
       "  u'blanc.A1.A.SG.Abs',\n",
       "  u'petit.A1.C.PAU.Dat',\n",
       "  u'blanc.A1.B.PL.Abs',\n",
       "  u'petit.A1.B.SG.obl',\n",
       "  u'effray\\xe9.A2.A.PL.Abs',\n",
       "  u'petit.A1.D.PAU.erg',\n",
       "  u'deux.A2.C.PAU.Erg',\n",
       "  u'profond.A2.B.PL.Erg',\n",
       "  u'suivant.A1.B.SG.Abs',\n",
       "  u'sept.A2.C.PL.Dat',\n",
       "  u'terrible.A1.B.PL.Abs',\n",
       "  u'noir.A2.B.SG.Erg',\n",
       "  u'rouge.A1.C.SG.Dat',\n",
       "  u'petit.A1.A.PAU.Dat',\n",
       "  u'deux.A2.B.PAU.Dat',\n",
       "  u'petit.A1.A.PAU.Erg',\n",
       "  u'blanc.A1.D.SG.obl',\n",
       "  u'gros.A1.C.PL.Abs',\n",
       "  u'gros.A1.C.PAU.Abs',\n",
       "  u'blanc.A1.A.PAU.obl',\n",
       "  u'petit.A1.A.PL.Abs',\n",
       "  u'courageux.A2.B.SG.Abs',\n",
       "  u'deux.A2.D.PAU.obl',\n",
       "  u'blanc.A1.C.PAU.Abs',\n",
       "  u'noir.A2.C.PL.Abs',\n",
       "  u'noir.A2.D.PL.Abs',\n",
       "  u'noir.A2.A.PL.Abs',\n",
       "  u'petit.A1.A.SG.Erg',\n",
       "  u'noir.A2.B.SG.Abs',\n",
       "  u'blanc.A1.C.SG.Erg',\n",
       "  u'maigre.A2.C.SG.Abs',\n",
       "  u'bless\\xe9.A2.A.SG.obl',\n",
       "  u'noir.A2.D.PAU.Abs',\n",
       "  u'petit.A1.B.SG.Erg',\n",
       "  u'grand.A2.A.SG.obl',\n",
       "  u'vert.A1.D.PAU.erg',\n",
       "  u'terrible.A1.B.SG.Erg',\n",
       "  u'dernier.A1.D.SG.Erg',\n",
       "  u'rouge.A1.B.SG.Abs',\n",
       "  u'trois.A2.C.PAU.Abs',\n",
       "  u'cinq.A1.A.PAU.obl',\n",
       "  u'blanc.A1.B.SG.Erg',\n",
       "  u'blanc.A1.B.SG.Dat',\n",
       "  u'blanc.A1.D.SG.Dat',\n",
       "  u'noir.A2.A.SG.Erg',\n",
       "  u'grand.A2.C.SG.obl',\n",
       "  u'autre.A1.C.PL.obl',\n",
       "  u'blanc.A1.C.SG.obl',\n",
       "  u'vert.A1.D.PL.Abs',\n",
       "  u'suivant.A1.D.PL.Erg',\n",
       "  u'jaune.A2.C.PAU.Erg',\n",
       "  u'vert.A1.B.SG.Abs',\n",
       "  u'jaune.A2.D.PAU.Abs',\n",
       "  u'petit.A1.A.SG.Dat',\n",
       "  u'gros.A1.D.PAU.Erg',\n",
       "  u'effray\\xe9.A2.C.SG.Erg',\n",
       "  u'effray\\xe9.A2.D.SG.erg',\n",
       "  u'treize.A2.C.PL.erg',\n",
       "  u'm\\xe9chant.A2.A.SG.obl',\n",
       "  u'trois.A2.A.PAU.Erg',\n",
       "  u'grand.A2.A.SG.Abs',\n",
       "  u'courageux.A2.D.SG.Abs',\n",
       "  u'blanc.A1.D.PAU.Abs',\n",
       "  u'courageux.A2.A.PAU.obl',\n",
       "  u'm\\xe9chant.A2.D.SG.obl',\n",
       "  u'bless\\xe9.A2.B.SG.obl',\n",
       "  u'petit.A1.D.SG.Dat',\n",
       "  u'quatre.A1.D.PAU.Abs',\n",
       "  u'blanc.A1.C.PL.Abs',\n",
       "  u'cinq.A1.C.PAU.obl',\n",
       "  u'noir.A2.A.SG.obl',\n",
       "  u'suivant.A1.C.SG.Erg',\n",
       "  u'quatre.A1.A.PAU.obl',\n",
       "  u'blanc.A1.A.PL.Erg',\n",
       "  u'petit.A1.C.SG.obl',\n",
       "  u'jaune.A2.B.PL.Abs',\n",
       "  u'deux.A2.C.PAU.Dat',\n",
       "  u'courageux.A2.C.PL.obl',\n",
       "  u'grand.A2.A.PL.obl',\n",
       "  u'bas.A1.A.SG.obl',\n",
       "  u'maigre.A2.A.PL.Dat',\n",
       "  u'quatre.A1.D.PAU.erg',\n",
       "  u'petit.A1.D.PL.Erg',\n",
       "  u'deux.A2.A.PAU.erg',\n",
       "  u'effray\\xe9.A2.B.PAU.obl',\n",
       "  u'deux.A2.D.PAU.Dat',\n",
       "  u'terrible.A1.D.SG.Abs',\n",
       "  u'petit.A1.B.SG.Abs',\n",
       "  u'vert.A1.B.PL.Erg',\n",
       "  u'trois.A2.A.PAU.Abs',\n",
       "  u'jaune.A2.C.PL.erg',\n",
       "  u'noir.A2.C.PAU.Erg',\n",
       "  u'blanc.A1.D.SG.erg',\n",
       "  u'blanc.A1.B.SG.Abs',\n",
       "  u'quatre.A1.C.PAU.Erg',\n",
       "  u'rouge.A1.C.PL.Abs',\n",
       "  u'noir.A2.B.PL.Erg',\n",
       "  u'rouge.A1.A.PAU.Dat',\n",
       "  u'noir.A2.C.SG.obl',\n",
       "  u'dernier.A1.A.SG.obl',\n",
       "  u'gros.A1.A.PAU.Abs',\n",
       "  u'disparu.A2.C.PAU.Abs',\n",
       "  u'troisi\\xe8me.A2.A.SG.Abs',\n",
       "  u'quatre.A1.A.PAU.Abs',\n",
       "  u'deux.A2.A.PAU.Abs',\n",
       "  u'courageux.A2.A.PL.Abs',\n",
       "  u'terrible.A1.C.PL.obl',\n",
       "  u'treize.A2.A.PL.Abs',\n",
       "  u'treize.A2.C.PL.Dat',\n",
       "  u'courageux.A2.A.PL.erg',\n",
       "  u'petit.A1.A.PL.erg',\n",
       "  u'vilain.A1.D.PAU.Dat',\n",
       "  u'grand.A2.D.SG.Erg',\n",
       "  u'diff\\xe9rent.A1.C.PAU.Abs',\n",
       "  u'vert.A1.A.SG.obl',\n",
       "  u'maigre.A2.D.PL.Erg',\n",
       "  u'blanc.A1.D.PL.obl',\n",
       "  u'noir.A2.C.PL.obl',\n",
       "  u'deux.A2.D.PAU.erg',\n",
       "  u'noir.A2.A.PL.obl',\n",
       "  u'profond.A2.A.SG.obl',\n",
       "  u'gros.A1.C.PAU.erg',\n",
       "  u'noir.A2.D.SG.Abs',\n",
       "  u'deux.A2.A.PAU.Dat',\n",
       "  u'grand.A2.A.PL.Abs',\n",
       "  u'trois.A2.A.PAU.obl',\n",
       "  u'quatre.A1.B.PAU.Abs',\n",
       "  u'maigre.A2.C.PAU.Erg',\n",
       "  u'grand.A2.D.SG.obl',\n",
       "  u'm\\xe9chant.A2.C.PAU.Abs',\n",
       "  u'dernier.A1.C.PL.erg',\n",
       "  u'vilain.A1.A.PAU.dat',\n",
       "  u'autre.A1.A.SG.Erg',\n",
       "  u'noir.A2.A.SG.Abs',\n",
       "  u'cinq.A1.C.PAU.Abs',\n",
       "  u'deux.A2.D.PAU.Abs',\n",
       "  u'blanc.A1.D.PL.Erg',\n",
       "  u'grand.A2.D.PAU.Abs',\n",
       "  u'grand.A2.B.SG.erg',\n",
       "  u'noir.A2.D.SG.Dat',\n",
       "  u'deux.A2.D.PAU.Erg',\n",
       "  u'petit.A1.D.SG.Erg',\n",
       "  u'grand.A2.D.PAU.Erg',\n",
       "  u'disparu.A2.C.SG.obl',\n",
       "  u'm\\xe9chant.A2.C.PAU.Dat',\n",
       "  u'six.A1.D.PL.Abs',\n",
       "  u'rouge.A1.B.PL.Abs',\n",
       "  u'noir.A2.C.SG.Erg',\n",
       "  u'gros.A1.C.SG.Erg',\n",
       "  u'gros.A1.C.SG.obl',\n",
       "  u'grand.A2.B.SG.Erg',\n",
       "  u'sept.A2.B.PL.Abs',\n",
       "  u'grand.A2.D.PAU.obl',\n",
       "  u'grand.A2.B.SG.Dat',\n",
       "  u'suivant.A1.C.PAU.Abs',\n",
       "  u'petit.A1.D.SG.Abs',\n",
       "  u'jaune.A2.D.PL.Abs',\n",
       "  u'petit.A1.C.PL.Dat',\n",
       "  u'rouge.A1.B.SG.Dat',\n",
       "  u'deux.A2.C.PAU.erg',\n",
       "  u'noir.A2.C.SG.erg',\n",
       "  u'grand.A2.C.PL.Dat',\n",
       "  u'nouveau.A2.C.SG.Erg',\n",
       "  u'petit.A1.A.SG.erg',\n",
       "  u'maigre.A2.A.PL.obl',\n",
       "  u'deux.A2.A.PAU.obl',\n",
       "  u'gros.A1.C.PL.obl',\n",
       "  u'nouveau.A2.C.PL.Abs',\n",
       "  u'terrible.A1.D.PAU.obl',\n",
       "  u'maigre.A2.C.PAU.obl',\n",
       "  u'deux.A2.C.PAU.obl',\n",
       "  u'diff\\xe9rent.A1.B.SG.Abs',\n",
       "  u'trois.A2.C.PAU.Erg',\n",
       "  u'effray\\xe9.A2.A.PAU.Erg',\n",
       "  u'maigre.A2.D.PAU.Erg',\n",
       "  u'profond.A2.D.SG.Erg',\n",
       "  u'vert.A1.A.SG.Erg',\n",
       "  u'rouge.A1.D.SG.Abs',\n",
       "  u'petit.A1.B.PAU.erg',\n",
       "  u'deux.A2.B.PAU.erg',\n",
       "  u'blanc.A1.A.PAU.Abs',\n",
       "  u'profond.A2.D.SG.Abs',\n",
       "  u'furieux.A1.C.SG.Erg',\n",
       "  u'gros.A1.A.PAU.obl',\n",
       "  u'petit.A1.C.SG.Abs',\n",
       "  u'rouge.A1.C.SG.obl',\n",
       "  u'trois.A2.D.PAU.erg',\n",
       "  u'm\\xe9chant.A2.C.PL.Abs',\n",
       "  u'petit.A1.D.PAU.Abs',\n",
       "  u'gros.A1.D.PL.Erg',\n",
       "  u'm\\xe9chant.A2.A.PL.Dat',\n",
       "  u'blanc.A1.B.SG.obl',\n",
       "  u'cinq.A1.B.PAU.Abs',\n",
       "  u'h\\xe9ro\\xefque.A1.D.PL.Abs',\n",
       "  u'furieux.A1.A.PL.obl',\n",
       "  u'rouge.A1.D.SG.Erg',\n",
       "  u'petit.A1.B.PAU.Erg',\n",
       "  u'furieux.A1.D.PL.Abs',\n",
       "  u'noir.A2.B.PAU.Abs',\n",
       "  u'blanc.A1.A.PL.erg',\n",
       "  u'deux.A2.C.PAU.Abs',\n",
       "  u'profond.A2.A.PL.obl',\n",
       "  u'deux.A2.B.PAU.Abs',\n",
       "  u'bless\\xe9.A2.A.SG.Abs',\n",
       "  u'jaune.A2.A.PAU.Abs',\n",
       "  u'trois.A2.D.PAU.Erg',\n",
       "  u'h\\xe9ro\\xefque.A1.C.PL.obl',\n",
       "  u'deux.A2.B.PAU.Erg',\n",
       "  u'quatre.A1.A.PAU.Erg',\n",
       "  u'effray\\xe9.A2.C.PL.Abs',\n",
       "  u'profond.A2.B.SG.Abs',\n",
       "  u'petit.A1.A.SG.obl',\n",
       "  u'rouge.A1.D.PAU.Abs',\n",
       "  u'rouge.A1.D.PL.Abs',\n",
       "  u'm\\xe9chant.A2.B.PL.Abs',\n",
       "  u'deux.A2.A.PAU.Erg',\n",
       "  u'furieux.A1.C.SG.Abs',\n",
       "  u'gros.A1.D.SG.Erg',\n",
       "  u'bless\\xe9.A2.A.PAU.Erg',\n",
       "  u'noir.A2.C.SG.Abs',\n",
       "  u'nombreux.A2.B.PL.Abs',\n",
       "  u'dernier.A1.A.SG.Abs',\n",
       "  u'autre.A1.D.PL.Abs',\n",
       "  u'petit.A1.D.PL.Abs',\n",
       "  u'sept.A2.C.PL.Erg',\n",
       "  u'six.A1.A.PL.Abs',\n",
       "  u'vert.A1.C.SG.erg',\n",
       "  u'petit.A1.B.PAU.Abs',\n",
       "  u'grand.A2.C.SG.Abs',\n",
       "  u'noir.A2.D.SG.Erg',\n",
       "  u'six.A1.A.PL.Erg',\n",
       "  u'm\\xe9chant.A2.C.PAU.obl',\n",
       "  u'grand.A2.A.SG.Dat',\n",
       "  u'diff\\xe9rent.A1.C.PL.obl',\n",
       "  u'diff\\xe9rent.A1.B.SG.Dat',\n",
       "  u'grand.A2.D.SG.Abs',\n",
       "  u'rouge.A1.D.PAU.Erg',\n",
       "  u'grand.A2.B.SG.Abs',\n",
       "  u'grand.A2.B.SG.obl',\n",
       "  u'nouveau.A2.B.SG.obl',\n",
       "  u'deux.A2.B.PAU.obl',\n",
       "  u'profond.A2.B.SG.Erg',\n",
       "  u'petit.A1.C.SG.Erg',\n",
       "  u'vert.A1.C.SG.Abs',\n",
       "  u'petit.A1.A.SG.Abs',\n",
       "  u'suivant.A1.C.SG.obl',\n",
       "  u'bless\\xe9.A2.A.PL.Abs',\n",
       "  u'furieux.A1.B.SG.Erg'],\n",
       " 'DET': [u'DEF.A.PL.erg',\n",
       "  u'IND.B.SG.obl',\n",
       "  u'IND.D.PL.Erg',\n",
       "  u'DEM.A.PAU.Erg',\n",
       "  u'DEF.B.SG.dat',\n",
       "  u'IND.C.PL.obl',\n",
       "  u'IND.D.PAU.Erg',\n",
       "  u'IND.B.PL.obl',\n",
       "  u'DEF.A.PAU.dat',\n",
       "  u'DEF.C.PL.Abs',\n",
       "  u'IND.A.PL.dat',\n",
       "  u'IND.A.SG.Erg',\n",
       "  u'DEF.C.PAU.erg',\n",
       "  u'DEF.D.PL.obl',\n",
       "  u'DEF.B.SG.Dat',\n",
       "  u'DEF.A.SG.Erg',\n",
       "  u'DEF.C.SG.obl',\n",
       "  u'DEM.C.PL.Dat',\n",
       "  u'DEF.C.PL.Dat',\n",
       "  u'DEF.B.PL.Dat',\n",
       "  u'DEF.B.SG.Abs',\n",
       "  u'DEF.B.PAU.Erg',\n",
       "  u'DEF.C.PAU.Abs',\n",
       "  u'IND.D.PAU.Abs',\n",
       "  u'DEM.D.PAU.Erg',\n",
       "  u'DEM.B.PAU.Abs',\n",
       "  u'DEM.D.PL.Erg',\n",
       "  u'DEM.C.PAU.obl',\n",
       "  u'IND.B.SG.Erg',\n",
       "  u'DEM.A.PL.Abs',\n",
       "  u'DEM.D.PL.Abs',\n",
       "  u'DEF.D.SG.dat',\n",
       "  u'IND.A.PL.obl',\n",
       "  u'DEF.B.SG.erg',\n",
       "  u'DEF.B.PAU.Abs',\n",
       "  u'DEM.C.PAU.Abs',\n",
       "  u'IND.C.PAU.Dat',\n",
       "  u'IND.D.PL.Abs',\n",
       "  u'DEF.D.PL.dat',\n",
       "  u'IND.B.PAU.erg',\n",
       "  u'DEF.C.SG.Erg',\n",
       "  u'DEF.C.PL.obl',\n",
       "  u'DEF.A.SG.Abs',\n",
       "  u'IND.A.PL.Erg',\n",
       "  u'DEF.B.PL.erg',\n",
       "  u'DEM.A.SG.obl',\n",
       "  u'IND.B.PL.Abs',\n",
       "  u'IND.A.PAU.Abs',\n",
       "  u'IND.C.PL.Erg',\n",
       "  u'DEF.B.SG.obl',\n",
       "  u'DEF.C.SG.erg',\n",
       "  u'IND.C.PAU.obl',\n",
       "  u'IND.C.PAU.Erg',\n",
       "  u'DEM.C.PL.obl',\n",
       "  u'DEM.A.PL.Dat',\n",
       "  u'DEF.C.PAU.obl',\n",
       "  u'DEF.D.SG.Abs',\n",
       "  u'IND.A.PAU.erg',\n",
       "  u'DEF.C.SG.Dat',\n",
       "  u'IND.D.SG.Dat',\n",
       "  u'DEF.D.SG.Erg',\n",
       "  u'DEF.D.PL.Erg',\n",
       "  u'DEF.D.PL.Abs',\n",
       "  u'IND.A.SG.obl',\n",
       "  u'IND.D.PAU.obl',\n",
       "  u'DEF.B.PAU.Dat',\n",
       "  u'IND.D.SG.Abs',\n",
       "  u'DEM.B.SG.Dat',\n",
       "  u'DEF.C.PL.Erg',\n",
       "  u'IND.D.SG.Erg',\n",
       "  u'DEF.D.PL.erg',\n",
       "  u'IND.B.SG.erg',\n",
       "  u'DEM.B.SG.Abs',\n",
       "  u'IND.D.PAU.erg',\n",
       "  u'IND.A.PL.erg',\n",
       "  u'DEM.A.PAU.Dat',\n",
       "  u'DEM.C.PAU.Dat',\n",
       "  u'IND.C.SG.Dat',\n",
       "  u'DEM.D.SG.Abs',\n",
       "  u'DEF.C.SG.Abs',\n",
       "  u'DEM.A.PL.obl',\n",
       "  u'DEM.C.SG.Abs',\n",
       "  u'DEF.A.SG.erg',\n",
       "  u'DEF.A.PAU.Erg',\n",
       "  u'DEF.A.SG.dat',\n",
       "  u'DEF.D.PAU.Erg',\n",
       "  u'DEM.B.PL.Abs',\n",
       "  u'DEM.C.SG.Erg',\n",
       "  u'IND.A.PL.Abs',\n",
       "  u'DEM.A.SG.Abs',\n",
       "  u'DEM.C.PAU.Erg',\n",
       "  u'IND.C.SG.obl',\n",
       "  u'DEF.A.PL.Erg',\n",
       "  u'DEF.A.PAU.obl',\n",
       "  u'DEF.D.PAU.obl',\n",
       "  u'DEF.C.SG.dat',\n",
       "  u'IND.B.PL.Dat',\n",
       "  u'DEF.A.SG.Dat',\n",
       "  u'DEF.D.PAU.erg',\n",
       "  u'DEF.A.PAU.Dat',\n",
       "  u'IND.C.PAU.erg',\n",
       "  u'DEM.D.SG.Erg',\n",
       "  u'DEF.A.PL.Dat',\n",
       "  u'DEF.D.SG.obl',\n",
       "  u'IND.B.SG.Dat',\n",
       "  u'IND.C.PAU.Abs',\n",
       "  u'IND.D.PL.obl',\n",
       "  u'DEF.D.PL.Dat',\n",
       "  u'DEM.B.PAU.obl',\n",
       "  u'DEF.C.PAU.Dat',\n",
       "  u'IND.A.SG.Abs',\n",
       "  u'DEF.D.PAU.Abs',\n",
       "  u'DEF.B.PL.obl',\n",
       "  u'DEF.B.PL.Abs',\n",
       "  u'DEM.B.SG.Erg',\n",
       "  u'DEF.B.PL.Erg',\n",
       "  u'IND.C.PL.Abs',\n",
       "  u'IND.B.SG.Abs',\n",
       "  u'DEF.D.SG.Dat',\n",
       "  u'IND.C.SG.Erg',\n",
       "  u'DEF.B.SG.Erg',\n",
       "  u'DEF.A.PL.obl',\n",
       "  u'IND.D.SG.obl',\n",
       "  u'DEF.D.PAU.Dat',\n",
       "  u'DEF.B.PAU.obl',\n",
       "  u'IND.C.PL.Dat',\n",
       "  u'IND.A.PAU.Erg',\n",
       "  u'IND.B.PAU.Erg',\n",
       "  u'IND.B.PAU.Dat',\n",
       "  u'DEM.A.PAU.Abs',\n",
       "  u'DEF.C.PAU.Erg',\n",
       "  u'DEM.C.PL.Abs',\n",
       "  u'DEM.D.PAU.obl',\n",
       "  u'DEF.A.PAU.erg',\n",
       "  u'IND.B.PAU.Abs',\n",
       "  u'IND.D.SG.erg',\n",
       "  u'IND.C.PL.erg',\n",
       "  u'DEM.B.SG.obl',\n",
       "  u'IND.C.SG.erg',\n",
       "  u'DEM.C.SG.obl',\n",
       "  u'DEM.A.SG.Erg',\n",
       "  u'DEM.B.PAU.Erg',\n",
       "  u'DEM.B.PL.Erg',\n",
       "  u'DEF.A.PAU.Abs',\n",
       "  u'DEM.A.PL.Erg',\n",
       "  u'DEM.C.SG.Dat',\n",
       "  u'DEF.A.SG.obl',\n",
       "  u'DEF.A.PL.Abs',\n",
       "  u'IND.A.SG.erg',\n",
       "  u'IND.C.SG.Abs',\n",
       "  u'DEM.D.PAU.Abs',\n",
       "  u'DEM.A.SG.erg',\n",
       "  u'DEM.D.SG.obl',\n",
       "  u'DEF.C.PL.erg',\n",
       "  u'IND.A.PAU.obl'],\n",
       " 'NOM': [u'place.B.N3.Sg.Obl',\n",
       "  u'villageois.C.N4.Sg.Erg',\n",
       "  u'nuit.C.N3.Sg.Obl',\n",
       "  u'chasseur.D.N3.Pl.Dat',\n",
       "  u'loup.B.N2.Pau.Abs',\n",
       "  u'autruche.C.N4.Sg.Erg',\n",
       "  u'dragon.D.N3.Pl.Obl',\n",
       "  u'ma\\xeetre.A.N3.Sg.Obl',\n",
       "  u'Elphaba.D.N4.Sg.Obl',\n",
       "  u'donjon.D.N2.Sg.Obl',\n",
       "  u'd\\xe9mon.B.N1.Pl.Erg',\n",
       "  u'croc.A.N1.Pl.Abs',\n",
       "  u'visage.D.N1.Sg.Abs',\n",
       "  u'sort.D.N1.Pl.Dat',\n",
       "  u'lance.C.N3.Sg.Obl',\n",
       "  u'femme.C.N1.Pl.Obl',\n",
       "  u'table.A.N2.Sg.Erg',\n",
       "  u'main.D.N2.Sg.Abs',\n",
       "  u'jardin.B.N3.Sg.Obl',\n",
       "  u'chatte.C.N1.Pau.Abs',\n",
       "  u'h\\xe9ros.A.N1.Pau.Erg',\n",
       "  u'gar\\xe7on.D.N1.Sg.Erg',\n",
       "  u'arbre.D.N4.Pau.Erg',\n",
       "  u'coussin.C.N1.Pl.Obl',\n",
       "  u'Agathos.D.N3.Pl.Obl',\n",
       "  u'croc.A.N1.Sg.Abs',\n",
       "  u'livre.D.N1.Sg.Erg',\n",
       "  u'chatte.C.N1.Pau.Dat',\n",
       "  u'corps.B.N3.Pau.Abs',\n",
       "  u'p\\xe8re.A.N3.Pl.Erg',\n",
       "  u'autruche.C.N4.Pl.Dat',\n",
       "  u'cuisine.D.N4.Sg.Abs',\n",
       "  u'chemin.A.N1.Sg.Abs',\n",
       "  u'couteau.A.N2.Sg.Erg',\n",
       "  u'autruche.C.N4.Pl.Obl',\n",
       "  u'raison.A.N1.Pl.Abs',\n",
       "  u'coussin.C.N1.Sg.Abs',\n",
       "  u'sort.D.N1.Sg.Abs',\n",
       "  u'esprit.B.N2.Sg.Dat',\n",
       "  u'fille.A.N2.Sg.Erg',\n",
       "  u'balai.C.N1.Sg.Erg',\n",
       "  u'livre.D.N1.Sg.Obl',\n",
       "  u'crapaud.B.N3.Sg.Obl',\n",
       "  u'livre.D.N1.Pau.Erg',\n",
       "  u'enfant.C.N4.Pl.Dat',\n",
       "  u'crapaud.B.N3.Pl.Erg',\n",
       "  u'gar\\xe7on.D.N1.Pl.Obl',\n",
       "  u'gargouille.D.N4.Pl.Abs',\n",
       "  u'souris.D.N1.Pl.Abs',\n",
       "  u'mort.B.N4.Sg.Obl',\n",
       "  u'village.C.N3.Sg.Dat',\n",
       "  u'lance.C.N3.Pau.Abs',\n",
       "  u'Nicole.C.N2.Sg.Obl',\n",
       "  u'lumi\\xe8re.A.N4.Sg.Dat',\n",
       "  u'd\\xe9mon.B.N1.Pl.Abs',\n",
       "  u'd\\xe9mon.B.N1.Sg.Dat',\n",
       "  u'lit.D.N3.Pl.Erg',\n",
       "  u'combattant.A.N4.Pl.Abs',\n",
       "  u'sorcier.A.N2.Sg.Abs',\n",
       "  u'village.C.N3.Pl.Dat',\n",
       "  u'Nicole.C.N2.Sg.Abs',\n",
       "  u'sorcier.A.N2.Pl.Dat',\n",
       "  u'Nabil.D.N3.Sg.Dat',\n",
       "  u'crapaud.B.N3.Pau.Abs',\n",
       "  u'Elphaba.D.N4.Sg.Abs',\n",
       "  u'ma\\xeetre.A.N3.Sg.Abs',\n",
       "  u'nuit.C.N3.Pau.Erg',\n",
       "  u'blessure.B.N1.Sg.Erg',\n",
       "  u'nuit.C.N3.Pl.Abs',\n",
       "  u'peau.B.N2.Sg.Abs',\n",
       "  u'infirmi\\xe8re.B.N1.Pl.Obl',\n",
       "  u'proximit\\xe9.D.N4.Sg.Obl',\n",
       "  u'col\\xe8re.A.N1.Pl.Erg',\n",
       "  u'enfant.C.N4.Pl.Obl',\n",
       "  u'chef.C.N2.Pl.Dat',\n",
       "  u'dragon.D.N3.Sg.Erg',\n",
       "  u'vote.B.N4.Sg.Erg',\n",
       "  u'gargouille.D.N4.Pl.Obl',\n",
       "  u'balai.C.N1.Pau.Erg',\n",
       "  u'souris.D.N1.Sg.Erg',\n",
       "  u'sorcier.A.N2.Pau.Obl',\n",
       "  u'robe.C.N1.Sg.Abs',\n",
       "  u'infirmi\\xe8re.B.N1.Pau.Abs',\n",
       "  u'louve.A.N3.Sg.Erg',\n",
       "  u'arbre.D.N4.Sg.Obl',\n",
       "  u'coyote.A.N4.Pl.Obl',\n",
       "  u'village.C.N3.Sg.Erg',\n",
       "  u'l\\xe9gende.C.N2.Sg.Abs',\n",
       "  u'd\\xe9g\\xe2t.D.N1.Pl.Obl',\n",
       "  u'for\\xeat.A.N2.Sg.Obl',\n",
       "  u'lit.D.N3.Sg.Obl',\n",
       "  u'louve.A.N3.Sg.Obl',\n",
       "  u'Kaleb.B.N2.Sg.Erg',\n",
       "  u'blessure.B.N1.Pl.Erg',\n",
       "  u'villageoise.A.N4.Pl.Erg',\n",
       "  u'oeil.C.N3.Pl.Obl',\n",
       "  u'Hoderi.B.N4.Sg.Abs',\n",
       "  u'souris.D.N1.Pau.Erg',\n",
       "  u'lueur.C.N3.Sg.Erg',\n",
       "  u'lune.C.N4.Sg.Obl',\n",
       "  u'homme.A.N2.Pl.Abs',\n",
       "  u'Katisha.A.N3.Sg.Obl',\n",
       "  u'gar\\xe7on.D.N1.Pl.Abs',\n",
       "  u'enfant.C.N4.Sg.Obl',\n",
       "  u'combat.D.N2.Pl.Erg',\n",
       "  u'infirmi\\xe8re.B.N1.Sg.Erg',\n",
       "  u'visage.D.N1.Pl.Abs',\n",
       "  u'souffrance.D.N1.Sg.Erg',\n",
       "  u'homme.A.N2.Sg.Erg',\n",
       "  u'autruche.C.N4.Pau.Abs',\n",
       "  u'nuit.C.N3.Sg.Erg',\n",
       "  u'combattant.A.N4.Sg.Erg',\n",
       "  u'd\\xe9mon.B.N1.Sg.Erg',\n",
       "  u'couteau.A.N2.Sg.Abs',\n",
       "  u'col\\xe8re.A.N1.Pau.Erg',\n",
       "  u'chasseur.D.N3.Pau.Dat',\n",
       "  u'Mahira.C.N4.Sg.Abs',\n",
       "  u'sorcier.A.N2.Pl.Erg',\n",
       "  u'poisson.D.N2.Pau.Abs',\n",
       "  u'caf\\xe9.A.N2.Pl.Abs',\n",
       "  u'hurlement.C.N4.Pl.Abs',\n",
       "  u'grimoire.B.N4.Pl.Erg',\n",
       "  u'gorge.A.N3.Sg.Abs',\n",
       "  u'poisson.D.N2.Pl.Abs',\n",
       "  u'main.D.N2.Pl.Abs',\n",
       "  u'chasseur.D.N3.Pl.Abs',\n",
       "  u'combattant.A.N4.Pl.Dat',\n",
       "  u'caf\\xe9.A.N2.Pau.Abs',\n",
       "  u'cuisine.D.N4.Sg.Dat',\n",
       "  u'ombre.A.N2.Sg.Abs',\n",
       "  u'raison.A.N1.Sg.Obl',\n",
       "  u'loup.B.N2.Pl.Erg',\n",
       "  u'cr\\xe9ature.B.N2.Pl.Abs',\n",
       "  u'c\\xf4t\\xe9.C.N3.Sg.Obl',\n",
       "  u'coyote.A.N4.Pau.Abs',\n",
       "  u'Violette.A.N1.Sg.Abs',\n",
       "  u'main.D.N2.Pl.Obl',\n",
       "  u'fille.A.N2.Sg.Abs',\n",
       "  u'tornade.A.N4.Sg.Erg',\n",
       "  u'croc.A.N1.Pl.Erg',\n",
       "  u'loup.B.N2.Sg.Dat',\n",
       "  u'col\\xe8re.A.N1.Sg.Erg',\n",
       "  u'caillou.B.N4.Pl.Obl',\n",
       "  u'm\\xe8re.A.N4.Pau.Erg',\n",
       "  u'fille.A.N2.Pl.Dat',\n",
       "  u'Agathos.D.N3.Sg.Obl',\n",
       "  u'maison.C.N2.Pl.Obl',\n",
       "  u'grimoire.B.N4.Sg.Abs',\n",
       "  u'villageois.C.N4.Pl.Obl',\n",
       "  u'obscurit\\xe9.A.N1.Sg.Obl',\n",
       "  u'Clemencia.C.N1.Sg.Obl',\n",
       "  u'caillou.B.N4.Pl.Abs',\n",
       "  u'louve.A.N3.Sg.Abs',\n",
       "  u'table.A.N2.Sg.Abs',\n",
       "  u'lueur.C.N3.Pl.Obl',\n",
       "  u'Mahira.C.N4.Pau.Abs',\n",
       "  u'balai.C.N1.Pl.Erg',\n",
       "  u'arbre.D.N4.Pl.Abs',\n",
       "  u'cuisine.D.N4.Sg.Obl',\n",
       "  u'esprit.B.N2.Pau.Abs',\n",
       "  u'caf\\xe9.A.N2.Sg.Abs',\n",
       "  u'chef.C.N2.Sg.Erg',\n",
       "  u'l\\xe9gende.C.N2.Pau.Abs',\n",
       "  u'infirmi\\xe8re.B.N1.Pl.Abs',\n",
       "  u'enfant.C.N4.Pau.Erg',\n",
       "  u'Elphaba.D.N4.Sg.Erg',\n",
       "  u'l\\xe9gume.C.N4.Pl.Obl',\n",
       "  u'lit.D.N3.Pl.Abs',\n",
       "  u'maison.C.N2.Pau.Obl',\n",
       "  u'loup.B.N2.Pl.Obl',\n",
       "  u'nuit.C.N3.Pau.Obl',\n",
       "  u'table.A.N2.Pl.Obl',\n",
       "  u'Kaleb.B.N2.Pl.Obl',\n",
       "  u'viande.D.N3.Pl.Abs',\n",
       "  u'sort.D.N1.Sg.Erg',\n",
       "  u'lumi\\xe8re.A.N4.Sg.Abs',\n",
       "  u'mort.B.N4.Sg.Abs',\n",
       "  u'Hoderi.B.N4.Sg.Erg',\n",
       "  u'caillou.B.N4.Pau.Dat',\n",
       "  u'place.B.N3.Sg.Abs',\n",
       "  u'souris.D.N1.Pl.Erg',\n",
       "  u'harmonie.C.N4.Sg.Obl',\n",
       "  u'combat.D.N2.Pl.Abs',\n",
       "  u'corps.B.N3.Sg.Obl',\n",
       "  u'villageoise.A.N4.Sg.Abs',\n",
       "  u'chambre.A.N3.Pau.Abs',\n",
       "  u'coussin.C.N1.Pl.Erg',\n",
       "  u'Violette.A.N1.Sg.Erg',\n",
       "  u'loup.B.N2.Pau.Dat',\n",
       "  u'infirmi\\xe8re.B.N1.Pl.Dat',\n",
       "  u'chat.C.N3.Pau.Erg',\n",
       "  u'chat.C.N3.Sg.Erg',\n",
       "  u'Freja.C.N2.Sg.Erg',\n",
       "  u'combattant.A.N4.Pl.Erg',\n",
       "  u'sorcier.A.N2.Pau.Dat',\n",
       "  u'fille.A.N2.Pl.Obl',\n",
       "  u'infirmi\\xe8re.B.N1.Pau.Obl',\n",
       "  u'sorcier.A.N2.Sg.Obl',\n",
       "  u'demande.B.N1.Sg.Obl',\n",
       "  u'lumi\\xe8re.A.N4.Pl.Abs',\n",
       "  u'gar\\xe7on.D.N1.Pl.Erg',\n",
       "  u'gargouille.D.N4.Pau.Abs',\n",
       "  u'coussin.C.N1.Sg.Obl',\n",
       "  u'visage.D.N1.Pau.Erg',\n",
       "  u'gorge.A.N3.Pl.Obl',\n",
       "  u'ombre.A.N2.Sg.Erg',\n",
       "  u'dernier-N.D.N4.Pl.Abs',\n",
       "  u'combattant.A.N4.Sg.Obl',\n",
       "  u'sortil\\xe8ge.B.N3.Sg.Obl',\n",
       "  u'histoire.A.N3.Pau.Abs',\n",
       "  u'oeil.C.N3.Pl.Erg',\n",
       "  u'b\\xfbcher.B.N1.Sg.Abs',\n",
       "  u'souffrance.D.N1.Pau.Obl',\n",
       "  u'table.A.N2.Sg.Obl',\n",
       "  u'lance.C.N3.Sg.Erg',\n",
       "  u'main.D.N2.Pl.Erg',\n",
       "  u'maison.C.N2.Sg.Erg',\n",
       "  u'serpent.B.N2.Pl.Abs',\n",
       "  u'village.C.N3.Sg.Abs',\n",
       "  u'enfant.C.N4.Sg.Erg',\n",
       "  u'femme.C.N1.Pl.Dat',\n",
       "  u'robe.C.N1.Sg.Erg',\n",
       "  u'mort.B.N4.Sg.Dat',\n",
       "  u'chasseur.D.N3.Pau.Abs',\n",
       "  u'chat.C.N3.Pl.Dat',\n",
       "  u'grimoire.B.N4.Sg.Obl',\n",
       "  u'd\\xe9mon.B.N1.Pl.Obl',\n",
       "  u'milieu.A.N4.Sg.Obl',\n",
       "  u'villageois.C.N4.Pl.Dat',\n",
       "  u'construction.D.N4.Sg.Obl',\n",
       "  u'cri.B.N3.Pau.Abs',\n",
       "  u'marais.A.N4.Sg.Abs',\n",
       "  u'maison.C.N2.Sg.Obl',\n",
       "  u'douleur.C.N2.Sg.Obl',\n",
       "  u'loup.B.N2.Sg.Erg',\n",
       "  u'loup.B.N2.Pau.Erg',\n",
       "  u'main.D.N2.Pau.Obl',\n",
       "  u'Freja.C.N2.Sg.Obl',\n",
       "  u'gorge.A.N3.Sg.Erg',\n",
       "  u'coup.D.N2.Pl.Erg',\n",
       "  u'chasseur.D.N3.Sg.Obl',\n",
       "  u'table.A.N2.Pau.Erg',\n",
       "  u'manoir.B.N4.Sg.Obl',\n",
       "  u'chat.C.N3.Sg.Obl',\n",
       "  u'homme.A.N2.Sg.Obl',\n",
       "  u'coussin.C.N1.Pl.Abs',\n",
       "  u'chambre.A.N3.Sg.Obl',\n",
       "  u'Violette.A.N1.Sg.Obl',\n",
       "  u'parent.D.N4.Pl.Erg',\n",
       "  u'loup.B.N2.Pl.Abs',\n",
       "  u'infirmi\\xe8re.B.N1.Sg.Abs',\n",
       "  u'plaine.D.N1.Pl.Obl',\n",
       "  u'poisson.D.N2.Sg.Abs',\n",
       "  u'feu.B.N3.Sg.Obl',\n",
       "  u'balai.C.N1.Pau.Obl',\n",
       "  u'autruche.C.N4.Pl.Abs',\n",
       "  u'couteau.A.N2.Pau.Erg',\n",
       "  u'souffrance.D.N1.Sg.Abs',\n",
       "  u'fille.A.N2.Pau.Erg',\n",
       "  u'coyote.A.N4.Sg.Abs',\n",
       "  u'enfant.C.N4.Pau.Obl',\n",
       "  u'parent.D.N4.Sg.Dat',\n",
       "  u'mort.B.N4.Sg.Erg',\n",
       "  u'Katisha.A.N3.Sg.Dat',\n",
       "  u'sortil\\xe8ge.B.N3.Pl.Obl',\n",
       "  u'col\\xe8re.A.N1.Sg.Abs',\n",
       "  u'Kaleb.B.N2.Pl.Erg',\n",
       "  u'chasseur.D.N3.Pl.Obl',\n",
       "  u'croc.A.N1.Pl.Obl',\n",
       "  u'coyote.A.N4.Pl.Abs',\n",
       "  u'blessure.B.N1.Sg.Dat',\n",
       "  u'balai.C.N1.Pl.Obl',\n",
       "  u'gar\\xe7on.D.N1.Sg.Dat',\n",
       "  u'h\\xe9ros.A.N1.Pl.Abs',\n",
       "  u'femme.C.N1.Pl.Erg',\n",
       "  u'Nabil.D.N3.Sg.Erg',\n",
       "  u'enfant.C.N4.Pau.Abs',\n",
       "  u'serpent.B.N2.Pau.Erg',\n",
       "  u'combattant.A.N4.Pau.Obl',\n",
       "  u'balai.C.N1.Pl.Abs',\n",
       "  u'main.D.N2.Sg.Obl',\n",
       "  u'main.D.N2.Pau.Abs',\n",
       "  u'jour.D.N2.Sg.Obl',\n",
       "  u'Kaleb.B.N2.Pl.Abs',\n",
       "  u'h\\xe9ros.A.N1.Pl.Obl',\n",
       "  u'combattant.A.N4.Sg.Abs',\n",
       "  u'histoire.A.N3.Sg.Abs',\n",
       "  u'fille.A.N2.Pl.Abs',\n",
       "  u'gar\\xe7on.D.N1.Pau.Abs',\n",
       "  u'combat.D.N2.Sg.Obl',\n",
       "  u'b\\xfbcher.B.N1.Sg.Obl',\n",
       "  u'cri.B.N3.Sg.Obl',\n",
       "  u'coyote.A.N4.Pl.Dat',\n",
       "  u'robe.C.N1.Pl.Abs',\n",
       "  u'serpent.B.N2.Sg.Dat',\n",
       "  u'th\\xe9.D.N4.Sg.Erg',\n",
       "  u'sorcier.A.N2.Pau.Abs',\n",
       "  u'donjon.D.N2.Sg.Abs',\n",
       "  u'ombre.A.N2.Pau.Dat',\n",
       "  u'louve.A.N3.Pau.Abs',\n",
       "  u'gargouille.D.N4.Pau.Erg',\n",
       "  u'lever-N.B.N2.Sg.Obl',\n",
       "  u'sortil\\xe8ge.B.N3.Sg.Abs',\n",
       "  u'fille.A.N2.Sg.Dat',\n",
       "  u'arbre.D.N4.Pau.Obl',\n",
       "  u'histoire.A.N3.Pl.Erg',\n",
       "  u'femme.C.N1.Pau.Erg',\n",
       "  u'Agathos.D.N3.Sg.Abs',\n",
       "  u'villageois.C.N4.Pl.Abs',\n",
       "  u'chatte.C.N1.Sg.Dat',\n",
       "  u'lance.C.N3.Sg.Abs',\n",
       "  u'nouvelle-N.B.N1.Sg.Erg',\n",
       "  u'marais.A.N4.Sg.Obl',\n",
       "  u'p\\xe8re.A.N3.Pau.Erg',\n",
       "  u'viande.D.N3.Sg.Abs',\n",
       "  u'Mahira.C.N4.Sg.Dat',\n",
       "  u'chasseur.D.N3.Pau.Erg',\n",
       "  u'chat.C.N3.Sg.Abs',\n",
       "  u'Clemencia.C.N1.Sg.Erg',\n",
       "  u'Violette.A.N1.Pau.Erg',\n",
       "  u'histoire.A.N3.Sg.Obl',\n",
       "  u'grimoire.B.N4.Sg.Erg',\n",
       "  u'dragon.D.N3.Pau.Erg',\n",
       "  u'l\\xe9gende.C.N2.Sg.Erg',\n",
       "  u'esprit.B.N2.Sg.Erg',\n",
       "  u'chatte.C.N1.Pau.Obl',\n",
       "  u'fille.A.N2.Pau.Dat',\n",
       "  u'souris.D.N1.Pau.Abs',\n",
       "  u'louve.A.N3.Pl.Erg',\n",
       "  u'fille.A.N2.Pl.Erg',\n",
       "  u'autruche.C.N4.Pau.Erg',\n",
       "  u'viande.D.N3.Pau.Abs',\n",
       "  u'village.C.N3.Sg.Obl',\n",
       "  u'autruche.C.N4.Sg.Obl',\n",
       "  u'lune.C.N4.Sg.Abs',\n",
       "  u'chat.C.N3.Pl.Erg',\n",
       "  u'homme.A.N2.Pl.Obl',\n",
       "  u'soeur.B.N1.Pl.Erg',\n",
       "  u'coyote.A.N4.Pl.Erg',\n",
       "  u'chasseur.D.N3.Sg.Abs',\n",
       "  u'oeil.C.N3.Pl.Abs',\n",
       "  u'lance.C.N3.Sg.Dat',\n",
       "  u'villageoise.A.N4.Sg.Erg',\n",
       "  u'sorcier.A.N2.Pau.Erg',\n",
       "  u'coup.D.N2.Pau.Abs',\n",
       "  u'corps.B.N3.Sg.Abs',\n",
       "  u'd\\xe9g\\xe2t.D.N1.Pl.Abs',\n",
       "  u'chat.C.N3.Pau.Abs',\n",
       "  u'chambre.A.N3.Pl.Erg',\n",
       "  u'infirmi\\xe8re.B.N1.Sg.Dat',\n",
       "  u'villageois.C.N4.Sg.Obl',\n",
       "  u'l\\xe9gume.C.N4.Pl.Erg',\n",
       "  u'dragon.D.N3.Sg.Abs',\n",
       "  u'Kaleb.B.N2.Sg.Obl',\n",
       "  u'fille.A.N2.Sg.Obl',\n",
       "  u'ombre.A.N2.Pl.Abs',\n",
       "  u'milieu.A.N4.Pl.Obl',\n",
       "  u'couteau.A.N2.Sg.Obl',\n",
       "  u'fille.A.N2.Pau.Obl',\n",
       "  u'loup.B.N2.Sg.Abs',\n",
       "  u'table.A.N2.Pau.Obl',\n",
       "  u'chambre.A.N3.Pl.Obl',\n",
       "  u'Nabil.D.N3.Sg.Abs',\n",
       "  u'cri.B.N3.Sg.Erg',\n",
       "  u'lueur.C.N3.Pau.Erg',\n",
       "  u'fruit.D.N3.Pau.Abs',\n",
       "  u'fruit.D.N3.Pl.Abs',\n",
       "  u'for\\xeat.A.N2.Sg.Erg',\n",
       "  u'enfant.C.N4.Pl.Abs',\n",
       "  u'lit.D.N3.Sg.Erg',\n",
       "  u'cri.B.N3.Pl.Abs',\n",
       "  u'lueur.C.N3.Sg.Abs',\n",
       "  u'serpent.B.N2.Sg.Abs',\n",
       "  u'arbre.D.N4.Sg.Erg',\n",
       "  u'manoir.B.N4.Sg.Abs',\n",
       "  u'Mahira.C.N4.Sg.Obl',\n",
       "  u'excuse.D.N3.Pl.Abs',\n",
       "  u'sorcier.A.N2.Pl.Obl',\n",
       "  u'fille.A.N2.Pau.Abs',\n",
       "  u'parent.D.N4.Pl.Abs',\n",
       "  u'villageoise.A.N4.Pau.Dat',\n",
       "  u'dragon.D.N3.Pl.Abs',\n",
       "  u'lueur.C.N3.Sg.Dat',\n",
       "  u'poisson.D.N2.Sg.Erg',\n",
       "  u'soeur.B.N1.Sg.Obl',\n",
       "  u'chef.C.N2.Sg.Obl',\n",
       "  u'Kaleb.B.N2.Sg.Dat',\n",
       "  u'disparition.C.N2.Pl.Abs',\n",
       "  u'croc.A.N1.Pau.Erg',\n",
       "  u'Agathos.D.N3.Sg.Erg',\n",
       "  u'crapaud.B.N3.Pl.Dat',\n",
       "  u'villageois.C.N4.Pl.Erg',\n",
       "  u'nuit.C.N3.Sg.Abs',\n",
       "  u'obscurit\\xe9.A.N1.Sg.Erg',\n",
       "  u'th\\xe9.D.N4.Pl.Abs',\n",
       "  u'chasseur.D.N3.Pl.Erg',\n",
       "  u'Clemencia.C.N1.Sg.Abs',\n",
       "  u'Nabil.D.N3.Sg.Obl',\n",
       "  u'mort.B.N4.Pl.Abs',\n",
       "  u'd\\xe9mon.B.N1.Sg.Obl',\n",
       "  u'chef.C.N2.Sg.Dat',\n",
       "  u'ma\\xeetre.A.N3.Sg.Erg',\n",
       "  u'jardin.B.N3.Pl.Obl',\n",
       "  u'gargouille.D.N4.Pau.Dat',\n",
       "  u'chat.C.N3.Sg.Dat',\n",
       "  u'maison.C.N2.Sg.Abs',\n",
       "  u'mort.B.N4.Pl.Dat',\n",
       "  u'villageois.C.N4.Sg.Abs',\n",
       "  u'soeur.B.N1.Sg.Abs',\n",
       "  u'sort.D.N1.Pl.Abs',\n",
       "  u'poisson.D.N2.Sg.Obl',\n",
       "  u'autruche.C.N4.Sg.Abs',\n",
       "  u'villageoise.A.N4.Pl.Dat',\n",
       "  u'coyote.A.N4.Pau.Erg',\n",
       "  u'bras.A.N2.Pl.Obl',\n",
       "  u'main.D.N2.Pau.Erg',\n",
       "  u'enfant.C.N4.Pau.Dat',\n",
       "  u'livre.D.N1.Sg.Abs',\n",
       "  u'autruche.C.N4.Sg.Dat',\n",
       "  u'balai.C.N1.Sg.Abs',\n",
       "  u'd\\xe9mon.B.N1.Sg.Abs',\n",
       "  u'gar\\xe7on.D.N1.Pau.Erg',\n",
       "  u'th\\xe9.D.N4.Sg.Abs',\n",
       "  u'infirmi\\xe8re.B.N1.Sg.Obl',\n",
       "  u'chatte.C.N1.Sg.Erg',\n",
       "  u'sortil\\xe8ge.B.N3.Sg.Erg',\n",
       "  u'harmonie.C.N4.Sg.Erg',\n",
       "  u'combattant.A.N4.Pl.Obl',\n",
       "  u'histoire.A.N3.Pl.Obl',\n",
       "  u'lune.C.N4.Sg.Erg',\n",
       "  u'lance.C.N3.Pau.Erg',\n",
       "  u'villageoise.A.N4.Pau.Abs',\n",
       "  u'Nicole.C.N2.Sg.Erg',\n",
       "  u'sorcier.A.N2.Sg.Erg',\n",
       "  u'coussin.C.N1.Pau.Abs',\n",
       "  u'coyote.A.N4.Sg.Dat',\n",
       "  u'gar\\xe7on.D.N1.Sg.Abs',\n",
       "  u'chambre.A.N3.Sg.Dat',\n",
       "  u'robe.C.N1.Sg.Obl',\n",
       "  u'combattant.A.N4.Pau.Abs',\n",
       "  u'louve.A.N3.Sg.Dat',\n",
       "  u'combat.D.N2.Sg.Abs',\n",
       "  u'louve.A.N3.Pl.Dat',\n",
       "  u'viande.D.N3.Pl.Obl',\n",
       "  u'Freja.C.N2.Sg.Abs',\n",
       "  u'louve.A.N3.Pau.Erg',\n",
       "  u'manoir.B.N4.Sg.Dat',\n",
       "  u'village.C.N3.Pl.Obl',\n",
       "  u'nuit.C.N3.Pau.Abs',\n",
       "  u'blessure.B.N1.Sg.Abs',\n",
       "  u'louve.A.N3.Pl.Abs',\n",
       "  u'souris.D.N1.Pl.Obl',\n",
       "  u'coup.D.N2.Sg.Abs',\n",
       "  u'feu.B.N3.Sg.Abs',\n",
       "  u'lune.C.N4.Pl.Obl',\n",
       "  u'villageoise.A.N4.Pl.Abs',\n",
       "  u'lance.C.N3.Pl.Abs',\n",
       "  u'chasseur.D.N3.Sg.Erg',\n",
       "  u'sort.D.N1.Pau.Erg',\n",
       "  u'loup.B.N2.Sg.Obl',\n",
       "  u'souris.D.N1.Sg.Abs',\n",
       "  u'soeur.B.N1.Sg.Erg',\n",
       "  u'soeur.B.N1.Pl.Abs',\n",
       "  u'infirmi\\xe8re.B.N1.Pau.Erg',\n",
       "  u'lit.D.N3.Sg.Abs',\n",
       "  u'\\u0153uf.B.N3.Pau.Erg',\n",
       "  u'plaine.D.N1.Sg.Obl',\n",
       "  u'chat.C.N3.Pl.Abs',\n",
       "  u'Kaleb.B.N2.Sg.Abs',\n",
       "  u'arbre.D.N4.Sg.Abs',\n",
       "  u'villageoise.A.N4.Pl.Obl',\n",
       "  u'crapaud.B.N3.Pl.Obl',\n",
       "  u'gargouille.D.N4.Sg.Obl',\n",
       "  u'villageois.C.N4.Sg.Dat',\n",
       "  u'coussin.C.N1.Sg.Erg',\n",
       "  u'homme.A.N2.Pl.Erg',\n",
       "  u'corps.B.N3.Sg.Dat',\n",
       "  u'ombre.A.N2.Sg.Obl',\n",
       "  u'sortil\\xe8ge.B.N3.Pl.Abs',\n",
       "  u'dragon.D.N3.Sg.Dat',\n",
       "  u'chef.C.N2.Sg.Abs',\n",
       "  u'village.C.N3.Pau.Abs',\n",
       "  u'for\\xeat.A.N2.Pl.Abs',\n",
       "  u'Katisha.A.N3.Sg.Erg',\n",
       "  u'l\\xe9gume.C.N4.Pl.Abs',\n",
       "  u'enfant.C.N4.Pl.Erg',\n",
       "  u'arbre.D.N4.Pl.Obl',\n",
       "  u'esprit.B.N2.Pl.Erg',\n",
       "  u'couteau.A.N2.Pau.Dat',\n",
       "  u'infirmi\\xe8re.B.N1.Pl.Erg',\n",
       "  u'\\u0153uf.B.N3.Pl.Abs',\n",
       "  u'nuit.C.N3.Sg.Dat',\n",
       "  u'matin.C.N1.Sg.Obl',\n",
       "  u'voleuse.C.N3.Pau.Abs',\n",
       "  u'cri.B.N3.Sg.Abs',\n",
       "  u'souffrance.D.N1.Pl.Erg',\n",
       "  u'vengeance.B.N2.Sg.Obl',\n",
       "  u'chambre.A.N3.Pau.Obl',\n",
       "  u'Nicole.C.N2.Sg.Dat',\n",
       "  u'cri.B.N3.Pl.Erg',\n",
       "  u'for\\xeat.A.N2.Sg.Abs',\n",
       "  u'd\\xe9mon.B.N1.Pau.Obl',\n",
       "  u'vote.B.N4.Sg.Abs',\n",
       "  u'gorge.A.N3.Sg.Obl',\n",
       "  u'enfant.C.N4.Sg.Abs',\n",
       "  u'manoir.B.N4.Sg.Erg',\n",
       "  u'm\\xe8re.A.N4.Sg.Erg',\n",
       "  u'serpent.B.N2.Sg.Erg',\n",
       "  u'croc.A.N1.Sg.Erg',\n",
       "  u'Mahira.C.N4.Sg.Erg',\n",
       "  u'couteau.A.N2.Pl.Erg',\n",
       "  u'louve.A.N3.Pl.Obl',\n",
       "  u'lune.C.N4.Pau.Abs',\n",
       "  u'\\u0153uf.B.N3.Pau.Abs',\n",
       "  u'parent.D.N4.Pl.Obl',\n",
       "  u'\\u0153uf.B.N3.Sg.Abs',\n",
       "  u'tornade.A.N4.Sg.Abs'],\n",
       " 'PRO': [u'PRO.D.Pau.Erg',\n",
       "  u'PRO.B.Pl.Erg',\n",
       "  u'PRO.C.Sg.Erg',\n",
       "  u'PRO.C.Sg.Abs',\n",
       "  u'PRO.B.Sg.Erg',\n",
       "  u'PRO.A.Pau.Erg',\n",
       "  u'PRO.B.Pau.Abs',\n",
       "  u'PRO.D.Sg.Erg',\n",
       "  u'PRO.D.Pl.Erg',\n",
       "  u'PRO.C.Pau.Erg',\n",
       "  u'PRO.A.Pau.Abs'],\n",
       " 'VER': [u'hurler.VI.V1.Pst.TroisSg.B',\n",
       "  u'hurler.VI.V1.Pst.TroisSg.C',\n",
       "  u'hurler.VI.V1.Pst.TroisSg.A',\n",
       "  u'passer.VI.V1.Pst.TroisPau.C',\n",
       "  u'\\xeatre.VT.V2.Prs.TroisPl.D',\n",
       "  u'\\xeatre.VT.V2.Prs.TroisPl.A',\n",
       "  u'prot\\xe9ger.VT.V1.Prs.TroisPl.C',\n",
       "  u'\\xeatre.VT.V2.Prs.TroisPl.B',\n",
       "  u'porter.VT.V1.Pst.TroisSg.C',\n",
       "  u'\\xe9changer.VT.V1.Prs.TroisPl.C',\n",
       "  u'prot\\xe9ger.VT.V1.Prs.TroisSg.C',\n",
       "  u'prot\\xe9ger.VT.V1.Prs.TroisSg.A',\n",
       "  u'br\\xfbler-Med.VI.V2.Prs.TroisSg.B',\n",
       "  u'prot\\xe9ger.VT.V1.Prs.TroisSg.D',\n",
       "  u'boire.VT.V2.Prs.TroisPau.A',\n",
       "  u'arr\\xeater.VT.V2.Prs.TroisSg.B',\n",
       "  u'mourir.VI.V1.Prs.TroisSg.D',\n",
       "  u'acheter.VT.V2.Pst.TroisPl.C',\n",
       "  u'remercier.VT.V2.Pst.TroisPau.C',\n",
       "  u'revenir.VI.V1.Pst.TroisPau.A',\n",
       "  u'acheter.VT.V2.Pst.TroisSg.D',\n",
       "  u'jeter.VT.V2.Prs.TroisPl.D',\n",
       "  u'jardiner.VT.V1.Prs.TroisSg.A',\n",
       "  u'chasser.VT.V2.Pst.TroisPl.B',\n",
       "  u'chasser.VT.V2.Pst.TroisPl.C',\n",
       "  u'chasser.VT.V2.Pst.TroisPl.A',\n",
       "  u'donner.VT.V1.Prs.TroisPl.D',\n",
       "  u'tourner-Mov.VI.V2.Prs.TroisSg.D',\n",
       "  u'approcher.VI.V2.Pst.TroisPau.B',\n",
       "  u'passer.VI.V1.Pst.TroisPl.C',\n",
       "  u'chasser.VT.V2.Pst.TroisSg.D',\n",
       "  u'donner.VT.V1.Prs.TroisSg.D',\n",
       "  u'redevenir.VT.V1.Prs.TroisSg.C',\n",
       "  u'donner.VT.V1.Prs.TroisSg.A',\n",
       "  u'chasser.VT.V2.Pst.TroisSg.A',\n",
       "  u'donner.VT.V1.Prs.TroisSg.C',\n",
       "  u'donner.VT.V1.Prs.TroisSg.B',\n",
       "  u'conna\\xeetre.VT.V1.Prs.TroisPl.B',\n",
       "  u'boire.VT.V2.Pst.TroisSg.A',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisPl.D',\n",
       "  u'apporter.VT.V1.Prs.TroisPl.B',\n",
       "  u'dormir.VI.V1.Pst.TroisPau.D',\n",
       "  u'dormir.VI.V1.Pst.TroisPau.A',\n",
       "  u'voir.VT.V1.Prs.TroisPl.B',\n",
       "  u'planter.VT.V1.Prs.TroisPau.C',\n",
       "  u'rejoindre.VT.V2.Prs.TroisSg.A',\n",
       "  u'rejoindre.VT.V2.Prs.TroisSg.C',\n",
       "  u'r\\xeavasser.VI.V2.Prs.TroisPl.D',\n",
       "  u'prot\\xe9ger.VT.V1.Pst.TroisSg.C',\n",
       "  u'prot\\xe9ger.VT.V1.Pst.TroisSg.B',\n",
       "  u'illustrer.VT.V2.Prs.TroisPau.A',\n",
       "  u'd\\xe9couvrir.VT.V2.Prs.TroisPau.C',\n",
       "  u'parler.VI.V2.Pst.TroisPau.A',\n",
       "  u'enlever.VT.V1.Pst.TroisSg.A',\n",
       "  u'prot\\xe9ger.VT.V1.Prs.TroisPl.D',\n",
       "  u'enfermer.VT.V1.Prs.TroisPl.D',\n",
       "  u'nourrir.VT.V1.Prs.TroisPl.D',\n",
       "  u'chasser.VT.V2.Prs.TroisPau.A',\n",
       "  u'enlever.VT.V1.Pst.TroisPl.C',\n",
       "  u'reconstruire.VT.V2.Prs.TroisSg.B',\n",
       "  u'partir.VI.V1.Pst.TroisSg.D',\n",
       "  u'apporter.VT.V1.Pst.TroisPl.B',\n",
       "  u'partir.VI.V1.Pst.TroisPl.D',\n",
       "  u'acheter.VT.V2.Prs.TroisSg.C',\n",
       "  u'retourner.VI.V2.Prs.TroisPau.C',\n",
       "  u'montrer.VT.V2.Pst.TroisPau.D',\n",
       "  u'changer.VT.V2.Prs.TroisPl.C',\n",
       "  u'conna\\xeetre.VT.V1.Prs.TroisSg.B',\n",
       "  u'changer.VT.V2.Prs.TroisPl.D',\n",
       "  u'surplomber.VT.V2.Prs.TroisSg.A',\n",
       "  u'surplomber.VT.V2.Prs.TroisSg.C',\n",
       "  u'voler.VT.V1.Prs.TroisSg.B',\n",
       "  u'manger.VT.V2.Prs.TroisSg.B',\n",
       "  u'lancer.VT.V1.Prs.TroisSg.D',\n",
       "  u'lancer.VT.V1.Prs.TroisSg.B',\n",
       "  u'recouvrir.VT.V2.Prs.TroisPau.A',\n",
       "  u'planter.VT.V1.Prs.TroisPl.A',\n",
       "  u'faire.VT.V1.Prs.TroisSg.A',\n",
       "  u'planter.VT.V1.Prs.TroisSg.A',\n",
       "  u'prendre.VT.V1.Prs.TroisPl.C',\n",
       "  u'sortir-Mov.VI.V2.Prs.TroisSg.A',\n",
       "  u'dormir.VI.V1.Prs.TroisPau.A',\n",
       "  u'dormir.VI.V1.Prs.TroisPau.D',\n",
       "  u'prot\\xe9ger.VT.V1.Pst.TroisPl.A',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisPau.B',\n",
       "  u'prot\\xe9ger.VT.V1.Pst.TroisPl.C',\n",
       "  u'prot\\xe9ger.VT.V1.Pst.TroisPl.B',\n",
       "  u'chercher.VT.V2.Pst.TroisPau.A',\n",
       "  u'transpercer.VT.V1.Prs.TroisSg.D',\n",
       "  u'transpercer.VT.V1.Prs.TroisSg.A',\n",
       "  u'transpercer.VT.V1.Prs.TroisSg.C',\n",
       "  u'transpercer.VT.V1.Prs.TroisSg.B',\n",
       "  u'vivre.VI.V2.Prs.TroisSg.C',\n",
       "  u'acheter.VT.V2.Prs.TroisPl.A',\n",
       "  u'offrir.VT.V1.Pst.TroisPl.C',\n",
       "  u'noyer.VT.V2.Prs.TroisSg.D',\n",
       "  u'entrer.VI.V1.Prs.TroisSg.D',\n",
       "  u'entrer.VI.V1.Prs.TroisSg.C',\n",
       "  u'entrer.VI.V1.Prs.TroisSg.A',\n",
       "  u'recouvrir.VT.V2.Pst.TroisSg.D',\n",
       "  u'partir.VI.V1.Pst.TroisPau.D',\n",
       "  u'partir.VI.V1.Pst.TroisPau.C',\n",
       "  u'envahir.VT.V2.Prs.TroisPl.A',\n",
       "  u'transformer.VT.V1.Prs.TroisSg.A',\n",
       "  u'offrir.VT.V1.Pst.TroisPau.C',\n",
       "  u'voler-Act.VI.V2.Pst.TroisPau.A',\n",
       "  u'manger.VT.V2.Pst.TroisSg.C',\n",
       "  u'cacher.VT.V2.Prs.TroisSg.A',\n",
       "  u'cacher.VT.V2.Prs.TroisSg.B',\n",
       "  u'lancer.VT.V1.Prs.TroisPau.D',\n",
       "  u'supporter.VT.V1.Prs.TroisSg.D',\n",
       "  u'changer.VT.V2.Prs.TroisSg.C',\n",
       "  u'chercher.VT.V2.Pst.TroisSg.D',\n",
       "  u'surplomber.VT.V2.Pst.TroisSg.A',\n",
       "  u'chercher.VT.V2.Pst.TroisSg.C',\n",
       "  u'surplomber.VT.V2.Pst.TroisSg.C',\n",
       "  u'surplomber.VT.V2.Pst.TroisSg.B',\n",
       "  u'voir.VT.V1.Pst.TroisPl.D',\n",
       "  u'prendre.VT.V1.Prs.TroisSg.D',\n",
       "  u'prendre.VT.V1.Prs.TroisSg.A',\n",
       "  u'prendre.VT.V1.Prs.TroisSg.B',\n",
       "  u'prendre.VT.V1.Prs.TroisSg.C',\n",
       "  u'offrir.VT.V1.Pst.TroisSg.A',\n",
       "  u'offrir.VT.V1.Prs.TroisSg.A',\n",
       "  u'd\\xe9tester.VT.V2.Pst.TroisPl.C',\n",
       "  u'voler.VT.V1.Prs.TroisSg.D',\n",
       "  u'attraper.VT.V2.Pst.TroisSg.D',\n",
       "  u'allumer.VT.V2.Prs.TroisSg.B',\n",
       "  u'montrer.VT.V2.Pst.TroisSg.A',\n",
       "  u'interroger.VT.V2.Prs.TroisSg.D',\n",
       "  u'tomber.VI.V2.Pst.TroisPau.A',\n",
       "  u'arriver.VI.V2.Pst.TroisPl.C',\n",
       "  u'd\\xe9couvrir.VT.V2.Pst.TroisSg.B',\n",
       "  u'enfermer.VT.V1.Pst.TroisSg.A',\n",
       "  u'faire.VT.V1.Prs.TroisPl.D',\n",
       "  u'faire.VT.V1.Prs.TroisPl.A',\n",
       "  u'supporter.VT.V1.Prs.TroisPau.C',\n",
       "  u'supporter.VT.V1.Prs.TroisPau.D',\n",
       "  u'sortir-Mov.VI.V2.Pst.TroisSg.C',\n",
       "  u'chasser.VT.V2.Pst.TroisPau.D',\n",
       "  u'sortir-Mov.VI.V2.Pst.TroisSg.D',\n",
       "  u'approcher.VI.V2.Pst.TroisSg.C',\n",
       "  u'chercher.VT.V2.Pst.TroisPl.D',\n",
       "  u'arriver.VI.V2.Prs.TroisPau.D',\n",
       "  u'arriver.VI.V2.Prs.TroisPau.A',\n",
       "  u'arriver.VI.V2.Prs.TroisPau.B',\n",
       "  u'pousser.VT.V1.Prs.TroisPl.A',\n",
       "  u'hurler.VI.V1.Prs.TroisSg.C',\n",
       "  u'jeter.VT.V2.Pst.TroisPl.B',\n",
       "  u'supporter.VT.V1.Pst.TroisPau.C',\n",
       "  u'voir.VT.V1.Pst.TroisPau.A',\n",
       "  u'supporter.VT.V1.Pst.TroisPau.D',\n",
       "  u'montrer.VT.V2.Prs.TroisPl.B',\n",
       "  u'montrer.VT.V2.Prs.TroisPl.D',\n",
       "  u'voler.VT.V1.Pst.TroisPl.C',\n",
       "  u'voir.VT.V1.Pst.TroisSg.A',\n",
       "  u'voir.VT.V1.Pst.TroisSg.B',\n",
       "  u'pleurer.VT.V1.Prs.TroisSg.B',\n",
       "  u'manger.VT.V2.Prs.TroisPau.D',\n",
       "  u'manger.VT.V2.Prs.TroisPau.B',\n",
       "  u'aller.VI.V1.Pst.TroisSg.B',\n",
       "  u'attraper.VT.V2.Prs.TroisSg.B',\n",
       "  u'reconna\\xeetre.VT.V1.Prs.TroisSg.A',\n",
       "  u'donner.VT.V1.Pst.TroisPl.D',\n",
       "  u'donner.VT.V1.Pst.TroisPl.B',\n",
       "  u'lancer.VT.V1.Pst.TroisPl.B',\n",
       "  u'acheter.VT.V2.Pst.TroisPau.B',\n",
       "  u'enfermer.VT.V1.Pst.TroisPau.D',\n",
       "  u'aller.VI.V1.Prs.TroisSg.A',\n",
       "  u'envahir.VT.V2.Prs.TroisSg.D',\n",
       "  u'envahir.VT.V2.Prs.TroisSg.C',\n",
       "  u'envahir.VT.V2.Prs.TroisSg.A',\n",
       "  u'd\\xe9tester.VT.V2.Pst.TroisPau.D',\n",
       "  u'tomber.VI.V2.Prs.TroisPau.A',\n",
       "  u'tomber.VI.V2.Prs.TroisPau.C',\n",
       "  u'tomber.VI.V2.Prs.TroisPau.B',\n",
       "  u'pousser.VT.V1.Pst.TroisPl.C',\n",
       "  u'donner.VT.V1.Prs.TroisPau.C',\n",
       "  u'aller.VI.V1.Pst.TroisPl.A',\n",
       "  u'redevenir.VT.V1.Pst.TroisSg.A',\n",
       "  u'dormir.VI.V1.Pst.TroisPl.A',\n",
       "  u'apporter.VT.V1.Pst.TroisSg.B',\n",
       "  u'pousser.VT.V1.Pst.TroisSg.C',\n",
       "  u'envahir.VT.V2.Pst.TroisSg.B',\n",
       "  u'envahir.VT.V2.Pst.TroisSg.C',\n",
       "  u'd\\xe9tester.VT.V2.Prs.TroisPl.C',\n",
       "  u'prendre.VT.V1.Pst.TroisPl.C',\n",
       "  u'offrir.VT.V1.Prs.TroisPl.D',\n",
       "  u'pousser.VT.V1.Pst.TroisPau.C',\n",
       "  u'apporter.VT.V1.Pst.TroisPl.D',\n",
       "  u'chercher.VT.V2.Prs.TroisPau.C',\n",
       "  u'apporter.VT.V1.Pst.TroisPl.A',\n",
       "  u'manquer-Med.VI.V1.Prs.TroisSg.A',\n",
       "  u'pleurer.VT.V1.Prs.TroisPl.D',\n",
       "  u'chasser.VT.V2.Prs.TroisPl.D',\n",
       "  u'chasser.VT.V2.Prs.TroisPl.C',\n",
       "  u'chasser.VT.V2.Prs.TroisPl.A',\n",
       "  u'cacher.VT.V2.Pst.TroisSg.A',\n",
       "  u'boire.VT.V2.Prs.TroisPl.A',\n",
       "  u'montrer.VT.V2.Prs.TroisSg.D',\n",
       "  u'dormir.VI.V1.Prs.TroisPau.C',\n",
       "  u'offrir.VT.V1.Prs.TroisSg.D',\n",
       "  u'transpercer.VT.V1.Prs.TroisPau.B',\n",
       "  u'accueillir.VT.V2.Prs.TroisSg.C',\n",
       "  u'embrasser.VT.V1.Pst.TroisSg.D',\n",
       "  u'changer.VT.V2.Pst.TroisPau.C',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisPau.A',\n",
       "  u'parler.VI.V2.Prs.TroisSg.C',\n",
       "  u'parler.VI.V2.Prs.TroisSg.B',\n",
       "  u'cacher.VT.V2.Pst.TroisPl.D',\n",
       "  u'sauter.VI.V2.Prs.TroisSg.A',\n",
       "  u'sauter.VI.V2.Prs.TroisSg.B',\n",
       "  u'dormir.VI.V1.Pst.TroisSg.C',\n",
       "  u'donner.VT.V1.Pst.TroisSg.C',\n",
       "  u'donner.VT.V1.Pst.TroisSg.B',\n",
       "  u'donner.VT.V1.Pst.TroisSg.D',\n",
       "  u'lancer.VT.V1.Pst.TroisSg.B',\n",
       "  u'lancer.VT.V1.Pst.TroisSg.C',\n",
       "  u'lancer.VT.V1.Pst.TroisSg.D',\n",
       "  u'chercher.VT.V2.Prs.TroisSg.D',\n",
       "  u'chercher.VT.V2.Prs.TroisSg.B',\n",
       "  u'chercher.VT.V2.Prs.TroisSg.C',\n",
       "  u'chercher.VT.V2.Prs.TroisSg.A',\n",
       "  u'courir.VI.V1.Prs.TroisPau.B',\n",
       "  u'courir.VI.V1.Prs.TroisPau.A',\n",
       "  u'boire.VT.V2.Prs.TroisSg.A',\n",
       "  u'boire.VT.V2.Prs.TroisSg.D',\n",
       "  u'supporter.VT.V1.Prs.TroisSg.B',\n",
       "  u'supporter.VT.V1.Prs.TroisSg.C',\n",
       "  u'avoir.VT.V1.Pst.TroisPl.C',\n",
       "  u'jeter.VT.V2.Prs.TroisSg.A',\n",
       "  u'partir.VI.V1.Prs.TroisSg.B',\n",
       "  u'survoler.VT.V1.Prs.TroisSg.B',\n",
       "  u'arriver.VI.V2.Pst.TroisSg.C',\n",
       "  u'raconter.VT.V1.Prs.TroisSg.A',\n",
       "  u'parler.VI.V2.Prs.TroisPl.D',\n",
       "  u'pr\\xe9parer.VT.V2.Prs.TroisPl.C',\n",
       "  u'planter.VT.V1.Pst.TroisSg.C',\n",
       "  u'supporter.VT.V1.Pst.TroisSg.A',\n",
       "  u'entrer.VI.V1.Prs.TroisPau.D',\n",
       "  u'dispara\\xeetre.VI.V1.Pst.TroisPau.A',\n",
       "  u'descendre.VT.V1.Prs.TroisSg.A',\n",
       "  u'dispara\\xeetre.VI.V1.Pst.TroisPau.D',\n",
       "  u'chasser.VT.V2.Prs.TroisSg.A',\n",
       "  u'supporter.VT.V1.Prs.TroisPl.C',\n",
       "  u'supporter.VT.V1.Prs.TroisPl.A',\n",
       "  u'jeter.VT.V2.Prs.TroisPl.C',\n",
       "  u'supporter.VT.V1.Prs.TroisPl.D',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisPl.D',\n",
       "  u'sortir-Mov.VI.V2.Pst.TroisPl.A',\n",
       "  u'compter.VT.V2.Pst.TroisPl.C',\n",
       "  u'jeter.VT.V2.Pst.TroisSg.D',\n",
       "  u'jeter.VT.V2.Pst.TroisSg.B',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisPl.B',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisPl.C',\n",
       "  u'courir.VI.V1.Pst.TroisSg.C',\n",
       "  u'dormir.VI.V1.Prs.TroisSg.A',\n",
       "  u'dormir.VI.V1.Prs.TroisSg.C',\n",
       "  u'transformer.VT.V1.Pst.TroisSg.D',\n",
       "  u'jeter.VT.V2.Prs.TroisSg.D',\n",
       "  u'jeter.VT.V2.Prs.TroisSg.C',\n",
       "  u'jardiner.VT.V1.Pst.TroisSg.A',\n",
       "  u'sauter.VI.V2.Pst.TroisSg.B',\n",
       "  u'poss\\xe9der.VT.V1.Prs.TroisSg.C',\n",
       "  u'noyer.VT.V2.Pst.TroisSg.A',\n",
       "  u'chercher.VT.V2.Prs.TroisPl.D',\n",
       "  u'r\\xeavasser.VI.V2.Pst.TroisSg.D',\n",
       "  u'partir.VI.V1.Pst.TroisPau.B',\n",
       "  u'boire.VT.V2.Pst.TroisPl.A',\n",
       "  u'montrer.VT.V2.Pst.TroisPl.D',\n",
       "  u'boire.VT.V2.Pst.TroisPl.D',\n",
       "  u'hurler.VI.V1.Prs.TroisPau.B',\n",
       "  u'montrer.VT.V2.Pst.TroisSg.C',\n",
       "  u'montrer.VT.V2.Pst.TroisSg.D',\n",
       "  u'lancer.VT.V1.Prs.TroisPau.A',\n",
       "  u'jeter.VT.V2.Pst.TroisPau.C',\n",
       "  u'pr\\xe9parer.VT.V2.Prs.TroisSg.B',\n",
       "  u'compter.VT.V2.Pst.TroisPau.A',\n",
       "  u'embrasser.VT.V1.Pst.TroisPau.C',\n",
       "  u'br\\xfbler.VT.V2.Pst.TroisSg.B',\n",
       "  u'aller.VI.V1.Prs.TroisSg.B',\n",
       "  u'boire.VT.V2.Pst.TroisSg.D',\n",
       "  u'tomber.VI.V2.Prs.TroisSg.A',\n",
       "  u'manger.VT.V2.Pst.TroisPau.B',\n",
       "  u'manger.VT.V2.Pst.TroisPau.D',\n",
       "  u'pr\\xe9senter.VT.V2.Prs.TroisPl.D',\n",
       "  u'pr\\xe9senter.VT.V2.Prs.TroisPl.A',\n",
       "  u'courir.VI.V1.Pst.TroisPau.B',\n",
       "  u'courir.VI.V1.Pst.TroisPau.A',\n",
       "  u'courir.VI.V1.Prs.TroisSg.B',\n",
       "  u'courir.VI.V1.Prs.TroisSg.C',\n",
       "  u'courir.VI.V1.Prs.TroisSg.A',\n",
       "  u'd\\xe9vorer.VT.V2.Prs.TroisPl.A',\n",
       "  u'fuir.VT.V1.Pst.TroisPau.D',\n",
       "  u'tomber.VI.V2.Pst.TroisSg.A',\n",
       "  u'tomber.VI.V2.Pst.TroisSg.C',\n",
       "  u'\\xeatre.VT.V2.Prs.TroisSg.B',\n",
       "  u'\\xeatre.VT.V2.Prs.TroisSg.A',\n",
       "  u'jeter.VT.V2.Prs.TroisPl.B',\n",
       "  u'courir.VI.V1.Pst.TroisSg.B',\n",
       "  u'fuir.VT.V1.Prs.TroisSg.B',\n",
       "  u'fuir.VT.V1.Prs.TroisSg.A',\n",
       "  u'entrer.VI.V1.Pst.TroisSg.C',\n",
       "  u'manger.VT.V2.Pst.TroisPl.D',\n",
       "  u'pleurer-Act.VI.V2.Pst.TroisPau.C',\n",
       "  u'tomber.VI.V2.Prs.TroisSg.D',\n",
       "  u'transformer.VT.V1.Prs.TroisSg.D',\n",
       "  u'interroger.VT.V2.Prs.TroisPau.A',\n",
       "  u'tomber.VI.V2.Prs.TroisSg.B',\n",
       "  u'tomber.VI.V2.Prs.TroisSg.C',\n",
       "  u'compter.VT.V2.Prs.TroisPl.B',\n",
       "  u'sortir-Mov.VI.V2.Prs.TroisPau.A',\n",
       "  u'tomber.VI.V2.Prs.TroisPl.B',\n",
       "  u'tomber.VI.V2.Prs.TroisPl.D',\n",
       "  u'dormir.VI.V1.Prs.TroisPl.D',\n",
       "  u'dormir.VI.V1.Prs.TroisPl.C',\n",
       "  u'dormir.VI.V1.Prs.TroisPl.B',\n",
       "  u'dormir.VI.V1.Prs.TroisPl.A',\n",
       "  u'acheter.VT.V2.Prs.TroisPau.C',\n",
       "  u'supporter.VT.V1.Pst.TroisPl.A',\n",
       "  u'fuir.VT.V1.Pst.TroisSg.A',\n",
       "  u'allumer.VT.V2.Pst.TroisSg.B',\n",
       "  u'parler.VI.V2.Pst.TroisSg.A',\n",
       "  u'parler.VI.V2.Pst.TroisSg.B',\n",
       "  u'raconter.VT.V1.Pst.TroisSg.B',\n",
       "  u'sauter.VI.V2.Prs.TroisPau.C',\n",
       "  u'remercier.VT.V2.Pst.TroisPl.C',\n",
       "  u'remercier.VT.V2.Pst.TroisPl.D',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisSg.C',\n",
       "  u'changer.VT.V2.Pst.TroisPl.B',\n",
       "  u'rejoindre.VT.V2.Pst.TroisSg.C',\n",
       "  u'raconter.VT.V1.Pst.TroisPau.C',\n",
       "  u'arriver.VI.V2.Prs.TroisPl.C',\n",
       "  u'arriver.VI.V2.Prs.TroisPl.D',\n",
       "  u'dispara\\xeetre.VI.V1.Pst.TroisSg.C',\n",
       "  u'dispara\\xeetre.VI.V1.Pst.TroisSg.A',\n",
       "  u'chasser-Mov.VT.V2.Prs.TroisPl.C',\n",
       "  u'approcher.VI.V2.Prs.TroisSg.B',\n",
       "  u'approcher.VI.V2.Prs.TroisSg.C',\n",
       "  u'approcher.VI.V2.Prs.TroisSg.D',\n",
       "  u'voir.VT.V1.Prs.TroisPau.B',\n",
       "  u'voir.VT.V1.Prs.TroisPau.A',\n",
       "  u'manger.VT.V2.Prs.TroisPl.D',\n",
       "  u'pousser.VT.V1.Prs.TroisPl.C',\n",
       "  u'pousser.VT.V1.Prs.TroisPl.B',\n",
       "  u'manger.VT.V2.Prs.TroisPl.B',\n",
       "  u'manger.VT.V2.Prs.TroisPl.C',\n",
       "  u'passer.VI.V1.Prs.TroisPl.A',\n",
       "  u'aller.VI.V1.Prs.TroisPl.A',\n",
       "  u'aller.VI.V1.Prs.TroisPl.C',\n",
       "  u'compter.VT.V2.Prs.TroisPau.A',\n",
       "  u'attraper.VT.V2.Pst.TroisPau.D',\n",
       "  u'pousser.VT.V1.Prs.TroisSg.A',\n",
       "  u'pousser.VT.V1.Prs.TroisSg.B',\n",
       "  u'chercher.VT.V2.Prs.TroisPau.D',\n",
       "  u'inqui\\xe9ter.VT.V2.Pst.TroisPl.C',\n",
       "  u'\\xeatre.VT.V2.Pst.TroisSg.C',\n",
       "  u'\\xeatre.VT.V2.Pst.TroisSg.B',\n",
       "  u'\\xeatre.VT.V2.Pst.TroisSg.A',\n",
       "  u'tomber.VI.V2.Pst.TroisPl.B',\n",
       "  u'raconter.VT.V1.Prs.TroisSg.C',\n",
       "  u'compter.VT.V2.Prs.TroisSg.A',\n",
       "  u'entrer.VI.V1.Pst.TroisPau.C',\n",
       "  u'pleurer-Act.VI.V2.Prs.TroisSg.C',\n",
       "  u'd\\xe9vorer.VT.V2.Prs.TroisSg.B',\n",
       "  u'apporter.VT.V1.Prs.TroisPau.B',\n",
       "  u'chercher.VT.V2.Pst.TroisSg.B',\n",
       "  u'entrer.VI.V1.Prs.TroisPl.D',\n",
       "  u'faire.VT.V1.Pst.TroisSg.B',\n",
       "  u'recouvrir.VT.V2.Prs.TroisSg.B',\n",
       "  u'\\xeatre.VT.V2.Pst.TroisPau.A',\n",
       "  u'pleurer-Act.VI.V2.Pst.TroisPl.C',\n",
       "  u'demander.VT.V2.Prs.TroisPl.D',\n",
       "  u'arriver.VI.V2.Prs.TroisSg.C',\n",
       "  u'arriver.VI.V2.Pst.TroisPau.A',\n",
       "  u'arriver.VI.V2.Prs.TroisSg.D',\n",
       "  u'porter.VT.V1.Pst.TroisPl.C',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisSg.D',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisSg.B',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisSg.C',\n",
       "  u'dispara\\xeetre.VI.V1.Prs.TroisSg.A',\n",
       "  u'hurler.VI.V1.Pst.TroisPau.A',\n",
       "  u'voir.VT.V1.Prs.TroisSg.A',\n",
       "  u'voir.VT.V1.Prs.TroisSg.C',\n",
       "  u'voir.VT.V1.Prs.TroisSg.B',\n",
       "  u'ressusciter.VT.V1.Prs.TroisSg.D']}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in cellules:\n",
    "    cellules[k]=list(cellules[k])\n",
    "cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yamlDump(serie+\"FilledCells.yaml\",cellules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
