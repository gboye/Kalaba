{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problèmes et Extensions\n",
    "\n",
    "## Problèmes\n",
    "- javascript runs fail\n",
    "- faire de nouvelles sorties pour les kalabas sans séparateurs de mots\n",
    " - radicaux seuls\n",
    " - découpage en syntagmes pour l'exercice sur l'ordre des syntagmes\n",
    "\n",
    "## Extensions\n",
    "- traitement du paucal\n",
    " - 2,3,4,5 ou suffixe P sur le nom sans numéral\n",
    "- ajout des compléments/ajouts multiples\n",
    " - séparation par ;\n",
    " - gestion des dislocations gauches dans les multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "#from cellbell import ding\n",
    "from itertools import groupby\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle,copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(theNotebook)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Gestion partagée des numéros à traiter & gestion des variantes\n",
    "\n",
    "Le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable\n",
    "\n",
    "Après la réussite de la variante de base, on change automatiquement la variante à -Corr pour générer les fichiers de solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Corr\n",
      "[18] Kanonik\n"
     ]
    }
   ],
   "source": [
    "# numerosKalaba=[5]\n",
    "# %store numerosKalaba\n",
    "%store -r numerosKalaba typeKalaba\n",
    "variante=\"\"\n",
    "if 'nextVariante' in globals():\n",
    "    variante=nextVariante\n",
    "print variante\n",
    "print numerosKalaba, typeKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/Library/Mobile Documents/com~apple~CloudDocs/Downloads/23-Kanoniks/Kanonik-18-ok/\n"
     ]
    }
   ],
   "source": [
    "home = expanduser(\"~\")\n",
    "\n",
    "if typeKalaba!=\"Kanonik\":\n",
    "    numeroKalaba=\"22-K%d/\"%numerosKalaba[0]\n",
    "    repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/\"\n",
    "    serie=repertoire+numeroKalaba\n",
    "else:\n",
    "    repertoire=home+\"/Library/Mobile Documents/com~apple~CloudDocs/Downloads/\"\n",
    "    serie=repertoire+\"23-Kanoniks/\"\n",
    "    serie=serie+\"Kanonik-%02d-ok/\"%numerosKalaba[0]\n",
    "print serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')\n",
    "    \n",
    "    \n",
    "complementPhrases=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Kalaba 3 et 5\n",
    "Pour le kalaba 3 et le 5, pas de séparateur entre les mots\n",
    "Pour le kalaba 5, mettre Mahira dans Mots.csv et Agathos dans Phrases.csv (pour la gestion du puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "séparateur  \n"
     ]
    }
   ],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=0\n",
    "\n",
    "#casNombreDet=True\n",
    "RightLeft=True\n",
    "\n",
    "if (numerosKalaba[0] in [3,5]) and variante==\"\" and typeKalaba!=\"Kanonik\":\n",
    "    separateurPhonoCloze=\"\"\n",
    "else:\n",
    "    separateurPhonoCloze=\" \"\n",
    "# separateurPhonoCloze=\" \"    \n",
    "separateurMots=separateurPhonoCloze\n",
    "print \"séparateur\",separateurMots\n",
    "#separateurMots=\" \"\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False        #False\n",
    "print_radicaux=False     #False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.safe_load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.safe_load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.safe_load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.safe_load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Gloses.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\columnbreak\\\\vfill\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Nom\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Genre', 'Nombre', 'Pers', 'Temps'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOM', 'VER', 'ADJ', 'PRO', 'DET']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Genre': True, 'Nombre': True, 'Pers': False, 'Temps': False},\n",
       " 'DET': {'Genre': True, 'Nombre': True, 'Pers': False, 'Temps': False},\n",
       " 'NOM': {'Genre': True, 'Nombre': True, 'Pers': False, 'Temps': False},\n",
       " 'PRO': {'Genre': True, 'Nombre': True, 'Pers': False, 'Temps': False},\n",
       " 'VER': {'Genre': True, 'Nombre': False, 'Pers': True, 'Temps': True}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['COMP', 'VER', 'AJOUT', 'SUJ', 'OBJ', 'IND'], 'GP': ['PREP', 'GN'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GP', 'NOM', 'DET', 'GADJ']}\n"
     ]
    }
   ],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]\n",
    "syntagmesLR=copy.deepcopy(syntagmes)\n",
    "print syntagmesLR\n",
    "syntagmesRL=copy.deepcopy(syntagmes)\n",
    "for element in syntagmesRL:\n",
    "    syntagmesRL[element].reverse()\n",
    "nomFonctions=syntagmes[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LR',\n",
       " {'GADJ': ['ADV', 'ADJ', 'GP'],\n",
       "  'GN': ['GP', 'NOM', 'DET', 'GADJ'],\n",
       "  'GP': ['PREP', 'GN'],\n",
       "  'Phrase': ['COMP', 'VER', 'AJOUT', 'SUJ', 'OBJ', 'IND']},\n",
       " 'RL',\n",
       " {'GADJ': ['GP', 'ADJ', 'ADV'],\n",
       "  'GN': ['GADJ', 'DET', 'NOM', 'GP'],\n",
       "  'GP': ['GN', 'PREP'],\n",
       "  'Phrase': ['IND', 'OBJ', 'SUJ', 'AJOUT', 'VER', 'COMP']})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"LR\",syntagmesLR, \"RL\",syntagmesRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS', 'FUT', '3Sg', '3Du', '3Pl', 'Ani', 'Ina', 'Hum']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tableaux des formes utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellules={c:set() for c in \"NOM VER ADJ DET PRO\".split(\" \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Introduire les pronoms kalaba\n",
    "- identifier qu'il s'agit d'un pronom\n",
    "- parser le référent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounNumber(nom,nombre):\n",
    "    if nom[len(nom)-1] in [\"s\",\"x\"]:\n",
    "        if nombre==\"\": nombre=\"PL\"\n",
    "    elif nom[len(nom)-1] in [\"P\",\"D\"]:\n",
    "        if nombre==\"\": \n",
    "            if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"PAU\"\n",
    "            elif \"Du\" in valAttributs[\"Nombre\"] and nom[len(nom)-1]==\"D\":\n",
    "                nombre=\"DU\"\n",
    "            else:\n",
    "                nombre=\"PL\"\n",
    "    else:\n",
    "        if nombre==\"\": nombre=\"SG\"\n",
    "    return nombre\n",
    "\n",
    "def getNounGender(ref):\n",
    "    nom=ref.rstrip(\"P\").rstrip(\"D\")\n",
    "    nomLexeme=PFM.lexique.formeLexeme[nom][0]\n",
    "    classesNom=nomLexeme.split('.')[1:]\n",
    "    print classesNom\n",
    "    proGender=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "    return proGender, classesNom\n",
    "\n",
    "\n",
    "def getRef(pronom):\n",
    "    m=re.match(\"^(.*)#(.*)#\",pronom)\n",
    "    if m:\n",
    "        pro=m.group(1)\n",
    "        ref=m.group(2)\n",
    "    else:\n",
    "        print \"mauvaise notation pour un pronom\"\n",
    "        pro=\"\"\n",
    "        ref=\"\"\n",
    "    return pro,ref"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "pro,ref=getRef(u\"elles#fillesD#\")\n",
    "proNum=getNounNumber(ref,nombre=\"\")\n",
    "proGen,proClasse=getNounGender(ref)\n",
    "nomLexeme=PFM.lexique.formeLexeme[pro][0]\n",
    "print pro, nomLexeme, proNum, ref, proNum, proGen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Traitement des GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_gn(departP,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug or 1: print \"groupe departP :\", departP\n",
    "    groupe_nom=[]\n",
    "    if departP[0]==\"de\" and departP[1]==\"les\":\n",
    "        depart=[\"des\"]+departP[2:]\n",
    "    else:\n",
    "        depart=departP\n",
    "    if debug or 1: print \"groupe depart :\", depart\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        if not \"#\" in mot:\n",
    "            groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    pro=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    if len(groupe_nom)==1:\n",
    "#         print \"Pronom ?\",groupe_nom\n",
    "        nomSeul=groupe_nom[0]\n",
    "        boolPro=(\"#\" in nomSeul)\n",
    "    else:\n",
    "        boolPro=False\n",
    "    if boolPro:\n",
    "        proForm,proRef=getRef(nomSeul)\n",
    "        nomLexeme=PFM.lexique.formeLexeme[proForm][0]\n",
    "        print \"ref nomSeul\",proForm,proRef\n",
    "        nombre=getNounNumber(proRef,nombre=\"\")\n",
    "        classe,classesNom=getNounGender(proRef)\n",
    "        pro.append(nomLexeme)\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "#                    else:\n",
    "        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "        cellules[\"PRO\"].add(\".\".join([nomLexeme,classe.capitalize(),nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "        if debug or 0:\n",
    "            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "        if cas==\"ERG\":\n",
    "            erg_genre=classe\n",
    "            erg_nombre=nombre\n",
    "            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "        elif cas==\"ABS\":\n",
    "            abs_genre=classe\n",
    "            abs_nombre=nombre\n",
    "            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for mot in groupe_nom:\n",
    "            if reste==0:\n",
    "    #            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "                if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                    nombre=\"DU\"\n",
    "                    if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                else:\n",
    "                    if \"Pau\" in valAttributs[\"Nombre\"] and mot in \"deux trois quatre cinq\".split():\n",
    "                        nombre=\"PAU\"\n",
    "                        if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                    if mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot[:-1]][0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                        except:\n",
    "                            nomLexeme=PFM.lexique.formeLexeme[mot.lower()][0]\n",
    "                    categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                    if debug or 0: \n",
    "                        print \"mot\",[mot]\n",
    "                        print \"vedette\",nomLexeme,categorie\n",
    "                        print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                    if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                        tete=categorie\n",
    "                        if debug or 0: print \"tête :\", tete\n",
    "                        tampon=tete.split('.')\n",
    "    #                    classe=tampon[0]\n",
    "                        classesNom=nomLexeme.split('.')[1:]\n",
    "                        if debug or 0: print \"classesNom\",classesNom \n",
    "                        classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                        if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                        try:\n",
    "                            typeMot=tampon[1]\n",
    "                        except IndexError:\n",
    "                            typeMot=''\n",
    "                        # modif pour les mots à pluriels en x\n",
    "                        # 23/11/19\n",
    "                        #\n",
    "                        nombre=getNounNumber(mot,nombre)\n",
    "#                         if mot[len(mot)-1] in [\"s\",\"x\"]:\n",
    "#                             if nombre==\"\": nombre=\"PL\"\n",
    "#                         elif mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "#                             if nombre==\"\":\n",
    "#                                 # modif pour permettre le pluriel dans les cas où il n'y a pas de paucal.\n",
    "#                                 # 30/5/21\n",
    "#                                 #\n",
    "#                                 if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "#                                     nombre=\"PAU\"\n",
    "#                                 elif \"Du\" in valAttributs[\"Nombre\"] and mot[len(mot)-1]==\"D\":\n",
    "#                                     nombre=\"DU\"\n",
    "#                                 else:\n",
    "#                                     nombre=\"PL\"\n",
    "#                         else:\n",
    "#                             if nombre==\"\": nombre=\"SG\"\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre\n",
    "\n",
    "                        nom.append(nomLexeme)\n",
    "    #                    if typeCas==\"NoCas\":\n",
    "    #                        cas=\"\"\n",
    "                        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                            cas=\"\"\n",
    "    #                    else:\n",
    "                        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                        cellules[\"NOM\"].add(\".\".join([nomLexeme,nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "                        if cas==\"ERG\":\n",
    "                            erg_genre=classe\n",
    "                            erg_nombre=nombre\n",
    "                            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                        elif cas==\"ABS\":\n",
    "                            abs_genre=classe\n",
    "                            abs_nombre=nombre\n",
    "                            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"DET\"]:\n",
    "#\n",
    "# Modif pour accepter les majuscules en début de phrase\n",
    "#\n",
    "#                         det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                        det.append(nomLexeme)\n",
    "\n",
    "    #                elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"]:\n",
    "#\n",
    "# Modif pour accepter les majuscules en début de phrase\n",
    "#\n",
    "#                         adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                        adj.append(nomLexeme)\n",
    "\n",
    "                    elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                        gp.append(mot)\n",
    "                        reste=1\n",
    "            else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "                gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det and not boolPro: \n",
    "        if nom[0][0]==nom[0][0].upper():\n",
    "            det.append(PFM.lexique.formeLexeme[\"les\"][0])\n",
    "        else:\n",
    "            det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "\n",
    "    tempSyntagme=[]\n",
    "\n",
    "    if pro:\n",
    "        for mot in pro:\n",
    "    #\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "            noligMot=mot.split(\".\")[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            #\n",
    "            # traitement des noms propres avec tiret\n",
    "            # traitement des noms paucals sans ordinaux\n",
    "            #\n",
    "            if \"-\" in noligMot:\n",
    "                noLigs=noligMot.split(\"-\")\n",
    "                if len(noLigs)>1:\n",
    "                    noligMot=noLigs[0]+\"\".join([c for c in noLigs[1:]])\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "            print ref\n",
    "    #        mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot)\n",
    "            texte.append(ref)\n",
    "            tempSyntagme.append(ref)\n",
    "        structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "        mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "        \n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            print \"pas de nombre\"\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "#             print mot,casDet,nombreDet\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        cellules[\"DET\"].add(\".\".join([mot,classeDet,nombreDet,casDet]).strip(\".\"))\n",
    "\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        cellules[\"ADJ\"].add(\".\".join([mot,classeAdj,nombreAdj,casAdj]).strip(\".\"))\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        #\n",
    "        # traitement des noms propres avec tiret\n",
    "        # traitement des noms paucals sans ordinaux\n",
    "        #\n",
    "        if \"-\" in noligMot:\n",
    "            noLigs=noligMot.split(\"-\")\n",
    "            if len(noLigs)>1:\n",
    "                noligMot=noLigs[0]+\"\".join([c.lower() for c in noLigs[1:]])\n",
    "#         noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        if noligMot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    if debug or 0:\n",
    "        print \"fin faire_gn\",listeMots\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/14529523/python-split-for-lists\n",
    "\n",
    "l = [\"data\",\"more data\",\";\",\"data 2\",\"more data 2\",\"danger\",\";\",\"date3\",\"lll\"]\n",
    "[list(group) for k, group in groupby(l, lambda x: x == \";\") if not k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplier_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    lGroupes=[list(group) for k, group in groupby(groupe_prep, lambda x: x == \";\") if not k]\n",
    "    if len(lGroupes)>1:\n",
    "        print lGroupes\n",
    "    for lGp in lGroupes:\n",
    "        mots.extend(faire_gp(lGp,fonction))\n",
    "    return mots\n",
    "    \n",
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug or 1: print \"faire_gp\", \" \".join(groupe_prep), \"fonction\",fonction\n",
    "    formePreposition=groupe_prep[0]\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "    if debug or 1: print formePreposition, preposition\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        # noligMot=groupe_prep[0]\n",
    "        noligMot=preposition\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        \n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                lexemesLocaux.add(noligMot.upper())\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug or 1: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug or 1:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print \"ref\",ref,noligMot\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['une', 'jeune', 'princesse', 'mari\\xc3\\xa9e']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etendre_contraction(\"une jeune princesse mariée\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else:\n",
    "#        if \"{preview}\" in liste:\n",
    "#            print \"preview\",prefixe,liste,suffixe\n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Traitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "texHeader=[]\n",
    "if \"theNotebook\" in globals():\n",
    "    version=theNotebook\n",
    "    texHeader.append(\"%% script : \"+version)\n",
    "texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    ecriture_nom=serie+complementPhrases+\"Ecrit.csv\"\n",
    "    ordre_nom=serie+complementPhrases+\"Ordre.csv\"\n",
    "    mots_nom=serie+complementPhrases+\"Mots.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\"\n",
    "    if len(args)>=4:\n",
    "        ecriture_nom=args[3]\n",
    "    else:\n",
    "        ecriture_nom=\"\"\n",
    "    if len(args)>=5:\n",
    "        ordre_nom=args[4]\n",
    "    else:\n",
    "        ordre_nom=\"\"\n",
    "    if len(args)>=6:\n",
    "        mots_nom=args[5]\n",
    "    else:\n",
    "        mots_nom=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrerCloze(filtre):\n",
    "    result=[]\n",
    "    for ligne in clozeLines:\n",
    "        if type(ligne)==str:\n",
    "            ligne=unicode(ligne.decode('utf8'))\n",
    "        ligne=ligne.strip()\n",
    "        if not ligne.startswith(\"#\"):\n",
    "            clozeElements=ligne.split(\";\")\n",
    "            if clozeElements[1] in filtre:\n",
    "                result.append(ligne)\n",
    "        else:\n",
    "            result.append(ligne)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if not isinstance(item, basestring):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewerBegin=\"\\\\begin{preview}\\\\begin{flushleft}\"\n",
    "previewerEnd=\"\\\\end{flushleft}\\\\end{preview}\"\n",
    "\n",
    "def latex2ipa(mot):\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLignePreview=\"\\\\end{preview}\"\n",
    "    if \" \" in mot:\n",
    "        result=[]\n",
    "        for element in mot.split():\n",
    "            result.append(latex2ipa(element))\n",
    "        return separateurMots.join(result)\n",
    "    else:\n",
    "        mot=mot.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "    #    print mot\n",
    "        mot=mot.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "    #    print mot\n",
    "        element=mot.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "    #    print element\n",
    "        cleElement=element.strip().strip(\"\\\\{}\")\n",
    "    #    print cleElement\n",
    "        if element==\"\\\\ex\": cleElement=\"\"\n",
    "        if cleElement:\n",
    "            if not cleElement in traductions:\n",
    "                print mot\n",
    "                print cleElement\n",
    "                print traductions\n",
    "                warnings.warn(\"pas de transcription pour %s\"%cleElement)\n",
    "                return None\n",
    "            else:\n",
    "                return traductions[cleElement]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex2ipa(\"\\\\begin{preview}\\\\DEFMSg{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previewer(chaine,numLignesVides=0,suffixe=\"\"):\n",
    "    flatChaine=[mot+suffixe for mot in list(flatten(chaine))]\n",
    "    result=previewerBegin+separateurMots.join(flatChaine)+\"\\\\\\\\\"*numLignesVides+previewerEnd\n",
    "    return [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "texteMots=set()\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.lexemes[\"construire\"].formes.index(\"construisit\")\n",
    "valAttributs[\"Genre\"]\n",
    "localClasses=[\"N\"]\n",
    "[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "localCas=\"Nom\"\n",
    "not localCas or localCas in sujetVerbe\n",
    "sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliserMajusculesMinuscules(mot):\n",
    "    result=mot\n",
    "    if \"'\" in mot:\n",
    "        lMots=mot.split(\"'\")\n",
    "        result=\"'\".join([normaliserMajusculesMinuscules(m) for m in lMots])\n",
    "    elif len(mot)>1 and mot!=mot.lower() and mot!=mot.capitalize():\n",
    "        result=mot[0]+mot[1:].lower()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"d'E-st'Ogm\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliserMajusculesMinuscules(u\"d'E-St'OGM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Introduire les pronoms dans les phrases\n",
    "\n",
    "- clitiques verbaux entre dièses pour permettre l'inclusion en français et l'exclusion en kalaba\n",
    "  - Marie TAB #les# voyait TAB ,les enfants TAB TAB dans la cour\n",
    "    - FR: Les enfants, Marie les voyait dans la cour.\n",
    "    - KB: Marie voyait les enfants dans la cour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFr(line):\n",
    "    result=line\n",
    "    m=re.search(ur\"((\\w+)#\\S+#)\",result)\n",
    "    if m:\n",
    "        result=result.replace(m.group(1),m.group(2))\n",
    "        result=cleanFr(result)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'elles pensent \\xe0 lui'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFr(u\"elles#sorcières# pensent à lui#garçon#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemblage des phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Niveau phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortie=\"latex\"):\n",
    "    print sortie\n",
    "    phrasesLocales=phrase_file.readlines()\n",
    "    syntagmesLocaux=[]\n",
    "    numLignes=len(phrasesLocales)\n",
    "    numImages=1\n",
    "    numLignesVides=0\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    elif sortie==\"images\":\n",
    "        numImages=1\n",
    "        numLignesVides=0\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "        numLignesVides=0\n",
    "\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLigneNoPreview=\"\\\\\\\\\"*numLignesVides\n",
    "    finLignePreview=\"\\\\\\\\\"*numLignesVides+\"\\\\end{preview}\"\n",
    "    numLignes=(len(phrasesLocales)//numImages)*numImages\n",
    "\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrasesLocales[:numLignes]):\n",
    "        if debug: print nPhrase,line\n",
    "        #phrase contient une position par fonction\n",
    "        #pour accueillir les équivalents kalabas des chunks français\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").replace(u\"’\",\" \").split(\"\\t\")\n",
    "        tampon=[t.strip() for t in tampon]\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug or 1: \n",
    "            print \"===========================================\"            \n",
    "            print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "#             print nPhrase,tampon\n",
    "            #\n",
    "            # Introduire les clitiques non-traités\n",
    "            # \n",
    "            # #les# voit \n",
    "            #\n",
    "            m=re.search(ur\"#.*#\\s*(.*)\",tampon[1])\n",
    "            if m:\n",
    "                verbe=m.group(1).split(\" \")\n",
    "            else:\n",
    "                verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            tempVerbe=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print tempVerbe\n",
    "            formeCitation=tempVerbe[0]\n",
    "            lexemesLocaux.add(formeCitation)\n",
    "            for element in tempVerbe[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            if len(tempVerbe)>1:\n",
    "                typeVerbe=tempVerbe[1]\n",
    "            else: \n",
    "                typeVerbe=\"\"\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    frObjetCas=\"\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            if debug: print (frSujetCas,frObjetCas,klbSujet)\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (\"FAIRE_GN SUJET\",localMots,(localClasses,localNombre,localCas))\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas,localNombre,localClasses,sujetVerbe\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            ########################\n",
    "            #\n",
    "            # Modification pour permettre les accords par défaut\n",
    "            # avec des verbes transitifs sans objet pour les systèmes ergatifs\n",
    "            #\n",
    "            ########################\n",
    "            if klbSujet==\"OBJ\" and len(tampon)<3:\n",
    "                tampon.append(\"\")\n",
    "            if len(tampon)>=3:\n",
    "                if tampon[2] and tampon[2].startswith(\",\"):\n",
    "                    tampon[2]=tampon[2][1:]\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "                    # pourquoi un traitement spécial pour sortie==\"mots\"\n",
    "#                     elif sortie==\"mots\": print \"objet\",objet\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe and localCas!=\"Nom\":\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    print \"verbe ergatif sans objet\",[objet]\n",
    "                    print tampon\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                if tampon[3] and tampon[3].startswith(\",\"):\n",
    "                    tampon[3]=tampon[3][1:]\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=previewer(faire_gp(indirect,\"IND\"),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            ###################\n",
    "            #\n",
    "            # Modification pour ajouts multiples séparés par ;\n",
    "            # 24/11/19\n",
    "            #\n",
    "            ###################\n",
    "            if len(tampon)>=5:\n",
    "                if tampon[4] and tampon[4].startswith(\",\"):\n",
    "                    tampon[4]=tampon[4][1:]\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=previewer(multiplier_gp(comp),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=multiplier_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                if tampon[5] and tampon[5].startswith(\",\"):\n",
    "                    tampon[5]=tampon[5][1:]\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                if sortie==\"ordre\":\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=previewer(multiplier_gp(ajout),suffixe=\"{}\")\n",
    "                else:\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=multiplier_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "            noligFormeCitation=noligFormeCitation.replace(\"-\",\"\")\n",
    "            \n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent)\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            cellules[\"VER\"].add(\".\".join([verbeLexeme,morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize(),nombrePersonne,classeVerbe,nombreVerbe]).strip(\".\"))\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=previewer([glose],suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            lexemesLocaux.add(noligFormeCitation)\n",
    "            texte.append(glose)\n",
    "            if sortie in [\"latex\",\"traductions\"]: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            syntagmesBruts=[]\n",
    "            syntagmesEtiquetes=[]\n",
    "            for nMot,mot in enumerate(phrase):\n",
    "                if mot!=0:\n",
    "                    \n",
    "                    if isinstance(mot,basestring):\n",
    "                        syntagmeLocal=latex2ipa(mot)\n",
    "                    else:\n",
    "                        interFlat=[]\n",
    "                        for m in flatten(mot):\n",
    "                            mList=re.findall(ur\"\\\\[^{]+{}\",m)\n",
    "                            if mList:\n",
    "                                interFlat.extend(mList)\n",
    "                            else:\n",
    "                                interFlat.append(m)\n",
    "                        if debug: print \"interFlat\",interFlat\n",
    "                        if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                            interFlat.reverse()\n",
    "                        syntagmeLocal=separateurMots.join([latex2ipa(f) for f in interFlat])\n",
    "                    syntagmesBruts.append(syntagmeLocal)\n",
    "                    syntagmesEtiquetes.append(syntagmeLocal)\n",
    "                    if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                        syntagmesEtiquetes.append(syntagmes[\"Phrase\"][nMot])\n",
    "                    else:\n",
    "                        syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "#                    syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "                    printflat(mot,\"{}\")\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts[::-1])+\";\"+\" \".join(syntagmesEtiquetes[::-1])\n",
    "            else:\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            print ligneSyntagmesLocaux\n",
    "            syntagmesLocaux.append(ligneSyntagmesLocaux)\n",
    "            localAccumulateur=[accu for accu in accumulateur if accu!=\"\"]\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "                if sortie==\"images\":\n",
    "                    if nPhrase%numImages==0:\n",
    "                        prefixe=\"\\\\begin{preview}\"\n",
    "                    else:\n",
    "                        prefixe=\"\"\n",
    "                    if nPhrase%numImages==numImages-1:\n",
    "                        finLigne=finLignePreview\n",
    "                    else:\n",
    "                        finLigne=finLigneNoPreview\n",
    "                elif sortie==\"mots\":\n",
    "                    localAccumulateur=[debutLignePreview+accu+finLignePreview for accu in accumulateur if accu!=\"\"]\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(localAccumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\" and separateurMots==\"\":\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur[::-1])+finLigne)\n",
    "            else:\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortie in [\"latex\",\"traductions\"]:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortie in [\"latex\",\"traductions\"]: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            ##############\n",
    "            #\n",
    "            # Modification pour ajouts multiples\n",
    "            # suppression des ; de séparation dans la traduction\n",
    "            #\n",
    "            ##############\n",
    "            if \",\" in line:\n",
    "                consts=line.split(\"\\t\")\n",
    "                disloc=[]\n",
    "                canon=[]\n",
    "                for const in consts:\n",
    "                    if const.startswith(\",\"):\n",
    "                        if \";\" in const:\n",
    "                            subConsts=const.split(\";\")\n",
    "                            print \"############## ; ##########@\"\n",
    "                            print subConsts\n",
    "                            disloc.append(subConsts[0][1:])\n",
    "                            for subConst in subConsts[1:]:\n",
    "                                canon.append(subConst.lstrip())\n",
    "                        else:\n",
    "                            disloc.append(const[1:])\n",
    "                    else:\n",
    "                        canon.append(const)\n",
    "                line=\",\\t\".join(disloc).strip()+\", \"+\"\\t\".join(canon)\n",
    "            if \" ; \" in line:\n",
    "                line=line.replace(\" ; \",\" \")\n",
    "            line=cleanFr(line)            \n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                if element==u\"À\":element=u\"à\"\n",
    "                if element==\"Au\":element=\"au\"\n",
    "                if element==\"Aux\":element=\"aux\"\n",
    "                element=element.strip(\"#\").replace(u\"’\",\"'\")\n",
    "                #\n",
    "                # Modification pour accepter les suffixes P et D à la fin des noms\n",
    "                # 31/5/21\n",
    "                #\n",
    "                if element[-2:] in [\"sP\",\"sD\"]:\n",
    "                    element=element[:-1]\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=normaliserMajusculesMinuscules(element)\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(caracteres)\n",
    "            if sortie==\"latex\": \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            elif sortie==\"images\":\n",
    "                ajouterExemple(marqueurCommentaire+\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "            elif sortie in [\"ordre\",\"mots\"]:\n",
    "                ajouterExemple(\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "                #if sortie==\"mots\": ajouterExemple(\"\\\\begin{preview}\"+\".\"+\"\\\\end{preview}\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortie==\"latex\" and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRONOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PRO\"][\"cols\"],tableaux[\"PRO\"],texte,dimensionsTableaux[\"PRO\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"PRO\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "            with codecs.open(serie+complementPhrases+\"Syntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in syntagmesLocaux:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "        elif (sortie==\"traductions\" and variante==\"-Corr\"):\n",
    "            with codecs.open(serie+complementPhrases+\"Traductions\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")            \n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "#    elif sortie==\"images\":\n",
    "#        with codecs.open(serie+complementPhrases+\"Images\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "#            for exemple in exemples:\n",
    "#                output.write(exemple+\"\\n\")\n",
    "    elif sortie in [\"images\",\"ordre\",\"mots\"]:\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "            for texHead in texHeader:\n",
    "                output.write(texHead+\"\\n\")\n",
    "            for exemple in exemples:\n",
    "                output.write(exemple+\"\\n\")\n",
    "    if sortie in [\"images\",\"traductions\",\"ordre\",\"mots\"]:\n",
    "        if sortie==\"mots\":print\n",
    "        clozeTraductions=[]\n",
    "        clozeExemples=exemples[:]\n",
    "        filtreLignes=[\"\\\\begin{phrases}\",\"\\\\ex\",\"\\\\gloses\",\"\\\\end{phrases}\"]\n",
    "        if sortie==\"traductions\":\n",
    "            clozeExemples=[exemple for exemple in clozeExemples if (not exemple in filtreLignes) and not exemple.startswith(\"%\")]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(clozeExemples)]*3):\n",
    "            if sortie==\"traductions\" and 0:\n",
    "                print \"ortho\",orthoLigne\n",
    "                print \"phono\",phonoLigne\n",
    "                print \"trad\",tradLigne\n",
    "            phonoLigne=phonoLigne.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "            phonoLigne=phonoLigne.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "            phonoLigne=phonoLigne.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoMots=phonoLigne.strip(marqueurCommentaire).replace(finLignePreview,\"\").strip().split()\n",
    "            tradLigne=tradLigne.strip(marqueurCommentaire).replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")\n",
    "                if element==\"\\\\ex\": cleElement=\"\"\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print \"no key\", cleElement,phonoMots\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n",
    "        if sortie==\"ordre\" and separateurMots==\"\":\n",
    "            dictSyntagmes={}\n",
    "            dictTraductions={}\n",
    "            ordreCles=[]\n",
    "            for element in syntagmesLocaux:\n",
    "                clePhono,valSyntagmes=element.split(\";\")\n",
    "                dictSyntagmes[clePhono]=\" \".join([v for v in valSyntagmes.split() if not v in nomFonctions])\n",
    "                ordreCles.append(clePhono)\n",
    "            for element in clozeTraductions:\n",
    "                clePhono,valTrad,valMots=element.split(\";\")\n",
    "                dictTraductions[clePhono]=valTrad\n",
    "            morceauxPhrases=[\"%s;%s\"%(dictSyntagmes[c],dictTraductions[c]) for c in ordreCles]\n",
    "            with codecs.open(serie+complementPhrases+\"OrdreSyntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in morceauxPhrases:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['COMP', 'VER', 'AJOUT', 'SUJ', 'OBJ', 'IND'], 'GP': ['PREP', 'GN'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GP', 'NOM', 'DET', 'GADJ']}\n"
     ]
    }
   ],
   "source": [
    "sortie=\"traductions\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if traduction_nom.endswith(\"csv\") and variante!=\"-Corr\":\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the translation file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,sortie=sortie)\n",
    "            traduction_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['IND', 'OBJ', 'SUJ', 'AJOUT', 'VER', 'COMP'], 'GP': ['GN', 'PREP'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['GADJ', 'DET', 'NOM', 'GP']}\n",
      "latex\n",
      "===========================================\n",
      "Afior\test\tune grande planète\t\t\t\n",
      "\n",
      "groupe departP : [u'Afior']\n",
      "groupe depart : [u'Afior']\n",
      "groupe departP : [u'une', u'grande', u'plan\\xe8te']\n",
      "groupe depart : [u'une', u'grande', u'plan\\xe8te']\n",
      "===========================================\n",
      "le lapin avec Léina\tverront\tces planètes\t\t\t\n",
      "\n",
      "groupe departP : [u'le', u'lapin', u'avec', u'L\\xe9ina']\n",
      "groupe depart : [u'le', u'lapin', u'avec', u'L\\xe9ina']\n",
      "faire_gp avec Léina fonction \n",
      "avec avec\n",
      "pas de Cas\n",
      "groupe prep : [u'avec', u'L\\xe9ina']\n",
      "ref \\AVEC avec\n",
      "groupe departP : [u'L\\xe9ina']\n",
      "groupe depart : [u'L\\xe9ina']\n",
      "groupe departP : [u'ces', u'plan\\xe8tes']\n",
      "groupe depart : [u'ces', u'plan\\xe8tes']\n",
      "===========================================\n",
      "les étoiles\tbrillent\t\t\t\tdans le ciel\n",
      "\n",
      "groupe departP : [u'les', u'\\xe9toiles']\n",
      "groupe depart : [u'les', u'\\xe9toiles']\n",
      "faire_gp dans le ciel fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'le', u'ciel']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'le', u'ciel']\n",
      "groupe depart : [u'le', u'ciel']\n",
      "===========================================\n",
      "Léina\tprend\tdes lunettes\t\tpour le soleil\t\n",
      "\n",
      "groupe departP : [u'L\\xe9ina']\n",
      "groupe depart : [u'L\\xe9ina']\n",
      "groupe departP : [u'des', u'lunettes']\n",
      "groupe depart : [u'des', u'lunettes']\n",
      "faire_gp pour le soleil fonction \n",
      "pour pour\n",
      "pas de Cas\n",
      "groupe prep : [u'pour', u'le', u'soleil']\n",
      "ref \\POUR pour\n",
      "groupe departP : [u'le', u'soleil']\n",
      "groupe depart : [u'le', u'soleil']\n",
      "===========================================\n",
      "les lunettes\tbrillent\t\t\t\t\n",
      "\n",
      "groupe departP : [u'les', u'lunettes']\n",
      "groupe depart : [u'les', u'lunettes']\n",
      "===========================================\n",
      "les enfants\tdécouvrent\tla planète\t\t\t\n",
      "\n",
      "groupe departP : [u'les', u'enfants']\n",
      "groupe depart : [u'les', u'enfants']\n",
      "groupe departP : [u'la', u'plan\\xe8te']\n",
      "groupe depart : [u'la', u'plan\\xe8te']\n",
      "===========================================\n",
      "le ciel de la planète\tbrille\t\t\t\t\n",
      "\n",
      "groupe departP : [u'le', u'ciel', u'de', u'la', u'plan\\xe8te']\n",
      "groupe depart : [u'le', u'ciel', u'de', u'la', u'plan\\xe8te']\n",
      "faire_gp de la planète fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'la', u'plan\\xe8te']\n",
      "ref \\DE de\n",
      "groupe departP : [u'la', u'plan\\xe8te']\n",
      "groupe depart : [u'la', u'plan\\xe8te']\n",
      "===========================================\n",
      "ils#enfants#\tlongent\tla longue rivière\t\t\t\n",
      "\n",
      "groupe departP : [u'ils#enfants#']\n",
      "groupe depart : [u'ils#enfants#']\n",
      "ref nomSeul ils enfants\n",
      "[u'Hum']\n",
      "\\PROHumPl\n",
      "groupe departP : [u'la', u'longue', u'rivi\\xe8re']\n",
      "groupe depart : [u'la', u'longue', u'rivi\\xe8re']\n",
      "===========================================\n",
      "Almael\tmange \tla tartine d'Anouk\t\t\t\n",
      "\n",
      "groupe departP : [u'Almael']\n",
      "groupe depart : [u'Almael']\n",
      "groupe departP : [u'la', u'tartine', u'd', u'Anouk']\n",
      "groupe depart : [u'la', u'tartine', u'd', u'Anouk']\n",
      "faire_gp de Anouk fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'Anouk']\n",
      "ref \\DE de\n",
      "groupe departP : [u'Anouk']\n",
      "groupe depart : [u'Anouk']\n",
      "===========================================\n",
      "elle#Anouk#\tvoit\tla rambarde\t\t\t\n",
      "\n",
      "groupe departP : [u'elle#Anouk#']\n",
      "groupe depart : [u'elle#Anouk#']\n",
      "ref nomSeul elle Anouk\n",
      "[u'Hum']\n",
      "\\PROHumSg\n",
      "groupe departP : [u'la', u'rambarde']\n",
      "groupe depart : [u'la', u'rambarde']\n",
      "===========================================\n",
      "les deux enfants\tmangent\tles deux tartines\t\t\tsur la rambarde\n",
      "\n",
      "groupe departP : [u'les', u'deux', u'enfants']\n",
      "groupe depart : [u'les', u'deux', u'enfants']\n",
      "groupe departP : [u'les', u'deux', u'tartines']\n",
      "groupe depart : [u'les', u'deux', u'tartines']\n",
      "faire_gp sur la rambarde fonction \n",
      "sur sur\n",
      "pas de Cas\n",
      "groupe prep : [u'sur', u'la', u'rambarde']\n",
      "ref \\SUR sur\n",
      "groupe departP : [u'la', u'rambarde']\n",
      "groupe depart : [u'la', u'rambarde']\n",
      "===========================================\n",
      "Anouk\tdécouvre\tl'oxygène\t\tdans cette grotte\t\n",
      "\n",
      "groupe departP : [u'Anouk']\n",
      "groupe depart : [u'Anouk']\n",
      "groupe departP : [u'l', u'oxyg\\xe8ne']\n",
      "groupe depart : [u'l', u'oxyg\\xe8ne']\n",
      "faire_gp dans cette grotte fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'cette', u'grotte']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'cette', u'grotte']\n",
      "groupe depart : [u'cette', u'grotte']\n",
      "===========================================\n",
      "ils#enfants#\tdécouvrent \tun escalier\t\tdevant la grotte\t\n",
      "\n",
      "groupe departP : [u'ils#enfants#']\n",
      "groupe depart : [u'ils#enfants#']\n",
      "ref nomSeul ils enfants\n",
      "[u'Hum']\n",
      "\\PROHumPl\n",
      "groupe departP : [u'un', u'escalier']\n",
      "groupe depart : [u'un', u'escalier']\n",
      "faire_gp devant la grotte fonction \n",
      "devant devant\n",
      "pas de Cas\n",
      "groupe prep : [u'devant', u'la', u'grotte']\n",
      "ref \\DEVANT devant\n",
      "groupe departP : [u'la', u'grotte']\n",
      "groupe depart : [u'la', u'grotte']\n",
      "===========================================\n",
      "une lueur verte\tbrille\t\t\tdans la grotte sombre\tdevant les enfants\n",
      "\n",
      "groupe departP : [u'une', u'lueur', u'verte']\n",
      "groupe depart : [u'une', u'lueur', u'verte']\n",
      "faire_gp dans la grotte sombre fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'la', u'grotte', u'sombre']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'la', u'grotte', u'sombre']\n",
      "groupe depart : [u'la', u'grotte', u'sombre']\n",
      "faire_gp devant les enfants fonction \n",
      "devant devant\n",
      "pas de Cas\n",
      "groupe prep : [u'devant', u'les', u'enfants']\n",
      "ref \\DEVANT devant\n",
      "groupe departP : [u'les', u'enfants']\n",
      "groupe depart : [u'les', u'enfants']\n",
      "===========================================\n",
      "elle#Léina#\tverra\tla lueur\t\t\t\n",
      "\n",
      "groupe departP : [u'elle#L\\xe9ina#']\n",
      "groupe depart : [u'elle#L\\xe9ina#']\n",
      "ref nomSeul elle Léina\n",
      "[u'Hum']\n",
      "\\PROHumSg\n",
      "groupe departP : [u'la', u'lueur']\n",
      "groupe depart : [u'la', u'lueur']\n",
      "===========================================\n",
      "ils#enfants#\tmangeront\tles lasagnes\t\t\tavec des pommes\n",
      "\n",
      "groupe departP : [u'ils#enfants#']\n",
      "groupe depart : [u'ils#enfants#']\n",
      "ref nomSeul ils enfants\n",
      "[u'Hum']\n",
      "\\PROHumPl\n",
      "groupe departP : [u'les', u'lasagnes']\n",
      "groupe depart : [u'les', u'lasagnes']\n",
      "faire_gp avec des pommes fonction \n",
      "avec avec\n",
      "pas de Cas\n",
      "groupe prep : [u'avec', u'des', u'pommes']\n",
      "ref \\AVEC avec\n",
      "groupe departP : [u'des', u'pommes']\n",
      "groupe depart : [u'des', u'pommes']\n",
      "===========================================\n",
      "les lasagnes\tatterrissent\t\t\tdans la rivière\t\n",
      "\n",
      "groupe departP : [u'les', u'lasagnes']\n",
      "groupe depart : [u'les', u'lasagnes']\n",
      "faire_gp dans la rivière fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'la', u'rivi\\xe8re']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'la', u'rivi\\xe8re']\n",
      "groupe depart : [u'la', u'rivi\\xe8re']\n",
      "===========================================\n",
      "les enfants\tlancent\tles pommes\t\t\t\n",
      "\n",
      "groupe departP : [u'les', u'enfants']\n",
      "groupe depart : [u'les', u'enfants']\n",
      "groupe departP : [u'les', u'pommes']\n",
      "groupe depart : [u'les', u'pommes']\n",
      "===========================================\n",
      "les deux mammouths\tregarderont\tles filles \t\t\t\n",
      "\n",
      "groupe departP : [u'les', u'deux', u'mammouths']\n",
      "groupe depart : [u'les', u'deux', u'mammouths']\n",
      "groupe departP : [u'les', u'filles']\n",
      "groupe depart : [u'les', u'filles']\n",
      "===========================================\n",
      "Almael\tjoue\t\t\tavec les cailloux de la rivière\tsous l'orage\n",
      "\n",
      "groupe departP : [u'Almael']\n",
      "groupe depart : [u'Almael']\n",
      "faire_gp avec les cailloux de la rivière fonction \n",
      "avec avec\n",
      "pas de Cas\n",
      "groupe prep : [u'avec', u'les', u'cailloux', u'de', u'la', u'rivi\\xe8re']\n",
      "ref \\AVEC avec\n",
      "groupe departP : [u'les', u'cailloux', u'de', u'la', u'rivi\\xe8re']\n",
      "groupe depart : [u'les', u'cailloux', u'de', u'la', u'rivi\\xe8re']\n",
      "faire_gp de la rivière fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'la', u'rivi\\xe8re']\n",
      "ref \\DE de\n",
      "groupe departP : [u'la', u'rivi\\xe8re']\n",
      "groupe depart : [u'la', u'rivi\\xe8re']\n",
      "faire_gp sous l orage fonction \n",
      "sous sous\n",
      "pas de Cas\n",
      "groupe prep : [u'sous', u'l', u'orage']\n",
      "ref \\SOUS sous\n",
      "groupe departP : [u'l', u'orage']\n",
      "groupe depart : [u'l', u'orage']\n",
      "===========================================\n",
      "le lapin \tjouera\t\t\tavec un oS\t\n",
      "\n",
      "groupe departP : [u'le', u'lapin']\n",
      "groupe depart : [u'le', u'lapin']\n",
      "faire_gp avec un oS fonction \n",
      "avec avec\n",
      "pas de Cas\n",
      "groupe prep : [u'avec', u'un', u'oS']\n",
      "ref \\AVEC avec\n",
      "groupe departP : [u'un', u'oS']\n",
      "groupe depart : [u'un', u'oS']\n",
      "===========================================\n",
      "l'oS\tatterrira\t\t\tdans l'obscurité\t\n",
      "\n",
      "groupe departP : [u'l', u'oS']\n",
      "groupe depart : [u'l', u'oS']\n",
      "faire_gp dans l obscurité fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'l', u'obscurit\\xe9']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'l', u'obscurit\\xe9']\n",
      "groupe depart : [u'l', u'obscurit\\xe9']\n",
      "===========================================\n",
      "la lave\tpousse\tl'oxygène\t\t\t\n",
      "\n",
      "groupe departP : [u'la', u'lave']\n",
      "groupe depart : [u'la', u'lave']\n",
      "groupe departP : [u'l', u'oxyg\\xe8ne']\n",
      "groupe depart : [u'l', u'oxyg\\xe8ne']\n",
      "===========================================\n",
      "les deux filles\tregardent\tla lave\t\t\t\n",
      "\n",
      "groupe departP : [u'les', u'deux', u'filles']\n",
      "groupe depart : [u'les', u'deux', u'filles']\n",
      "groupe departP : [u'la', u'lave']\n",
      "groupe depart : [u'la', u'lave']\n",
      "===========================================\n",
      "le vent \tlancent\tles poissons\t\t\tdans les étoiles\n",
      "\n",
      "groupe departP : [u'le', u'vent']\n",
      "groupe depart : [u'le', u'vent']\n",
      "groupe departP : [u'les', u'poissons']\n",
      "groupe depart : [u'les', u'poissons']\n",
      "faire_gp dans les étoiles fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'les', u'\\xe9toiles']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'les', u'\\xe9toiles']\n",
      "groupe depart : [u'les', u'\\xe9toiles']\n",
      "===========================================\n",
      "des mammouths\tdécouvriront\tles poissons\t\t\t\n",
      "\n",
      "groupe departP : [u'des', u'mammouths']\n",
      "groupe depart : [u'des', u'mammouths']\n",
      "groupe departP : [u'les', u'poissons']\n",
      "groupe depart : [u'les', u'poissons']\n",
      "===========================================\n",
      "ces deux oiseaux\tverront\tles enfants\t\t\t\n",
      "\n",
      "groupe departP : [u'ces', u'deux', u'oiseaux']\n",
      "groupe depart : [u'ces', u'deux', u'oiseaux']\n",
      "groupe departP : [u'les', u'enfants']\n",
      "groupe depart : [u'les', u'enfants']\n",
      "===========================================\n",
      "les ailes des oiseaux\tcassent\tles crânes des deux poissons\t\t\t\n",
      "\n",
      "groupe departP : [u'les', u'ailes', u'des', u'oiseaux']\n",
      "groupe depart : [u'les', u'ailes', u'des', u'oiseaux']\n",
      "faire_gp de les oiseaux fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'les', u'oiseaux']\n",
      "ref \\DE de\n",
      "groupe departP : [u'les', u'oiseaux']\n",
      "groupe depart : [u'les', u'oiseaux']\n",
      "groupe departP : [u'les', u'cr\\xe2nes', u'des', u'deux', u'poissons']\n",
      "groupe depart : [u'les', u'cr\\xe2nes', u'des', u'deux', u'poissons']\n",
      "faire_gp de les deux poissons fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'les', u'deux', u'poissons']\n",
      "ref \\DE de\n",
      "groupe departP : [u'les', u'deux', u'poissons']\n",
      "groupe depart : [u'les', u'deux', u'poissons']\n",
      "===========================================\n",
      "le magicien\tcapture\tLéina\t\t\t\n",
      "\n",
      "groupe departP : [u'le', u'magicien']\n",
      "groupe depart : [u'le', u'magicien']\n",
      "groupe departP : [u'L\\xe9ina']\n",
      "groupe depart : [u'L\\xe9ina']\n",
      "===========================================\n",
      "l'enfant\tpoussera\tdes cris\t\t\t\n",
      "\n",
      "groupe departP : [u'l', u'enfant']\n",
      "groupe depart : [u'l', u'enfant']\n",
      "groupe departP : [u'des', u'cris']\n",
      "groupe depart : [u'des', u'cris']\n",
      "===========================================\n",
      "le lapin blanc\tprend\tla pelle bleue\t\t\tdans la grande maison\n",
      "\n",
      "groupe departP : [u'le', u'lapin', u'blanc']\n",
      "groupe depart : [u'le', u'lapin', u'blanc']\n",
      "groupe departP : [u'la', u'pelle', u'bleue']\n",
      "groupe depart : [u'la', u'pelle', u'bleue']\n",
      "faire_gp dans la grande maison fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'la', u'grande', u'maison']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'la', u'grande', u'maison']\n",
      "groupe depart : [u'la', u'grande', u'maison']\n",
      "===========================================\n",
      "le lapin\tlancent\tla pelle \tà la licorne\t\t\n",
      "\n",
      "groupe departP : [u'le', u'lapin']\n",
      "groupe depart : [u'le', u'lapin']\n",
      "groupe departP : [u'la', u'pelle']\n",
      "groupe depart : [u'la', u'pelle']\n",
      "faire_gp à la licorne fonction IND\n",
      "à à\n",
      "pas de Cas\n",
      "groupe prep : [u'\\xe0', u'la', u'licorne']\n",
      "ref \\A à\n",
      "groupe departP : [u'la', u'licorne']\n",
      "groupe depart : [u'la', u'licorne']\n",
      "===========================================\n",
      "il#lapin#\tdécouvrira\tl'obscurité\t\tdans cette maison\t\n",
      "\n",
      "groupe departP : [u'il#lapin#']\n",
      "groupe depart : [u'il#lapin#']\n",
      "ref nomSeul il lapin\n",
      "[u'Ani']\n",
      "\\PROAniSg\n",
      "groupe departP : [u'l', u'obscurit\\xe9']\n",
      "groupe depart : [u'l', u'obscurit\\xe9']\n",
      "faire_gp dans cette maison fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'cette', u'maison']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'cette', u'maison']\n",
      "groupe depart : [u'cette', u'maison']\n",
      "===========================================\n",
      "cette pelle \tatterrit\t\t\tdans l'escalier\t\n",
      "\n",
      "groupe departP : [u'cette', u'pelle']\n",
      "groupe depart : [u'cette', u'pelle']\n",
      "faire_gp dans l escalier fonction \n",
      "dans dans\n",
      "pas de Cas\n",
      "groupe prep : [u'dans', u'l', u'escalier']\n",
      "ref \\DANS dans\n",
      "groupe departP : [u'l', u'escalier']\n",
      "groupe depart : [u'l', u'escalier']\n",
      "===========================================\n",
      "la licorne\taide\tle lapin blanc\t\t\t\n",
      "\n",
      "groupe departP : [u'la', u'licorne']\n",
      "groupe depart : [u'la', u'licorne']\n",
      "groupe departP : [u'le', u'lapin', u'blanc']\n",
      "groupe depart : [u'le', u'lapin', u'blanc']\n",
      "===========================================\n",
      "le magicien\tcassera\tla grande maison de la licorne\t\t\t\n",
      "\n",
      "groupe departP : [u'le', u'magicien']\n",
      "groupe depart : [u'le', u'magicien']\n",
      "groupe departP : [u'la', u'grande', u'maison', u'de', u'la', u'licorne']\n",
      "groupe depart : [u'la', u'grande', u'maison', u'de', u'la', u'licorne']\n",
      "faire_gp de la licorne fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'la', u'licorne']\n",
      "ref \\DE de\n",
      "groupe departP : [u'la', u'licorne']\n",
      "groupe depart : [u'la', u'licorne']\n",
      "===========================================\n",
      "cette licorne\tcasse\tla baguette magique du magicien\t\t\t\n",
      "\n",
      "groupe departP : [u'cette', u'licorne']\n",
      "groupe depart : [u'cette', u'licorne']\n",
      "groupe departP : [u'la', u'baguette', u'magique', u'du', u'magicien']\n",
      "groupe depart : [u'la', u'baguette', u'magique', u'du', u'magicien']\n",
      "faire_gp de le magicien fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'le', u'magicien']\n",
      "ref \\DE de\n",
      "groupe departP : [u'le', u'magicien']\n",
      "groupe depart : [u'le', u'magicien']\n",
      "===========================================\n",
      "il#magicien#\tcasse\tles ailes de la licorne\t\t\t\n",
      "\n",
      "groupe departP : [u'il#magicien#']\n",
      "groupe depart : [u'il#magicien#']\n",
      "ref nomSeul il magicien\n",
      "[u'Hum']\n",
      "\\PROHumSg\n",
      "groupe departP : [u'les', u'ailes', u'de', u'la', u'licorne']\n",
      "groupe depart : [u'les', u'ailes', u'de', u'la', u'licorne']\n",
      "faire_gp de la licorne fonction \n",
      "de de\n",
      "pas de Cas\n",
      "groupe prep : [u'de', u'la', u'licorne']\n",
      "ref \\DE de\n",
      "groupe departP : [u'la', u'licorne']\n",
      "groupe depart : [u'la', u'licorne']\n",
      "===========================================\n",
      "cette licorne\tpousse\tun cri\t\t\tdevant le magicien\n",
      "\n",
      "groupe departP : [u'cette', u'licorne']\n",
      "groupe depart : [u'cette', u'licorne']\n",
      "groupe departP : [u'un', u'cri']\n",
      "groupe depart : [u'un', u'cri']\n",
      "faire_gp devant le magicien fonction \n",
      "devant devant\n",
      "pas de Cas\n",
      "groupe prep : [u'devant', u'le', u'magicien']\n",
      "ref \\DEVANT devant\n",
      "groupe departP : [u'le', u'magicien']\n",
      "groupe depart : [u'le', u'magicien']\n",
      "===========================================\n",
      "le magicien\técrira\tla formule\t\tavec le stylo sur la feuille\t\n",
      "\n",
      "groupe departP : [u'le', u'magicien']\n",
      "groupe depart : [u'le', u'magicien']\n",
      "groupe departP : [u'la', u'formule']\n",
      "groupe depart : [u'la', u'formule']\n",
      "faire_gp avec le stylo sur la feuille fonction \n",
      "avec avec\n",
      "pas de Cas\n",
      "groupe prep : [u'avec', u'le', u'stylo', u'sur', u'la', u'feuille']\n",
      "ref \\AVEC avec\n",
      "groupe departP : [u'le', u'stylo', u'sur', u'la', u'feuille']\n",
      "groupe depart : [u'le', u'stylo', u'sur', u'la', u'feuille']\n",
      "faire_gp sur la feuille fonction \n",
      "sur sur\n",
      "pas de Cas\n",
      "groupe prep : [u'sur', u'la', u'feuille']\n",
      "ref \\SUR sur\n",
      "groupe departP : [u'la', u'feuille']\n",
      "groupe depart : [u'la', u'feuille']\n",
      "===========================================\n",
      "Léina\tprendra\tla formule\t\tsur cette feuille devant le stylo\t\n",
      "\n",
      "groupe departP : [u'L\\xe9ina']\n",
      "groupe depart : [u'L\\xe9ina']\n",
      "groupe departP : [u'la', u'formule']\n",
      "groupe depart : [u'la', u'formule']\n",
      "faire_gp sur cette feuille devant le stylo fonction \n",
      "sur sur\n",
      "pas de Cas\n",
      "groupe prep : [u'sur', u'cette', u'feuille', u'devant', u'le', u'stylo']\n",
      "ref \\SUR sur\n",
      "groupe departP : [u'cette', u'feuille', u'devant', u'le', u'stylo']\n",
      "groupe depart : [u'cette', u'feuille', u'devant', u'le', u'stylo']\n",
      "faire_gp devant le stylo fonction \n",
      "devant devant\n",
      "pas de Cas\n",
      "groupe prep : [u'devant', u'le', u'stylo']\n",
      "ref \\DEVANT devant\n",
      "groupe departP : [u'le', u'stylo']\n",
      "groupe depart : [u'le', u'stylo']\n",
      "===========================================\n",
      "la licorne\tdeviendra\tune tortue\t\n",
      "\n",
      "groupe departP : [u'la', u'licorne']\n",
      "groupe depart : [u'la', u'licorne']\n",
      "groupe departP : [u'une', u'tortue']\n",
      "groupe depart : [u'une', u'tortue']\n",
      "===========================================\n",
      "la tortue\tmange\t\t\t\tsous l'orage\n",
      "\n",
      "groupe departP : [u'la', u'tortue']\n",
      "groupe depart : [u'la', u'tortue']\n",
      "faire_gp sous l orage fonction \n",
      "sous sous\n",
      "pas de Cas\n",
      "groupe prep : [u'sous', u'l', u'orage']\n",
      "ref \\SOUS sous\n",
      "groupe departP : [u'l', u'orage']\n",
      "groupe depart : [u'l', u'orage']\n",
      "===========================================\n",
      "la tortue \tregarde\tce soleil\t\t\t\n",
      "\n",
      "groupe departP : [u'la', u'tortue']\n",
      "groupe depart : [u'la', u'tortue']\n",
      "groupe departP : [u'ce', u'soleil']\n",
      "groupe depart : [u'ce', u'soleil']\n",
      "===========================================\n",
      "le chevalier\tverra\tla formule\t\t\t\n",
      "\n",
      "groupe departP : [u'le', u'chevalier']\n",
      "groupe depart : [u'le', u'chevalier']\n",
      "groupe departP : [u'la', u'formule']\n",
      "groupe depart : [u'la', u'formule']\n",
      "===========================================\n",
      "les deux chevaliers\tvoient\tun crâne\t\t\tdevant le feu\n",
      "\n",
      "groupe departP : [u'les', u'deux', u'chevaliers']\n",
      "groupe depart : [u'les', u'deux', u'chevaliers']\n",
      "groupe departP : [u'un', u'cr\\xe2ne']\n",
      "groupe depart : [u'un', u'cr\\xe2ne']\n",
      "faire_gp devant le feu fonction \n",
      "devant devant\n",
      "pas de Cas\n",
      "groupe prep : [u'devant', u'le', u'feu']\n",
      "ref \\DEVANT devant\n",
      "groupe departP : [u'le', u'feu']\n",
      "groupe depart : [u'le', u'feu']\n",
      "===========================================\n",
      "le chevalier\tlancera\tun gros caillou noir\t\tsur le magicien\t\n",
      "groupe departP : [u'le', u'chevalier']\n",
      "groupe depart : [u'le', u'chevalier']\n",
      "groupe departP : [u'un', u'gros', u'caillou', u'noir']\n",
      "groupe depart : [u'un', u'gros', u'caillou', u'noir']\n",
      "faire_gp sur le magicien fonction \n",
      "sur sur\n",
      "pas de Cas\n",
      "groupe prep : [u'sur', u'le', u'magicien']\n",
      "ref \\SUR sur\n",
      "groupe departP : [u'le', u'magicien']\n",
      "groupe depart : [u'le', u'magicien']\n"
     ]
    }
   ],
   "source": [
    "sortie=\"latex\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file,sortie=sortie)\n",
    "phrase_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"Phrases-Clozes\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\xe9toile',\n",
       " u'transforme',\n",
       " u'regardent',\n",
       " u'capturer',\n",
       " u'longera',\n",
       " u'brilleront',\n",
       " u'aider',\n",
       " u'enfants',\n",
       " u'voit',\n",
       " u'transformer',\n",
       " u'le',\n",
       " u'noir',\n",
       " u'plan\\xe8tes',\n",
       " u'devenir',\n",
       " u'la',\n",
       " u'L\\xe9ina',\n",
       " u'PRO',\n",
       " u'maison',\n",
       " u'eux',\n",
       " u'briller',\n",
       " u'regarder',\n",
       " u'mangent',\n",
       " u'sur',\n",
       " u'pelle',\n",
       " u'vert',\n",
       " u'rambarde',\n",
       " u'Anouk',\n",
       " u'atterrir',\n",
       " u'lancera',\n",
       " u'sont',\n",
       " u'tartines',\n",
       " u'deviendra',\n",
       " u'devient',\n",
       " u'voir',\n",
       " u'obscurit\\xe9',\n",
       " u'pommes',\n",
       " u'capturera',\n",
       " u'l',\n",
       " u'jouent',\n",
       " u'cri',\n",
       " u'licorne',\n",
       " u'manger',\n",
       " u'd\\xe9couvrir',\n",
       " u'en',\n",
       " u'lance',\n",
       " u'longeront',\n",
       " u'joueront',\n",
       " u'aide',\n",
       " u'lancent',\n",
       " u'jouer',\n",
       " u'DEM',\n",
       " u'captureront',\n",
       " u'brille',\n",
       " u'aidera',\n",
       " u'est',\n",
       " u'cassera',\n",
       " u'poussera',\n",
       " u'filles',\n",
       " u'prennent',\n",
       " u'pousser',\n",
       " u'casser',\n",
       " u'ailes',\n",
       " u'verront',\n",
       " u'pousse',\n",
       " u'casse',\n",
       " u'aile',\n",
       " u'd\\xe9couvrent',\n",
       " u'cris',\n",
       " u'formule',\n",
       " u'atterriront',\n",
       " u'\\xe9crivent',\n",
       " u'casseront',\n",
       " u'pousseront',\n",
       " u'les',\n",
       " u'longent',\n",
       " u'chevaliers',\n",
       " u'magicien',\n",
       " u'magiques',\n",
       " u'regarderont',\n",
       " u'oS',\n",
       " u'lasagnes',\n",
       " u'\\xe0',\n",
       " u'lunettes',\n",
       " u'mammouth',\n",
       " u'\\xeatre',\n",
       " u'\\xe9toiles',\n",
       " u'bleue',\n",
       " u'lasagne',\n",
       " u'stylo',\n",
       " u'enfant',\n",
       " u'poisson',\n",
       " u'lapin',\n",
       " u'aideront',\n",
       " u'orage',\n",
       " u'lancer',\n",
       " u'os',\n",
       " u'escalier',\n",
       " u'vent',\n",
       " u'longue',\n",
       " u'rivi\\xe8re',\n",
       " u'transformera',\n",
       " u'ciel',\n",
       " u'd\\xe9couvre',\n",
       " u'ce',\n",
       " u'tartine',\n",
       " u'\\xe9crira',\n",
       " u'd\\xe9couvrira',\n",
       " u'\\xe9crire',\n",
       " u'tortue',\n",
       " u'blanc',\n",
       " u'deviendront',\n",
       " u'capturent',\n",
       " u'bleu',\n",
       " u'chevalier',\n",
       " u'long',\n",
       " u'lueur',\n",
       " u'feu',\n",
       " u'oiseaux',\n",
       " u'pomme',\n",
       " u'magique',\n",
       " u'cr\\xe2nes',\n",
       " u'atterrissent',\n",
       " u'regarde',\n",
       " u'feuille',\n",
       " u'plan\\xe8te',\n",
       " u'prend',\n",
       " u'Almael',\n",
       " u'prendre',\n",
       " u'verte',\n",
       " u'prendra',\n",
       " u'devant',\n",
       " u'poissons',\n",
       " u'des',\n",
       " u'dans',\n",
       " u'avec',\n",
       " u'pour',\n",
       " u'sous',\n",
       " u'un',\n",
       " u'mangera',\n",
       " u'sera',\n",
       " u'voient',\n",
       " u'sombre',\n",
       " u'atterrira',\n",
       " u'prendront',\n",
       " u'cette',\n",
       " u'grotte',\n",
       " u'cailloux',\n",
       " u'il',\n",
       " u'cassent',\n",
       " u'poussent',\n",
       " u'longe',\n",
       " u'aident',\n",
       " u'baguette',\n",
       " u'oxyg\\xe8ne',\n",
       " u'soleil',\n",
       " u'transforment',\n",
       " u'elles',\n",
       " u'\\xe9criront',\n",
       " u'lave',\n",
       " u'lui',\n",
       " u'brillent',\n",
       " u'atterrit',\n",
       " u'joue',\n",
       " u'DEF',\n",
       " u'mangeront',\n",
       " u'grand',\n",
       " u'seront',\n",
       " u'mammouths',\n",
       " u'une',\n",
       " u'Afior',\n",
       " u'de',\n",
       " u'deviennent',\n",
       " u'cr\\xe2ne',\n",
       " u'capture',\n",
       " u'lunette',\n",
       " u'verra',\n",
       " u'transformeront',\n",
       " u'elle',\n",
       " u'lanceront',\n",
       " u'IND',\n",
       " u'jouera',\n",
       " u'mange',\n",
       " u'gros',\n",
       " u'brillera',\n",
       " u'd\\xe9couvriront',\n",
       " u'ils',\n",
       " u'\\xe9crit',\n",
       " u'longer',\n",
       " u'caillou',\n",
       " u'oiseau',\n",
       " u'fille',\n",
       " u'regardera',\n",
       " u'grande',\n",
       " u'ces']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFM.lexique.formeLexeme.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Fichiers secondaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if typeKalaba!=\"Kanonik\":\n",
    "    sortie=\"images\"\n",
    "    if \"RightLeft\" in globals() and RightLeft:\n",
    "        syntagmes=syntagmesRL\n",
    "    else:\n",
    "        syntagmes=syntagmesLR\n",
    "    print syntagmes\n",
    "\n",
    "    lexemesLocaux=set()\n",
    "    if ecriture_nom.endswith(\"csv\"):\n",
    "        try:\n",
    "            ecriture_file = codecs.open(ecriture_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the file', ecriture_nom\n",
    "            sys.exit()      \n",
    "        else:\n",
    "            try:\n",
    "                cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "            except IOError:\n",
    "                print 'I could not open the cloze file', cloze_nom\n",
    "                sys.exit()\n",
    "            else:\n",
    "                ecriture={}\n",
    "                for line in cloze_file.readlines():\n",
    "                    line=line.strip()\n",
    "                    if not line.startswith(\"#\"):\n",
    "                        elementsCloze=line.split(\";\")\n",
    "                        ecriture[elementsCloze[0]]=elementsCloze[5]\n",
    "                cloze_file.close()\n",
    "                exemples=[]\n",
    "                accumulateur=[]\n",
    "                vocabulaire=[]\n",
    "    #            prononciationExtrait=[]\n",
    "                faire_phrases(ecriture_file,sortie=sortie)\n",
    "                ecriture_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "if typeKalaba!=\"Kanonik\":\n",
    "    sortie=\"ordre\"\n",
    "    syntagmes=syntagmesLR\n",
    "    print syntagmes\n",
    "\n",
    "    lexemesLocaux=set()\n",
    "    if ordre_nom.endswith(\"csv\"):\n",
    "        try:\n",
    "            ordre_file = codecs.open(ordre_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the file', ordre_nom\n",
    "            sys.exit()      \n",
    "        else:\n",
    "            try:\n",
    "                cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "            except IOError:\n",
    "                print 'I could not open the cloze file', cloze_nom\n",
    "                sys.exit()\n",
    "            else:\n",
    "                ordre={}\n",
    "                for line in cloze_file.readlines():\n",
    "                    line=line.strip()\n",
    "                    if not line.startswith(\"#\"):\n",
    "                        elementsCloze=line.split(\";\")\n",
    "                        ordre[elementsCloze[0]]=elementsCloze[5]\n",
    "                cloze_file.close()\n",
    "                exemples=[]\n",
    "                accumulateur=[]\n",
    "                vocabulaire=[]\n",
    "    #            prononciationExtrait=[]\n",
    "                faire_phrases(ordre_file,sortie=sortie)\n",
    "                ordre_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if typeKalaba!=\"Kanonik\":\n",
    "    sortie=\"mots\"\n",
    "    if \"RightLeft\" in globals() and RightLeft:\n",
    "        syntagmes=syntagmesRL\n",
    "    else:\n",
    "        syntagmes=syntagmesLR\n",
    "    print syntagmes\n",
    "\n",
    "    lexemesLocaux=set()\n",
    "    if mots_nom.endswith(\"csv\"):\n",
    "        try:\n",
    "            mots_file = codecs.open(mots_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the file', mots_nom\n",
    "            sys.exit()      \n",
    "        else:\n",
    "            try:\n",
    "                cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "            except IOError:\n",
    "                print 'I could not open the cloze file', cloze_nom\n",
    "                sys.exit()\n",
    "            else:\n",
    "                motsIsoles={}\n",
    "                for line in cloze_file.readlines():\n",
    "                    line=line.strip()\n",
    "                    if not line.startswith(\"#\"):\n",
    "                        elementsCloze=line.split(\";\")\n",
    "                        motsIsoles[elementsCloze[0]]=elementsCloze[5]\n",
    "                cloze_file.close()\n",
    "                exemples=[]\n",
    "                accumulateur=[]\n",
    "                vocabulaire=[]\n",
    "    #            prononciationExtrait=[]\n",
    "                faire_phrases(mots_file,sortie=sortie)\n",
    "                mots_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok pour cette étape\n"
     ]
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "if variante==\"\": \n",
    "    print \"faire la correction\"\n",
    "    nextVariante=\"-Corr\"\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "else:\n",
    "    print u\"ok pour cette étape\"\n",
    "    del nextVariante\n",
    "    ding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post-traitements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.formeLexeme[\"trois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yamlDump(nFile,content):\n",
    "    with open(nFile, 'w') as output:\n",
    "        yaml.dump(content, output, default_flow_style=False,allow_unicode=True)\n",
    "\n",
    "    with open(nFile, 'r') as input:\n",
    "        yamlLines=input.readlines()\n",
    "\n",
    "    yamlText=\"\".join(yamlLines)\n",
    "    yamlText=re.sub(r\"!!python/unicode\",\"\",yamlText)\n",
    "    yamlText=re.sub(r\"\\n\\s*-\\s*\",\", \",yamlText)\n",
    "    yamlText=re.sub(r\":,\\s*\",\": \",yamlText)\n",
    "    yamlText=re.sub(r\": *([^\\n]+)\",\": [\\g<1>]\",yamlText)\n",
    "\n",
    "\n",
    "    with open(nFile, 'w') as output:\n",
    "        output.write(yamlText)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': [u'noir.Ina.SG',\n",
       "  u'magique.Ina.SG',\n",
       "  u'long.Ina.SG',\n",
       "  u'vert.Ina.SG',\n",
       "  u'blanc.Ani.SG',\n",
       "  u'gros.Ina.SG',\n",
       "  u'sombre.Ina.SG',\n",
       "  u'grand.Ina.SG',\n",
       "  u'bleu.Ina.SG'],\n",
       " 'DET': [u'DEF.Hum.PL',\n",
       "  u'IND.Ina.SG',\n",
       "  u'DEF.Ani.DU',\n",
       "  u'IND.Ani.PL',\n",
       "  u'DEM.Ani.SG',\n",
       "  u'DEF.Ina.DU',\n",
       "  u'DEF.Hum.SG',\n",
       "  u'IND.Ani.SG',\n",
       "  u'DEF.Ani.PL',\n",
       "  u'DEM.Ani.DU',\n",
       "  u'DEM.Ina.SG',\n",
       "  u'IND.Ina.PL',\n",
       "  u'DEM.Ina.PL',\n",
       "  u'DEF.Ani.SG',\n",
       "  u'DEF.Ina.SG',\n",
       "  u'DEF.Ina.PL',\n",
       "  u'DEF.Hum.DU'],\n",
       " 'NOM': [u'\\xe9toile.Ina.Pl',\n",
       "  u'ciel.Ina.Sg',\n",
       "  u'maison.Ina.Sg',\n",
       "  u'enfant.Hum.Du',\n",
       "  u'rivi\\xe8re.Ina.Sg',\n",
       "  u'obscurit\\xe9.Ina.Sg',\n",
       "  u'stylo.Ina.Sg',\n",
       "  u'cr\\xe2ne.Ina.Pl',\n",
       "  u'poisson.Ani.Pl',\n",
       "  u'chevalier.Hum.Du',\n",
       "  u'tartine.Ina.Sg',\n",
       "  u'cri.Ina.Pl',\n",
       "  u'enfant.Hum.Sg',\n",
       "  u'vent.Ina.Sg',\n",
       "  u'formule.Ina.Sg',\n",
       "  u'soleil.Ina.Sg',\n",
       "  u'poisson.Ani.Du',\n",
       "  u'tartine.Ina.Du',\n",
       "  u'oiseau.Ani.Pl',\n",
       "  u'grotte.Ina.Sg',\n",
       "  u'lasagne.Ina.Pl',\n",
       "  u'lapin.Ani.Sg',\n",
       "  u'L\\xe9ina.Hum.Sg',\n",
       "  u'caillou.Ina.Sg',\n",
       "  u'plan\\xe8te.Ina.Sg',\n",
       "  u'lueur.Ina.Sg',\n",
       "  u'chevalier.Hum.Sg',\n",
       "  u'aile.Ina.Pl',\n",
       "  u'mammouth.Ani.Pl',\n",
       "  u'caillou.Ina.Pl',\n",
       "  u'cr\\xe2ne.Ina.Sg',\n",
       "  u'pomme.Ina.Pl',\n",
       "  u'lave.Ina.Sg',\n",
       "  u'fille.Hum.Pl',\n",
       "  u'Almael.Hum.Sg',\n",
       "  u'baguette.Ina.Sg',\n",
       "  u'magicien.Hum.Sg',\n",
       "  u'oxyg\\xe8ne.Ina.Sg',\n",
       "  u'enfant.Hum.Pl',\n",
       "  u'oiseau.Ani.Du',\n",
       "  u'os.Ina.Sg',\n",
       "  u'mammouth.Ani.Du',\n",
       "  u'pelle.Ina.Sg',\n",
       "  u'Afior.Ina.Sg',\n",
       "  u'feuille.Ina.Sg',\n",
       "  u'rambarde.Ina.Sg',\n",
       "  u'tortue.Ani.Sg',\n",
       "  u'licorne.Ani.Sg',\n",
       "  u'escalier.Ina.Sg',\n",
       "  u'orage.Ina.Sg',\n",
       "  u'feu.Ina.Sg',\n",
       "  u'fille.Hum.Du',\n",
       "  u'plan\\xe8te.Ina.Pl',\n",
       "  u'Anouk.Hum.Sg',\n",
       "  u'lunette.Ina.Pl',\n",
       "  u'cri.Ina.Sg'],\n",
       " 'PRO': [u'PRO.Hum.Sg', u'PRO.Ani.Sg', u'PRO.Hum.Pl'],\n",
       " 'VER': [u'aider.Prs.TroisSg.Ani',\n",
       "  u'\\xe9crire.Fut.TroisSg.Hum',\n",
       "  u'prendre.Prs.TroisSg.Ani',\n",
       "  u'pousser.Fut.TroisSg.Hum',\n",
       "  u'casser.Fut.TroisSg.Hum',\n",
       "  u'voir.Prs.TroisDu.Hum',\n",
       "  u'lancer.Prs.TroisSg.Ani',\n",
       "  u'd\\xe9couvrir.Prs.TroisSg.Hum',\n",
       "  u'regarder.Fut.TroisDu.Ani',\n",
       "  u'd\\xe9couvrir.Prs.TroisPl.Hum',\n",
       "  u'manger.Fut.TroisPl.Hum',\n",
       "  u'atterrir.Fut.TroisSg.Ina',\n",
       "  u'regarder.Prs.TroisSg.Ani',\n",
       "  u'briller.Prs.TroisSg.Ina',\n",
       "  u'voir.Fut.TroisDu.Ani',\n",
       "  u'manger.Prs.TroisSg.Ani',\n",
       "  u'longer.Prs.TroisPl.Hum',\n",
       "  u'voir.Fut.TroisSg.Hum',\n",
       "  u'prendre.Prs.TroisSg.Hum',\n",
       "  u'casser.Prs.TroisPl.Ina',\n",
       "  u'capturer.Prs.TroisSg.Hum',\n",
       "  u'jouer.Fut.TroisSg.Ani',\n",
       "  u'regarder.Prs.TroisDu.Hum',\n",
       "  u'briller.Prs.TroisPl.Ina',\n",
       "  u'd\\xe9couvrir.Fut.TroisPl.Ani',\n",
       "  u'pousser.Prs.TroisSg.Ani',\n",
       "  u'casser.Prs.TroisSg.Ani',\n",
       "  u'voir.Prs.TroisSg.Hum',\n",
       "  u'jouer.Prs.TroisSg.Hum',\n",
       "  u'lancer.Prs.TroisPl.Hum',\n",
       "  u'devenir.Fut.TroisSg.Ani',\n",
       "  u'manger.Prs.TroisSg.Hum',\n",
       "  u'prendre.Fut.TroisSg.Hum',\n",
       "  u'manger.Prs.TroisDu.Hum',\n",
       "  u'atterrir.Prs.TroisSg.Ina',\n",
       "  u'd\\xe9couvrir.Fut.TroisSg.Ani',\n",
       "  u'\\xeatre.Prs.TroisSg.Ina',\n",
       "  u'voir.Fut.TroisSg.Ani',\n",
       "  u'atterrir.Prs.TroisPl.Ina',\n",
       "  u'casser.Prs.TroisSg.Hum',\n",
       "  u'lancer.Prs.TroisSg.Ina',\n",
       "  u'lancer.Fut.TroisSg.Hum',\n",
       "  u'pousser.Prs.TroisSg.Ina']}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in cellules:\n",
    "    cellules[k]=list(cellules[k])\n",
    "cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yamlDump(serie+\"FilledCells.yaml\",cellules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
