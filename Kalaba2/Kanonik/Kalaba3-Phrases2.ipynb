{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problèmes et Extensions\n",
    "\n",
    "## Problèmes\n",
    "- javascript runs fail\n",
    "- faire de nouvelles sorties pour les kalabas sans séparateurs de mots\n",
    " - radicaux seuls\n",
    " - découpage en syntagmes pour l'exercice sur l'ordre des syntagmes\n",
    "\n",
    "## Extensions\n",
    "- traitement du paucal\n",
    " - 2,3,4,5 ou suffixe P sur le nom sans numéral\n",
    "- ajout des compléments/ajouts multiples\n",
    " - séparation par ;\n",
    " - gestion des dislocations gauches dans les multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalaba3-Phrases2\n"
     ]
    }
   ],
   "source": [
    "print(theNotebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter & gestion des variantes\n",
    "\n",
    "Le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable\n",
    "\n",
    "Après la réussite de la variante de base, on change automatiquement la variante à -Corr pour générer les fichiers de solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Corr\n",
      "21-K5\n"
     ]
    }
   ],
   "source": [
    "# numerosKalaba=[4]\n",
    "# %store numerosKalaba\n",
    "%store -r numerosKalaba\n",
    "variante=\"\"\n",
    "if 'nextVariante' in globals():\n",
    "    variante=nextVariante\n",
    "print variante\n",
    "numeroKalaba=\"21-K%d\"%numerosKalaba[0]\n",
    "print numeroKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')\n",
    "    \n",
    "    \n",
    "from os.path import expanduser\n",
    "#from cellbell import ding\n",
    "from itertools import groupby\n",
    "home = expanduser(\"~\")\n",
    "serie=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/%s/\"%numeroKalaba\n",
    "complementPhrases=\"\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle,copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "séparateur  \n"
     ]
    }
   ],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=0\n",
    "\n",
    "#casNombreDet=True\n",
    "RightLeft=True\n",
    "\n",
    "if (numerosKalaba[0] in [3,5]) and variante==\"\":\n",
    "    separateurPhonoCloze=\"\"\n",
    "else:\n",
    "    separateurPhonoCloze=\" \"\n",
    "# separateurPhonoCloze=\" \"    \n",
    "separateurMots=separateurPhonoCloze\n",
    "print \"séparateur\",separateurMots\n",
    "#separateurMots=\" \"\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False        #False\n",
    "print_radicaux=False     #False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.safe_load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.safe_load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.safe_load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.safe_load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Gloses.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\columnbreak\\\\vfill\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Nom\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cas', 'Genre', 'Nombre', 'Pers', 'Temps'}"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOM', 'VER', 'ADJ', 'PRO', 'DET']"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'DET': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'NOM': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'PRO': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'VER': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': False,\n",
       "  'Pers': True,\n",
       "  'Temps': True}}"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'AJOUT', 'OBJ', 'COMP', 'IND', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'DET', 'GP']}\n"
     ]
    }
   ],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]\n",
    "syntagmesLR=copy.deepcopy(syntagmes)\n",
    "print syntagmesLR\n",
    "syntagmesRL=copy.deepcopy(syntagmes)\n",
    "for element in syntagmesRL:\n",
    "    syntagmesRL[element].reverse()\n",
    "nomFonctions=syntagmes[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LR',\n",
       " {'GADJ': ['ADV', 'ADJ', 'GP'],\n",
       "  'GN': ['GADJ', 'NOM', 'DET', 'GP'],\n",
       "  'GP': ['GN', 'PREP'],\n",
       "  'Phrase': ['VER', 'AJOUT', 'OBJ', 'COMP', 'IND', 'SUJ']},\n",
       " 'RL',\n",
       " {'GADJ': ['GP', 'ADJ', 'ADV'],\n",
       "  'GN': ['GP', 'DET', 'NOM', 'GADJ'],\n",
       "  'GP': ['PREP', 'GN'],\n",
       "  'Phrase': ['SUJ', 'IND', 'COMP', 'OBJ', 'AJOUT', 'VER']})"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"LR\",syntagmesLR, \"RL\",syntagmesRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS', 'PST', '3Sg', '3Pau', '3Pl', 'A', 'B', 'C', 'D']"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableaux des formes utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellules={c:set() for c in \"NOM VER ADJ DET PRO\".split(\" \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduire les pronoms kalaba\n",
    "- identifier qu'il s'agit d'un pronom\n",
    "- parser le référent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounNumber(nom,nombre):\n",
    "    if nom[len(nom)-1] in [\"s\",\"x\"]:\n",
    "        if nombre==\"\": nombre=\"PL\"\n",
    "    elif nom[len(nom)-1] in [\"P\",\"D\"]:\n",
    "        if nombre==\"\": \n",
    "            if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"PAU\"\n",
    "            elif \"Du\" in valAttributs[\"Nombre\"] and nom[len(nom)-1]==\"D\":\n",
    "                nombre=\"DU\"\n",
    "            else:\n",
    "                nombre=\"PL\"\n",
    "    else:\n",
    "        if nombre==\"\": nombre=\"SG\"\n",
    "    return nombre\n",
    "\n",
    "def getNounGender(ref):\n",
    "    nom=ref.rstrip(\"P\").rstrip(\"D\")\n",
    "    nomLexeme=PFM.lexique.formeLexeme[nom][0]\n",
    "    classesNom=nomLexeme.split('.')[1:]\n",
    "    print classesNom\n",
    "    proGender=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "    return proGender, classesNom\n",
    "\n",
    "\n",
    "def getRef(pronom):\n",
    "    m=re.match(\"^(.*)#(.*)#\",pronom)\n",
    "    if m:\n",
    "        pro=m.group(1)\n",
    "        ref=m.group(2)\n",
    "    else:\n",
    "        print \"mauvaise notation pour un pronom\"\n",
    "        pro=\"\"\n",
    "        ref=\"\"\n",
    "    return pro,ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'N4', u'C']\n",
      "lui PRO PL chats PL C\n"
     ]
    }
   ],
   "source": [
    "pro,ref=getRef(u\"lui#chats#\")\n",
    "proNum=getNounNumber(ref,nombre=\"\")\n",
    "proGen,proClasse=getNounGender(ref)\n",
    "nomLexeme=PFM.lexique.formeLexeme[pro][0]\n",
    "print pro, nomLexeme, proNum, ref, proNum, proGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_gn(depart,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom=[]\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        if not \"#\" in mot:\n",
    "            groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    pro=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    if len(groupe_nom)==1:\n",
    "#         print \"Pronom ?\",groupe_nom\n",
    "        nomSeul=groupe_nom[0]\n",
    "        boolPro=(\"#\" in nomSeul)\n",
    "    else:\n",
    "        boolPro=False\n",
    "    if boolPro:\n",
    "        proForm,proRef=getRef(nomSeul)\n",
    "        nomLexeme=PFM.lexique.formeLexeme[proForm][0]\n",
    "        print \"ref nomSeul\",proForm,proRef\n",
    "        nombre=getNounNumber(proRef,nombre=\"\")\n",
    "        classe,classesNom=getNounGender(proRef)\n",
    "        pro.append(nomLexeme)\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "#                    else:\n",
    "        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "        cellules[\"PRO\"].add(\".\".join([nomLexeme,classe.capitalize(),nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "        if debug or 0:\n",
    "            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "        if cas==\"ERG\":\n",
    "            erg_genre=classe\n",
    "            erg_nombre=nombre\n",
    "            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "        elif cas==\"ABS\":\n",
    "            abs_genre=classe\n",
    "            abs_nombre=nombre\n",
    "            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for mot in groupe_nom:\n",
    "            if reste==0:\n",
    "    #            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "                if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                    nombre=\"DU\"\n",
    "                    if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                else:\n",
    "                    if \"Pau\" in valAttributs[\"Nombre\"] and mot in \"deux trois quatre cinq\".split():\n",
    "                        nombre=\"PAU\"\n",
    "                        if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                    if mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot[:-1]][0]\n",
    "                    else:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                    categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                    if debug or 0: \n",
    "                        print \"mot\",[mot]\n",
    "                        print \"vedette\",nomLexeme,categorie\n",
    "                        print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                    if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                        tete=categorie\n",
    "                        if debug or 0: print \"tête :\", tete\n",
    "                        tampon=tete.split('.')\n",
    "    #                    classe=tampon[0]\n",
    "                        classesNom=nomLexeme.split('.')[1:]\n",
    "                        if debug or 0: print \"classesNom\",classesNom \n",
    "                        classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                        if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                        try:\n",
    "                            typeMot=tampon[1]\n",
    "                        except IndexError:\n",
    "                            typeMot=''\n",
    "                        # modif pour les mots à pluriels en x\n",
    "                        # 23/11/19\n",
    "                        #\n",
    "                        nombre=getNounNumber(mot,nombre)\n",
    "#                         if mot[len(mot)-1] in [\"s\",\"x\"]:\n",
    "#                             if nombre==\"\": nombre=\"PL\"\n",
    "#                         elif mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "#                             if nombre==\"\":\n",
    "#                                 # modif pour permettre le pluriel dans les cas où il n'y a pas de paucal.\n",
    "#                                 # 30/5/21\n",
    "#                                 #\n",
    "#                                 if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "#                                     nombre=\"PAU\"\n",
    "#                                 elif \"Du\" in valAttributs[\"Nombre\"] and mot[len(mot)-1]==\"D\":\n",
    "#                                     nombre=\"DU\"\n",
    "#                                 else:\n",
    "#                                     nombre=\"PL\"\n",
    "#                         else:\n",
    "#                             if nombre==\"\": nombre=\"SG\"\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre\n",
    "\n",
    "                        nom.append(nomLexeme)\n",
    "    #                    if typeCas==\"NoCas\":\n",
    "    #                        cas=\"\"\n",
    "                        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                            cas=\"\"\n",
    "    #                    else:\n",
    "                        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                        cellules[\"NOM\"].add(\".\".join([nomLexeme,nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "                        if cas==\"ERG\":\n",
    "                            erg_genre=classe\n",
    "                            erg_nombre=nombre\n",
    "                            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                        elif cas==\"ABS\":\n",
    "                            abs_genre=classe\n",
    "                            abs_nombre=nombre\n",
    "                            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"DET\"]:\n",
    "                        det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "    #                elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"]:\n",
    "                        adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                    elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                        gp.append(mot)\n",
    "                        reste=1\n",
    "            else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "                gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det and not boolPro: \n",
    "        if nom[0][0]==nom[0][0].upper():\n",
    "            det.append(PFM.lexique.formeLexeme[\"les\"][0])\n",
    "        else:\n",
    "            det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "\n",
    "    tempSyntagme=[]\n",
    "\n",
    "    if pro:\n",
    "        for mot in pro:\n",
    "    #\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "            noligMot=mot.split(\".\")[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            #\n",
    "            # traitement des noms propres avec tiret\n",
    "            # traitement des noms paucals sans ordinaux\n",
    "            #\n",
    "            if \"-\" in noligMot:\n",
    "                noLigs=noligMot.split(\"-\")\n",
    "                if len(noLigs)>1:\n",
    "                    noligMot=noLigs[0]+\"\".join([c for c in noLigs[1:]])\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "    #        mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot)\n",
    "            texte.append(ref)\n",
    "            tempSyntagme.append(ref)\n",
    "        structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "        mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "        \n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            print \"pas de nombre\"\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "#             print mot,casDet,nombreDet\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        cellules[\"DET\"].add(\".\".join([mot,classeDet,nombreDet,casDet]).strip(\".\"))\n",
    "\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        cellules[\"ADJ\"].add(\".\".join([mot,classeAdj,nombreAdj,casAdj]).strip(\".\"))\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        #\n",
    "        # traitement des noms propres avec tiret\n",
    "        # traitement des noms paucals sans ordinaux\n",
    "        #\n",
    "        if \"-\" in noligMot:\n",
    "            noLigs=noligMot.split(\"-\")\n",
    "            if len(noLigs)>1:\n",
    "                noligMot=noLigs[0]+\"\".join([c.lower() for c in noLigs[1:]])\n",
    "#         noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        if noligMot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    if debug or 0:\n",
    "        print \"fin faire_gn\",listeMots\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/14529523/python-split-for-lists\n",
    "\n",
    "l = [\"data\",\"more data\",\";\",\"data 2\",\"more data 2\",\"danger\",\";\",\"date3\",\"lll\"]\n",
    "[list(group) for k, group in groupby(l, lambda x: x == \";\") if not k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplier_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    lGroupes=[list(group) for k, group in groupby(groupe_prep, lambda x: x == \";\") if not k]\n",
    "    if len(lGroupes)>1:\n",
    "        print lGroupes\n",
    "    for lGp in lGroupes:\n",
    "        mots.extend(faire_gp(lGp,fonction))\n",
    "    return mots\n",
    "    \n",
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", groupe_prep\n",
    "    formePreposition=groupe_prep[0]\n",
    "    if debug: print [formePreposition], formePreposition\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        noligMot=groupe_prep[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        \n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                lexemesLocaux.add(noligMot.upper())\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print ref\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else:\n",
    "#        if \"{preview}\" in liste:\n",
    "#            print \"preview\",prefixe,liste,suffixe\n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "texHeader=[]\n",
    "version=theNotebook\n",
    "texHeader.append(\"%% script : \"+version)\n",
    "texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    ecriture_nom=serie+complementPhrases+\"Ecrit.csv\"\n",
    "    ordre_nom=serie+complementPhrases+\"Ordre.csv\"\n",
    "    mots_nom=serie+complementPhrases+\"Mots.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\"\n",
    "    if len(args)>=4:\n",
    "        ecriture_nom=args[3]\n",
    "    else:\n",
    "        ecriture_nom=\"\"\n",
    "    if len(args)>=5:\n",
    "        ordre_nom=args[4]\n",
    "    else:\n",
    "        ordre_nom=\"\"\n",
    "    if len(args)>=6:\n",
    "        mots_nom=args[5]\n",
    "    else:\n",
    "        mots_nom=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrerCloze(filtre):\n",
    "    result=[]\n",
    "    for ligne in clozeLines:\n",
    "        if type(ligne)==str:\n",
    "            ligne=unicode(ligne.decode('utf8'))\n",
    "        ligne=ligne.strip()\n",
    "        if not ligne.startswith(\"#\"):\n",
    "            clozeElements=ligne.split(\";\")\n",
    "            if clozeElements[1] in filtre:\n",
    "                result.append(ligne)\n",
    "        else:\n",
    "            result.append(ligne)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if not isinstance(item, basestring):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewerBegin=\"\\\\begin{preview}\\\\begin{flushleft}\"\n",
    "previewerEnd=\"\\\\end{flushleft}\\\\end{preview}\"\n",
    "def latex2ipa(mot):\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLignePreview=\"\\\\end{preview}\"\n",
    "    if \" \" in mot:\n",
    "        result=[]\n",
    "        for element in mot.split():\n",
    "            result.append(latex2ipa(element))\n",
    "        return separateurMots.join(result)\n",
    "    else:\n",
    "        mot=mot.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "    #    print mot\n",
    "        mot=mot.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "    #    print mot\n",
    "        element=mot.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "    #    print element\n",
    "        cleElement=element.strip().strip(\"\\\\{}\")\n",
    "    #    print cleElement\n",
    "        if element==\"\\\\ex\": cleElement=\"\"\n",
    "        if cleElement:\n",
    "            if not cleElement in traductions: \n",
    "                print cleElement\n",
    "                print traductions\n",
    "                warnings.warn(\"pas de transcription pour %s\"%cleElement,mot)\n",
    "                return None\n",
    "            else:\n",
    "                return traductions[cleElement]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex2ipa(\"\\\\begin{preview}\\\\DEFMSg{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previewer(chaine,numLignesVides=0,suffixe=\"\"):\n",
    "    flatChaine=[mot+suffixe for mot in list(flatten(chaine))]\n",
    "    result=previewerBegin+separateurMots.join(flatChaine)+\"\\\\\\\\\"*numLignesVides+previewerEnd\n",
    "    return [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "texteMots=set()\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.lexemes[\"construire\"].formes.index(\"construisit\")\n",
    "valAttributs[\"Genre\"]\n",
    "localClasses=[\"N\"]\n",
    "[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "localCas=\"Nom\"\n",
    "not localCas or localCas in sujetVerbe\n",
    "sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliserMajusculesMinuscules(mot):\n",
    "    result=mot\n",
    "    if \"'\" in mot:\n",
    "        lMots=mot.split(\"'\")\n",
    "        result=\"'\".join([normaliserMajusculesMinuscules(m) for m in lMots])\n",
    "    elif len(mot)>1 and mot!=mot.lower() and mot!=mot.capitalize():\n",
    "        result=mot[0]+mot[1:].lower()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"d'E-st'Ogm\""
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliserMajusculesMinuscules(u\"d'E-St'OGM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduire les pronoms dans les phrases\n",
    "\n",
    "- clitiques verbaux entre dièses pour permettre l'inclusion en français et l'exclusion en kalaba\n",
    "  - Marie TAB #les# voyait TAB ,les enfants TAB TAB dans la cour\n",
    "    - FR: Les enfants, Marie les voyait dans la cour.\n",
    "    - KB: Marie voyait les enfants dans la cour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFr(line):\n",
    "    result=line\n",
    "    m=re.search(ur\"((\\w+)#\\S+#)\",result)\n",
    "    if m:\n",
    "        result=result.replace(m.group(1),m.group(2))\n",
    "        result=cleanFr(result)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'elles pensent \\xe0 lui'"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFr(u\"elles#sorcières# pensent à lui#garçon#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortie=\"latex\"):\n",
    "    print sortie\n",
    "    phrasesLocales=phrase_file.readlines()\n",
    "    syntagmesLocaux=[]\n",
    "    numLignes=len(phrasesLocales)\n",
    "    numImages=1\n",
    "    numLignesVides=0\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    elif sortie==\"images\":\n",
    "        numImages=1\n",
    "        numLignesVides=0\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "        numLignesVides=0\n",
    "\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLigneNoPreview=\"\\\\\\\\\"*numLignesVides\n",
    "    finLignePreview=\"\\\\\\\\\"*numLignesVides+\"\\\\end{preview}\"\n",
    "    numLignes=(len(phrasesLocales)//numImages)*numImages\n",
    "\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrasesLocales[:numLignes]):\n",
    "        print nPhrase,line\n",
    "        #phrase contient une position par fonction\n",
    "        #pour accueillir les équivalents kalabas des chunks français\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").replace(u\"’\",\" \").split(\"\\t\")\n",
    "        tampon=[t.strip() for t in tampon]\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug: \n",
    "            print \"===========================================\"            \n",
    "            print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "#             print nPhrase,tampon\n",
    "            #\n",
    "            # Introduire les clitiques non-traités\n",
    "            # \n",
    "            # #les# voit \n",
    "            #\n",
    "            m=re.search(ur\"#.*#\\s*(.*)\",tampon[1])\n",
    "            if m:\n",
    "                verbe=m.group(1).split(\" \")\n",
    "            else:\n",
    "                verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            tempVerbe=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print tempVerbe\n",
    "            formeCitation=tempVerbe[0]\n",
    "            lexemesLocaux.add(formeCitation)\n",
    "            for element in tempVerbe[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            if len(tempVerbe)>1:\n",
    "                typeVerbe=tempVerbe[1]\n",
    "            else: \n",
    "                typeVerbe=\"\"\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    frObjetCas=\"\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            if debug: print (frSujetCas,frObjetCas,klbSujet)\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (\"FAIRE_GN SUJET\",localMots,(localClasses,localNombre,localCas))\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas,localNombre,localClasses,sujetVerbe\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            if len(tampon)>=3:\n",
    "                if tampon[2] and tampon[2].startswith(\",\"):\n",
    "                    tampon[2]=tampon[2][1:]\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe and localCas!=\"Nom\":\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                if tampon[3] and tampon[3].startswith(\",\"):\n",
    "                    tampon[3]=tampon[3][1:]\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=previewer(faire_gp(indirect,\"IND\"),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            ###################\n",
    "            #\n",
    "            # Modification pour ajouts multiples séparés par ;\n",
    "            # 24/11/19\n",
    "            #\n",
    "            ###################\n",
    "            if len(tampon)>=5:\n",
    "                if tampon[4] and tampon[4].startswith(\",\"):\n",
    "                    tampon[4]=tampon[4][1:]\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=previewer(multiplier_gp(comp),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=multiplier_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                if tampon[5] and tampon[5].startswith(\",\"):\n",
    "                    tampon[5]=tampon[5][1:]\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                if sortie==\"ordre\":\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=previewer(multiplier_gp(ajout),suffixe=\"{}\")\n",
    "                else:\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=multiplier_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "            noligFormeCitation=noligFormeCitation.replace(\"-\",\"\")\n",
    "\n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent)\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            cellules[\"VER\"].add(\".\".join([verbeLexeme,morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize(),nombrePersonne,classeVerbe,nombreVerbe]).strip(\".\"))\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=previewer([glose],suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            lexemesLocaux.add(noligFormeCitation)\n",
    "            texte.append(glose)\n",
    "            if sortie in [\"latex\",\"traductions\"]: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            syntagmesBruts=[]\n",
    "            syntagmesEtiquetes=[]\n",
    "            for nMot,mot in enumerate(phrase):\n",
    "                if mot!=0:\n",
    "                    \n",
    "                    if isinstance(mot,basestring):\n",
    "                        syntagmeLocal=latex2ipa(mot)\n",
    "                    else:\n",
    "                        interFlat=[]\n",
    "                        for m in flatten(mot):\n",
    "                            mList=re.findall(ur\"\\\\[^{]+{}\",m)\n",
    "                            if mList:\n",
    "                                interFlat.extend(mList)\n",
    "                            else:\n",
    "                                interFlat.append(m)\n",
    "                        if debug: print \"interFlat\",interFlat\n",
    "                        if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                            interFlat.reverse()\n",
    "                        syntagmeLocal=separateurMots.join([latex2ipa(f) for f in interFlat])\n",
    "                    syntagmesBruts.append(syntagmeLocal)\n",
    "                    syntagmesEtiquetes.append(syntagmeLocal)\n",
    "                    if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                        syntagmesEtiquetes.append(syntagmes[\"Phrase\"][nMot])\n",
    "                    else:\n",
    "                        syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "#                    syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "                    printflat(mot,\"{}\")\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts[::-1])+\";\"+\" \".join(syntagmesEtiquetes[::-1])\n",
    "            else:\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            print ligneSyntagmesLocaux\n",
    "            syntagmesLocaux.append(ligneSyntagmesLocaux)\n",
    "            localAccumulateur=[accu for accu in accumulateur if accu!=\"\"]\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "                if sortie==\"images\":\n",
    "                    if nPhrase%numImages==0:\n",
    "                        prefixe=\"\\\\begin{preview}\"\n",
    "                    else:\n",
    "                        prefixe=\"\"\n",
    "                    if nPhrase%numImages==numImages-1:\n",
    "                        finLigne=finLignePreview\n",
    "                    else:\n",
    "                        finLigne=finLigneNoPreview\n",
    "                elif sortie==\"mots\":\n",
    "                    localAccumulateur=[debutLignePreview+accu+finLignePreview for accu in accumulateur if accu!=\"\"]\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(localAccumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\" and separateurMots==\"\":\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur[::-1])+finLigne)\n",
    "            else:\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortie in [\"latex\",\"traductions\"]:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortie in [\"latex\",\"traductions\"]: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            ##############\n",
    "            #\n",
    "            # Modification pour ajouts multiples\n",
    "            # suppression des ; de séparation dans la traduction\n",
    "            #\n",
    "            ##############\n",
    "            if \",\" in line:\n",
    "                consts=line.split(\"\\t\")\n",
    "                disloc=[]\n",
    "                canon=[]\n",
    "                for const in consts:\n",
    "                    if const.startswith(\",\"):\n",
    "                        if \";\" in const:\n",
    "                            subConsts=const.split(\";\")\n",
    "                            print \"##############@\"\n",
    "                            print subConsts\n",
    "                            disloc.append(subConsts[0][1:])\n",
    "                            for subConst in subConsts[1:]:\n",
    "                                canon.append(subConst.lstrip())\n",
    "                        else:\n",
    "                            disloc.append(const[1:])\n",
    "                    else:\n",
    "                        canon.append(const)\n",
    "                line=\",\\t\".join(disloc).strip()+\", \"+\"\\t\".join(canon)\n",
    "            if \" ; \" in line:\n",
    "                line=line.replace(\" ; \",\" \")\n",
    "            line=cleanFr(line)            \n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                element=element.strip(\"#\").replace(u\"’\",\"'\")\n",
    "                #\n",
    "                # Modification pour accepter les suffixes P et D à la fin des noms\n",
    "                # 31/5/21\n",
    "                #\n",
    "                if element[-2:] in [\"sP\",\"sD\"]:\n",
    "                    element=element[:-1]\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=normaliserMajusculesMinuscules(element)\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(caracteres)\n",
    "            if sortie==\"latex\": \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            elif sortie==\"images\":\n",
    "                ajouterExemple(marqueurCommentaire+\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "            elif sortie in [\"ordre\",\"mots\"]:\n",
    "                ajouterExemple(\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "                #if sortie==\"mots\": ajouterExemple(\"\\\\begin{preview}\"+\".\"+\"\\\\end{preview}\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortie==\"latex\" and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "            with codecs.open(serie+complementPhrases+\"Syntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in syntagmesLocaux:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "        elif (sortie==\"traductions\" and variante==\"-Corr\"):\n",
    "            with codecs.open(serie+complementPhrases+\"Traductions\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")            \n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "#    elif sortie==\"images\":\n",
    "#        with codecs.open(serie+complementPhrases+\"Images\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "#            for exemple in exemples:\n",
    "#                output.write(exemple+\"\\n\")\n",
    "    elif sortie in [\"images\",\"ordre\",\"mots\"]:\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "            for texHead in texHeader:\n",
    "                output.write(texHead+\"\\n\")\n",
    "            for exemple in exemples:\n",
    "                output.write(exemple+\"\\n\")\n",
    "    if sortie in [\"images\",\"traductions\",\"ordre\",\"mots\"]:\n",
    "        clozeTraductions=[]\n",
    "        clozeExemples=exemples[:]\n",
    "        filtreLignes=[\"\\\\begin{phrases}\",\"\\\\ex\",\"\\\\gloses\",\"\\\\end{phrases}\"]\n",
    "        if sortie==\"traductions\":\n",
    "            clozeExemples=[exemple for exemple in clozeExemples if (not exemple in filtreLignes) and not exemple.startswith(\"%\")]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(clozeExemples)]*3):\n",
    "            if sortie==\"traductions\" and 0:\n",
    "                print \"ortho\",orthoLigne\n",
    "                print \"phono\",phonoLigne\n",
    "                print \"trad\",tradLigne\n",
    "            phonoLigne=phonoLigne.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "            phonoLigne=phonoLigne.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "            phonoLigne=phonoLigne.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoMots=phonoLigne.strip(marqueurCommentaire).replace(finLignePreview,\"\").strip().split()\n",
    "            tradLigne=tradLigne.strip(marqueurCommentaire).replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")\n",
    "                if element==\"\\\\ex\": cleElement=\"\"\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print cleElement,phonoMots\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n",
    "        if sortie==\"ordre\" and separateurMots==\"\":\n",
    "            dictSyntagmes={}\n",
    "            dictTraductions={}\n",
    "            ordreCles=[]\n",
    "            for element in syntagmesLocaux:\n",
    "                clePhono,valSyntagmes=element.split(\";\")\n",
    "                dictSyntagmes[clePhono]=\" \".join([v for v in valSyntagmes.split() if not v in nomFonctions])\n",
    "                ordreCles.append(clePhono)\n",
    "            for element in clozeTraductions:\n",
    "                clePhono,valTrad,valMots=element.split(\";\")\n",
    "                dictTraductions[clePhono]=valTrad\n",
    "            morceauxPhrases=[\"%s;%s\"%(dictSyntagmes[c],dictTraductions[c]) for c in ordreCles]\n",
    "            with codecs.open(serie+complementPhrases+\"OrdreSyntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in morceauxPhrases:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'AJOUT', 'OBJ', 'COMP', 'IND', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'DET', 'GP']}\n"
     ]
    }
   ],
   "source": [
    "sortie=\"traductions\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if traduction_nom.endswith(\"csv\") and variante!=\"-Corr\":\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the translation file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,sortie=sortie)\n",
    "            traduction_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'IND', 'COMP', 'OBJ', 'AJOUT', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['GP', 'DET', 'NOM', 'GADJ']}\n",
      "latex\n",
      "0 une légende\traconte\tl'histoire des sorcières du grand manoir\t\t\t\n",
      "\n",
      "1 la légende\tcompte\tquatre sorcières\t\t\t\n",
      "\n",
      "2 AgathoS \test \tla fille de Freja\t\t\t\n",
      "\n",
      "3 Elphaba \test\tla grande soeur de Freja \t\t\t\n",
      "\n",
      "4 Freja \test\tla maîtresse du grand manoir\t\t\t\n",
      "\n",
      "5 Clemencia \tdétestait\tles enfants du village \t\t\t\n",
      "\n",
      "6 les trois sorcières du grand manoir\tportaient\tdes robes noires\t\t\t\n",
      "\n",
      "7 la sorcière verte \tchange\tles enfants \t\ten gargouilles\t\n",
      "\n",
      "8 AgathoS\tpossède\tun chat noir\t\t\t\n",
      "\n",
      "9 les yeux noirs d'AgathoS\tjettent\tdes sortilèges\t\t\t\n",
      "\n",
      "10 le chat noir\tjetait\tdes sortilèges\t\t\tavec les yeux\n",
      "\n",
      "11 le grand manoir des sorcières\tsurplombait \tle marais \t\t\t,à proximité de la forêt\n",
      "\n",
      "12 les crapauds du marais \tdétestent\tles villageois\t\t\t\n",
      "\n",
      "13 Hoderi \tjette\tdes cailloux\t\t\t,dans le village à côté ; avec Clemencia\n",
      "\n",
      "[[u'dans', u'le', u'village', u'\\xe0', u'c\\xf4t\\xe9'], [u'avec', u'Clemencia']]\n",
      "##############@\n",
      "[u',dans le village \\xe0 c\\xf4t\\xe9 ', u' avec Clemencia\\n']\n",
      "14 les sorcières\tsont\tdes méchantes créatures\t\t\t,pour les chasseurs\n",
      "\n",
      "15 le village \tcomptait \tdE nombreuses disparitions\t\t\t\n",
      "\n",
      "16 quatre enfants\tpartirent \t\t\tdans la forêt\t\n",
      "\n",
      "17 les enfants\tdécouvrirent \tle manoir des sorcières\t\t\t\n",
      "\n",
      "18 les trois sorcières\tjardinaient \t\t\t\t,à côté des crapauds du marais\n",
      "\n",
      "19 les quatre enfants \tjetaient \tdes cailloux \taux sorcières\t\t\n",
      "\n",
      "20 les enfantsP\t volèrent \tles légumes\taux sorcières\t\t\n",
      "\n",
      "21 Elphaba \tdéteste\tles enfants\t\t\t\n",
      "\n",
      "22 les sorcièresP\tchangèrent\tles enfants \t\ten gargouilles\t\n",
      "\n",
      "23 la maîtresse du manoir \tenferma\t les gargouilles\t\tdans un donjon au milieu du manoir\t\n",
      "\n",
      "24 les chasseurs de sorcières\tprotégeaient\tles enfants du village\t\t\t\n",
      "\n",
      "25 les chasseurs \tcherchent \tles enfantsP disparus \t\t\tdans la nuit noire\n",
      "\n",
      "26 les sorcièresP\tvolèrent \t\t\tsur les balais\t\n",
      "\n",
      "27 elles#sorcièresP#\t enlevaient\tles enfants \t\tdes villageois\t\n",
      "\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'N1', u'A']\n",
      "28 les sorcièresP\tjetèrent \tun sortilège \taux villageois\t\t\n",
      "\n",
      "29 l’obscurité \tsurplombait \t le village des chasseurs\t\t\t,avec le grimoire\n",
      "\n",
      "30 les trois femmes\tchangent\tles légumes\t\ten cailloux\t\n",
      "\n",
      "31 les quatre chasseurs \tpartirent \t\t\tdans la forêt\t\n",
      "\n",
      "32 l’obscurité \tcachait\tle chemin\t\t\t\n",
      "\n",
      "33 les six hommes \tdormirent \t\t\t\tà côté du marais\n",
      "\n",
      "34 l'obscurité \tsurplombe \t le marais\t\t\tau matin\n",
      "\n",
      "35 les hommes \tcherchent \tle grand marais du manoir des sorcièresP\t\t\t\n",
      "\n",
      "36 le chat noir \t sortit \t\t\tdu grand manoir\t\n",
      "\n",
      "37 les chasseurs \tentrent \t\t\tdans le manoir des trois sorcières\t\n",
      "\n",
      "38 Hoderi \tprotège\tFreja\t\t\t\n",
      "\n",
      "39 les deux sorcières\tcachent\tle grimoire de Clemencia\t\t\t\n",
      "\n",
      "40 le chat noir d’AgathoS\tprotégeait\t le grimoire du manoir\t\t\t\n",
      "\n",
      "41 Clemencia \tdisparaît \t\t\t\t,dans le manoir\n",
      "\n",
      "42 Hoderi \tétait\t\t\tdans le manoir\t\n",
      "\n",
      "43 un chasseur\tcherche\tles autres chasseurs\t\t\t\n",
      "\n",
      "44 Hoderi \tcherchait\tle donjon des enfantsP\t\t\t\n",
      "\n",
      "45 le chasseur \tdécouvre\tles enfantsP disparus \t\t \t\n",
      "\n",
      "46 Hoderi \tpart\t\t\tdu donjon\t,avec les quatre gargouilles\n",
      "\n",
      "47 Clemencia \t vole\tle grimoire \taux méchantes sorcières\t\t\n",
      "\n",
      "48 Elphaba \tcherche\tles deux chasseurs\t\t\t\n",
      "\n",
      "49 ils#chasseursD#\tprotègent \tles gargouilles\t\t\t\n",
      "\n",
      "ref nomSeul ils chasseursD\n",
      "[u'N1', u'D']\n",
      "50 Elphaba \tconnaît\tsept sortilèges dans le grimoire\t\t\t\n",
      "\n",
      "51 la grande soeur de la méchante sorcière \tcourut \t\t\t dans le marais\t\n",
      "\n",
      "52 Clemencia \tjetait\tElphaba\t\tdans le marais\t\n",
      "\n",
      "53 le grand chasseur \t noie\tElphaba \t\t\t\n",
      "\n",
      "54 Elphaba \tmeurt\t\t\t\tdans le marais vert\n",
      "\n",
      "55 la fille de Freja\thurla\t\t\t\t\n",
      "\n",
      "56 la nuit noire\tétait\t\t\tsur le village\t\n",
      "\n",
      "57 les deux sorcières\tpleurent\tla mort d'Elphaba\t\t\t\n",
      "\n",
      "58 Hoderi \tcherchait\tles deux sorcières\t\t\t\n",
      "\n",
      "59 les six hommes \tpréparent \tle bûcher\t\t\t\n",
      "\n",
      "60 la fille de Clemencia\tprépare\tles légumes\t\t\t\n",
      "\n",
      "61 AgathoS \tpartait\t\t\tdans l'obscurité de la forêt\t,avec un balai\n",
      "\n",
      "62 les quatre pères\tenfermaient\tla sorcière\t\t\t\n",
      "\n",
      "63 les deux chasseurs\tallument \tun grand feu\t\t\t\n",
      "\n",
      "64 la peau verte de Freja\tbrûle\t\t\t\tsur le bûcher\n",
      "\n",
      "65 Freja \thurlait\t\t\t\t,sur le bûcher ; de douleur\n",
      "\n",
      "[[u'sur', u'le', u'b\\xfbcher'], [u'de', u'douleur']]\n",
      "##############@\n",
      "[u',sur le b\\xfbcher ', u' de douleur\\n']\n",
      "66 la mère d'AgathoS\tfuit\tle bûcher\t\t\t\n",
      "\n",
      "67 la maîtresse du manoir \tfuyait\tles chasseursD\t\t\t,dans la nuit noire\n",
      "\n",
      "68 AgathoS \trejoint\tFreja \t\tdans la forêt\t\n",
      "\n",
      "69 les deux sorcières\tdisparurent\t\t\tdans la forêt\t,dans l'obscurité\n",
      "\n",
      "70 les six hommes\tcherchèrent\tles sorcièresD\t\t\t\n",
      "\n",
      "71 la nuit\tnoyait\tle chemin\t\tdes deux sorcières \tdans l'obscurité de la forêt\n",
      "\n",
      "72 la nuit noire\tinquiétait\tles villageois\t\t\t\n",
      "\n",
      "73 les pères\tembrassèrent\tles enfantsP\t\t\t\n",
      "\n",
      "74 les villageois\trejoignirent\tle village\t\tdans la nuit noire\t\n",
      "\n",
      "75 les chasseurs\trejoignirent\tle village\t\ten héros\t\n",
      "\n",
      "76 les villageois\tremercièrent\tles chasseurs de sorcières\t\t\t\n",
      "\n",
      "77 les chasseurs\tsont \tdes héros\t\t\t\n",
      "\n",
      "78 les enfantsP\tpleurÈRENT\t\t\t\t,dans les bras des parents\n",
      "\n",
      "79 les villageois \tnourrissent \tles héroïques chasseurs \t\t\tavec les derniers légumes du village\n",
      "\n",
      "80 les légumes\tsont \tles dernIERs du village\t\t\t\n",
      "\n",
      "81 le village \tdort\t\t\t\t\n",
      "\n",
      "82 les villageois\tdorment\t\t\tdans le village\t\n",
      "\n",
      "83 les deux héros\tbrûlèrent\tle grand manoir\t\t\t\n",
      "\n",
      "84 les sorcièresD\tvoient\tle manoir en feu\t\t,dans la forêt\t\n",
      "\n",
      "85 AgathoS\tsurvole\tle manoir en feu\t\t\tavec un  balais\n",
      "\n",
      "86 les deux sorcières\tcherchent\tle grimoire\t\tau village\t\n",
      "\n",
      "87 elles#sorcièresD#\tvolent\tle livre des sortilèges\taux chasseursD\t\t\n",
      "\n",
      "ref nomSeul elles sorcièresD\n",
      "[u'N1', u'A']\n",
      "88 les voleusesD\tretournent\t\t\tau manoir en feu\t\n",
      "\n",
      "89 Freja\tchange\tle chat noir d'AgathoS\t\ten enfant\t\n",
      "\n",
      "90 AgathoS\tinterroge\tle livre des sortilèges\t\t\tpour l'esprit d'Elphaba\n",
      "\n",
      "91 un sortilège\tressuscite\tElphaba\t\tdans le marais du manoir\t\n",
      "\n",
      "92 les crapauds verts\tvoient\tles sortilèges des sorcières\t\t\t\n",
      "\n",
      "93 le chat noir\tentre\t\t\tdans le village des chasseurs\t\n",
      "\n",
      "94 les enfants\taccueillent\tle chat noir\t\t\t\n",
      "\n",
      "95 l'enfant en robe noire\tjette\tdes cailloux\taux villageois\t\tdans l'obscurité\n",
      "\n",
      "96 un villageoiS\tcompte\tles cailloux de l'enfant\t\t\t\n",
      "\n",
      "97 il#villageoiS#\thurle\t\tsur l'enfant\t\t\n",
      "\n",
      "ref nomSeul il villageoiS\n",
      "[u'N2', u'C']\n",
      "98 l'enfant \tpleure\t\t\t\tdans le village\n",
      "\n",
      "99 les sorcièresP\tsurplombent\tle village\t\t\t,sur des balais\n",
      "\n",
      "100 les trois sorcières\tallumèrent\tun feu\t\tsur la place ; au milieu du village\t\n",
      "\n",
      "[[u'sur', u'la', u'place'], [u'au', u'milieu', u'du', u'village']]\n",
      "101 les villageois\tpleurAIENT\t\t\t\t\n",
      "\n",
      "102 la lumière\tmanque\t\tau village\t\t\n",
      "\n",
      "103 Elphaba\tallume\tun bûcher\t\t\tpar esprit de vengeance ; pour les chasseurs\n",
      "\n",
      "[[u'par', u'esprit', u'de', u'vengeance'], [u'pour', u'les', u'chasseurs']]\n",
      "104 AgathoS\tattrape\tHoderi\t\t\t\n",
      "\n",
      "105 Clemencia\tinterroge\tles sorcières\t\t\tsur la raison de la vengeance\n",
      "\n",
      "106 le chat noir\tpoussa\tClemencia\t\tvers le feu\t\n",
      "\n",
      "107 Clemencia\treconnaît\tla troisième sorcière\t\t\t\n",
      "\n",
      "108 AgathoS\ttourne\t\t\t\tavec la robe noire\n",
      "\n",
      "109 une tornade\tfait\tdes dégâts\t\tdans le village\t\n",
      "\n",
      "110 Hoderi\thurla\t\t\t\t\n",
      "\n",
      "111 la maîtresse du manoir en feu\tarrête\tle feu\t\t\t\n",
      "\n",
      "112 la tornade\tdisparaît\t\t\tau milieu des femmes du village\t\n",
      "\n",
      "113 les trois sorcières\tdescendent\t\t\tdes balais\tdans la nuit\n",
      "\n",
      "114 Elphaba\tprésente\tles raisons des dégâts dans le village\t\t\t\n",
      "\n",
      "115 le chat noir d'AgathoS\tredevient\tun chat \t\t\taux yeux du village\n",
      "\n",
      "116 des femmes\tpoussèrent\tdes hurlements\t\t\ten raison du sortilège\n",
      "\n",
      "117 les sorcières\tdemandent\tdes excuses\taux villageoises \t\t\n",
      "\n",
      "118 les enfants\t#les# détestent\tles légumes des sorcières\t\t\t\n",
      "\n",
      "119 les mèresP des méchants enfantsP\tattrapèrent\tles gargouillesP\t\t\t\n",
      "\n",
      "120 les sept femmes\tdemandent\tdes excuses\taux méchants enfantsP\t\t\n",
      "\n",
      "121 les enfantsP\tprésentent\tdes excuses\taux sept femmes\tau milieu du village\t\n",
      "\n",
      "122 les hommes\tfirent\tun vote \t\t\t\n",
      "\n",
      "123 l'obscurité\tfit\tplace\tà la lumière\t\t\n",
      "\n",
      "124 les sorcièresP\tchangèrent\tles cailloux des jardins des villageois\t\ten légumes\t\n",
      "\n",
      "125 les dégâts dans le village\tdisparaissent\t\t\t\tavec l'obscurité\n",
      "\n",
      "126 les sorcièresP\tsortent\t\t\tdu village\t\n",
      "\n",
      "127 elles#sorcièresP#\trevinrent\t\t\tvers les chasseurs ; en balais\tavec des légumes\n",
      "\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'N1', u'A']\n",
      "[[u'vers', u'les', u'chasseurs'], [u'en', u'balais']]\n",
      "128 les villageois\téchangent\tdes légumes\t\t\tavec elles#sorcièresP#\n",
      "\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'N1', u'A']\n",
      "129 les hommes du village\treconstruisent\tle manoir\t\t\t\n",
      "\n",
      "130 les sorcières\tinterrogent\tElphaba\t\tsur la demande des hommes\t\n",
      "\n",
      "131 les deux chasseurs\tpartirent\t\t\t\tvers le manoir\n",
      "\n",
      "132 le vote des hommes\tcompte\t\t\t\tpour le village\n",
      "\n",
      "133 la nouvELLE\tfait\tdes lumières\t\tdans les yeux noirs d'AgathoS\t\n",
      "\n",
      "134 les sorcièresP\tcoururent\t\t\tà la construction du manoir de Freja\t\n",
      "\n",
      "135 le villageoiS\tmange\tdes légumes\t\t\tdans le manoir des sorcières\n",
      "\n",
      "136 les sorcières\tremercièrent\tles villageois\t\t\t\n",
      "\n",
      "137 les trois femmes\téchangèrent\tles méchants enfantsP du village en crapauds du marais\t\t\t\n",
      "\n",
      "138 les parents\teurent\tdes nouveaux enfants\t\t\t\n",
      "\n",
      "139 la nouvelle harmonie\tchange\tles parents\t\t\t\n",
      "\n",
      "140 les villageois\tmangent\tdes légumes \t\t\tavec les sorcièresP\n",
      "\n",
      "141 les deux chasseurs de sorcières\tchassent\tles méchants enfants des autres villages\t\t\t\n",
      "\n",
      "142 les trois sorcières\tdorment\t\t\tdans le nouveau manoir à proximité du marais\t\n",
      "\n",
      "143 les crapauds du marais\tpleurent\tles parents du village\t\t\t,pendant la nuit\n",
      "\n",
      "144 ils#crapauds#\tmangent\tdes cailloux\t\t\t,au lever du jour\n",
      "\n",
      "ref nomSeul ils crapauds\n",
      "[u'N4', u'B']\n",
      "145 le chat noir d'AgathoS\tcourt\t\t\tdans le village ; à côté du grand manoir\t\n",
      "\n",
      "[[u'dans', u'le', u'village'], [u'\\xe0', u'c\\xf4t\\xe9', u'du', u'grand', u'manoir']]\n",
      "146 le village\tvit\t\t\ten harmonie avec les sorcières\t\n",
      "\n",
      "147 les villageois\tracontent\tla légende\taux enfants\t\t\n",
      "\n",
      "148 le manoir\tfait\tune lumière \t\t,dans la nuit\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sortie=\"latex\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file,sortie=sortie)\n",
    "phrase_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"Phrases-Clozes\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'IND', 'COMP', 'OBJ', 'AJOUT', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['GP', 'DET', 'NOM', 'GADJ']}\n",
      "I could not open the file /Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/21-K5/Ecrit.csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sortie=\"images\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if ecriture_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        ecriture_file = codecs.open(ecriture_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', ecriture_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            ecriture={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    ecriture[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(ecriture_file,sortie=sortie)\n",
    "            ecriture_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortie=\"ordre\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if ordre_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        ordre_file = codecs.open(ordre_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', ordre_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            ordre={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    ordre[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(ordre_file,sortie=sortie)\n",
    "            ordre_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortie=\"mots\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if mots_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        mots_file = codecs.open(mots_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', mots_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            motsIsoles={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    motsIsoles[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(mots_file,sortie=sortie)\n",
    "            mots_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "if variante==\"\": \n",
    "    print \"faire la correction\"\n",
    "    nextVariante=\"-Corr\"\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "else:\n",
    "    print u\"ok pour cette étape\"\n",
    "    del nextVariante\n",
    "    ding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFM.lexique.formeLexeme[\"trois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yamlDump(nFile,content):\n",
    "    with open(nFile, 'w') as output:\n",
    "        yaml.dump(content, output, default_flow_style=False,allow_unicode=True)\n",
    "\n",
    "    with open(nFile, 'r') as input:\n",
    "        yamlLines=input.readlines()\n",
    "\n",
    "    yamlText=\"\".join(yamlLines)\n",
    "    yamlText=re.sub(r\"!!python/unicode\",\"\",yamlText)\n",
    "    yamlText=re.sub(r\"\\n\\s*-\\s*\",\", \",yamlText)\n",
    "    yamlText=re.sub(r\":,\\s*\",\": \",yamlText)\n",
    "    yamlText=re.sub(r\": *([^\\n]+)\",\": [\\g<1>]\",yamlText)\n",
    "\n",
    "\n",
    "    with open(nFile, 'w') as output:\n",
    "        output.write(yamlText)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in cellules:\n",
    "    cellules[k]=list(cellules[k])\n",
    "cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamlDump(serie+\"FilledCells.yaml\",cellules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py27)",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
