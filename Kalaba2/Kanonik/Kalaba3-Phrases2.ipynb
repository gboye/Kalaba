{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problèmes et Extensions\n",
    "\n",
    "## Problèmes\n",
    "- javascript runs fail\n",
    "- faire de nouvelles sorties pour les kalabas sans séparateurs de mots\n",
    " - radicaux seuls\n",
    " - découpage en syntagmes pour l'exercice sur l'ordre des syntagmes\n",
    "\n",
    "## Extensions\n",
    "- traitement du paucal\n",
    " - 2,3,4,5 ou suffixe P sur le nom sans numéral\n",
    "- ajout des compléments/ajouts multiples\n",
    " - séparation par ;\n",
    " - gestion des dislocations gauches dans les multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalaba3-Phrases2\n"
     ]
    }
   ],
   "source": [
    "print(theNotebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter & gestion des variantes\n",
    "\n",
    "Le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable\n",
    "\n",
    "Après la réussite de la variante de base, on change automatiquement la variante à -Corr pour générer les fichiers de solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Corr\n",
      "21-K5\n"
     ]
    }
   ],
   "source": [
    "# numerosKalaba=[5]\n",
    "# %store numerosKalaba\n",
    "%store -r numerosKalaba\n",
    "variante=\"\"\n",
    "if 'nextVariante' in globals():\n",
    "    variante=nextVariante\n",
    "print variante\n",
    "numeroKalaba=\"21-K%d\"%numerosKalaba[0]\n",
    "print numeroKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')\n",
    "    \n",
    "    \n",
    "from os.path import expanduser\n",
    "#from cellbell import ding\n",
    "from itertools import groupby\n",
    "home = expanduser(\"~\")\n",
    "serie=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/%s/\"%numeroKalaba\n",
    "complementPhrases=\"\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle,copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "séparateur  \n"
     ]
    }
   ],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=0\n",
    "\n",
    "#casNombreDet=True\n",
    "RightLeft=True\n",
    "\n",
    "if (numerosKalaba[0] in [3,5]) and variante==\"\":\n",
    "    separateurPhonoCloze=\"\"\n",
    "else:\n",
    "    separateurPhonoCloze=\" \"\n",
    "separateurPhonoCloze=\" \"    \n",
    "separateurMots=separateurPhonoCloze\n",
    "print \"séparateur\",separateurMots\n",
    "#separateurMots=\" \"\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False        #False\n",
    "print_radicaux=False     #False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.safe_load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.safe_load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.safe_load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.safe_load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Gloses.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\columnbreak\\\\vfill\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Nom\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cas', 'Genre', 'Nombre', 'Pers', 'Temps'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOM', 'VER', 'ADJ', 'PRO', 'DET']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'DET': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'NOM': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'PRO': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'VER': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': False,\n",
       "  'Pers': True,\n",
       "  'Temps': True}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'AJOUT', 'OBJ', 'COMP', 'IND', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'DET', 'GP']}\n"
     ]
    }
   ],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]\n",
    "syntagmesLR=copy.deepcopy(syntagmes)\n",
    "print syntagmesLR\n",
    "syntagmesRL=copy.deepcopy(syntagmes)\n",
    "for element in syntagmesRL:\n",
    "    syntagmesRL[element].reverse()\n",
    "nomFonctions=syntagmes[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LR',\n",
       " {'GADJ': ['ADV', 'ADJ', 'GP'],\n",
       "  'GN': ['GADJ', 'NOM', 'DET', 'GP'],\n",
       "  'GP': ['GN', 'PREP'],\n",
       "  'Phrase': ['VER', 'AJOUT', 'OBJ', 'COMP', 'IND', 'SUJ']},\n",
       " 'RL',\n",
       " {'GADJ': ['GP', 'ADJ', 'ADV'],\n",
       "  'GN': ['GP', 'DET', 'NOM', 'GADJ'],\n",
       "  'GP': ['PREP', 'GN'],\n",
       "  'Phrase': ['SUJ', 'IND', 'COMP', 'OBJ', 'AJOUT', 'VER']})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"LR\",syntagmesLR, \"RL\",syntagmesRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS', 'PST', '3Sg', '3Pau', '3Pl', 'HUM', 'ANIM', 'INAN']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduire les pronoms kalaba\n",
    "- identifier qu'il s'agit d'un pronom\n",
    "- parser le référent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounNumber(nom,nombre):\n",
    "    if nom[len(nom)-1] in [\"s\",\"x\"]:\n",
    "        if nombre==\"\": nombre=\"PL\"\n",
    "    elif nom[len(nom)-1] in [\"P\",\"D\"]:\n",
    "        if nombre==\"\": \n",
    "            if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"PAU\"\n",
    "            elif \"Du\" in valAttributs[\"Nombre\"] and nom[len(nom)-1]==\"D\":\n",
    "                nombre=\"DU\"\n",
    "            else:\n",
    "                nombre=\"PL\"\n",
    "    else:\n",
    "        if nombre==\"\": nombre=\"SG\"\n",
    "    return nombre\n",
    "\n",
    "def getNounGender(ref):\n",
    "    nom=ref.rstrip(\"P\").rstrip(\"D\")\n",
    "    nomLexeme=PFM.lexique.formeLexeme[nom][0]\n",
    "    classesNom=nomLexeme.split('.')[1:]\n",
    "    proGender=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "    return proGender, classesNom\n",
    "\n",
    "\n",
    "def getRef(pronom):\n",
    "    m=re.match(\"^(.*)#(.*)#\",pronom)\n",
    "    if m:\n",
    "        pro=m.group(1)\n",
    "        ref=m.group(2)\n",
    "    else:\n",
    "        print \"mauvaise notation pour un pronom\"\n",
    "        pro=\"\"\n",
    "        ref=\"\"\n",
    "    return pro,ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lui PRO PL chats PL ANIM\n"
     ]
    }
   ],
   "source": [
    "pro,ref=getRef(u\"lui#chats#\")\n",
    "proNum=getNounNumber(ref,nombre=\"\")\n",
    "proGen,proClasse=getNounGender(ref)\n",
    "nomLexeme=PFM.lexique.formeLexeme[pro][0]\n",
    "print pro, nomLexeme, proNum, ref, proNum, proGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_gn(depart,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom=[]\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        if not \"#\" in mot:\n",
    "            groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    pro=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    if len(groupe_nom)==1:\n",
    "#         print \"Pronom ?\",groupe_nom\n",
    "        nomSeul=groupe_nom[0]\n",
    "        boolPro=(\"#\" in nomSeul)\n",
    "    else:\n",
    "        boolPro=False\n",
    "    if boolPro:\n",
    "        proForm,proRef=getRef(nomSeul)\n",
    "        nomLexeme=PFM.lexique.formeLexeme[proForm][0]\n",
    "        print \"ref nomSeul\",proForm,proRef\n",
    "        nombre=getNounNumber(proRef,nombre=\"\")\n",
    "        classe,classesNom=getNounGender(proRef)\n",
    "        pro.append(nomLexeme)\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "#                    else:\n",
    "        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "        if debug or 0:\n",
    "            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "        if cas==\"ERG\":\n",
    "            erg_genre=classe\n",
    "            erg_nombre=nombre\n",
    "            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "        elif cas==\"ABS\":\n",
    "            abs_genre=classe\n",
    "            abs_nombre=nombre\n",
    "            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for mot in groupe_nom:\n",
    "            if reste==0:\n",
    "    #            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "                if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                    nombre=\"DU\"\n",
    "                    if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                else:\n",
    "                    if \"Pau\" in valAttributs[\"Nombre\"] and mot in \"deux trois quatre cinq\".split():\n",
    "                        nombre=\"PAU\"\n",
    "                        if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                    if mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot[:-1]][0]\n",
    "                    else:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                    categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                    if debug or 0: \n",
    "                        print \"mot\",[mot]\n",
    "                        print \"vedette\",nomLexeme,categorie\n",
    "                        print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                    if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                        tete=categorie\n",
    "                        if debug or 0: print \"tête :\", tete\n",
    "                        tampon=tete.split('.')\n",
    "    #                    classe=tampon[0]\n",
    "                        classesNom=nomLexeme.split('.')[1:]\n",
    "                        if debug or 0: print \"classesNom\",classesNom \n",
    "                        classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                        if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                        try:\n",
    "                            typeMot=tampon[1]\n",
    "                        except IndexError:\n",
    "                            typeMot=''\n",
    "                        # modif pour les mots à pluriels en x\n",
    "                        # 23/11/19\n",
    "                        #\n",
    "                        nombre=getNounNumber(mot,nombre)\n",
    "#                         if mot[len(mot)-1] in [\"s\",\"x\"]:\n",
    "#                             if nombre==\"\": nombre=\"PL\"\n",
    "#                         elif mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "#                             if nombre==\"\":\n",
    "#                                 # modif pour permettre le pluriel dans les cas où il n'y a pas de paucal.\n",
    "#                                 # 30/5/21\n",
    "#                                 #\n",
    "#                                 if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "#                                     nombre=\"PAU\"\n",
    "#                                 elif \"Du\" in valAttributs[\"Nombre\"] and mot[len(mot)-1]==\"D\":\n",
    "#                                     nombre=\"DU\"\n",
    "#                                 else:\n",
    "#                                     nombre=\"PL\"\n",
    "#                         else:\n",
    "#                             if nombre==\"\": nombre=\"SG\"\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre\n",
    "\n",
    "                        nom.append(nomLexeme)\n",
    "    #                    if typeCas==\"NoCas\":\n",
    "    #                        cas=\"\"\n",
    "                        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                            cas=\"\"\n",
    "    #                    else:\n",
    "                        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "                        if cas==\"ERG\":\n",
    "                            erg_genre=classe\n",
    "                            erg_nombre=nombre\n",
    "                            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                        elif cas==\"ABS\":\n",
    "                            abs_genre=classe\n",
    "                            abs_nombre=nombre\n",
    "                            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"DET\"]:\n",
    "                        det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "    #                elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"]:\n",
    "                        adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                    elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                        gp.append(mot)\n",
    "                        reste=1\n",
    "            else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "                gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det and not boolPro: \n",
    "        if nom[0][0]==nom[0][0].upper():\n",
    "            det.append(PFM.lexique.formeLexeme[\"les\"][0])\n",
    "        else:\n",
    "            det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "\n",
    "    tempSyntagme=[]\n",
    "\n",
    "    if pro:\n",
    "        for mot in pro:\n",
    "    #\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "            noligMot=mot.split(\".\")[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            #\n",
    "            # traitement des noms propres avec tiret\n",
    "            # traitement des noms paucals sans ordinaux\n",
    "            #\n",
    "            if \"-\" in noligMot:\n",
    "                noLigs=noligMot.split(\"-\")\n",
    "                if len(noLigs)>1:\n",
    "                    noligMot=noLigs[0]+\"\".join([c for c in noLigs[1:]])\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "    #        mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot)\n",
    "            texte.append(ref)\n",
    "            tempSyntagme.append(ref)\n",
    "        structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "        mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "        \n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            print \"pas de nombre\"\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "#             print mot,casDet,nombreDet\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        #\n",
    "        # traitement des noms propres avec tiret\n",
    "        # traitement des noms paucals sans ordinaux\n",
    "        #\n",
    "        if \"-\" in noligMot:\n",
    "            noLigs=noligMot.split(\"-\")\n",
    "            if len(noLigs)>1:\n",
    "                noligMot=noLigs[0]+\"\".join([c.lower() for c in noLigs[1:]])\n",
    "#         noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        if noligMot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    if debug or 0:\n",
    "        print \"fin faire_gn\",listeMots\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/14529523/python-split-for-lists\n",
    "\n",
    "l = [\"data\",\"more data\",\";\",\"data 2\",\"more data 2\",\"danger\",\";\",\"date3\",\"lll\"]\n",
    "[list(group) for k, group in groupby(l, lambda x: x == \";\") if not k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplier_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    lGroupes=[list(group) for k, group in groupby(groupe_prep, lambda x: x == \";\") if not k]\n",
    "    if len(lGroupes)>1:\n",
    "        print lGroupes\n",
    "    for lGp in lGroupes:\n",
    "        mots.extend(faire_gp(lGp,fonction))\n",
    "    return mots\n",
    "    \n",
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", groupe_prep\n",
    "    formePreposition=groupe_prep[0]\n",
    "    if debug: print [formePreposition], formePreposition\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        noligMot=groupe_prep[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        \n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                lexemesLocaux.add(noligMot.upper())\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print ref\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else:\n",
    "#        if \"{preview}\" in liste:\n",
    "#            print \"preview\",prefixe,liste,suffixe\n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "texHeader=[]\n",
    "version=theNotebook\n",
    "texHeader.append(\"%% script : \"+version)\n",
    "texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    ecriture_nom=serie+complementPhrases+\"Ecrit.csv\"\n",
    "    ordre_nom=serie+complementPhrases+\"Ordre.csv\"\n",
    "    mots_nom=serie+complementPhrases+\"Mots.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\"\n",
    "    if len(args)>=4:\n",
    "        ecriture_nom=args[3]\n",
    "    else:\n",
    "        ecriture_nom=\"\"\n",
    "    if len(args)>=5:\n",
    "        ordre_nom=args[4]\n",
    "    else:\n",
    "        ordre_nom=\"\"\n",
    "    if len(args)>=6:\n",
    "        mots_nom=args[5]\n",
    "    else:\n",
    "        mots_nom=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrerCloze(filtre):\n",
    "    result=[]\n",
    "    for ligne in clozeLines:\n",
    "        if type(ligne)==str:\n",
    "            ligne=unicode(ligne.decode('utf8'))\n",
    "        ligne=ligne.strip()\n",
    "        if not ligne.startswith(\"#\"):\n",
    "            clozeElements=ligne.split(\";\")\n",
    "            if clozeElements[1] in filtre:\n",
    "                result.append(ligne)\n",
    "        else:\n",
    "            result.append(ligne)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if not isinstance(item, basestring):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewerBegin=\"\\\\begin{preview}\\\\begin{flushleft}\"\n",
    "previewerEnd=\"\\\\end{flushleft}\\\\end{preview}\"\n",
    "def latex2ipa(mot):\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLignePreview=\"\\\\end{preview}\"\n",
    "    if \" \" in mot:\n",
    "        result=[]\n",
    "        for element in mot.split():\n",
    "            result.append(latex2ipa(element))\n",
    "        return separateurMots.join(result)\n",
    "    else:\n",
    "        mot=mot.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "    #    print mot\n",
    "        mot=mot.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "    #    print mot\n",
    "        element=mot.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "    #    print element\n",
    "        cleElement=element.strip().strip(\"\\\\{}\")\n",
    "    #    print cleElement\n",
    "        if element==\"\\\\ex\": cleElement=\"\"\n",
    "        if cleElement:\n",
    "            if not cleElement in traductions: \n",
    "                print cleElement\n",
    "                print traductions\n",
    "                warnings.warn(\"pas de transcription pour %s\"%cleElement,mot)\n",
    "                return None\n",
    "            else:\n",
    "                return traductions[cleElement]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex2ipa(\"\\\\begin{preview}\\\\DEFMSg{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previewer(chaine,numLignesVides=0,suffixe=\"\"):\n",
    "    flatChaine=[mot+suffixe for mot in list(flatten(chaine))]\n",
    "    result=previewerBegin+separateurMots.join(flatChaine)+\"\\\\\\\\\"*numLignesVides+previewerEnd\n",
    "    return [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "texteMots=set()\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.lexemes[\"construire\"].formes.index(\"construisit\")\n",
    "valAttributs[\"Genre\"]\n",
    "localClasses=[\"N\"]\n",
    "[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "localCas=\"Nom\"\n",
    "not localCas or localCas in sujetVerbe\n",
    "sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliserMajusculesMinuscules(mot):\n",
    "    result=mot\n",
    "    if \"'\" in mot:\n",
    "        lMots=mot.split(\"'\")\n",
    "        result=\"'\".join([normaliserMajusculesMinuscules(m) for m in lMots])\n",
    "    elif len(mot)>1 and mot!=mot.lower() and mot!=mot.capitalize():\n",
    "        result=mot[0]+mot[1:].lower()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"d'E-st'Ogm\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliserMajusculesMinuscules(u\"d'E-St'OGM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduire les pronoms dans les phrases\n",
    "\n",
    "- clitiques verbaux entre dièses pour permettre l'inclusion en français et l'exclusion en kalaba\n",
    "  - Marie TAB #les# voyait TAB ,les enfants TAB TAB dans la cour\n",
    "    - FR: Les enfants, Marie les voyait dans la cour.\n",
    "    - KB: Marie voyait les enfants dans la cour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFr(line):\n",
    "    result=line\n",
    "    m=re.search(ur\"((\\w+)#\\S+#)\",result)\n",
    "    if m:\n",
    "        result=result.replace(m.group(1),m.group(2))\n",
    "        result=cleanFr(result)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'elles pensent \\xe0 lui'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFr(u\"elles#sorcières# pensent à lui#garçon#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortie=\"latex\"):\n",
    "    print sortie\n",
    "    phrasesLocales=phrase_file.readlines()\n",
    "    syntagmesLocaux=[]\n",
    "    numLignes=len(phrasesLocales)\n",
    "    numImages=1\n",
    "    numLignesVides=0\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    elif sortie==\"images\":\n",
    "        numImages=1\n",
    "        numLignesVides=0\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "        numLignesVides=0\n",
    "\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLigneNoPreview=\"\\\\\\\\\"*numLignesVides\n",
    "    finLignePreview=\"\\\\\\\\\"*numLignesVides+\"\\\\end{preview}\"\n",
    "    numLignes=(len(phrasesLocales)//numImages)*numImages\n",
    "\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrasesLocales[:numLignes]):\n",
    "        #phrase contient une position par fonction\n",
    "        #pour accueillir les équivalents kalabas des chunks français\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").replace(u\"’\",\" \").split(\"\\t\")\n",
    "        tampon=[t.strip() for t in tampon]\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug: \n",
    "            print \"===========================================\"            \n",
    "            print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "            print nPhrase,tampon\n",
    "            #\n",
    "            # Introduire les clitiques non-traités\n",
    "            # \n",
    "            # #les# voit \n",
    "            #\n",
    "            m=re.search(ur\"#.*#\\s*(.*)\",tampon[1])\n",
    "            if m:\n",
    "                verbe=m.group(1).split(\" \")\n",
    "            else:\n",
    "                verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            tempVerbe=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print tempVerbe\n",
    "            formeCitation=tempVerbe[0]\n",
    "            lexemesLocaux.add(formeCitation)\n",
    "            for element in tempVerbe[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            if len(tempVerbe)>1:\n",
    "                typeVerbe=tempVerbe[1]\n",
    "            else: \n",
    "                typeVerbe=\"\"\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    frObjetCas=\"\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            if debug: print (frSujetCas,frObjetCas,klbSujet)\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (\"FAIRE_GN SUJET\",localMots,(localClasses,localNombre,localCas))\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas,localNombre,localClasses,sujetVerbe\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            if len(tampon)>=3:\n",
    "                if tampon[2] and tampon[2].startswith(\",\"):\n",
    "                    tampon[2]=tampon[2][1:]\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe and localCas!=\"Nom\":\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                if tampon[3] and tampon[3].startswith(\",\"):\n",
    "                    tampon[3]=tampon[3][1:]\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=previewer(faire_gp(indirect,\"IND\"),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            ###################\n",
    "            #\n",
    "            # Modification pour ajouts multiples séparés par ;\n",
    "            # 24/11/19\n",
    "            #\n",
    "            ###################\n",
    "            if len(tampon)>=5:\n",
    "                if tampon[4] and tampon[4].startswith(\",\"):\n",
    "                    tampon[4]=tampon[4][1:]\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=previewer(multiplier_gp(comp),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=multiplier_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                if tampon[5] and tampon[5].startswith(\",\"):\n",
    "                    tampon[5]=tampon[5][1:]\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                if sortie==\"ordre\":\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=previewer(multiplier_gp(ajout),suffixe=\"{}\")\n",
    "                else:\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=multiplier_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "            noligFormeCitation=noligFormeCitation.replace(\"-\",\"\")\n",
    "\n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent)\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=previewer([glose],suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            lexemesLocaux.add(noligFormeCitation)\n",
    "            texte.append(glose)\n",
    "            if sortie in [\"latex\",\"traductions\"]: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            syntagmesBruts=[]\n",
    "            syntagmesEtiquetes=[]\n",
    "            for nMot,mot in enumerate(phrase):\n",
    "                if mot!=0:\n",
    "                    \n",
    "                    if isinstance(mot,basestring):\n",
    "                        syntagmeLocal=latex2ipa(mot)\n",
    "                    else:\n",
    "                        interFlat=[]\n",
    "                        for m in flatten(mot):\n",
    "                            mList=re.findall(ur\"\\\\[^{]+{}\",m)\n",
    "                            if mList:\n",
    "                                interFlat.extend(mList)\n",
    "                            else:\n",
    "                                interFlat.append(m)\n",
    "                        if debug: print \"interFlat\",interFlat\n",
    "                        if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                            interFlat.reverse()\n",
    "                        syntagmeLocal=separateurMots.join([latex2ipa(f) for f in interFlat])\n",
    "                    syntagmesBruts.append(syntagmeLocal)\n",
    "                    syntagmesEtiquetes.append(syntagmeLocal)\n",
    "                    if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                        syntagmesEtiquetes.append(syntagmes[\"Phrase\"][nMot])\n",
    "                    else:\n",
    "                        syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "#                    syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "                    printflat(mot,\"{}\")\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts[::-1])+\";\"+\" \".join(syntagmesEtiquetes[::-1])\n",
    "            else:\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            print ligneSyntagmesLocaux\n",
    "            syntagmesLocaux.append(ligneSyntagmesLocaux)\n",
    "            localAccumulateur=[accu for accu in accumulateur if accu!=\"\"]\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "                if sortie==\"images\":\n",
    "                    if nPhrase%numImages==0:\n",
    "                        prefixe=\"\\\\begin{preview}\"\n",
    "                    else:\n",
    "                        prefixe=\"\"\n",
    "                    if nPhrase%numImages==numImages-1:\n",
    "                        finLigne=finLignePreview\n",
    "                    else:\n",
    "                        finLigne=finLigneNoPreview\n",
    "                elif sortie==\"mots\":\n",
    "                    localAccumulateur=[debutLignePreview+accu+finLignePreview for accu in accumulateur if accu!=\"\"]\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(localAccumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\" and separateurMots==\"\":\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur[::-1])+finLigne)\n",
    "            else:\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortie in [\"latex\",\"traductions\"]:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortie in [\"latex\",\"traductions\"]: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            ##############\n",
    "            #\n",
    "            # Modification pour ajouts multiples\n",
    "            # suppression des ; de séparation dans la traduction\n",
    "            #\n",
    "            ##############\n",
    "            if \",\" in line:\n",
    "                consts=line.split(\"\\t\")\n",
    "                disloc=[]\n",
    "                canon=[]\n",
    "                for const in consts:\n",
    "                    if const.startswith(\",\"):\n",
    "                        if \";\" in const:\n",
    "                            subConsts=const.split(\";\")\n",
    "                            print \"##############@\"\n",
    "                            print subConsts\n",
    "                            disloc.append(subConsts[0][1:])\n",
    "                            for subConst in subConsts[1:]:\n",
    "                                canon.append(subConst.lstrip())\n",
    "                        else:\n",
    "                            disloc.append(const[1:])\n",
    "                    else:\n",
    "                        canon.append(const)\n",
    "                line=\",\\t\".join(disloc).strip()+\", \"+\"\\t\".join(canon)\n",
    "            if \" ; \" in line:\n",
    "                line=line.replace(\" ; \",\" \")\n",
    "            line=cleanFr(line)            \n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                element=element.strip(\"#\").replace(u\"’\",\"'\")\n",
    "                #\n",
    "                # Modification pour accepter les suffixes P et D à la fin des noms\n",
    "                # 31/5/21\n",
    "                #\n",
    "                if element[-2:] in [\"sP\",\"sD\"]:\n",
    "                    element=element[:-1]\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=normaliserMajusculesMinuscules(element)\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(caracteres)\n",
    "            if sortie==\"latex\": \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            elif sortie==\"images\":\n",
    "                ajouterExemple(marqueurCommentaire+\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "            elif sortie in [\"ordre\",\"mots\"]:\n",
    "                ajouterExemple(\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "                #if sortie==\"mots\": ajouterExemple(\"\\\\begin{preview}\"+\".\"+\"\\\\end{preview}\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortie==\"latex\" and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "            with codecs.open(serie+complementPhrases+\"Syntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in syntagmesLocaux:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "        elif (sortie==\"traductions\" and variante==\"-Corr\"):\n",
    "            with codecs.open(serie+complementPhrases+\"Traductions\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")            \n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "#    elif sortie==\"images\":\n",
    "#        with codecs.open(serie+complementPhrases+\"Images\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "#            for exemple in exemples:\n",
    "#                output.write(exemple+\"\\n\")\n",
    "    elif sortie in [\"images\",\"ordre\",\"mots\"]:\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "            for texHead in texHeader:\n",
    "                output.write(texHead+\"\\n\")\n",
    "            for exemple in exemples:\n",
    "                output.write(exemple+\"\\n\")\n",
    "    if sortie in [\"images\",\"traductions\",\"ordre\",\"mots\"]:\n",
    "        clozeTraductions=[]\n",
    "        clozeExemples=exemples[:]\n",
    "        filtreLignes=[\"\\\\begin{phrases}\",\"\\\\ex\",\"\\\\gloses\",\"\\\\end{phrases}\"]\n",
    "        if sortie==\"traductions\":\n",
    "            clozeExemples=[exemple for exemple in clozeExemples if (not exemple in filtreLignes) and not exemple.startswith(\"%\")]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(clozeExemples)]*3):\n",
    "            if sortie==\"traductions\" and 0:\n",
    "                print \"ortho\",orthoLigne\n",
    "                print \"phono\",phonoLigne\n",
    "                print \"trad\",tradLigne\n",
    "            phonoLigne=phonoLigne.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "            phonoLigne=phonoLigne.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "            phonoLigne=phonoLigne.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoMots=phonoLigne.strip(marqueurCommentaire).replace(finLignePreview,\"\").strip().split()\n",
    "            tradLigne=tradLigne.strip(marqueurCommentaire).replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")\n",
    "                if element==\"\\\\ex\": cleElement=\"\"\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print cleElement,phonoMots\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n",
    "        if sortie==\"ordre\" and separateurMots==\"\":\n",
    "            dictSyntagmes={}\n",
    "            dictTraductions={}\n",
    "            ordreCles=[]\n",
    "            for element in syntagmesLocaux:\n",
    "                clePhono,valSyntagmes=element.split(\";\")\n",
    "                dictSyntagmes[clePhono]=\" \".join([v for v in valSyntagmes.split() if not v in nomFonctions])\n",
    "                ordreCles.append(clePhono)\n",
    "            for element in clozeTraductions:\n",
    "                clePhono,valTrad,valMots=element.split(\";\")\n",
    "                dictTraductions[clePhono]=valTrad\n",
    "            morceauxPhrases=[\"%s;%s\"%(dictSyntagmes[c],dictTraductions[c]) for c in ordreCles]\n",
    "            with codecs.open(serie+complementPhrases+\"OrdreSyntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in morceauxPhrases:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'AJOUT', 'OBJ', 'COMP', 'IND', 'SUJ'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GADJ', 'NOM', 'DET', 'GP']}\n"
     ]
    }
   ],
   "source": [
    "sortie=\"traductions\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if traduction_nom.endswith(\"csv\") and variante!=\"-Corr\":\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the translation file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,sortie=sortie)\n",
    "            traduction_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'IND', 'COMP', 'OBJ', 'AJOUT', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['GP', 'DET', 'NOM', 'GADJ']}\n",
      "latex\n",
      "0 [u'une l\\xe9gende', u'raconte', u'l histoire des sorci\\xe8res du grand manoir']\n",
      "1 [u'la l\\xe9gende', u'compte', u'quatre sorci\\xe8res']\n",
      "2 [u'AgathoS', u'est', u'la fille de Freja']\n",
      "3 [u'Elphaba', u'est', u'la grande soeur de Freja']\n",
      "4 [u'Freja', u'est', u'la ma\\xeetresse du grand manoir']\n",
      "5 [u'Clemencia', u'd\\xe9testait', u'les enfants du village']\n",
      "6 [u'les trois sorci\\xe8res du grand manoir', u'portaient', u'des robes noires']\n",
      "7 [u'la sorci\\xe8re verte', u'change', u'les enfants', u'', u'en gargouilles']\n",
      "8 [u'AgathoS', u'poss\\xe8de', u'un chat noir']\n",
      "9 [u'les yeux noirs d AgathoS', u'jettent', u'des sortil\\xe8ges']\n",
      "10 [u'le chat noir', u'jetait', u'des sortil\\xe8ges', u'', u'', u'avec les yeux']\n",
      "12 [u'les crapauds du marais', u'd\\xe9testent', u'les villageois']\n",
      "13 [u'Hoderi', u'jette', u'des cailloux', u'', u'', u',dans le village \\xe0 c\\xf4t\\xe9 ; avec Clemencia']\n",
      "[[u'dans', u'le', u'village', u'\\xe0', u'c\\xf4t\\xe9'], [u'avec', u'Clemencia']]\n",
      "##############@\n",
      "[u',dans le village \\xe0 c\\xf4t\\xe9 ', u' avec Clemencia\\n']\n",
      "14 [u'les sorci\\xe8res', u'sont', u'des m\\xe9chantes cr\\xe9atures', u'', u'', u',pour les chasseurs']\n",
      "15 [u'le village', u'comptait', u'dE nombreuses disparitions']\n",
      "16 [u'quatre enfants', u'partirent', u'', u'', u'dans la for\\xeat']\n",
      "17 [u'les enfants', u'd\\xe9couvrirent', u'le manoir des sorci\\xe8res']\n",
      "18 [u'les trois sorci\\xe8res', u'jardinaient', u'', u'', u'', u',\\xe0 c\\xf4t\\xe9 des crapauds du marais']\n",
      "19 [u'les quatre enfants', u'jetaient', u'des cailloux', u'aux sorci\\xe8res']\n",
      "20 [u'les enfantsP', u'vol\\xe8rent', u'les l\\xe9gumes', u'aux sorci\\xe8res']\n",
      "21 [u'Elphaba', u'd\\xe9teste', u'les enfants']\n",
      "22 [u'les sorci\\xe8resP', u'chang\\xe8rent', u'les enfants', u'', u'en gargouilles']\n",
      "23 [u'la ma\\xeetresse du manoir', u'enferma', u'les gargouilles', u'', u'dans un donjon au milieu du manoir']\n",
      "24 [u'les chasseurs de sorci\\xe8res', u'prot\\xe9geaient', u'les enfants du village']\n",
      "25 [u'les chasseurs', u'cherchent', u'les enfantsP disparus', u'', u'', u'dans la nuit noire']\n",
      "26 [u'les sorci\\xe8resP', u'vol\\xe8rent', u'', u'', u'sur les balais']\n",
      "27 [u'elles#sorci\\xe8resP#', u'enlevaient', u'les enfants', u'', u'des villageois']\n",
      "ref nomSeul elles sorcièresP\n",
      "28 [u'les sorci\\xe8resP', u'jet\\xe8rent', u'un sortil\\xe8ge', u'aux villageois']\n",
      "29 [u'l obscurit\\xe9', u'surplombait', u'le village des chasseurs', u'', u'', u',avec le grimoire']\n",
      "30 [u'les trois femmes', u'changent', u'les l\\xe9gumes', u'', u'en cailloux']\n",
      "31 [u'les quatre chasseurs', u'partirent', u'', u'', u'dans la for\\xeat']\n",
      "32 [u'l obscurit\\xe9', u'cachait', u'le chemin']\n",
      "33 [u'les six hommes', u'dormirent', u'', u'', u'', u'\\xe0 c\\xf4t\\xe9 du marais']\n",
      "34 [u'l obscurit\\xe9', u'surplombe', u'le marais', u'', u'', u'au matin']\n",
      "35 [u'les hommes', u'cherchent', u'le grand marais du manoir des sorci\\xe8resP']\n",
      "36 [u'le chat noir', u'sortit', u'', u'', u'du grand manoir']\n",
      "37 [u'les chasseurs', u'entrent', u'', u'', u'dans le manoir des trois sorci\\xe8res']\n",
      "38 [u'Hoderi', u'prot\\xe8ge', u'Freja']\n",
      "39 [u'les deux sorci\\xe8res', u'cachent', u'le grimoire de Clemencia']\n",
      "40 [u'le chat noir d AgathoS', u'prot\\xe9geait', u'le grimoire du manoir']\n",
      "41 [u'Clemencia', u'dispara\\xeet', u'', u'', u'', u',dans le manoir']\n",
      "42 [u'Hoderi', u'\\xe9tait', u'', u'', u'dans le manoir']\n",
      "43 [u'un chasseur', u'cherche', u'les autres chasseurs']\n",
      "44 [u'Hoderi', u'cherchait', u'le donjon des enfantsP']\n",
      "45 [u'le chasseur', u'd\\xe9couvre', u'les enfantsP disparus']\n",
      "47 [u'Clemencia', u'vole', u'le grimoire', u'aux m\\xe9chantes sorci\\xe8res']\n",
      "48 [u'Elphaba', u'cherche', u'les deux chasseurs']\n",
      "49 [u'ils#chasseursD#', u'prot\\xe8gent', u'les gargouilles']\n",
      "ref nomSeul ils chasseursD\n",
      "50 [u'Elphaba', u'conna\\xeet', u'sept sortil\\xe8ges dans le grimoire']\n",
      "51 [u'la grande soeur de la m\\xe9chante sorci\\xe8re', u'courut', u'', u'', u'dans le marais']\n",
      "52 [u'Clemencia', u'jetait', u'Elphaba', u'', u'dans le marais']\n",
      "53 [u'le grand chasseur', u'noie', u'Elphaba']\n",
      "54 [u'Elphaba', u'meurt', u'', u'', u'', u'dans le marais vert']\n",
      "55 [u'la fille de Freja', u'hurla']\n",
      "57 [u'les deux sorci\\xe8res', u'pleurent', u'la mort d Elphaba']\n",
      "58 [u'Hoderi', u'cherchait', u'les deux sorci\\xe8res']\n",
      "59 [u'les six hommes', u'pr\\xe9parent', u'le b\\xfbcher']\n",
      "60 [u'la fille de Clemencia', u'pr\\xe9pare', u'les l\\xe9gumes']\n",
      "61 [u'AgathoS', u'partait', u'', u'', u'dans l obscurit\\xe9 de la for\\xeat', u',avec un balai']\n",
      "62 [u'les quatre p\\xe8res', u'enfermaient', u'la sorci\\xe8re']\n",
      "63 [u'les deux chasseurs', u'allument', u'un grand feu']\n",
      "64 [u'la peau verte de Freja', u'br\\xfble', u'', u'', u'', u'sur le b\\xfbcher']\n",
      "65 [u'Freja', u'hurlait', u'', u'', u'', u',sur le b\\xfbcher ; de douleur']\n",
      "[[u'sur', u'le', u'b\\xfbcher'], [u'de', u'douleur']]\n",
      "##############@\n",
      "[u',sur le b\\xfbcher ', u' de douleur\\n']\n",
      "66 [u'la m\\xe8re d AgathoS', u'fuit', u'le b\\xfbcher']\n",
      "67 [u'la ma\\xeetresse du manoir', u'fuyait', u'les chasseursD', u'', u'', u',dans la nuit noire']\n",
      "68 [u'AgathoS', u'rejoint', u'Freja', u'', u'dans la for\\xeat']\n",
      "69 [u'les deux sorci\\xe8res', u'disparurent', u'', u'', u'dans la for\\xeat', u',dans l obscurit\\xe9']\n",
      "70 [u'les six hommes', u'cherch\\xe8rent', u'les sorci\\xe8resD']\n",
      "71 [u'la nuit', u'noyait', u'le chemin', u'', u'des deux sorci\\xe8res', u'dans l obscurit\\xe9 de la for\\xeat']\n",
      "73 [u'les p\\xe8res', u'embrass\\xe8rent', u'les enfantsP']\n",
      "74 [u'les villageois', u'rejoignirent', u'le village', u'', u'dans la nuit noire']\n",
      "75 [u'les chasseurs', u'rejoignirent', u'le village', u'', u'en h\\xe9ros']\n",
      "76 [u'les villageois', u'remerci\\xe8rent', u'les chasseurs de sorci\\xe8res']\n",
      "77 [u'les chasseurs', u'sont', u'des h\\xe9ros']\n",
      "78 [u'les enfantsP', u'pleur\\xc8RENT', u'', u'', u'', u',dans les bras des parents']\n",
      "79 [u'les villageois', u'nourrissent', u'les h\\xe9ro\\xefques chasseurs', u'', u'', u'avec les derniers l\\xe9gumes du village']\n",
      "80 [u'les l\\xe9gumes', u'sont', u'les dernIERs du village']\n",
      "81 [u'le village', u'dort']\n",
      "82 [u'les villageois', u'dorment', u'', u'', u'dans le village']\n",
      "83 [u'les deux h\\xe9ros', u'br\\xfbl\\xe8rent', u'le grand manoir']\n",
      "84 [u'les sorci\\xe8resD', u'voient', u'le manoir en feu', u'', u',dans la for\\xeat']\n",
      "85 [u'AgathoS', u'survole', u'le manoir en feu', u'', u'', u'avec un  balais']\n",
      "86 [u'les deux sorci\\xe8res', u'cherchent', u'le grimoire', u'', u'au village']\n",
      "87 [u'elles#sorci\\xe8resD#', u'volent', u'le livre des sortil\\xe8ges', u'aux chasseursD']\n",
      "ref nomSeul elles sorcièresD\n",
      "88 [u'les voleusesD', u'retournent', u'', u'', u'au manoir en feu']\n",
      "89 [u'Freja', u'change', u'le chat noir d AgathoS', u'', u'en enfant']\n",
      "90 [u'AgathoS', u'interroge', u'le livre des sortil\\xe8ges', u'', u'', u'pour l esprit d Elphaba']\n",
      "91 [u'un sortil\\xe8ge', u'ressuscite', u'Elphaba', u'', u'dans le marais du manoir']\n",
      "92 [u'les crapauds verts', u'voient', u'les sortil\\xe8ges des sorci\\xe8res']\n",
      "93 [u'le chat noir', u'entre', u'', u'', u'dans le village des chasseurs']\n",
      "94 [u'les enfants', u'accueillent', u'le chat noir']\n",
      "95 [u'l enfant en robe noire', u'jette', u'des cailloux', u'aux villageois', u'', u'dans l obscurit\\xe9']\n",
      "96 [u'un villageoiS', u'compte', u'les cailloux de l enfant']\n",
      "97 [u'il#villageoiS#', u'hurle', u'', u'sur l enfant']\n",
      "ref nomSeul il villageoiS\n",
      "98 [u'l enfant', u'pleure', u'', u'', u'', u'dans le village']\n",
      "99 [u'les sorci\\xe8resP', u'surplombent', u'le village', u'', u'', u',sur des balais']\n",
      "100 [u'les trois sorci\\xe8res', u'allum\\xe8rent', u'un feu', u'', u'sur la place ; au milieu du village']\n",
      "[[u'sur', u'la', u'place'], [u'au', u'milieu', u'du', u'village']]\n",
      "101 [u'les villageois', u'pleurAIENT']\n",
      "102 [u'la lumi\\xe8re', u'manque', u'', u'au village']\n",
      "103 [u'Elphaba', u'allume', u'un b\\xfbcher', u'', u'', u'par esprit de vengeance ; pour les chasseurs']\n",
      "[[u'par', u'esprit', u'de', u'vengeance'], [u'pour', u'les', u'chasseurs']]\n",
      "104 [u'AgathoS', u'attrape', u'Hoderi']\n",
      "105 [u'Clemencia', u'interroge', u'les sorci\\xe8res', u'', u'', u'sur la raison de la vengeance']\n",
      "107 [u'Clemencia', u'reconna\\xeet', u'la troisi\\xe8me sorci\\xe8re']\n",
      "108 [u'AgathoS', u'tourne', u'', u'', u'', u'avec la robe noire']\n",
      "109 [u'une tornade', u'fait', u'des d\\xe9g\\xe2ts', u'', u'dans le village']\n",
      "110 [u'Hoderi', u'hurla']\n",
      "111 [u'la ma\\xeetresse du manoir en feu', u'arr\\xeate', u'le feu']\n",
      "112 [u'la tornade', u'dispara\\xeet', u'', u'', u'au milieu des femmes villageoises']\n",
      "113 [u'les trois sorci\\xe8res', u'descendent', u'', u'', u'des balais', u'dans la nuit']\n",
      "114 [u'Elphaba', u'pr\\xe9sente', u'les raisons des d\\xe9g\\xe2ts dans le village']\n",
      "115 [u'le chat noir d AgathoS', u'redevient', u'un chat', u'', u'', u'aux yeux du village']\n",
      "116 [u'des femmes', u'pouss\\xe8rent', u'des hurlements', u'', u'', u'en raison du sortil\\xe8ge']\n",
      "117 [u'les sorci\\xe8res', u'demandent', u'des excuses', u'aux villageoises']\n",
      "118 [u'les enfants', u'#les# d\\xe9testent', u'les l\\xe9gumes des sorci\\xe8res']\n",
      "119 [u'les m\\xe8resP des m\\xe9chants enfantsP', u'attrap\\xe8rent', u'les gargouillesP']\n",
      "120 [u'les sept femmes', u'demandent', u'des excuses', u'aux m\\xe9chants enfantsP']\n",
      "121 [u'les enfantsP', u'pr\\xe9sentent', u'des excuses', u'aux sept femmes', u'au milieu du village']\n",
      "122 [u'les hommes', u'firent', u'un vote']\n",
      "123 [u'l obscurit\\xe9', u'fit', u'place', u'\\xe0 la lumi\\xe8re']\n",
      "124 [u'les sorci\\xe8resP', u'chang\\xe8rent', u'les cailloux des jardins des villageois', u'', u'en l\\xe9gumes']\n",
      "125 [u'les d\\xe9g\\xe2ts dans le village', u'disparaissent', u'', u'', u'', u'avec l obscurit\\xe9']\n",
      "126 [u'les sorci\\xe8resP', u'sortent', u'', u'', u'du village']\n",
      "127 [u'elles#sorci\\xe8resP#', u'revinrent', u'', u'', u'vers les chasseurs ; en balais', u'avec des l\\xe9gumes']\n",
      "ref nomSeul elles sorcièresP\n",
      "[[u'vers', u'les', u'chasseurs'], [u'en', u'balais']]\n",
      "128 [u'les villageois', u'\\xe9changent', u'des l\\xe9gumes', u'', u'', u'avec elles#sorci\\xe8resP#']\n",
      "ref nomSeul elles sorcièresP\n",
      "129 [u'les hommes du village', u'reconstruisent', u'le manoir']\n",
      "130 [u'les sorci\\xe8res', u'interrogent', u'Elphaba', u'', u'sur la demande des hommes']\n",
      "131 [u'les deux chasseurs', u'partirent', u'', u'', u'', u'vers le manoir']\n",
      "132 [u'le vote des hommes', u'compte', u'', u'', u'', u'pour le village']\n",
      "133 [u'la nouvELLE', u'fait', u'des lumi\\xe8res', u'', u'dans les yeux noirs d AgathoS']\n",
      "134 [u'les sorci\\xe8resP', u'coururent', u'', u'', u'\\xe0 la construction du manoir de Freja']\n",
      "135 [u'le villageoiS', u'mange', u'des l\\xe9gumes', u'', u'', u'dans le manoir des sorci\\xe8res']\n",
      "136 [u'les sorci\\xe8res', u'remerci\\xe8rent', u'les villageois']\n",
      "137 [u'les trois femmes', u'\\xe9chang\\xe8rent', u'les m\\xe9chants enfantsP du village en crapauds du marais']\n",
      "138 [u'les parents', u'eurent', u'des nouveaux enfants']\n",
      "139 [u'la nouvelle harmonie', u'change', u'les parents']\n",
      "140 [u'les villageois', u'mangent', u'des l\\xe9gumes', u'', u'', u'avec les sorci\\xe8resP']\n",
      "141 [u'les deux chasseurs de sorci\\xe8res', u'chassent', u'les m\\xe9chants enfants des autres villages']\n",
      "143 [u'les crapauds du marais', u'pleurent', u'les parents du village', u'', u'', u',pendant la nuit']\n",
      "144 [u'ils#crapauds#', u'mangent', u'des cailloux', u'', u'', u',au lever du jour']\n",
      "ref nomSeul ils crapauds\n",
      "146 [u'le village', u'vit', u'', u'', u'en harmonie avec les sorci\\xe8res']\n",
      "147 [u'les villageois', u'racontent', u'la l\\xe9gende', u'aux enfants']\n",
      "148 [u'le manoir', u'fait', u'une lumi\\xe8re', u'', u',dans la nuit']\n"
     ]
    }
   ],
   "source": [
    "sortie=\"latex\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file,sortie=sortie)\n",
    "phrase_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"Phrases-Clozes\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['SUJ', 'IND', 'COMP', 'OBJ', 'AJOUT', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['GP', 'DET', 'NOM', 'GADJ']}\n",
      "I could not open the file /Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/21-K5/Ecrit.csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sortie=\"images\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if ecriture_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        ecriture_file = codecs.open(ecriture_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', ecriture_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            ecriture={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    ecriture[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(ecriture_file,sortie=sortie)\n",
    "            ecriture_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortie=\"ordre\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if ordre_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        ordre_file = codecs.open(ordre_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', ordre_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            ordre={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    ordre[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(ordre_file,sortie=sortie)\n",
    "            ordre_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortie=\"mots\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if mots_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        mots_file = codecs.open(mots_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', mots_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            motsIsoles={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    motsIsoles[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(mots_file,sortie=sortie)\n",
    "            mots_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "if variante==\"\": \n",
    "    print \"faire la correction\"\n",
    "    nextVariante=\"-Corr\"\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "else:\n",
    "    print u\"ok pour cette étape\"\n",
    "    del nextVariante\n",
    "    ding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFM.lexique.formeLexeme[\"trois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py27)",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
