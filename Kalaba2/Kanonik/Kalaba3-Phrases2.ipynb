{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problèmes et Extensions\n",
    "\n",
    "## Problèmes\n",
    "- javascript runs fail\n",
    "- faire de nouvelles sorties pour les kalabas sans séparateurs de mots\n",
    " - radicaux seuls\n",
    " - découpage en syntagmes pour l'exercice sur l'ordre des syntagmes\n",
    "\n",
    "## Extensions\n",
    "- traitement du paucal\n",
    " - 2,3,4,5 ou suffixe P sur le nom sans numéral\n",
    "- ajout des compléments/ajouts multiples\n",
    " - séparation par ;\n",
    " - gestion des dislocations gauches dans les multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javascript from :\n",
    "https://stackoverflow.com/questions/12544056/how-to-i-get-the-current-ipython-notebook-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalaba3-Phrases2\n"
     ]
    }
   ],
   "source": [
    "print(theNotebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestion partagée des numéros à traiter & gestion des variantes\n",
    "\n",
    "Le block suivant permet de partager les numéros à traiter entre les différents Notebooks.\n",
    "- %store -r variable lit la variable dans le stock\n",
    "- %store variable stocke la variable\n",
    "\n",
    "Après la réussite de la variante de base, on change automatiquement la variante à -Corr pour générer les fichiers de solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "21-K4\n"
     ]
    }
   ],
   "source": [
    "# numerosKalaba=[4]\n",
    "# %store numerosKalaba\n",
    "%store -r numerosKalaba\n",
    "variante=\"\"\n",
    "if 'nextVariante' in globals():\n",
    "    variante=nextVariante\n",
    "print variante\n",
    "numeroKalaba=\"21-K%d\"%numerosKalaba[0]\n",
    "print numeroKalaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "def ding():\n",
    "    os.system('afplay /System/Library/Sounds/Submarine.aiff')\n",
    "    \n",
    "    \n",
    "from os.path import expanduser\n",
    "#from cellbell import ding\n",
    "from itertools import groupby\n",
    "home = expanduser(\"~\")\n",
    "serie=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/00-ProjetKalaba/%s/\"%numeroKalaba\n",
    "complementPhrases=\"\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml, warnings\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle,copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "séparateur  \n"
     ]
    }
   ],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=0\n",
    "\n",
    "#casNombreDet=True\n",
    "RightLeft=True\n",
    "\n",
    "if (numerosKalaba[0] in [3,5]) and variante==\"\":\n",
    "    separateurPhonoCloze=\"\"\n",
    "else:\n",
    "    separateurPhonoCloze=\" \"\n",
    "# separateurPhonoCloze=\" \"    \n",
    "separateurMots=separateurPhonoCloze\n",
    "print \"séparateur\",separateurMots\n",
    "#separateurMots=\" \"\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False        #False\n",
    "print_radicaux=False     #False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.safe_load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.safe_load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.safe_load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.safe_load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Gloses.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\columnbreak\\\\vfill\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Nom\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cas', 'Genre', 'Nombre', 'Pers', 'Temps'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOM', 'VER', 'ADJ', 'PRO', 'DET']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'DET': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'NOM': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'PRO': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False},\n",
       " 'VER': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': False,\n",
       "  'Pers': True,\n",
       "  'Temps': True}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'SUJ', 'OBJ', 'COMP', 'IND', 'AJOUT'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GP', 'GADJ', 'NOM', 'DET']}\n"
     ]
    }
   ],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]\n",
    "syntagmesLR=copy.deepcopy(syntagmes)\n",
    "print syntagmesLR\n",
    "syntagmesRL=copy.deepcopy(syntagmes)\n",
    "for element in syntagmesRL:\n",
    "    syntagmesRL[element].reverse()\n",
    "nomFonctions=syntagmes[\"Phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LR',\n",
       " {'GADJ': ['ADV', 'ADJ', 'GP'],\n",
       "  'GN': ['GP', 'GADJ', 'NOM', 'DET'],\n",
       "  'GP': ['GN', 'PREP'],\n",
       "  'Phrase': ['VER', 'SUJ', 'OBJ', 'COMP', 'IND', 'AJOUT']},\n",
       " 'RL',\n",
       " {'GADJ': ['GP', 'ADJ', 'ADV'],\n",
       "  'GN': ['DET', 'NOM', 'GADJ', 'GP'],\n",
       "  'GP': ['PREP', 'GN'],\n",
       "  'Phrase': ['AJOUT', 'IND', 'COMP', 'OBJ', 'SUJ', 'VER']})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"LR\",syntagmesLR, \"RL\",syntagmesRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS', 'PST', '3Sg', '3Pau', '3Pl', 'HUM', 'ANIM', 'INAN']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableaux des formes utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellules={c:set() for c in \"NOM VER ADJ DET PRO\".split(\" \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduire les pronoms kalaba\n",
    "- identifier qu'il s'agit d'un pronom\n",
    "- parser le référent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounNumber(nom,nombre):\n",
    "    if nom[len(nom)-1] in [\"s\",\"x\"]:\n",
    "        if nombre==\"\": nombre=\"PL\"\n",
    "    elif nom[len(nom)-1] in [\"P\",\"D\"]:\n",
    "        if nombre==\"\": \n",
    "            if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"PAU\"\n",
    "            elif \"Du\" in valAttributs[\"Nombre\"] and nom[len(nom)-1]==\"D\":\n",
    "                nombre=\"DU\"\n",
    "            else:\n",
    "                nombre=\"PL\"\n",
    "    else:\n",
    "        if nombre==\"\": nombre=\"SG\"\n",
    "    return nombre\n",
    "\n",
    "def getNounGender(ref):\n",
    "    nom=ref.rstrip(\"P\").rstrip(\"D\")\n",
    "    nomLexeme=PFM.lexique.formeLexeme[nom][0]\n",
    "    classesNom=nomLexeme.split('.')[1:]\n",
    "    print classesNom\n",
    "    proGender=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "    return proGender, classesNom\n",
    "\n",
    "\n",
    "def getRef(pronom):\n",
    "    m=re.match(\"^(.*)#(.*)#\",pronom)\n",
    "    if m:\n",
    "        pro=m.group(1)\n",
    "        ref=m.group(2)\n",
    "    else:\n",
    "        print \"mauvaise notation pour un pronom\"\n",
    "        pro=\"\"\n",
    "        ref=\"\"\n",
    "    return pro,ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'HUM', u'N1']\n",
      "elles PRO PAU fillesD PAU HUM\n"
     ]
    }
   ],
   "source": [
    "pro,ref=getRef(u\"elles#fillesD#\")\n",
    "proNum=getNounNumber(ref,nombre=\"\")\n",
    "proGen,proClasse=getNounGender(ref)\n",
    "nomLexeme=PFM.lexique.formeLexeme[pro][0]\n",
    "print pro, nomLexeme, proNum, ref, proNum, proGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_gn(depart,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom=[]\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        if not \"#\" in mot:\n",
    "            groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    pro=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    if len(groupe_nom)==1:\n",
    "#         print \"Pronom ?\",groupe_nom\n",
    "        nomSeul=groupe_nom[0]\n",
    "        boolPro=(\"#\" in nomSeul)\n",
    "    else:\n",
    "        boolPro=False\n",
    "    if boolPro:\n",
    "        proForm,proRef=getRef(nomSeul)\n",
    "        nomLexeme=PFM.lexique.formeLexeme[proForm][0]\n",
    "        print \"ref nomSeul\",proForm,proRef\n",
    "        nombre=getNounNumber(proRef,nombre=\"\")\n",
    "        classe,classesNom=getNounGender(proRef)\n",
    "        pro.append(nomLexeme)\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "            cas=\"\"\n",
    "#                    else:\n",
    "        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "        cellules[\"PRO\"].add(\".\".join([nomLexeme,classe.capitalize(),nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "        if debug or 0:\n",
    "            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "        if cas==\"ERG\":\n",
    "            erg_genre=classe\n",
    "            erg_nombre=nombre\n",
    "            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "        elif cas==\"ABS\":\n",
    "            abs_genre=classe\n",
    "            abs_nombre=nombre\n",
    "            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for mot in groupe_nom:\n",
    "            if reste==0:\n",
    "    #            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "                if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                    nombre=\"DU\"\n",
    "                    if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                else:\n",
    "                    if \"Pau\" in valAttributs[\"Nombre\"] and mot in \"deux trois quatre cinq\".split():\n",
    "                        nombre=\"PAU\"\n",
    "                        if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "                    if mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot[:-1]][0]\n",
    "                    else:\n",
    "                        nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                    categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                    if debug or 0: \n",
    "                        print \"mot\",[mot]\n",
    "                        print \"vedette\",nomLexeme,categorie\n",
    "                        print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                    if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                        tete=categorie\n",
    "                        if debug or 0: print \"tête :\", tete\n",
    "                        tampon=tete.split('.')\n",
    "    #                    classe=tampon[0]\n",
    "                        classesNom=nomLexeme.split('.')[1:]\n",
    "                        if debug or 0: print \"classesNom\",classesNom \n",
    "                        classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                        if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                        try:\n",
    "                            typeMot=tampon[1]\n",
    "                        except IndexError:\n",
    "                            typeMot=''\n",
    "                        # modif pour les mots à pluriels en x\n",
    "                        # 23/11/19\n",
    "                        #\n",
    "                        nombre=getNounNumber(mot,nombre)\n",
    "#                         if mot[len(mot)-1] in [\"s\",\"x\"]:\n",
    "#                             if nombre==\"\": nombre=\"PL\"\n",
    "#                         elif mot[len(mot)-1] in [\"P\",\"D\"]:\n",
    "#                             if nombre==\"\":\n",
    "#                                 # modif pour permettre le pluriel dans les cas où il n'y a pas de paucal.\n",
    "#                                 # 30/5/21\n",
    "#                                 #\n",
    "#                                 if \"Pau\" in valAttributs[\"Nombre\"]:\n",
    "#                                     nombre=\"PAU\"\n",
    "#                                 elif \"Du\" in valAttributs[\"Nombre\"] and mot[len(mot)-1]==\"D\":\n",
    "#                                     nombre=\"DU\"\n",
    "#                                 else:\n",
    "#                                     nombre=\"PL\"\n",
    "#                         else:\n",
    "#                             if nombre==\"\": nombre=\"SG\"\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre\n",
    "\n",
    "                        nom.append(nomLexeme)\n",
    "    #                    if typeCas==\"NoCas\":\n",
    "    #                        cas=\"\"\n",
    "                        if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                            cas=\"\"\n",
    "    #                    else:\n",
    "                        cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                        cellules[\"NOM\"].add(\".\".join([nomLexeme,nombre.capitalize(),cas.capitalize()]).strip(\".\"))\n",
    "                        if debug or 0:\n",
    "                            print mot,nomLexeme,nombre,cellule\n",
    "\n",
    "\n",
    "                        if cas==\"ERG\":\n",
    "                            erg_genre=classe\n",
    "                            erg_nombre=nombre\n",
    "                            if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                        elif cas==\"ABS\":\n",
    "                            abs_genre=classe\n",
    "                            abs_nombre=nombre\n",
    "                            if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"DET\"]:\n",
    "                        det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "    #                elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    elif PFM.hierarchieCF.getCategory(categorie) in [\"ADJ\"]:\n",
    "                        adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                    elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                        gp.append(mot)\n",
    "                        reste=1\n",
    "            else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "                gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det and not boolPro: \n",
    "        if nom[0][0]==nom[0][0].upper():\n",
    "            det.append(PFM.lexique.formeLexeme[\"les\"][0])\n",
    "        else:\n",
    "            det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "\n",
    "    tempSyntagme=[]\n",
    "\n",
    "    if pro:\n",
    "        for mot in pro:\n",
    "    #\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "            noligMot=mot.split(\".\")[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            #\n",
    "            # traitement des noms propres avec tiret\n",
    "            # traitement des noms paucals sans ordinaux\n",
    "            #\n",
    "            if \"-\" in noligMot:\n",
    "                noLigs=noligMot.split(\"-\")\n",
    "                if len(noLigs)>1:\n",
    "                    noligMot=noLigs[0]+\"\".join([c for c in noLigs[1:]])\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "    #        mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot)\n",
    "            texte.append(ref)\n",
    "            tempSyntagme.append(ref)\n",
    "        structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "        mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "        \n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            print \"pas de nombre\"\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "#             print mot,casDet,nombreDet\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        cellules[\"DET\"].add(\".\".join([mot,classeDet,nombreDet,casDet]).strip(\".\"))\n",
    "\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        cellules[\"ADJ\"].add(\".\".join([mot,classeAdj,nombreAdj,casAdj]).strip(\".\"))\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        #\n",
    "        # traitement des noms propres avec tiret\n",
    "        # traitement des noms paucals sans ordinaux\n",
    "        #\n",
    "        if \"-\" in noligMot:\n",
    "            noLigs=noligMot.split(\"-\")\n",
    "            if len(noLigs)>1:\n",
    "                noligMot=noLigs[0]+\"\".join([c.lower() for c in noLigs[1:]])\n",
    "#         noligMot=noligMot.replace(\"-\",\"\")    \n",
    "        if noligMot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        lexemesLocaux.add(noligMot)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    if debug or 0:\n",
    "        print \"fin faire_gn\",listeMots\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/14529523/python-split-for-lists\n",
    "\n",
    "l = [\"data\",\"more data\",\";\",\"data 2\",\"more data 2\",\"danger\",\";\",\"date3\",\"lll\"]\n",
    "[list(group) for k, group in groupby(l, lambda x: x == \";\") if not k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplier_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    lGroupes=[list(group) for k, group in groupby(groupe_prep, lambda x: x == \";\") if not k]\n",
    "    if len(lGroupes)>1:\n",
    "        print lGroupes\n",
    "    for lGp in lGroupes:\n",
    "        mots.extend(faire_gp(lGp,fonction))\n",
    "    return mots\n",
    "    \n",
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", groupe_prep\n",
    "    formePreposition=groupe_prep[0]\n",
    "    if debug: print [formePreposition], formePreposition\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        noligMot=groupe_prep[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        noligMot=noligMot.replace(\"-\",\"\")\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        \n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                lexemesLocaux.add(noligMot.upper())\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print ref\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            lexemesLocaux.add(noligMot.upper())\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else:\n",
    "#        if \"{preview}\" in liste:\n",
    "#            print \"preview\",prefixe,liste,suffixe\n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "texHeader=[]\n",
    "version=theNotebook\n",
    "texHeader.append(\"%% script : \"+version)\n",
    "texHeader.append('%%%% run : %s' % time.strftime(\"%y%m%d-%H%M\"))\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    ecriture_nom=serie+complementPhrases+\"Ecrit.csv\"\n",
    "    ordre_nom=serie+complementPhrases+\"Ordre.csv\"\n",
    "    mots_nom=serie+complementPhrases+\"Mots.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\"\n",
    "    if len(args)>=4:\n",
    "        ecriture_nom=args[3]\n",
    "    else:\n",
    "        ecriture_nom=\"\"\n",
    "    if len(args)>=5:\n",
    "        ordre_nom=args[4]\n",
    "    else:\n",
    "        ordre_nom=\"\"\n",
    "    if len(args)>=6:\n",
    "        mots_nom=args[5]\n",
    "    else:\n",
    "        mots_nom=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrerCloze(filtre):\n",
    "    result=[]\n",
    "    for ligne in clozeLines:\n",
    "        if type(ligne)==str:\n",
    "            ligne=unicode(ligne.decode('utf8'))\n",
    "        ligne=ligne.strip()\n",
    "        if not ligne.startswith(\"#\"):\n",
    "            clozeElements=ligne.split(\";\")\n",
    "            if clozeElements[1] in filtre:\n",
    "                result.append(ligne)\n",
    "        else:\n",
    "            result.append(ligne)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if not isinstance(item, basestring):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewerBegin=\"\\\\begin{preview}\\\\begin{flushleft}\"\n",
    "previewerEnd=\"\\\\end{flushleft}\\\\end{preview}\"\n",
    "def latex2ipa(mot):\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLignePreview=\"\\\\end{preview}\"\n",
    "    if \" \" in mot:\n",
    "        result=[]\n",
    "        for element in mot.split():\n",
    "            result.append(latex2ipa(element))\n",
    "        return separateurMots.join(result)\n",
    "    else:\n",
    "        mot=mot.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "    #    print mot\n",
    "        mot=mot.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "    #    print mot\n",
    "        element=mot.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "    #    print element\n",
    "        cleElement=element.strip().strip(\"\\\\{}\")\n",
    "    #    print cleElement\n",
    "        if element==\"\\\\ex\": cleElement=\"\"\n",
    "        if cleElement:\n",
    "            if not cleElement in traductions: \n",
    "                print cleElement\n",
    "                print traductions\n",
    "                warnings.warn(\"pas de transcription pour %s\"%cleElement,mot)\n",
    "                return None\n",
    "            else:\n",
    "                return traductions[cleElement]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex2ipa(\"\\\\begin{preview}\\\\DEFMSg{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previewer(chaine,numLignesVides=0,suffixe=\"\"):\n",
    "    flatChaine=[mot+suffixe for mot in list(flatten(chaine))]\n",
    "    result=previewerBegin+separateurMots.join(flatChaine)+\"\\\\\\\\\"*numLignesVides+previewerEnd\n",
    "    return [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "texteMots=set()\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PFM.lexique.lexemes[\"construire\"].formes.index(\"construisit\")\n",
    "valAttributs[\"Genre\"]\n",
    "localClasses=[\"N\"]\n",
    "[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "localCas=\"Nom\"\n",
    "not localCas or localCas in sujetVerbe\n",
    "sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliserMajusculesMinuscules(mot):\n",
    "    result=mot\n",
    "    if \"'\" in mot:\n",
    "        lMots=mot.split(\"'\")\n",
    "        result=\"'\".join([normaliserMajusculesMinuscules(m) for m in lMots])\n",
    "    elif len(mot)>1 and mot!=mot.lower() and mot!=mot.capitalize():\n",
    "        result=mot[0]+mot[1:].lower()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"d'E-st'Ogm\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliserMajusculesMinuscules(u\"d'E-St'OGM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduire les pronoms dans les phrases\n",
    "\n",
    "- clitiques verbaux entre dièses pour permettre l'inclusion en français et l'exclusion en kalaba\n",
    "  - Marie TAB #les# voyait TAB ,les enfants TAB TAB dans la cour\n",
    "    - FR: Les enfants, Marie les voyait dans la cour.\n",
    "    - KB: Marie voyait les enfants dans la cour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFr(line):\n",
    "    result=line\n",
    "    m=re.search(ur\"((\\w+)#\\S+#)\",result)\n",
    "    if m:\n",
    "        result=result.replace(m.group(1),m.group(2))\n",
    "        result=cleanFr(result)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'elles pensent \\xe0 lui'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanFr(u\"elles#sorcières# pensent à lui#garçon#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortie=\"latex\"):\n",
    "    print sortie\n",
    "    phrasesLocales=phrase_file.readlines()\n",
    "    syntagmesLocaux=[]\n",
    "    numLignes=len(phrasesLocales)\n",
    "    numImages=1\n",
    "    numLignesVides=0\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    elif sortie==\"images\":\n",
    "        numImages=1\n",
    "        numLignesVides=0\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "        numLignesVides=0\n",
    "\n",
    "    debutLignePreview=\"\\\\begin{preview}\"\n",
    "    finLigneNoPreview=\"\\\\\\\\\"*numLignesVides\n",
    "    finLignePreview=\"\\\\\\\\\"*numLignesVides+\"\\\\end{preview}\"\n",
    "    numLignes=(len(phrasesLocales)//numImages)*numImages\n",
    "\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrasesLocales[:numLignes]):\n",
    "        if debug: print nPhrase,line\n",
    "        #phrase contient une position par fonction\n",
    "        #pour accueillir les équivalents kalabas des chunks français\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").replace(u\"’\",\" \").split(\"\\t\")\n",
    "        tampon=[t.strip() for t in tampon]\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug: \n",
    "            print \"===========================================\"            \n",
    "            print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "#             print nPhrase,tampon\n",
    "            #\n",
    "            # Introduire les clitiques non-traités\n",
    "            # \n",
    "            # #les# voit \n",
    "            #\n",
    "            m=re.search(ur\"#.*#\\s*(.*)\",tampon[1])\n",
    "            if m:\n",
    "                verbe=m.group(1).split(\" \")\n",
    "            else:\n",
    "                verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            tempVerbe=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print tempVerbe\n",
    "            formeCitation=tempVerbe[0]\n",
    "            lexemesLocaux.add(formeCitation)\n",
    "            for element in tempVerbe[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            if len(tempVerbe)>1:\n",
    "                typeVerbe=tempVerbe[1]\n",
    "            else: \n",
    "                typeVerbe=\"\"\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    frObjetCas=\"\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            if debug: print (frSujetCas,frObjetCas,klbSujet)\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (\"FAIRE_GN SUJET\",localMots,(localClasses,localNombre,localCas))\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas,localNombre,localClasses,sujetVerbe\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            if len(tampon)>=3:\n",
    "                if tampon[2] and tampon[2].startswith(\",\"):\n",
    "                    tampon[2]=tampon[2][1:]\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=previewer(localMots,suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe and localCas!=\"Nom\":\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                if tampon[3] and tampon[3].startswith(\",\"):\n",
    "                    tampon[3]=tampon[3][1:]\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=previewer(faire_gp(indirect,\"IND\"),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            ###################\n",
    "            #\n",
    "            # Modification pour ajouts multiples séparés par ;\n",
    "            # 24/11/19\n",
    "            #\n",
    "            ###################\n",
    "            if len(tampon)>=5:\n",
    "                if tampon[4] and tampon[4].startswith(\",\"):\n",
    "                    tampon[4]=tampon[4][1:]\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    if sortie==\"ordre\":\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=previewer(multiplier_gp(comp),suffixe=\"{}\")\n",
    "                    else:\n",
    "                        phrase[syntagmes['Phrase'].index('COMP')]=multiplier_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                if tampon[5] and tampon[5].startswith(\",\"):\n",
    "                    tampon[5]=tampon[5][1:]\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                if sortie==\"ordre\":\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=previewer(multiplier_gp(ajout),suffixe=\"{}\")\n",
    "                else:\n",
    "                    phrase[syntagmes['Phrase'].index('AJOUT')]=multiplier_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "            noligFormeCitation=noligFormeCitation.replace(\"-\",\"\")\n",
    "\n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent)\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            cellules[\"VER\"].add(\".\".join([verbeLexeme,morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize(),nombrePersonne,classeVerbe,nombreVerbe]).strip(\".\"))\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            if sortie==\"ordre\":\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=previewer([glose],suffixe=\"{}\")\n",
    "            else:\n",
    "                phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            lexemesLocaux.add(noligFormeCitation)\n",
    "            texte.append(glose)\n",
    "            if sortie in [\"latex\",\"traductions\"]: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            syntagmesBruts=[]\n",
    "            syntagmesEtiquetes=[]\n",
    "            for nMot,mot in enumerate(phrase):\n",
    "                if mot!=0:\n",
    "                    \n",
    "                    if isinstance(mot,basestring):\n",
    "                        syntagmeLocal=latex2ipa(mot)\n",
    "                    else:\n",
    "                        interFlat=[]\n",
    "                        for m in flatten(mot):\n",
    "                            mList=re.findall(ur\"\\\\[^{]+{}\",m)\n",
    "                            if mList:\n",
    "                                interFlat.extend(mList)\n",
    "                            else:\n",
    "                                interFlat.append(m)\n",
    "                        if debug: print \"interFlat\",interFlat\n",
    "                        if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                            interFlat.reverse()\n",
    "                        syntagmeLocal=separateurMots.join([latex2ipa(f) for f in interFlat])\n",
    "                    syntagmesBruts.append(syntagmeLocal)\n",
    "                    syntagmesEtiquetes.append(syntagmeLocal)\n",
    "                    if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                        syntagmesEtiquetes.append(syntagmes[\"Phrase\"][nMot])\n",
    "                    else:\n",
    "                        syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "#                    syntagmesEtiquetes.insert(-1,syntagmes[\"Phrase\"][nMot])\n",
    "                    printflat(mot,\"{}\")\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\":\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts[::-1])+\";\"+\" \".join(syntagmesEtiquetes[::-1])\n",
    "            else:\n",
    "                ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            ligneSyntagmesLocaux=separateurMots.join(syntagmesBruts)+\";\"+\" \".join(syntagmesEtiquetes)\n",
    "#            print ligneSyntagmesLocaux\n",
    "            syntagmesLocaux.append(ligneSyntagmesLocaux)\n",
    "            localAccumulateur=[accu for accu in accumulateur if accu!=\"\"]\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "                if sortie==\"images\":\n",
    "                    if nPhrase%numImages==0:\n",
    "                        prefixe=\"\\\\begin{preview}\"\n",
    "                    else:\n",
    "                        prefixe=\"\"\n",
    "                    if nPhrase%numImages==numImages-1:\n",
    "                        finLigne=finLignePreview\n",
    "                    else:\n",
    "                        finLigne=finLigneNoPreview\n",
    "                elif sortie==\"mots\":\n",
    "                    localAccumulateur=[debutLignePreview+accu+finLignePreview for accu in accumulateur if accu!=\"\"]\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(localAccumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if \"RightLeft\" in globals() and RightLeft and sortie==\"latex\" and separateurMots==\"\":\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur[::-1])+finLigne)\n",
    "            else:\n",
    "                ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortie in [\"latex\",\"traductions\"]:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "                if sortie in [\"images\",\"ordre\"]:\n",
    "                    prefixe=marqueurCommentaire\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortie in [\"latex\",\"traductions\"]: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            ##############\n",
    "            #\n",
    "            # Modification pour ajouts multiples\n",
    "            # suppression des ; de séparation dans la traduction\n",
    "            #\n",
    "            ##############\n",
    "            if \",\" in line:\n",
    "                consts=line.split(\"\\t\")\n",
    "                disloc=[]\n",
    "                canon=[]\n",
    "                for const in consts:\n",
    "                    if const.startswith(\",\"):\n",
    "                        if \";\" in const:\n",
    "                            subConsts=const.split(\";\")\n",
    "                            print \"##############@\"\n",
    "                            print subConsts\n",
    "                            disloc.append(subConsts[0][1:])\n",
    "                            for subConst in subConsts[1:]:\n",
    "                                canon.append(subConst.lstrip())\n",
    "                        else:\n",
    "                            disloc.append(const[1:])\n",
    "                    else:\n",
    "                        canon.append(const)\n",
    "                line=\",\\t\".join(disloc).strip()+\", \"+\"\\t\".join(canon)\n",
    "            if \" ; \" in line:\n",
    "                line=line.replace(\" ; \",\" \")\n",
    "            line=cleanFr(line)            \n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                element=element.strip(\"#\").replace(u\"’\",\"'\")\n",
    "                #\n",
    "                # Modification pour accepter les suffixes P et D à la fin des noms\n",
    "                # 31/5/21\n",
    "                #\n",
    "                if element[-2:] in [\"sP\",\"sD\"]:\n",
    "                    element=element[:-1]\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=normaliserMajusculesMinuscules(element)\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(caracteres)\n",
    "            if sortie==\"latex\": \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            elif sortie==\"images\":\n",
    "                ajouterExemple(marqueurCommentaire+\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "            elif sortie in [\"ordre\",\"mots\"]:\n",
    "                ajouterExemple(\"\\\\begin{preview}\"+\" \".join(accumulateur)+\".\"+\"\\\\end{preview}\")\n",
    "                #if sortie==\"mots\": ajouterExemple(\"\\\\begin{preview}\"+\".\"+\"\\\\end{preview}\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortie==\"latex\" and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortie in [\"latex\",\"traductions\"]: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortie in [\"latex\",\"traductions\"]:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRONOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PRO\"][\"cols\"],tableaux[\"PRO\"],texte,dimensionsTableaux[\"PRO\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"PRO\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "            with codecs.open(serie+complementPhrases+\"Syntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in syntagmesLocaux:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "        elif (sortie==\"traductions\" and variante==\"-Corr\"):\n",
    "            with codecs.open(serie+complementPhrases+\"Traductions\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")            \n",
    "\n",
    "        if sortie==\"latex\":\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for texHead in texHeader:\n",
    "                    output.write(texHead+\"\\n\")\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "#    elif sortie==\"images\":\n",
    "#        with codecs.open(serie+complementPhrases+\"Images\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "#            for exemple in exemples:\n",
    "#                output.write(exemple+\"\\n\")\n",
    "    elif sortie in [\"images\",\"ordre\",\"mots\"]:\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "            for texHead in texHeader:\n",
    "                output.write(texHead+\"\\n\")\n",
    "            for exemple in exemples:\n",
    "                output.write(exemple+\"\\n\")\n",
    "    if sortie in [\"images\",\"traductions\",\"ordre\",\"mots\"]:\n",
    "        clozeTraductions=[]\n",
    "        clozeExemples=exemples[:]\n",
    "        filtreLignes=[\"\\\\begin{phrases}\",\"\\\\ex\",\"\\\\gloses\",\"\\\\end{phrases}\"]\n",
    "        if sortie==\"traductions\":\n",
    "            clozeExemples=[exemple for exemple in clozeExemples if (not exemple in filtreLignes) and not exemple.startswith(\"%\")]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(clozeExemples)]*3):\n",
    "            if sortie==\"traductions\" and 0:\n",
    "                print \"ortho\",orthoLigne\n",
    "                print \"phono\",phonoLigne\n",
    "                print \"trad\",tradLigne\n",
    "            phonoLigne=phonoLigne.replace(previewerBegin,\"\").replace(previewerEnd,\"\")\n",
    "            phonoLigne=phonoLigne.replace(\"P{}\",\" \").replace(\"{}\",\" \")\n",
    "            phonoLigne=phonoLigne.replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoMots=phonoLigne.strip(marqueurCommentaire).replace(finLignePreview,\"\").strip().split()\n",
    "            tradLigne=tradLigne.strip(marqueurCommentaire).replace(debutLignePreview,\"\").replace(finLignePreview,\"\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")\n",
    "                if element==\"\\\\ex\": cleElement=\"\"\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print cleElement,phonoMots\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n",
    "        if sortie==\"ordre\" and separateurMots==\"\":\n",
    "            dictSyntagmes={}\n",
    "            dictTraductions={}\n",
    "            ordreCles=[]\n",
    "            for element in syntagmesLocaux:\n",
    "                clePhono,valSyntagmes=element.split(\";\")\n",
    "                dictSyntagmes[clePhono]=\" \".join([v for v in valSyntagmes.split() if not v in nomFonctions])\n",
    "                ordreCles.append(clePhono)\n",
    "            for element in clozeTraductions:\n",
    "                clePhono,valTrad,valMots=element.split(\";\")\n",
    "                dictTraductions[clePhono]=valTrad\n",
    "            morceauxPhrases=[\"%s;%s\"%(dictSyntagmes[c],dictTraductions[c]) for c in ordreCles]\n",
    "            with codecs.open(serie+complementPhrases+\"OrdreSyntagmes\"+variante+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in morceauxPhrases:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'SUJ', 'OBJ', 'COMP', 'IND', 'AJOUT'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GP', 'GADJ', 'NOM', 'DET']}\n",
      "traductions\n"
     ]
    }
   ],
   "source": [
    "sortie=\"traductions\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if traduction_nom.endswith(\"csv\") and variante!=\"-Corr\":\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the translation file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,sortie=sortie)\n",
    "            traduction_file.close()\n",
    "\n",
    "    localClozes=filtrerCloze(lexemesLocaux)\n",
    "    with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "        for ligne in localClozes:\n",
    "            output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['AJOUT', 'IND', 'COMP', 'OBJ', 'SUJ', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['DET', 'NOM', 'GADJ', 'GP']}\n",
      "latex\n",
      "[[u'dans', u'le', u'village', u'\\xe0', u'c\\xf4t\\xe9'], [u'avec', u'Clemencia']]\n",
      "##############@\n",
      "[u',dans le village \\xe0 c\\xf4t\\xe9 ', u' avec Clemencia\\n']\n",
      "ref nomSeul ils enfantsP\n",
      "[u'HUM', u'N3']\n",
      "[[u'dans', u'un', u'donjon', u'au', u'milieu', u'du', u'manoir'], [u'avec', u'trois', u'dragonsP', u'verts']]\n",
      "ref nomSeul ils dragonsP\n",
      "[u'ANIM', u'N1']\n",
      "ref nomSeul ils chasseurs\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'HUM', u'N2']\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'HUM', u'N2']\n",
      "ref nomSeul ils chasseursD\n",
      "[u'HUM', u'N1']\n",
      "[[u'sur', u'le', u'b\\xfbcher'], [u'de', u'douleur']]\n",
      "##############@\n",
      "[u',sur le b\\xfbcher ', u' de douleur\\n']\n",
      "ref nomSeul elles sorcièresD\n",
      "[u'HUM', u'N2']\n",
      "ref nomSeul il villageoiS\n",
      "[u'HUM', u'N2']\n",
      "[[u'sur', u'la', u'place'], [u'au', u'milieu', u'du', u'village']]\n",
      "[[u'par', u'esprit', u'de', u'vengeance'], [u'pour', u'les', u'chasseurs']]\n",
      "ref nomSeul il chat\n",
      "[u'ANIM', u'N3']\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'HUM', u'N2']\n",
      "[[u'en', u'balais'], [u'avec', u'des', u'l\\xe9gumes']]\n",
      "ref nomSeul elles sorcièresP\n",
      "[u'HUM', u'N2']\n",
      "[[u'pendant', u'cinq', u'nuits'], [u'dans', u'le', u'donjon']]\n",
      "##############@\n",
      "[u',pendant cinq nuits ', u' dans le donjon\\n']\n",
      "ref nomSeul ils espritP\n",
      "[u'ANIM', u'N3']\n",
      "ref nomSeul ils crapauds\n",
      "[u'ANIM', u'N1']\n",
      "[[u'dans', u'le', u'village'], [u'\\xe0', u'c\\xf4t\\xe9', u'du', u'grand', u'manoir']]\n"
     ]
    }
   ],
   "source": [
    "sortie=\"latex\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file,sortie=sortie)\n",
    "phrase_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"Phrases-Clozes\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['AJOUT', 'IND', 'COMP', 'OBJ', 'SUJ', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['DET', 'NOM', 'GADJ', 'GP']}\n",
      "images\n",
      "ref nomSeul elles fillesD\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul ils chasseurs\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul il chasseur\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul elles fillesD\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul il grimoire\n",
      "[u'INAN', u'N2']\n",
      "[[u'sous', u'le', u'lit', u'du', u'milieu'], [u'dans', u'la', u'chambre']]\n",
      "ref nomSeul il chasseur\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul il chasseur\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul elles voleusesD\n",
      "[u'HUM', u'N2']\n",
      "ref nomSeul elles fillesD\n",
      "[u'HUM', u'N1']\n",
      "ref nomSeul il dragon\n",
      "[u'ANIM', u'N1']\n"
     ]
    }
   ],
   "source": [
    "sortie=\"images\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if ecriture_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        ecriture_file = codecs.open(ecriture_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', ecriture_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            ecriture={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    ecriture[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(ecriture_file,sortie=sortie)\n",
    "            ecriture_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['VER', 'SUJ', 'OBJ', 'COMP', 'IND', 'AJOUT'], 'GP': ['GN', 'PREP'], 'GADJ': ['ADV', 'ADJ', 'GP'], 'GN': ['GP', 'GADJ', 'NOM', 'DET']}\n",
      "ordre\n"
     ]
    }
   ],
   "source": [
    "sortie=\"ordre\"\n",
    "syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if ordre_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        ordre_file = codecs.open(ordre_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', ordre_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            ordre={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    ordre[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(ordre_file,sortie=sortie)\n",
    "            ordre_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phrase': ['AJOUT', 'IND', 'COMP', 'OBJ', 'SUJ', 'VER'], 'GP': ['PREP', 'GN'], 'GADJ': ['GP', 'ADJ', 'ADV'], 'GN': ['DET', 'NOM', 'GADJ', 'GP']}\n",
      "mots\n"
     ]
    }
   ],
   "source": [
    "sortie=\"mots\"\n",
    "if \"RightLeft\" in globals() and RightLeft:\n",
    "    syntagmes=syntagmesRL\n",
    "else:\n",
    "    syntagmes=syntagmesLR\n",
    "print syntagmes\n",
    "\n",
    "lexemesLocaux=set()\n",
    "if mots_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        mots_file = codecs.open(mots_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the file', mots_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the cloze file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            motsIsoles={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    motsIsoles[elementsCloze[0]]=elementsCloze[5]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(mots_file,sortie=sortie)\n",
    "            mots_file.close()\n",
    "\n",
    "localClozes=filtrerCloze(lexemesLocaux)\n",
    "with codecs.open(serie+complementPhrases+\"%s-Clozes\"%sortie.capitalize()+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "    for ligne in localClozes:\n",
    "        output.write(ligne+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faire la correction\n"
     ]
    }
   ],
   "source": [
    "time.sleep(1)\n",
    "if variante==\"\": \n",
    "    print \"faire la correction\"\n",
    "    nextVariante=\"-Corr\"\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "    time.sleep(1)\n",
    "    ding()\n",
    "else:\n",
    "    print u\"ok pour cette étape\"\n",
    "    del nextVariante\n",
    "    ding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'trois.A2']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFM.lexique.formeLexeme[\"trois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yamlDump(nFile,content):\n",
    "    with open(nFile, 'w') as output:\n",
    "        yaml.dump(content, output, default_flow_style=False,allow_unicode=True)\n",
    "\n",
    "    with open(nFile, 'r') as input:\n",
    "        yamlLines=input.readlines()\n",
    "\n",
    "    yamlText=\"\".join(yamlLines)\n",
    "    yamlText=re.sub(r\"!!python/unicode\",\"\",yamlText)\n",
    "    yamlText=re.sub(r\"\\n\\s*-\\s*\",\", \",yamlText)\n",
    "    yamlText=re.sub(r\":,\\s*\",\": \",yamlText)\n",
    "    yamlText=re.sub(r\": *([^\\n]+)\",\": [\\g<1>]\",yamlText)\n",
    "\n",
    "\n",
    "    with open(nFile, 'w') as output:\n",
    "        output.write(yamlText)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': [u'troisi\\xe8me.A1.HUM.SG',\n",
       "  u'dernier.A1.HUM.PL',\n",
       "  u'gros.A1.INAN.SG',\n",
       "  u'blanc.A1.HUM.SG',\n",
       "  u'm\\xe9chant.A2.HUM.PL',\n",
       "  u'rouge.A2.ANIM.SG',\n",
       "  u'maigre.A2.HUM.SG',\n",
       "  u'noir.A1.INAN.PAU',\n",
       "  u'furieux.A1.INAN.SG',\n",
       "  u'sept.A1.INAN.PL',\n",
       "  u'gros.A1.INAN.PL',\n",
       "  u'gros.A1.ANIM.PL',\n",
       "  u'effray\\xe9.A2.HUM.PL',\n",
       "  u'vert.A2.INAN.PL',\n",
       "  u'maigre.A2.INAN.PAU',\n",
       "  u'noir.A1.ANIM.PL',\n",
       "  u'rouge.A2.INAN.PL',\n",
       "  u'six.A2.HUM.PL',\n",
       "  u'rouge.A2.HUM.SG',\n",
       "  u'grand.A1.ANIM.PAU',\n",
       "  u'deux.A1.ANIM.PAU',\n",
       "  u'petit.A2.INAN.SG',\n",
       "  u'blanc.A1.INAN.SG',\n",
       "  u'gros.A1.HUM.PAU',\n",
       "  u'petit.A2.ANIM.PAU',\n",
       "  u'gros.A1.HUM.SG',\n",
       "  u'grand.A1.ANIM.PL',\n",
       "  u'terrible.A2.INAN.PL',\n",
       "  u'blanc.A1.INAN.PAU',\n",
       "  u'terrible.A2.INAN.PAU',\n",
       "  u'h\\xe9ro\\xefque.A2.HUM.PL',\n",
       "  u'grand.A1.INAN.SG',\n",
       "  u'nouveau.A2.INAN.SG',\n",
       "  u'petit.A2.ANIM.PL',\n",
       "  u'profond.A1.INAN.PL',\n",
       "  u'noir.A1.INAN.PL',\n",
       "  u'maigre.A2.ANIM.PAU',\n",
       "  u'quatre.A1.HUM.PAU',\n",
       "  u'm\\xe9chant.A2.ANIM.PL',\n",
       "  u'gros.A1.HUM.PL',\n",
       "  u'dernier.A1.INAN.SG',\n",
       "  u'grand.A1.HUM.PL',\n",
       "  u'quatre.A1.INAN.PAU',\n",
       "  u'maigre.A2.HUM.PL',\n",
       "  u'vert.A2.ANIM.PL',\n",
       "  u'effray\\xe9.A2.INAN.SG',\n",
       "  u'deux.A1.HUM.PAU',\n",
       "  u'jaune.A2.ANIM.PAU',\n",
       "  u'petit.A2.ANIM.SG',\n",
       "  u'maigre.A2.INAN.SG',\n",
       "  u'furieux.A1.INAN.PL',\n",
       "  u'grand.A1.HUM.PAU',\n",
       "  u'maigre.A2.HUM.PAU',\n",
       "  u'petit.A2.HUM.PAU',\n",
       "  u'diff\\xe9rent.A2.HUM.PAU',\n",
       "  u'noir.A1.ANIM.SG',\n",
       "  u'courageux.A2.HUM.PAU',\n",
       "  u'disparu.A1.HUM.PAU',\n",
       "  u'courageux.A2.INAN.PL',\n",
       "  u'autre.A1.INAN.PL',\n",
       "  u'grand.A1.HUM.SG',\n",
       "  u'bless\\xe9.A1.INAN.SG',\n",
       "  u'bas.A1.INAN.SG',\n",
       "  u'gros.A1.INAN.PAU',\n",
       "  u'grand.A1.INAN.PL',\n",
       "  u'diff\\xe9rent.A2.HUM.PL',\n",
       "  u'nombreux.A2.INAN.PL',\n",
       "  u'blanc.A1.INAN.PL',\n",
       "  u'vert.A2.HUM.SG',\n",
       "  u'sept.A1.HUM.PL',\n",
       "  u'vert.A2.ANIM.PAU',\n",
       "  u'blanc.A1.ANIM.PL',\n",
       "  u'petit.A2.INAN.PAU',\n",
       "  u'effray\\xe9.A2.ANIM.PAU',\n",
       "  u'grand.A1.ANIM.SG',\n",
       "  u'maigre.A2.ANIM.SG',\n",
       "  u'trois.A2.ANIM.PAU',\n",
       "  u'bless\\xe9.A1.INAN.PAU',\n",
       "  u'cinq.A2.ANIM.PAU',\n",
       "  u'm\\xe9chant.A2.HUM.PAU',\n",
       "  u'nouveau.A2.HUM.PL',\n",
       "  u'vilain.A2.HUM.PAU',\n",
       "  u'petit.A2.HUM.PL',\n",
       "  u'jaune.A2.ANIM.SG',\n",
       "  u'rouge.A2.INAN.SG',\n",
       "  u'bless\\xe9.A1.HUM.SG',\n",
       "  u'petit.A2.HUM.SG',\n",
       "  u'maigre.A2.ANIM.PL',\n",
       "  u'jaune.A2.INAN.PAU',\n",
       "  u'rouge.A2.INAN.PAU',\n",
       "  u'noir.A1.INAN.SG',\n",
       "  u'deux.A1.INAN.PAU',\n",
       "  u'grand.A1.INAN.PAU',\n",
       "  u'gros.A1.ANIM.SG',\n",
       "  u'noir.A1.HUM.PL',\n",
       "  u'vilain.A2.ANIM.PAU',\n",
       "  u'treize.A1.HUM.PL',\n",
       "  u'jaune.A2.INAN.PL',\n",
       "  u'petit.A2.INAN.PL',\n",
       "  u'noir.A1.ANIM.PAU',\n",
       "  u'blanc.A1.ANIM.PAU',\n",
       "  u'trois.A2.HUM.PAU',\n",
       "  u'autre.A1.HUM.SG',\n",
       "  u'rouge.A2.ANIM.PAU',\n",
       "  u'dernier.A1.HUM.SG',\n",
       "  u'm\\xe9chant.A2.HUM.SG',\n",
       "  u'quatre.A1.ANIM.PAU',\n",
       "  u'cinq.A2.INAN.PAU',\n",
       "  u'bless\\xe9.A1.INAN.PL',\n",
       "  u'jaune.A2.HUM.SG',\n",
       "  u'gros.A1.ANIM.PAU',\n",
       "  u'autre.A1.HUM.PL',\n",
       "  u'rouge.A2.ANIM.PL',\n",
       "  u'jaune.A2.INAN.SG',\n",
       "  u'blanc.A1.ANIM.SG',\n",
       "  u'diff\\xe9rent.A2.INAN.SG',\n",
       "  u'trois.A2.INAN.PAU'],\n",
       " 'DET': [u'DEF.ANIM.PAU.Dat',\n",
       "  u'DEM.HUM.SG.Dat',\n",
       "  u'DEF.INAN.SG.Dat',\n",
       "  u'IND.HUM.PAU.obl',\n",
       "  u'DEM.ANIM.PAU.Erg',\n",
       "  u'DEF.INAN.PAU.obl',\n",
       "  u'IND.ANIM.PL.Abs',\n",
       "  u'IND.HUM.PL.Dat',\n",
       "  u'DEM.HUM.SG.obl',\n",
       "  u'DEF.INAN.PL.obl',\n",
       "  u'IND.INAN.PAU.Abs',\n",
       "  u'DEM.ANIM.SG.Erg',\n",
       "  u'IND.HUM.PAU.Dat',\n",
       "  u'IND.HUM.PAU.Erg',\n",
       "  u'DEM.ANIM.SG.Abs',\n",
       "  u'DEF.HUM.PL.Dat',\n",
       "  u'IND.HUM.PL.obl',\n",
       "  u'DEF.INAN.PAU.Erg',\n",
       "  u'DEM.INAN.PL.Erg',\n",
       "  u'DEF.ANIM.PAU.Erg',\n",
       "  u'IND.INAN.SG.obl',\n",
       "  u'DEF.ANIM.SG.Dat',\n",
       "  u'DEM.HUM.PAU.Abs',\n",
       "  u'DEF.INAN.SG.obl',\n",
       "  u'IND.INAN.PAU.obl',\n",
       "  u'DEM.ANIM.SG.obl',\n",
       "  u'DEM.INAN.PL.obl',\n",
       "  u'DEF.ANIM.SG.Abs',\n",
       "  u'DEF.INAN.SG.Abs',\n",
       "  u'DEM.HUM.PL.Abs',\n",
       "  u'IND.INAN.PL.obl',\n",
       "  u'IND.INAN.PL.Erg',\n",
       "  u'IND.ANIM.PAU.Abs',\n",
       "  u'DEF.INAN.PL.Dat',\n",
       "  u'DEM.INAN.SG.obl',\n",
       "  u'DEF.ANIM.PL.Abs',\n",
       "  u'DEM.ANIM.PL.obl',\n",
       "  u'IND.INAN.PL.Abs',\n",
       "  u'DEM.HUM.PL.Dat',\n",
       "  u'IND.HUM.SG.Dat',\n",
       "  u'DEM.ANIM.SG.Dat',\n",
       "  u'DEM.ANIM.PAU.obl',\n",
       "  u'DEM.HUM.PAU.Erg',\n",
       "  u'DEF.INAN.PL.Abs',\n",
       "  u'DEF.HUM.PAU.Dat',\n",
       "  u'DEM.INAN.SG.Erg',\n",
       "  u'DEF.ANIM.PAU.Abs',\n",
       "  u'IND.ANIM.PL.Dat',\n",
       "  u'IND.HUM.PAU.Abs',\n",
       "  u'DEF.INAN.PAU.Abs',\n",
       "  u'IND.ANIM.SG.Abs',\n",
       "  u'IND.ANIM.PL.obl',\n",
       "  u'DEM.INAN.SG.Abs',\n",
       "  u'DEM.INAN.PAU.obl',\n",
       "  u'IND.INAN.PAU.Erg',\n",
       "  u'DEM.HUM.SG.Erg',\n",
       "  u'DEF.ANIM.SG.Erg',\n",
       "  u'DEF.INAN.PAU.Dat',\n",
       "  u'IND.INAN.SG.Abs',\n",
       "  u'IND.HUM.SG.Erg',\n",
       "  u'DEM.HUM.PL.obl',\n",
       "  u'IND.HUM.SG.Abs',\n",
       "  u'IND.ANIM.SG.Erg',\n",
       "  u'DEF.HUM.PL.Abs',\n",
       "  u'DEF.INAN.SG.Erg',\n",
       "  u'IND.HUM.PL.Abs',\n",
       "  u'DEF.INAN.PL.Erg',\n",
       "  u'DEF.HUM.PL.obl',\n",
       "  u'IND.HUM.PL.Erg',\n",
       "  u'DEF.ANIM.SG.obl',\n",
       "  u'IND.ANIM.PAU.Erg',\n",
       "  u'IND.ANIM.SG.Dat',\n",
       "  u'DEF.ANIM.PL.Erg',\n",
       "  u'DEF.HUM.SG.Dat',\n",
       "  u'IND.INAN.SG.Erg',\n",
       "  u'IND.HUM.SG.obl',\n",
       "  u'DEM.INAN.PAU.Dat',\n",
       "  u'DEF.HUM.SG.obl',\n",
       "  u'DEF.HUM.SG.Abs',\n",
       "  u'DEM.HUM.PAU.Dat',\n",
       "  u'DEF.HUM.SG.Erg',\n",
       "  u'DEM.INAN.PAU.Abs',\n",
       "  u'DEM.HUM.SG.Abs',\n",
       "  u'DEM.HUM.PL.Erg',\n",
       "  u'DEF.HUM.PL.Erg',\n",
       "  u'DEM.INAN.PL.Abs',\n",
       "  u'DEM.ANIM.PAU.Abs',\n",
       "  u'DEM.HUM.PAU.obl',\n",
       "  u'IND.ANIM.PL.Erg',\n",
       "  u'DEF.ANIM.PL.Dat',\n",
       "  u'DEM.ANIM.PL.Dat',\n",
       "  u'IND.INAN.PAU.Dat',\n",
       "  u'DEM.ANIM.PL.Abs',\n",
       "  u'DEM.ANIM.PL.Erg',\n",
       "  u'IND.ANIM.PAU.Dat',\n",
       "  u'DEF.ANIM.PL.obl',\n",
       "  u'IND.ANIM.SG.obl',\n",
       "  u'DEF.HUM.PAU.Abs',\n",
       "  u'DEF.HUM.PAU.obl',\n",
       "  u'DEM.INAN.PAU.Erg',\n",
       "  u'DEF.HUM.PAU.Erg',\n",
       "  u'DEF.ANIM.PAU.obl',\n",
       "  u'IND.ANIM.PAU.obl'],\n",
       " 'NOM': [u'demande.INAN.N2.Sg.Obl',\n",
       "  u'arbre.INAN.N1.Pl.Erg',\n",
       "  u'chat.ANIM.N3.Pau.Erg',\n",
       "  u'coyote.ANIM.N3.Pl.Obl',\n",
       "  u'Elphaba.HUM.N2.Sg.Erg',\n",
       "  u'poisson.ANIM.N2.Sg.Abs',\n",
       "  u'vote.INAN.N2.Sg.Erg',\n",
       "  u'fille.HUM.N1.Pl.Obl',\n",
       "  u'maison.INAN.N2.Pau.Obl',\n",
       "  u'\\u0153uf.INAN.N3.Pau.Abs',\n",
       "  u'chatte.ANIM.N1.Pl.Obl',\n",
       "  u'sorcier.HUM.N2.Sg.Obl',\n",
       "  u'parent.HUM.N1.Pl.Obl',\n",
       "  u'peau.HUM.N3.Sg.Erg',\n",
       "  u'coyote.ANIM.N3.Pl.Abs',\n",
       "  u'lance.INAN.N1.Sg.Erg',\n",
       "  u'table.INAN.N2.Pl.Obl',\n",
       "  u'chasseur.HUM.N1.Sg.Obl',\n",
       "  u'fruit.INAN.N3.Sg.Abs',\n",
       "  u'Nicole.HUM.N3.Sg.Abs',\n",
       "  u'villageoise.HUM.N2.Pl.Obl',\n",
       "  u'coussin.INAN.N3.Sg.Erg',\n",
       "  u'gar\\xe7on.HUM.N2.Pl.Obl',\n",
       "  u'chat.ANIM.N3.Sg.Obl',\n",
       "  u'Agathos.HUM.N1.Pl.Erg',\n",
       "  u'esprit.ANIM.N3.Pl.Obl',\n",
       "  u'sorcier.HUM.N2.Sg.Abs',\n",
       "  u'poisson.ANIM.N2.Pau.Obl',\n",
       "  u'lune.INAN.N3.Sg.Erg',\n",
       "  u'm\\xe8re.HUM.N3.Pau.Erg',\n",
       "  u'main.HUM.N2.Pau.Obl',\n",
       "  u'for\\xeat.INAN.N2.Sg.Obl',\n",
       "  u'souris.ANIM.N2.Pl.Obl',\n",
       "  u'coussin.INAN.N3.Pl.Obl',\n",
       "  u'histoire.INAN.N3.Pl.Obl',\n",
       "  u'visage.INAN.N1.Pau.Obl',\n",
       "  u'gar\\xe7on.HUM.N2.Sg.Dat',\n",
       "  u'Nabil.HUM.N2.Sg.Obl',\n",
       "  u'sorcier.HUM.N2.Pl.Obl',\n",
       "  u'chambre.INAN.N3.Pau.Erg',\n",
       "  u'harmonie.INAN.N3.Sg.Erg',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pl.Erg',\n",
       "  u'autruche.ANIM.N1.Pau.Obl',\n",
       "  u'Violette.HUM.N1.Sg.Obl',\n",
       "  u'croc.INAN.N3.Pau.Obl',\n",
       "  u'place.INAN.N1.Sg.Abs',\n",
       "  u'couteau.INAN.N2.Sg.Abs',\n",
       "  u'oeil.HUM.N2.Pl.Erg',\n",
       "  u'viande.INAN.N1.Pau.Abs',\n",
       "  u'sort.INAN.N2.Pl.Abs',\n",
       "  u'manoir.INAN.N2.Sg.Abs',\n",
       "  u'souffrance.INAN.N2.Pau.Obl',\n",
       "  u'manoir.INAN.N2.Sg.Obl',\n",
       "  u'cri.INAN.N2.Pau.Abs',\n",
       "  u'Kaleb.HUM.N3.Pl.Obl',\n",
       "  u'fille.HUM.N1.Pl.Abs',\n",
       "  u'sortil\\xe8ge.INAN.N3.Sg.Abs',\n",
       "  u'Freja.HUM.N1.Sg.Abs',\n",
       "  u'esprit.ANIM.N3.Sg.Obl',\n",
       "  u'femme.HUM.N2.Pl.Dat',\n",
       "  u'dragon.ANIM.N1.Sg.Erg',\n",
       "  u'village.INAN.N3.Pau.Erg',\n",
       "  u'proximit\\xe9.INAN.N2.Sg.Obl',\n",
       "  u'souris.ANIM.N2.Sg.Erg',\n",
       "  u'Mahira.HUM.N1.Pau.Abs',\n",
       "  u'l\\xe9gume.HUM.N3.Pl.Erg',\n",
       "  u'souris.ANIM.N2.Pau.Dat',\n",
       "  u'chasseur.HUM.N1.Pau.Obl',\n",
       "  u'main.HUM.N2.Pl.Erg',\n",
       "  u'crapaud.ANIM.N1.Pl.Obl',\n",
       "  u'femme.HUM.N2.Pl.Obl',\n",
       "  u'caf\\xe9.INAN.N2.Sg.Erg',\n",
       "  u'viande.INAN.N1.Sg.Abs',\n",
       "  u'Clemencia.HUM.N2.Sg.Abs',\n",
       "  u'chasseur.HUM.N1.Pl.Dat',\n",
       "  u'parent.HUM.N1.Pl.Erg',\n",
       "  u'sorcier.HUM.N2.Pau.Obl',\n",
       "  u'croc.INAN.N3.Sg.Erg',\n",
       "  u'table.INAN.N2.Pau.Erg',\n",
       "  u'plaine.INAN.N1.Sg.Erg',\n",
       "  u'souris.ANIM.N2.Pau.Obl',\n",
       "  u'poisson.ANIM.N2.Pl.Obl',\n",
       "  u'robe.INAN.N2.Sg.Obl',\n",
       "  u'femme.HUM.N2.Pau.Erg',\n",
       "  u'lueur.INAN.N1.Sg.Obl',\n",
       "  u'chatte.ANIM.N1.Pau.Erg',\n",
       "  u'Clemencia.HUM.N2.Sg.Obl',\n",
       "  u'village.INAN.N3.Pl.Obl',\n",
       "  u'combat.INAN.N2.Sg.Obl',\n",
       "  u'caillou.INAN.N3.Pl.Abs',\n",
       "  u'Kaleb.HUM.N3.Pl.Abs',\n",
       "  u'col\\xe8re.INAN.N1.Pau.Erg',\n",
       "  u'sort.INAN.N2.Pau.Erg',\n",
       "  u'matin.INAN.N1.Sg.Obl',\n",
       "  u'arbre.INAN.N1.Pau.Obl',\n",
       "  u'fille.HUM.N1.Pau.Dat',\n",
       "  u'h\\xe9ros.HUM.N3.Pl.Obl',\n",
       "  u'coussin.INAN.N3.Sg.Abs',\n",
       "  u'th\\xe9.INAN.N2.Sg.Abs',\n",
       "  u'loup.ANIM.N1.Pl.Erg',\n",
       "  u'd\\xe9mon.ANIM.N3.Pau.Obl',\n",
       "  u'gargouille.ANIM.N2.Pau.Abs',\n",
       "  u'excuse.INAN.N3.Pl.Abs',\n",
       "  u'coussin.INAN.N3.Sg.Dat',\n",
       "  u'chambre.INAN.N3.Pl.Obl',\n",
       "  u'souris.ANIM.N2.Pl.Abs',\n",
       "  u'douleur.INAN.N3.Sg.Obl',\n",
       "  u'infirmi\\xe8re.HUM.N3.Sg.Obl',\n",
       "  u'villageois.HUM.N2.Sg.Erg',\n",
       "  u'sort.INAN.N2.Pl.Obl',\n",
       "  u'Mahira.HUM.N1.Sg.Erg',\n",
       "  u'sortil\\xe8ge.INAN.N3.Pl.Abs',\n",
       "  u'louve.ANIM.N2.Pau.Abs',\n",
       "  u'couteau.INAN.N2.Pau.Dat',\n",
       "  u'gorge.INAN.N1.Sg.Erg',\n",
       "  u'balai.INAN.N1.Pl.Abs',\n",
       "  u'histoire.INAN.N3.Sg.Abs',\n",
       "  u'poisson.ANIM.N2.Sg.Obl',\n",
       "  u'caf\\xe9.INAN.N2.Pl.Erg',\n",
       "  u'cri.INAN.N2.Sg.Erg',\n",
       "  u'villageois.HUM.N2.Pl.Abs',\n",
       "  u'\\u0153uf.INAN.N3.Pau.Erg',\n",
       "  u'Elphaba.HUM.N2.Sg.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Sg.Dat',\n",
       "  u'fille.HUM.N1.Sg.Dat',\n",
       "  u'table.INAN.N2.Sg.Obl',\n",
       "  u'viande.INAN.N1.Pl.Abs',\n",
       "  u'for\\xeat.INAN.N2.Sg.Erg',\n",
       "  u'louve.ANIM.N2.Sg.Abs',\n",
       "  u'souffrance.INAN.N2.Sg.Erg',\n",
       "  u'chasseur.HUM.N1.Pl.Obl',\n",
       "  u'raison.INAN.N3.Sg.Obl',\n",
       "  u'chatte.ANIM.N1.Sg.Erg',\n",
       "  u'gar\\xe7on.HUM.N2.Sg.Obl',\n",
       "  u'enfant.HUM.N3.Pau.Obl',\n",
       "  u'col\\xe8re.INAN.N1.Pl.Obl',\n",
       "  u'chat.ANIM.N3.Sg.Abs',\n",
       "  u'place.INAN.N1.Sg.Obl',\n",
       "  u'enfant.HUM.N3.Sg.Erg',\n",
       "  u'histoire.INAN.N3.Pau.Abs',\n",
       "  u'coussin.INAN.N3.Sg.Obl',\n",
       "  u'esprit.ANIM.N3.Pau.Abs',\n",
       "  u'fille.HUM.N1.Pl.Erg',\n",
       "  u'lance.INAN.N1.Sg.Obl',\n",
       "  u'cuisine.INAN.N1.Pl.Obl',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pau.Erg',\n",
       "  u'parent.HUM.N1.Sg.Dat',\n",
       "  u'lit.INAN.N1.Pl.Abs',\n",
       "  u'fille.HUM.N1.Sg.Obl',\n",
       "  u'Clemencia.HUM.N2.Sg.Erg',\n",
       "  u'milieu.INAN.N2.Pl.Obl',\n",
       "  u'l\\xe9gume.HUM.N3.Pl.Obl',\n",
       "  u'enfant.HUM.N3.Pau.Erg',\n",
       "  u'viande.INAN.N1.Sg.Erg',\n",
       "  u'cuisine.INAN.N1.Pau.Obl',\n",
       "  u'Kaleb.HUM.N3.Sg.Dat',\n",
       "  u'fruit.INAN.N3.Pl.Abs',\n",
       "  u'chatte.ANIM.N1.Pl.Abs',\n",
       "  u'mort.INAN.N3.Sg.Dat',\n",
       "  u'Violette.HUM.N1.Pau.Obl',\n",
       "  u'Katisha.HUM.N1.Sg.Obl',\n",
       "  u'coyote.ANIM.N3.Sg.Obl',\n",
       "  u'village.INAN.N3.Sg.Erg',\n",
       "  u'Nabil.HUM.N2.Sg.Abs',\n",
       "  u'nuit.INAN.N1.Pau.Abs',\n",
       "  u'chemin.INAN.N3.Sg.Abs',\n",
       "  u'lit.INAN.N1.Sg.Erg',\n",
       "  u'coup.INAN.N2.Pau.Erg',\n",
       "  u'livre.INAN.N1.Sg.Abs',\n",
       "  u'oeil.HUM.N2.Pl.Obl',\n",
       "  u'balai.INAN.N1.Sg.Obl',\n",
       "  u'couteau.INAN.N2.Sg.Erg',\n",
       "  u'sorcier.HUM.N2.Pl.Erg',\n",
       "  u'fille.HUM.N1.Pau.Abs',\n",
       "  u'voleuse.HUM.N2.Pau.Abs',\n",
       "  u'cri.INAN.N2.Pl.Erg',\n",
       "  u'cuisine.INAN.N1.Sg.Obl',\n",
       "  u'Agathos.HUM.N1.Sg.Erg',\n",
       "  u'poisson.ANIM.N2.Pl.Abs',\n",
       "  u'cuisine.INAN.N1.Pl.Erg',\n",
       "  u'village.INAN.N3.Pau.Abs',\n",
       "  u'h\\xe9ros.HUM.N3.Pl.Dat',\n",
       "  u'sorcier.HUM.N2.Pau.Erg',\n",
       "  u'autruche.ANIM.N1.Pl.Obl',\n",
       "  u'fruit.INAN.N3.Pau.Abs',\n",
       "  u'enfant.HUM.N3.Pl.Erg',\n",
       "  u'soeur.HUM.N3.Pl.Abs',\n",
       "  u'Katisha.HUM.N1.Pl.Erg',\n",
       "  u'coussin.INAN.N3.Pau.Abs',\n",
       "  u'lumi\\xe8re.INAN.N2.Pl.Abs',\n",
       "  u'combattant.HUM.N1.Pl.Erg',\n",
       "  u'soeur.HUM.N3.Pau.Abs',\n",
       "  u'main.HUM.N2.Pl.Obl',\n",
       "  u'croc.INAN.N3.Sg.Abs',\n",
       "  u'coyote.ANIM.N3.Sg.Abs',\n",
       "  u'table.INAN.N2.Pau.Abs',\n",
       "  u'village.INAN.N3.Pl.Erg',\n",
       "  u'serpent.ANIM.N3.Pl.Abs',\n",
       "  u'loup.ANIM.N1.Sg.Obl',\n",
       "  u'esprit.ANIM.N3.Sg.Dat',\n",
       "  u'souris.ANIM.N2.Sg.Abs',\n",
       "  u'd\\xe9g\\xe2t.INAN.N2.Pl.Erg',\n",
       "  u'couteau.INAN.N2.Pl.Obl',\n",
       "  u'sortil\\xe8ge.INAN.N3.Sg.Obl',\n",
       "  u'autruche.ANIM.N1.Pl.Abs',\n",
       "  u'maison.INAN.N2.Sg.Abs',\n",
       "  u'table.INAN.N2.Sg.Dat',\n",
       "  u'poisson.ANIM.N2.Sg.Erg',\n",
       "  u'coyote.ANIM.N3.Pau.Erg',\n",
       "  u'arbre.INAN.N1.Pau.Erg',\n",
       "  u'th\\xe9.INAN.N2.Sg.Erg',\n",
       "  u'louve.ANIM.N2.Sg.Erg',\n",
       "  u'chat.ANIM.N3.Pau.Obl',\n",
       "  u'nuit.INAN.N1.Sg.Obl',\n",
       "  u'chatte.ANIM.N1.Sg.Obl',\n",
       "  u'coyote.ANIM.N3.Pau.Obl',\n",
       "  u'dragon.ANIM.N1.Pau.Erg',\n",
       "  u'ma\\xeetre.HUM.N3.Sg.Erg',\n",
       "  u'chat.ANIM.N3.Sg.Erg',\n",
       "  u'Katisha.HUM.N1.Pau.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pau.Obl',\n",
       "  u'jardin.INAN.N1.Pl.Obl',\n",
       "  u'construction.INAN.N1.Sg.Obl',\n",
       "  u'couteau.INAN.N2.Pau.Erg',\n",
       "  u'l\\xe9gume.HUM.N3.Pl.Abs',\n",
       "  u'caf\\xe9.INAN.N2.Sg.Dat',\n",
       "  u'chasseur.HUM.N1.Pau.Erg',\n",
       "  u'grimoire.INAN.N2.Sg.Abs',\n",
       "  u'fruit.INAN.N3.Pau.Obl',\n",
       "  u'disparition.INAN.N3.Pl.Abs',\n",
       "  u'Agathos.HUM.N1.Pl.Obl',\n",
       "  u'chasseur.HUM.N1.Sg.Erg',\n",
       "  u'arbre.INAN.N1.Sg.Abs',\n",
       "  u'\\u0153uf.INAN.N3.Sg.Abs',\n",
       "  u'jour.INAN.N3.Sg.Obl',\n",
       "  u'enfant.HUM.N3.Pl.Dat',\n",
       "  u'caf\\xe9.INAN.N2.Pl.Abs',\n",
       "  u'village.INAN.N3.Sg.Abs',\n",
       "  u'obscurit\\xe9.INAN.N1.Sg.Obl',\n",
       "  u'\\u0153uf.INAN.N3.Pau.Obl',\n",
       "  u'parent.HUM.N1.Pl.Abs',\n",
       "  u'l\\xe9gende.INAN.N1.Pau.Abs',\n",
       "  u'lune.INAN.N3.Pl.Obl',\n",
       "  u'village.INAN.N3.Sg.Dat',\n",
       "  u'h\\xe9ros.HUM.N3.Pl.Abs',\n",
       "  u'croc.INAN.N3.Pl.Erg',\n",
       "  u'd\\xe9g\\xe2t.INAN.N2.Pl.Obl',\n",
       "  u'table.INAN.N2.Sg.Abs',\n",
       "  u'chasseur.HUM.N1.Pl.Erg',\n",
       "  u'balai.INAN.N1.Sg.Abs',\n",
       "  u'l\\xe9gende.INAN.N1.Sg.Erg',\n",
       "  u'gargouille.ANIM.N2.Pau.Obl',\n",
       "  u'\\u0153uf.INAN.N3.Pl.Abs',\n",
       "  u'crapaud.ANIM.N1.Pl.Dat',\n",
       "  u'gargouille.ANIM.N2.Pau.Dat',\n",
       "  u'gar\\xe7on.HUM.N2.Pl.Erg',\n",
       "  u'Agathos.HUM.N1.Sg.Obl',\n",
       "  u'coyote.ANIM.N3.Pl.Erg',\n",
       "  u'mort.INAN.N3.Sg.Abs',\n",
       "  u'Violette.HUM.N1.Sg.Erg',\n",
       "  u'villageois.HUM.N2.Pl.Erg',\n",
       "  u'plaine.INAN.N1.Sg.Obl',\n",
       "  u'd\\xe9mon.ANIM.N3.Pl.Abs',\n",
       "  u'lumi\\xe8re.INAN.N2.Sg.Obl',\n",
       "  u'c\\xf4t\\xe9.INAN.N3.Sg.Obl',\n",
       "  u'lueur.INAN.N1.Sg.Erg',\n",
       "  u'lit.INAN.N1.Pau.Obl',\n",
       "  u'chambre.INAN.N3.Pl.Erg',\n",
       "  u'Freja.HUM.N1.Sg.Obl',\n",
       "  u'Katisha.HUM.N1.Sg.Dat',\n",
       "  u'sorcier.HUM.N2.Pau.Abs',\n",
       "  u'th\\xe9.INAN.N2.Pl.Abs',\n",
       "  u'hurlement.INAN.N3.Pl.Abs',\n",
       "  u'h\\xe9ros.HUM.N3.Pau.Erg',\n",
       "  u'm\\xe8re.HUM.N3.Sg.Erg',\n",
       "  u'village.INAN.N3.Sg.Obl',\n",
       "  u'viande.INAN.N1.Pl.Obl',\n",
       "  u'soeur.HUM.N3.Sg.Erg',\n",
       "  u'Nabil.HUM.N2.Sg.Erg',\n",
       "  u'coup.INAN.N2.Pl.Erg',\n",
       "  u'livre.INAN.N1.Sg.Erg',\n",
       "  u'homme.HUM.N1.Pl.Obl',\n",
       "  u'bras.HUM.N1.Pl.Obl',\n",
       "  u'lumi\\xe8re.INAN.N2.Sg.Abs',\n",
       "  u'lit.INAN.N1.Sg.Abs',\n",
       "  u'sorcier.HUM.N2.Pl.Dat',\n",
       "  u'tornade.ANIM.N2.Sg.Erg',\n",
       "  u'gar\\xe7on.HUM.N2.Sg.Abs',\n",
       "  u'serpent.ANIM.N3.Sg.Dat',\n",
       "  u'voleuse.HUM.N2.Sg.Erg',\n",
       "  u'fruit.INAN.N3.Sg.Obl',\n",
       "  u'lever-nom.INAN.N1.Sg.Obl',\n",
       "  u'cr\\xe9ature.ANIM.N1.Pl.Abs',\n",
       "  u'chat.ANIM.N3.Pl.Abs',\n",
       "  u'croc.INAN.N3.Pau.Erg',\n",
       "  u'gorge.INAN.N1.Pl.Obl',\n",
       "  u'fille.HUM.N1.Pau.Erg',\n",
       "  u'autruche.ANIM.N1.Sg.Dat',\n",
       "  u'mort.INAN.N3.Pl.Dat',\n",
       "  u'Nicole.HUM.N3.Sg.Dat',\n",
       "  u'coussin.INAN.N3.Pl.Abs',\n",
       "  u'enfant.HUM.N3.Pl.Obl',\n",
       "  u'arbre.INAN.N1.Pl.Abs',\n",
       "  u'table.INAN.N2.Pau.Obl',\n",
       "  u'th\\xe9.INAN.N2.Sg.Dat',\n",
       "  u'ma\\xeetre.HUM.N3.Sg.Abs',\n",
       "  u'enfant.HUM.N3.Pl.Abs',\n",
       "  u'loup.ANIM.N1.Pl.Obl',\n",
       "  u'chef.HUM.N2.Sg.Abs',\n",
       "  u'loup.ANIM.N1.Sg.Abs',\n",
       "  u'caf\\xe9.INAN.N2.Pau.Abs',\n",
       "  u'crapaud.ANIM.N1.Pl.Erg',\n",
       "  u'autruche.ANIM.N1.Sg.Abs',\n",
       "  u'feu.ANIM.N3.Sg.Abs',\n",
       "  u'p\\xe8re.HUM.N2.Pau.Erg',\n",
       "  u'fille.HUM.N1.Pau.Obl',\n",
       "  u'coyote.ANIM.N3.Sg.Erg',\n",
       "  u'raison.INAN.N3.Pl.Abs',\n",
       "  u'maison.INAN.N2.Sg.Erg',\n",
       "  u'nouvelle-nom.INAN.N3.Sg.Erg',\n",
       "  u'd\\xe9g\\xe2t.INAN.N2.Pl.Abs',\n",
       "  u'grimoire.INAN.N2.Sg.Obl',\n",
       "  u'chambre.INAN.N3.Sg.Erg',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pl.Obl',\n",
       "  u'autruche.ANIM.N1.Pau.Abs',\n",
       "  u'Hoderi.HUM.N3.Sg.Abs',\n",
       "  u'balai.INAN.N1.Pau.Obl',\n",
       "  u'autruche.ANIM.N1.Pl.Dat',\n",
       "  u'femme.HUM.N2.Pl.Erg',\n",
       "  u'table.INAN.N2.Pl.Abs',\n",
       "  u'serpent.ANIM.N3.Sg.Erg',\n",
       "  u'serpent.ANIM.N3.Pau.Erg',\n",
       "  u'b\\xfbcher.INAN.N2.Sg.Obl',\n",
       "  u'gargouille.ANIM.N2.Pl.Abs',\n",
       "  u'chat.ANIM.N3.Pl.Obl',\n",
       "  u'l\\xe9gende.INAN.N1.Sg.Abs',\n",
       "  u'th\\xe9.INAN.N2.Sg.Obl',\n",
       "  u'chasseur.HUM.N1.Sg.Abs',\n",
       "  u'autruche.ANIM.N1.Sg.Obl',\n",
       "  u'souris.ANIM.N2.Pau.Erg',\n",
       "  u'poisson.ANIM.N2.Pl.Erg',\n",
       "  u'gar\\xe7on.HUM.N2.Pl.Abs',\n",
       "  u'd\\xe9mon.ANIM.N3.Pl.Obl',\n",
       "  u'b\\xfbcher.INAN.N2.Sg.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Sg.Erg',\n",
       "  u'p\\xe8re.HUM.N2.Pl.Erg',\n",
       "  u'chatte.ANIM.N1.Pau.Dat',\n",
       "  u'maison.INAN.N2.Pau.Abs',\n",
       "  u'dragon.ANIM.N1.Pau.Obl',\n",
       "  u'balai.INAN.N1.Pau.Abs',\n",
       "  u'louve.ANIM.N2.Pl.Obl',\n",
       "  u'arbre.INAN.N1.Sg.Erg',\n",
       "  u'donjon.INAN.N1.Sg.Abs',\n",
       "  u'lumi\\xe8re.INAN.N2.Sg.Dat',\n",
       "  u'robe.INAN.N2.Pl.Abs',\n",
       "  u'gar\\xe7on.HUM.N2.Pau.Erg',\n",
       "  u'poisson.ANIM.N2.Pau.Abs',\n",
       "  u'caf\\xe9.INAN.N2.Pau.Erg',\n",
       "  u'Nicole.HUM.N3.Sg.Erg',\n",
       "  u'souris.ANIM.N2.Sg.Obl',\n",
       "  u'nuit.INAN.N1.Sg.Erg',\n",
       "  u'Nicole.HUM.N3.Sg.Obl',\n",
       "  u'couteau.INAN.N2.Sg.Obl',\n",
       "  u'fruit.INAN.N3.Pl.Obl',\n",
       "  u'marais.INAN.N2.Sg.Obl',\n",
       "  u'livre.INAN.N1.Pau.Erg',\n",
       "  u'Mahira.HUM.N1.Sg.Obl',\n",
       "  u'chambre.INAN.N3.Pau.Obl',\n",
       "  u'balai.INAN.N1.Sg.Erg',\n",
       "  u'table.INAN.N2.Sg.Erg',\n",
       "  u'Katisha.HUM.N1.Sg.Erg',\n",
       "  u'nuit.INAN.N1.Pau.Obl',\n",
       "  u'lit.INAN.N1.Pau.Erg',\n",
       "  u'obscurit\\xe9.INAN.N1.Sg.Erg',\n",
       "  u'villageois.HUM.N2.Pl.Obl',\n",
       "  u'chat.ANIM.N3.Pl.Dat',\n",
       "  u'enfant.HUM.N3.Pau.Abs',\n",
       "  u'main.HUM.N2.Pau.Erg',\n",
       "  u'lance.INAN.N1.Sg.Abs',\n",
       "  u'gar\\xe7on.HUM.N2.Sg.Erg',\n",
       "  u'lance.INAN.N1.Pl.Obl',\n",
       "  u'dernier-nom.INAN.N3.Pl.Abs',\n",
       "  u'Violette.HUM.N1.Sg.Abs',\n",
       "  u'Kaleb.HUM.N3.Sg.Abs',\n",
       "  u'ombre.INAN.N1.Pl.Abs',\n",
       "  u'chasseur.HUM.N1.Pau.Dat',\n",
       "  u'fille.HUM.N1.Sg.Abs',\n",
       "  u'chasseur.HUM.N1.Pl.Abs',\n",
       "  u'villageoise.HUM.N2.Pl.Abs',\n",
       "  u'balai.INAN.N1.Pl.Obl',\n",
       "  u'histoire.INAN.N3.Sg.Obl',\n",
       "  u'donjon.INAN.N1.Sg.Obl',\n",
       "  u'lune.INAN.N3.Sg.Abs',\n",
       "  u'sorcier.HUM.N2.Sg.Erg',\n",
       "  u'lumi\\xe8re.INAN.N2.Sg.Erg',\n",
       "  u'chat.ANIM.N3.Pau.Abs',\n",
       "  u'lit.INAN.N1.Sg.Obl',\n",
       "  u'soeur.HUM.N3.Sg.Abs',\n",
       "  u'viande.INAN.N1.Sg.Obl',\n",
       "  u'chat.ANIM.N3.Pl.Erg',\n",
       "  u'vote.INAN.N2.Sg.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pl.Abs',\n",
       "  u'gar\\xe7on.HUM.N2.Pau.Obl',\n",
       "  u'voleuse.HUM.N2.Sg.Abs',\n",
       "  u'viande.INAN.N1.Pau.Erg',\n",
       "  u'vengeance.INAN.N3.Sg.Obl',\n",
       "  u'ombre.INAN.N1.Pau.Dat',\n",
       "  u'livre.INAN.N1.Sg.Obl',\n",
       "  u'chasseur.HUM.N1.Pau.Abs',\n",
       "  u'souffrance.INAN.N2.Pl.Erg',\n",
       "  u'maison.INAN.N2.Pl.Obl',\n",
       "  u'lit.INAN.N1.Pl.Erg',\n",
       "  u'd\\xe9mon.ANIM.N3.Pl.Erg',\n",
       "  u'Elphaba.HUM.N2.Sg.Obl',\n",
       "  u'cuisine.INAN.N1.Sg.Abs',\n",
       "  u'homme.HUM.N1.Pl.Abs',\n",
       "  u'coyote.ANIM.N3.Pl.Dat',\n",
       "  u'Nabil.HUM.N2.Sg.Dat',\n",
       "  u'balai.INAN.N1.Pau.Erg',\n",
       "  u'chatte.ANIM.N1.Pau.Abs',\n",
       "  u'marais.INAN.N2.Pl.Abs',\n",
       "  u'souris.ANIM.N2.Pl.Erg',\n",
       "  u'dragon.ANIM.N1.Pl.Abs',\n",
       "  u'\\u0153uf.INAN.N3.Pl.Obl',\n",
       "  u'fille.HUM.N1.Pl.Dat',\n",
       "  u'chat.ANIM.N3.Sg.Dat',\n",
       "  u'chambre.INAN.N3.Sg.Obl',\n",
       "  u'coyote.ANIM.N3.Pau.Abs',\n",
       "  u'caf\\xe9.INAN.N2.Sg.Abs',\n",
       "  u'for\\xeat.INAN.N2.Pl.Abs',\n",
       "  u'sortil\\xe8ge.INAN.N3.Pl.Obl',\n",
       "  u'main.HUM.N2.Pl.Abs',\n",
       "  u'plaine.INAN.N1.Pl.Obl',\n",
       "  u'feu.ANIM.N3.Sg.Obl',\n",
       "  u'lance.INAN.N1.Sg.Dat',\n",
       "  u'chatte.ANIM.N1.Pau.Obl',\n",
       "  u'manoir.INAN.N2.Sg.Erg',\n",
       "  u'marais.INAN.N2.Pl.Obl',\n",
       "  u'Kaleb.HUM.N3.Pl.Erg',\n",
       "  u'Nicole.HUM.N3.Pau.Erg',\n",
       "  u'arbre.INAN.N1.Pl.Obl',\n",
       "  u'autruche.ANIM.N1.Sg.Erg',\n",
       "  u'fruit.INAN.N3.Pau.Erg',\n",
       "  u'caillou.INAN.N3.Pau.Dat',\n",
       "  u'caillou.INAN.N3.Pl.Obl',\n",
       "  u'Freja.HUM.N1.Sg.Erg',\n",
       "  u'autruche.ANIM.N1.Pau.Erg',\n",
       "  u'maison.INAN.N2.Sg.Obl',\n",
       "  u'Hoderi.HUM.N3.Sg.Erg',\n",
       "  u'village.INAN.N3.Pl.Dat',\n",
       "  u'maison.INAN.N2.Pl.Erg',\n",
       "  u'dragon.ANIM.N1.Sg.Dat',\n",
       "  u'chasseur.HUM.N1.Sg.Dat',\n",
       "  u'enfant.HUM.N3.Pau.Dat',\n",
       "  u'loup.ANIM.N1.Pl.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pau.Abs',\n",
       "  u'caf\\xe9.INAN.N2.Pau.Obl',\n",
       "  u'enfant.HUM.N3.Sg.Obl',\n",
       "  u'visage.INAN.N1.Pl.Abs',\n",
       "  u'fille.HUM.N1.Sg.Erg',\n",
       "  u'chatte.ANIM.N1.Sg.Abs',\n",
       "  u'milieu.INAN.N2.Sg.Obl',\n",
       "  u'gargouille.ANIM.N2.Pl.Obl',\n",
       "  u'souris.ANIM.N2.Pau.Abs',\n",
       "  u'lune.INAN.N3.Pau.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pau.Dat',\n",
       "  u'infirmi\\xe8re.HUM.N3.Sg.Abs',\n",
       "  u'infirmi\\xe8re.HUM.N3.Pl.Dat',\n",
       "  u'harmonie.INAN.N3.Sg.Obl',\n",
       "  u'villageoise.HUM.N2.Pl.Dat',\n",
       "  u'gar\\xe7on.HUM.N2.Pau.Abs',\n",
       "  u'coussin.INAN.N3.Pau.Obl',\n",
       "  u'd\\xe9mon.ANIM.N3.Sg.Obl',\n",
       "  u'villageois.HUM.N2.Pl.Dat',\n",
       "  u'arbre.INAN.N1.Sg.Obl',\n",
       "  u'homme.HUM.N1.Pl.Erg',\n",
       "  u'dragon.ANIM.N1.Sg.Obl',\n",
       "  u'coyote.ANIM.N3.Sg.Dat',\n",
       "  u'sortil\\xe8ge.INAN.N3.Sg.Erg',\n",
       "  u'chef.HUM.N2.Pl.Dat'],\n",
       " 'PRO': [u'PRO.Hum.Pl.Erg',\n",
       "  u'PRO.Anim.Sg.Erg',\n",
       "  u'PRO.Inan.Sg.Erg',\n",
       "  u'PRO.Hum.Pau.Erg',\n",
       "  u'PRO.Anim.Pau.Abs',\n",
       "  u'PRO.Hum.Sg.Erg',\n",
       "  u'PRO.Anim.Pau.Erg',\n",
       "  u'PRO.Hum.Pau.Abs',\n",
       "  u'PRO.Hum.Pau.Obl',\n",
       "  u'PRO.Hum.Sg.Abs',\n",
       "  u'PRO.Hum.Pl.Abs',\n",
       "  u'PRO.Anim.Pl.Erg',\n",
       "  u'PRO.Anim.Sg.Abs'],\n",
       " 'VER': [u'voler.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'pousser.VT.V2.Pst.TroisPau.INAN',\n",
       "  u'sortir.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'surplomber.VT.V2.Prs.TroisPl.INAN',\n",
       "  u'porter.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'sauter.VI.V2.Pst.TroisSg.HUM',\n",
       "  u'descendre.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'dormir.VI.V2.Pst.TroisPau.ANIM',\n",
       "  u'donner.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'allumer.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'compter.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'montrer.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'\\xeatre.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'tomber.VI.V1.Prs.TroisPau.ANIM',\n",
       "  u'faire.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'pleurer-act.VI.V1.Pst.TroisPl.HUM',\n",
       "  u'avoir.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'dormir.VI.V2.Prs.TroisPau.INAN',\n",
       "  u'planter.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'reconna\\xeetre.VT.V1.Pst.TroisPau.HUM',\n",
       "  u'montrer.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'acheter.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'prendre.VT.V2.Prs.TroisSg.HUM',\n",
       "  u'\\xeatre.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'tomber.VI.V1.Prs.TroisPau.INAN',\n",
       "  u'offrir.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'acheter.VT.V2.Prs.TroisPl.ANIM',\n",
       "  u'manger.VT.V1.Prs.TroisPau.INAN',\n",
       "  u'acheter.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'transpercer.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'chasser.VT.V1.Pst.TroisPau.HUM',\n",
       "  u'chasser.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'manger.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'offrir.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'manger.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'd\\xe9tester.VT.V2.Pst.TroisPau.ANIM',\n",
       "  u'donner.VT.V1.Prs.TroisPau.ANIM',\n",
       "  u'arriver.VI.V2.Prs.TroisSg.HUM',\n",
       "  u'retourner.VI.V1.Prs.TroisPau.HUM',\n",
       "  u'chasser.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'pousser.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'surplomber.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'parler.VI.V2.Prs.TroisPl.INAN',\n",
       "  u'raconter.VT.V2.Pst.TroisPau.INAN',\n",
       "  u'hurler.VI.V1.Prs.TroisPau.ANIM',\n",
       "  u'dormir.VI.V2.Prs.TroisPl.HUM',\n",
       "  u'interroger.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'donner.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'boire.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'courir.VI.V2.Pst.TroisPau.INAN',\n",
       "  u'arriver.VI.V2.Pst.TroisPl.INAN',\n",
       "  u'offrir.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'tomber.VI.V1.Pst.TroisPau.ANIM',\n",
       "  u'reconstruire.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'donner.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'chasser.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'supporter.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'poss\\xe9der.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'\\xe9changer.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'transformer.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'acheter.VT.V2.Pst.TroisPau.INAN',\n",
       "  u'tomber.VI.V1.Pst.TroisPau.INAN',\n",
       "  u'dormir.VI.V2.Prs.TroisPau.HUM',\n",
       "  u'manger.VT.V1.Pst.TroisPau.HUM',\n",
       "  u'donner.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisPl.ANIM',\n",
       "  u'\\xeatre.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'interroger.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'boire.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'arriver.VI.V2.Pst.TroisPl.HUM',\n",
       "  u'lancer.VT.V2.Prs.TroisPau.HUM',\n",
       "  u'tomber.VI.V1.Prs.TroisSg.HUM',\n",
       "  u'courir.VI.V2.Pst.TroisSg.HUM',\n",
       "  u'arr\\xeater.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'arriver.VI.V2.Pst.TroisSg.HUM',\n",
       "  u'donner.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'pleurer.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'dormir.VI.V2.Pst.TroisPau.INAN',\n",
       "  u'manger.VT.V1.Pst.TroisPl.ANIM',\n",
       "  u'arriver.VI.V2.Pst.TroisPau.HUM',\n",
       "  u'chercher.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'faire.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'arriver.VI.V2.Prs.TroisPl.INAN',\n",
       "  u'manger.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'tomber.VI.V1.Pst.TroisPl.ANIM',\n",
       "  u'boire.VT.V2.Prs.TroisPau.INAN',\n",
       "  u'jeter.VT.V2.Prs.TroisSg.ANIM',\n",
       "  u'fuir.VT.V1.Pst.TroisPau.HUM',\n",
       "  u'lancer.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'donner.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'manger.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'jeter.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'chasser.VT.V1.Pst.TroisPl.ANIM',\n",
       "  u'nourrir.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'sauter.VI.V2.Prs.TroisPau.HUM',\n",
       "  u'dormir.VI.V2.Prs.TroisSg.ANIM',\n",
       "  u'montrer.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'tomber.VI.V1.Pst.TroisSg.INAN',\n",
       "  u'jeter.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'manger.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'lancer.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'survoler.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'compter.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'dormir.VI.V2.Pst.TroisSg.ANIM',\n",
       "  u'chasser.VT.V1.Prs.TroisPau.ANIM',\n",
       "  u'montrer.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'dormir.VI.V2.Prs.TroisSg.INAN',\n",
       "  u'raconter.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'pousser.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'voler.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'cacher.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'jeter.VT.V2.Pst.TroisSg.HUM',\n",
       "  u'tomber.VI.V1.Pst.TroisSg.HUM',\n",
       "  u'parler.VI.V2.Pst.TroisSg.HUM',\n",
       "  u'boire.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'\\xeatre.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'hurler.VI.V1.Pst.TroisSg.HUM',\n",
       "  u'conna\\xeetre.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'attraper.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'chasser.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'jeter.VT.V2.Prs.TroisPl.INAN',\n",
       "  u'redevenir.VT.V2.Pst.TroisSg.ANIM',\n",
       "  u'chasser.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'chasser.VT.V1.Prs.TroisPau.INAN',\n",
       "  u'prot\\xe9ger.VT.V2.Prs.TroisPl.ANIM',\n",
       "  u'fuir.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'lancer.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'jardiner.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'envahir.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'acheter.VT.V2.Prs.TroisPau.ANIM',\n",
       "  u'voir.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'changer.VT.V2.Prs.TroisSg.ANIM',\n",
       "  u'jeter.VT.V2.Pst.TroisPau.INAN',\n",
       "  u'arriver.VI.V2.Prs.TroisPau.INAN',\n",
       "  u'montrer.VT.V1.Pst.TroisPau.HUM',\n",
       "  u'illustrer.VT.V1.Prs.TroisPau.INAN',\n",
       "  u'dormir.VI.V2.Pst.TroisPl.ANIM',\n",
       "  u'chercher.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'lancer.VT.V2.Pst.TroisPl.ANIM',\n",
       "  u'acheter.VT.V2.Prs.TroisPau.INAN',\n",
       "  u'voir.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'offrir.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'courir.VI.V2.Pst.TroisSg.ANIM',\n",
       "  u'lancer.VT.V2.Pst.TroisSg.ANIM',\n",
       "  u'acheter.VT.V2.Pst.TroisSg.HUM',\n",
       "  u'acheter.VT.V2.Pst.TroisSg.ANIM',\n",
       "  u'allumer.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'arriver.VI.V2.Prs.TroisSg.ANIM',\n",
       "  u'cacher.VT.V2.Pst.TroisPl.ANIM',\n",
       "  u'arriver.VI.V2.Pst.TroisSg.INAN',\n",
       "  u'acheter.VT.V2.Prs.TroisPl.INAN',\n",
       "  u'lancer.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'arriver.VI.V2.Prs.TroisSg.INAN',\n",
       "  u'manger.VT.V1.Prs.TroisPau.ANIM',\n",
       "  u'arriver.VI.V2.Pst.TroisPau.INAN',\n",
       "  u'd\\xe9vorer.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'lancer.VT.V2.Prs.TroisPl.ANIM',\n",
       "  u'prot\\xe9ger.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'dormir.VI.V2.Pst.TroisPau.HUM',\n",
       "  u'vivre.VI.V1.Prs.TroisSg.INAN',\n",
       "  u'manger.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'partir.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'offrir.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'boire.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'br\\xfbler.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'partir.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'changer.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'montrer.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'pousser.VT.V2.Pst.TroisSg.HUM',\n",
       "  u'tomber.VI.V1.Prs.TroisPl.INAN',\n",
       "  u'pleurer.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'pr\\xe9parer.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'compter.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'rejoindre.VT.V2.Prs.TroisSg.HUM',\n",
       "  u'dispara\\xeetre.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'montrer.VT.V1.Pst.TroisSg.HUM',\n",
       "  u'acheter.VT.V2.Pst.TroisPau.ANIM',\n",
       "  u'arriver.VI.V2.Pst.TroisPau.ANIM',\n",
       "  u'supporter.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'd\\xe9couvrir.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'supporter.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'manger.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'tomber.VI.V1.Pst.TroisSg.ANIM',\n",
       "  u'chasser.VT.V1.Pst.TroisPau.INAN',\n",
       "  u'acheter.VT.V2.Prs.TroisSg.HUM',\n",
       "  u'rejoindre.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'offrir.VT.V1.Pst.TroisPl.ANIM',\n",
       "  u'chercher.VT.V1.Pst.TroisPau.HUM',\n",
       "  u'prot\\xe9ger.VT.V2.Prs.TroisSg.HUM',\n",
       "  u'supporter.VT.V1.Pst.TroisPl.ANIM',\n",
       "  u'planter.VT.V2.Prs.TroisSg.HUM',\n",
       "  u'd\\xe9vorer.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'changer.VT.V2.Pst.TroisPau.HUM',\n",
       "  u'montrer.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'parler.VI.V2.Pst.TroisPau.ANIM',\n",
       "  u'manger.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'manquer.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'remercier.VT.V2.Pst.TroisPau.HUM',\n",
       "  u'tomber.VI.V1.Prs.TroisPl.ANIM',\n",
       "  u'manger.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'pr\\xe9senter.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'd\\xe9couvrir.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'apporter.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'surplomber.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'tomber.VI.V1.Pst.TroisPl.INAN',\n",
       "  u'r\\xeavasser.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'arriver.VI.V2.Prs.TroisPl.ANIM',\n",
       "  u'sortir.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'montrer.VT.V1.Pst.TroisPl.ANIM',\n",
       "  u'lancer.VT.V2.Prs.TroisPau.INAN',\n",
       "  u'tomber.VI.V1.Prs.TroisSg.INAN',\n",
       "  u'acheter.VT.V2.Pst.TroisPl.ANIM',\n",
       "  u'surplomber.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'courir.VI.V2.Pst.TroisPau.HUM',\n",
       "  u'manger.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'pr\\xe9parer.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'donner.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'noyer.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'prot\\xe9ger.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'allumer.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'entrer.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'\\xeatre.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'd\\xe9tester.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'accueillir.VT.V2.Prs.TroisSg.ANIM',\n",
       "  u'revenir.VI.V2.Pst.TroisPau.HUM',\n",
       "  u'noyer.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'dormir.VI.V2.Pst.TroisSg.INAN',\n",
       "  u'lancer.VT.V2.Pst.TroisPau.INAN',\n",
       "  u'br\\xfbler.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'apporter.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'acheter.VT.V2.Prs.TroisSg.ANIM',\n",
       "  u'changer.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'dispara\\xeetre.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'supporter.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'hurler.VI.V1.Prs.TroisSg.HUM',\n",
       "  u'dormir.VI.V2.Prs.TroisPau.ANIM',\n",
       "  u'courir.VI.V2.Prs.TroisPau.ANIM',\n",
       "  u'pleurer-act.VI.V1.Pst.TroisPau.HUM',\n",
       "  u'donner.VT.V1.Pst.TroisPl.ANIM',\n",
       "  u'prendre.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'tomber.VI.V1.Prs.TroisSg.ANIM',\n",
       "  u'lancer.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'\\xeatre.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'tourner.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'chasser.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'redevenir.VT.V2.Prs.TroisSg.ANIM',\n",
       "  u'supporter.VT.V1.Prs.TroisPau.INAN',\n",
       "  u'ressusciter.VT.V2.Prs.TroisSg.HUM',\n",
       "  u'lancer.VT.V2.Pst.TroisPau.ANIM',\n",
       "  u'interroger.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'allumer.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'montrer.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'arriver.VI.V2.Prs.TroisPau.HUM',\n",
       "  u'chasser.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'enfermer.VT.V1.Pst.TroisSg.HUM',\n",
       "  u'chercher.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'supporter.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'supporter.VT.V1.Prs.TroisPau.ANIM',\n",
       "  u'embrasser.VT.V2.Pst.TroisPau.HUM',\n",
       "  u'enlever.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'd\\xe9tester.VT.V2.Prs.TroisPl.HUM',\n",
       "  u'fuir.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'boire.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'dormir.VI.V2.Prs.TroisSg.HUM',\n",
       "  u'dormir.VI.V2.Pst.TroisPl.HUM',\n",
       "  u'demander.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'offrir.VT.V1.Prs.TroisPau.ANIM',\n",
       "  u'supporter.VT.V1.Prs.TroisPau.HUM',\n",
       "  u'voler.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'arriver.VI.V2.Prs.TroisPl.HUM',\n",
       "  u'retourner.VI.V1.Pst.TroisPau.HUM',\n",
       "  u'offrir.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'boire.VT.V2.Prs.TroisPl.INAN',\n",
       "  u'chercher.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'manger.VT.V1.Pst.TroisPau.INAN',\n",
       "  u'donner.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'courir.VI.V2.Prs.TroisSg.ANIM',\n",
       "  u'r\\xeavasser.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'enfermer.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'apporter.VT.V1.Prs.TroisPl.ANIM',\n",
       "  u'inqui\\xe9ter.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'dormir.VI.V2.Prs.TroisPl.ANIM',\n",
       "  u'attraper.VT.V1.Pst.TroisSg.HUM',\n",
       "  u'faire.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'chercher.VT.V1.Prs.TroisPl.HUM',\n",
       "  u'supporter.VT.V1.Pst.TroisPau.INAN',\n",
       "  u'remercier.VT.V2.Pst.TroisPl.HUM',\n",
       "  u'lancer.VT.V2.Pst.TroisPau.HUM',\n",
       "  u'prendre.VT.V2.Pst.TroisSg.INAN',\n",
       "  u'montrer.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'offrir.VT.V1.Pst.TroisPl.HUM',\n",
       "  u'entrer.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'supporter.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'compter.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'chasser.VT.V1.Pst.TroisSg.INAN',\n",
       "  u'supporter.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'apporter.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'chercher.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'offrir.VT.V1.Pst.TroisSg.ANIM',\n",
       "  u'acheter.VT.V2.Pst.TroisPl.INAN',\n",
       "  u'montrer.VT.V1.Prs.TroisSg.ANIM',\n",
       "  u'lancer.VT.V2.Prs.TroisPau.ANIM',\n",
       "  u'cacher.VT.V2.Prs.TroisSg.INAN',\n",
       "  u'offrir.VT.V1.Prs.TroisPl.INAN',\n",
       "  u'offrir.VT.V1.Prs.TroisSg.INAN',\n",
       "  u'reconna\\xeetre.VT.V1.Prs.TroisSg.HUM',\n",
       "  u'attraper.VT.V1.Pst.TroisPau.ANIM',\n",
       "  u'dormir.VI.V2.Pst.TroisSg.HUM',\n",
       "  u'mourir.VI.V1.Prs.TroisSg.HUM',\n",
       "  u'donner.VT.V1.Pst.TroisPl.INAN',\n",
       "  u'passer.VI.V1.Prs.TroisPl.INAN']}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in cellules:\n",
    "    cellules[k]=list(cellules[k])\n",
    "cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamlDump(serie+\"FilledCells.yaml\",cellules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py27)",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
