{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/16-K5\"\n",
    "serie=repertoire+\"/\"\n",
    "variante=\"-Corr\"\n",
    "#variante=\"\"\n",
    "complementPhrases=\"\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=1\n",
    "#casNombreDet=True\n",
    "separateurPhonoCloze=\" \"\n",
    "separateurMots=separateurPhonoCloze\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=False\n",
    "print_glose=False\n",
    "print_radicaux=False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True\n",
    "no_form=\"***\"\n",
    "# no_grapho=['dormir', 'lit']\n",
    "# no_phono=['gros', 'coussin']\n",
    "no_grapho=['petit','Nabil',\"sur\"]\n",
    "no_phono=[\"grand\",\"autruche\",'dans']\n",
    "phono_no=u\"XXXXX\"\n",
    "grapho_no=u\"XXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Radicaux.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\\\\\\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Acc\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cas', 'Genre', 'Nombre', 'Pers', 'Temps', 'Trans'}"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VER', 'NOM', 'DET', 'ADJ']"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False,\n",
       "  'Trans': False},\n",
       " 'DET': {'Cas': True,\n",
       "  'Genre': False,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False,\n",
       "  'Trans': False},\n",
       " 'NOM': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False,\n",
       "  'Trans': False},\n",
       " 'VER': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': True,\n",
       "  'Temps': True,\n",
       "  'Trans': True}}"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS',\n",
       " 'PST',\n",
       " '3Sg',\n",
       " '3Du',\n",
       " '3Pl',\n",
       " 'VI',\n",
       " 'VT',\n",
       " 'VD',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'Sg',\n",
       " 'Du',\n",
       " 'Pl']"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_gn(depart,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom=[]\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    for mot in groupe_nom:\n",
    "        if reste==0:\n",
    "#            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "            if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"DU\"\n",
    "                if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "            else:\n",
    "                nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                if debug or 0: \n",
    "                    print \"mot\",[mot]\n",
    "                    print \"vedette\",PFM.lexique.formeLexeme[mot][0],categorie\n",
    "                    print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                    tete=categorie\n",
    "                    if debug or 0: print \"tête :\", tete\n",
    "                    tampon=tete.split('.')\n",
    "#                    classe=tampon[0]\n",
    "                    classesNom=PFM.lexique.formeLexeme[mot][0].split('.')[1:]\n",
    "                    if debug or 0: print \"classesNom\",classesNom \n",
    "                    classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                    if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                    try:\n",
    "                        typeMot=tampon[1]\n",
    "                    except IndexError:\n",
    "                        typeMot=''\n",
    "                    if mot[len(mot)-1]=='s':\n",
    "                        if nombre==\"\": nombre=\"PL\"\n",
    "                    else:\n",
    "                        if nombre==\"\": nombre=\"SG\"\n",
    "                    nom.append(PFM.lexique.formeLexeme[mot][0])\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "                    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                        cas=\"\"\n",
    "#                    else:\n",
    "                    cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                    if cas==\"ERG\":\n",
    "                        erg_genre=classe\n",
    "                        erg_nombre=nombre\n",
    "                        if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                    elif cas==\"ABS\":\n",
    "                        abs_genre=classe\n",
    "                        abs_nombre=nombre\n",
    "                        if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                elif categorie in [\"DET\"]:\n",
    "                    det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                elif categorie in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                    gp.append(mot)\n",
    "                    reste=1\n",
    "        else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "            gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det: det.append(\"IND\")\n",
    "    tempSyntagme=[]\n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "        if mot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", groupe_prep\n",
    "    formePreposition=groupe_prep[0]\n",
    "    if debug: print [formePreposition], formePreposition\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        noligMot=groupe_prep[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            texte.append(ref)\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print ref\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else: \n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%% version : __file__\n",
      "%% traitement : 160709-1534\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "print \"%% version : \"+version\n",
    "print \"%% traitement : \"+time_stamp\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortieLatex=True):\n",
    "    if sortieLatex:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortieLatex: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrase_file):\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").split(\"\\t\")\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug: print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "            verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            temp=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print temp\n",
    "            formeCitation=temp[0]\n",
    "            for element in temp[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            typeVerbe=temp[1]\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (localMots,(localClasses,localNombre,localCas))\n",
    "            phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            if len(tampon)>=3:\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe:\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']: phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            if len(tampon)>=5:\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    phrase[syntagmes['Phrase'].index('COMP')]=faire_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                phrase[syntagmes['Phrase'].index('AJOUT')]=faire_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "\n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent)\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            texte.append(glose)\n",
    "            if sortieLatex: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"{}\")\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortieLatex:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortieLatex: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=list(element)\n",
    "                    if caracteres[len(caracteres)-1]=='S':\n",
    "                        caracteres[len(caracteres)-1]='s'\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(\"\".join(caracteres))\n",
    "            if sortieLatex: \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortieLatex and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortieLatex: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortieLatex:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if 1:\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "    else:\n",
    "        clozeTraductions=[]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(exemples)]*3):\n",
    "            phonoMots=phonoLigne.strip().split(\"{}\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")[:-1]\n",
    "#                print element,cleElement\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print cleElement,traductions[cleElement]\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+\"Traductions\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print os.path.realpath(phrase_nom)\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file)\n",
    "phrase_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not open the sentence file /Users/gilles/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/16-K5/Traductions.csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.load(stream)\n",
    "if traduction_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the sentence file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the sentence file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[3]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,False)\n",
    "            traduction_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PFM.hierarchieCF.classes\n",
    "#discrimineur\n",
    "tableaux[\"NOM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
