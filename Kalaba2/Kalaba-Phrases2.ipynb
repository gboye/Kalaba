{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "repertoire=home+\"/ownCloud/Cours/Bordeaux/L1-LinguistiqueGenerale/Kalaba-Project/16-K5\"\n",
    "serie=repertoire+\"/\"\n",
    "variante=\"-Corr\"\n",
    "variante=\"\"\n",
    "complementPhrases=\"\"\n",
    "#########################IMPORTS############################################\n",
    "import codecs, optparse\n",
    "import re, random\n",
    "import sys,os,time\n",
    "import string\n",
    "import yaml\n",
    "import ParFuMor as PFM\n",
    "from ParFuMor import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################VARIABLES##########################################\n",
    "version=os.path.basename(\"__file__\")\n",
    "time_stamp='%s' % time.strftime(\"%y%m%d-%H%M\")\n",
    "debug=0\n",
    "debug_now=1\n",
    "#casNombreDet=True\n",
    "separateurPhonoCloze=\" \"\n",
    "separateurMots=separateurPhonoCloze\n",
    "marqueurCommentaire=\"%\"\n",
    "print_no=True\n",
    "print_taches=False\n",
    "print_coffee=False\n",
    "print_commands=True\n",
    "print_ortho=True\n",
    "print_phono=True\n",
    "print_glose=False\n",
    "print_radicaux=False\n",
    "#if separateurMots==\"\":\n",
    "#    print_glose=False\n",
    "if variante==\"-Corr\":\n",
    "    print_taches=False\n",
    "    print_coffee=False\n",
    "    print_commands=True\n",
    "    print_ortho=True\n",
    "    print_phono=True\n",
    "    print_glose=True    \n",
    "if print_glose:\n",
    "    separateurMots=\" \"\n",
    "if print_glose+print_ortho+print_phono>1:\n",
    "    print_phrases=True\n",
    "else:\n",
    "    print_phrases=False\n",
    "print_lexique=True\n",
    "print_cloze=True\n",
    "print_racines=True\n",
    "no_form=\"***\"\n",
    "# no_grapho=['dormir', 'lit']\n",
    "# no_phono=['gros', 'coussin']\n",
    "no_grapho=['petit','Nabil',\"sur\"]\n",
    "no_phono=[\"grand\",\"autruche\",'dans']\n",
    "phono_no=u\"XXXXX\"\n",
    "grapho_no=u\"XXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_glose+print_ortho+print_phono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1614,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prononciationBegin=[\n",
    "    \"\\\\begin{center}\",\n",
    "        \"\\\\begin{tabular}{lcc}\",\n",
    "        \"\\\\toprule\",\n",
    "        u\"Graphie & Prononciation & Mot français \\\\\\\\\",\n",
    "        \"\\\\midrule\"\n",
    "        ]\n",
    "prononciationEnd=[\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\",\n",
    "    \"\\\\end{center}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(serie+\"Gloses.yaml\", 'r') as stream:\n",
    "    gloses=yaml.load(stream)\n",
    "with open(serie+\"Stems.yaml\", 'r') as stream:\n",
    "    stems=yaml.load(stream)\n",
    "with open(serie+\"Phonology.yaml\", 'r') as stream:\n",
    "    phonology=yaml.load(stream)\n",
    "with open(serie+\"MorphoSyntax.yaml\", 'r') as stream:\n",
    "    morphosyntax=yaml.load(stream)\n",
    "with open(serie+\"Clozes.txt\", 'r') as stream:\n",
    "    clozeLines=stream.readlines()\n",
    "\n",
    "discrimineur=[]\n",
    "discriminant={}\n",
    "for line in clozeLines:\n",
    "    line=line.strip()\n",
    "    if not line.startswith(\"#\"):\n",
    "        elementsCloze=line.split(\";\")\n",
    "        discriminant[elementsCloze[0]]=\";\".join([element for element in elementsCloze[1:] if element!=elementsCloze[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "defaultCols=2\n",
    "defaultLong=0\n",
    "maxChunk=48\n",
    "dimensionsTableaux={i:{} for i in gloses}\n",
    "for categorie in gloses:\n",
    "    if \"Dimensions\" in morphosyntax:\n",
    "        if \"maxChunk\" in morphosyntax[\"Dimensions\"]:\n",
    "            maxChunk=morphosyntax[\"Dimensions\"][\"maxChunk\"]\n",
    "        print maxChunk\n",
    "        if categorie in morphosyntax[\"Dimensions\"] and morphosyntax[\"Dimensions\"][categorie]:\n",
    "#            print categorie\n",
    "            if \"cols\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=morphosyntax[\"Dimensions\"][categorie][\"cols\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            if \"long\" in morphosyntax[\"Dimensions\"][categorie]:\n",
    "                dimensionsTableaux[categorie][\"long\"]=morphosyntax[\"Dimensions\"][categorie][\"long\"]\n",
    "            else:\n",
    "                dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "        else:\n",
    "            dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "            dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "    else:\n",
    "        dimensionsTableaux[categorie][\"cols\"]=defaultCols\n",
    "        dimensionsTableaux[categorie][\"long\"]=defaultLong\n",
    "if print_radicaux:\n",
    "    nomTableaux=\"Tableaux-Radicaux.yaml\"\n",
    "else:\n",
    "    nomTableaux=\"Tableaux.yaml\"    \n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.load(stream)\n",
    "with open(serie+\"Hierarchie-S2.pkl\", 'rb') as input:\n",
    "   PFM.hierarchieCF = pickle.load(input)\n",
    "with open(serie+\"Lexique-S2.pkl\", 'rb') as input:\n",
    "   PFM.lexique = pickle.load(input)\n",
    "with open(serie+\"Regles-S2.pkl\", 'rb') as input:\n",
    "   PFM.regles = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\\xe0', 'les'], ['de', 'le'], ['de', 'les'], [u'\\xe0', 'le'], ['de']]"
      ]
     },
     "execution_count": 1618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[morphosyntax[\"Contractions\"][x] for x in morphosyntax[\"Contractions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des entêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################CONSTANTS##########################################\n",
    "head = [\n",
    "\"\\\\begin{tabular}[t]{|l|l|l|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Mot & Roman & Glose  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_n = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Nom & Genre & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} & V\\\\indice{L}  \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]\n",
    "head_v = [\n",
    "\"\\\\begin{tabular}[t]{|l|c|c|}\",\n",
    "\"\\\\addlinespace[-1.0em]\\\\hline\",\n",
    "\"Verbe & Type & C\\\\indice{1}C\\\\indice{2}C\\\\indice{3} \\\\\\\\\",\n",
    "\"\\\\hline\\\\strutgh{14pt}%\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tail = [\n",
    "\"\\\\hline\"\n",
    "\"\\\\end{tabular}\\\\\\\\\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des structures pour impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accumulerMots(mot):\n",
    "    accumulateur.append(mot)\n",
    "    return\n",
    "def ajouterExemple(exemple,printBool=False):\n",
    "    if printBool:\n",
    "        print exemple\n",
    "    exemples.append(exemple.strip())\n",
    "    del accumulateur[:]\n",
    "    return\n",
    "def ajouterVocabulaire(terme,printBool=False):\n",
    "    if printBool:\n",
    "        print terme\n",
    "    vocabulaire.append(terme.strip())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consonnes=phonology[\"consonnes\"]\n",
    "voyelles=phonology[\"voyelles\"]\n",
    "gabarits=phonology[\"gabarits\"]\n",
    "derives=phonology[\"derives\"]\n",
    "nom_classe=phonology[\"nom_classe\"]\n",
    "nom_apo=phonology[\"apophonies\"]\n",
    "\n",
    "nom_mut=phonology[\"mutations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sujetVerbe=[]\n",
    "if \"Cas\" in gloses[\"NOM\"]:\n",
    "    if \"Acc\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Nom\")\n",
    "    if \"Erg\" in gloses[\"NOM\"][\"Cas\"]:\n",
    "        sujetVerbe.append(\"Abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sujetVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributsMots=set()\n",
    "valAttributs={}\n",
    "for categorie in gloses:\n",
    "    if gloses[categorie]:\n",
    "        for element in gloses[categorie]:\n",
    "            attributsMots.add(element)\n",
    "            if gloses[categorie][element]:\n",
    "                if not element in valAttributs:\n",
    "                    valAttributs[element]=[]\n",
    "                for attribut in gloses[categorie][element]:\n",
    "                    if not attribut in valAttributs[element]:\n",
    "                        valAttributs[element].append(attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cas', 'Genre', 'Nombre', 'Pers', 'Temps', 'Trans'}"
      ]
     },
     "execution_count": 1626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsMots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VER', 'NOM', 'DET', 'ADJ']"
      ]
     },
     "execution_count": 1627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut={}\n",
    "flexCategories=[element for element in gloses if gloses[element]]\n",
    "for element in flexCategories:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsMots}\n",
    "flexCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1628,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False,\n",
       "  'Trans': False},\n",
       " 'DET': {'Cas': True,\n",
       "  'Genre': False,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False,\n",
       "  'Trans': False},\n",
       " 'NOM': {'Cas': True,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': False,\n",
       "  'Temps': False,\n",
       "  'Trans': False},\n",
       " 'VER': {'Cas': False,\n",
       "  'Genre': True,\n",
       "  'Nombre': True,\n",
       "  'Pers': True,\n",
       "  'Temps': True,\n",
       "  'Trans': True}}"
      ]
     },
     "execution_count": 1628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributsDetAdjNom=[\"Genre\",\"Nombre\",\"Cas\"]\n",
    "valAttribut={}\n",
    "for attribut in attributsDetAdjNom:\n",
    "    if attribut in gloses[\"N\"]:\n",
    "        valAttribut[attribut]=gloses[\"N\"][attribut]\n",
    "    elif attribut in gloses[\"ADJ\"]:\n",
    "        valAttribut[attribut]=gloses[\"ADJ\"][attribut]\n",
    "    elif attribut in gloses[\"DET\"]:\n",
    "        valAttribut[attribut]=gloses[\"DET\"][attribut]\n",
    "    else:\n",
    "        valAttribut[attribut]=[]\n",
    "boolAttribut={}\n",
    "for element in [\"DET\",\"ADJ\",\"N\"]:\n",
    "    boolAttribut[element]={key:key in gloses[element] for key in attributsDetAdjNom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#types=gloses[\"V\"][\"CF\"]\n",
    "if \"Cas\" in morphosyntax:\n",
    "    casSyntagmes=morphosyntax[\"Cas\"]\n",
    "else:\n",
    "    casSyntagmes=\"\"\n",
    "lexiquePrepositions=[stems[\"PREP\"][x][0] for x in stems[\"PREP\"]]\n",
    "casPreposition={}\n",
    "for preposition in lexiquePrepositions:\n",
    "    prep=preposition.upper()\n",
    "    if casSyntagmes and prep in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[prep].capitalize()\n",
    "    elif casSyntagmes and \"PREP\" in casSyntagmes:\n",
    "        casPreposition[preposition]=casSyntagmes[\"PREP\"].capitalize()\n",
    "    else:\n",
    "        casPreposition[preposition]=\"\"\n",
    "        \n",
    "i=2\n",
    "verbe_forme={}\n",
    "for forme in morphosyntax[\"VER\"][\"FormesBase\"]:\n",
    "    verbe_forme[i]=forme\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1630,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valAttribut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacement des numéros de personnes pour les noms de macro LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remplacerPersonnes(chaine):\n",
    "    chaine.replace(\"1\",\"Un\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 1632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remplacerPersonnes(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result\n",
    "\n",
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))\n",
    "\n",
    "deligatures=phonology[\"translations\"][\"deligatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syntagmes=morphosyntax[\"Syntagmes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contractions=morphosyntax[\"Contractions\"]\n",
    "for contraction in contractions:\n",
    "    temp=[]\n",
    "    for element in contractions[contraction]:\n",
    "        if isinstance(element,unicode):\n",
    "            temp.append(element)\n",
    "        else:\n",
    "            temp.append(element.decode(\"utf8\"))\n",
    "    contractions[contraction]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syllabes=phonology[\"syllabes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRS',\n",
       " 'PST',\n",
       " '3Sg',\n",
       " '3Du',\n",
       " '3Pl',\n",
       " 'VI',\n",
       " 'VT',\n",
       " 'VD',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'Sg',\n",
       " 'Du',\n",
       " 'Pl']"
      ]
     },
     "execution_count": 1637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributsFlexVerbe=[glosesVerbe for attributFlex in gloses[\"VER\"] for glosesVerbe in gloses[\"VER\"][attributFlex]]\n",
    "attributsFlexVerbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def taches():\n",
    "    '''\n",
    "    seuil1 pour avoir une tâche\n",
    "    seuil2 pour avoir plusieurs tâches\n",
    "    '''\n",
    "    seuil1=8\n",
    "    seuil2=14\n",
    "    def makeStain():\n",
    "        seed=random.randint(1,1000)\n",
    "        x=random.gauss(10,5)-1\n",
    "        y=random.gauss(2,1)\n",
    "        minimum=random.gauss(.2,.1)+.1\n",
    "        maximum=random.gauss(.1,.05)+.5\n",
    "        return \"\\\\taches{%s}{%s}{%s}{%s}{%s}\"%(seed,x,y,minimum,maximum)\n",
    "\n",
    "    if print_taches:\n",
    "        n=random.gauss(10,2.5)\n",
    "        if n<seuil1:\n",
    "            return \"\"\n",
    "        elif n<=seuil2:\n",
    "            return makeStain()\n",
    "        else:\n",
    "            nTaches=int(n-seuil1)\n",
    "            stains=\"\"\n",
    "            for i in range(nTaches):\n",
    "                stains+=makeStain()\n",
    "            return stains\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_tableau(tableau,tab=(head,tail,\"\")):\n",
    "    if len(tableau)==0: return\n",
    "    comment=tab[2]\n",
    "    for element in tab[0]:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tableau:\n",
    "        ajouterVocabulaire(comment+element)\n",
    "    for element in tab[1]:\n",
    "        ajouterVocabulaire(comment+element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_tableaux(cols,recuTableau,texte=\"\",debut=0,tab=(head,tail,\"\"),boolEchantillon=True):\n",
    "    tableau=sorted(list(set(recuTableau)))\n",
    "    if debug: print \"recuTableau\",(recuTableau)\n",
    "#    print (tableau)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\begin{multicols}{\"+str(cols)+\"}\")\n",
    "#    if texte!=\"\":\n",
    "    (table,reste)=filtrer_tableau(tableau,texte)\n",
    "#    print reste\n",
    "#    else:\n",
    "#        (table,reste)=tableau\n",
    "#        reste=[]\n",
    "    chunk=(len(table)-debut*cols)/cols+1\n",
    "    faire_tableaux(table,debut,cols,tab)\n",
    "    ajouterVocabulaire(tab[2]+\"\\\\end{multicols}\")\n",
    "    echantillon=min(len(reste),3)\n",
    "    if echantillon>0 and boolEchantillon:\n",
    "        for element in random.sample(reste,echantillon):\n",
    "#            print element\n",
    "            colonnes=element.split(\"&\")\n",
    "            graphie=colonnes[0].strip()\n",
    "            phonologie=colonnes[1].strip()\n",
    "            glose=colonnes[2].strip().strip(\"\\\\\")\n",
    "            prononciationExtrait.append(graphie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\"%phonologie+\"&\")\n",
    "            prononciationExtrait.append(\"\\\\blanc{%s}\\\\\\\\\"%glose)\n",
    "            if debug: print \"\".join(prononciationExtrait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_tableaux(tableau,debut=16,nombre=1,tab=(head,tail,\"\")):\n",
    "    reste=[]\n",
    "    if debug: print nombre,debut,tableau\n",
    "    if debut!=0:\n",
    "        for i in range(nombre):\n",
    "            faire_tableau(tableau[debut*i:debut*(i+1)],tab)\n",
    "        table=tableau[debut*nombre:]\n",
    "    else:\n",
    "        table=tableau\n",
    "    longueur=len(table)\n",
    "    chunk=longueur/nombre+1\n",
    "    if debug: print \"CHUNKING : \",longueur, nombre, chunk, table\n",
    "    if chunk<maxChunk:\n",
    "        chunks=chunk\n",
    "    else:\n",
    "        chunks=maxChunk\n",
    "        reste=table[maxChunk*nombre:]\n",
    "    if debug: print \"RESTE : \", chunk, reste\n",
    "    for i in range(nombre):\n",
    "        faire_tableau(table[chunks*i:chunks*(i+1)],tab)\n",
    "    if reste:\n",
    "        faire_tableaux(reste,0,nombre,tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1642,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filtrer_tableau(tableau,filtre):\n",
    "    presents=[]\n",
    "    absents=[]\n",
    "    for line in tableau:\n",
    "        elements=line.split(\" \")\n",
    "        cleElement=elements[0].replace(\"\\\\\",\"\")\n",
    "        if elements[0] in filtre:\n",
    "            if not discriminant[cleElement] in discrimineur:\n",
    "                discrimineur.append(discriminant[cleElement])\n",
    "    #                print \"présent\",elements[0]\n",
    "            presents.append(line)\n",
    "        else:\n",
    "#                print \"absent\",elements[0]\n",
    "            absents.append(line)\n",
    "    return (presents,absents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_gn(depart,cas):\n",
    "    global erg_genre, erg_nombre, abs_genre, abs_nombre\n",
    "    if debug: print \"groupe depart :\", depart\n",
    "    groupe_nom=[]\n",
    "    groupe_nom.append(depart[0])\n",
    "    if debug: print depart[0]\n",
    "    for mot in depart[1:]:\n",
    "        if debug: print mot\n",
    "        if not \"#\" in mot:\n",
    "            groupe_nom.extend(etendre_contraction([mot]))\n",
    "    if debug: print \"groupe nom :\", groupe_nom\n",
    "    mots=[]\n",
    "    det=[]\n",
    "    adj=[]\n",
    "    nom=[]\n",
    "    gp=[]\n",
    "    structureSyntagme={key:[] for key in syntagmes['GN']}\n",
    "    tete=\"\"\n",
    "    nombre=\"\"\n",
    "    classe=\"\"\n",
    "    classesNom=[]\n",
    "    reste=0\n",
    "    groupe_nom=[element for element in groupe_nom if element!=\"\"]\n",
    "    for mot in groupe_nom:\n",
    "        if reste==0:\n",
    "#            if mot==\"deux\" and \"Du\" in nombresNom:\n",
    "            if mot==\"deux\" and \"Du\" in valAttributs[\"Nombre\"]:\n",
    "                nombre=\"DU\"\n",
    "                if det==[]: det.append(PFM.lexique.formeLexeme[\"des\"][0])\n",
    "            else:\n",
    "                nomLexeme=PFM.lexique.formeLexeme[mot][0]\n",
    "                categorie=PFM.lexique.lexemes[nomLexeme].classe.split(\".\")[-1]\n",
    "                if debug or 0: \n",
    "                    print \"mot\",[mot]\n",
    "                    print \"vedette\",PFM.lexique.formeLexeme[mot][0],categorie\n",
    "                    print \"categories\",PFM.hierarchieCF.classes[\"NOM\"],PFM.hierarchieCF.getCategory(categorie)\n",
    "                if PFM.hierarchieCF.getCategory(categorie)==\"NOM\":\n",
    "                    tete=categorie\n",
    "                    if debug or 0: print \"tête :\", tete\n",
    "                    tampon=tete.split('.')\n",
    "#                    classe=tampon[0]\n",
    "                    classesNom=PFM.lexique.formeLexeme[mot][0].split('.')[1:]\n",
    "                    if debug or 0: print \"classesNom\",classesNom \n",
    "                    classe=[classeElement for classeElement in classesNom if classeElement in gloses[\"NOM\"][\"Genre\"]][0]\n",
    "                    if debug or 0: print \"classes\",mot,classe,classesNom\n",
    "                    try:\n",
    "                        typeMot=tampon[1]\n",
    "                    except IndexError:\n",
    "                        typeMot=''\n",
    "                    if mot[len(mot)-1]=='s':\n",
    "                        if nombre==\"\": nombre=\"PL\"\n",
    "                    else:\n",
    "                        if nombre==\"\": nombre=\"SG\"\n",
    "                    nom.append(PFM.lexique.formeLexeme[mot][0])\n",
    "#                    if typeCas==\"NoCas\":\n",
    "#                        cas=\"\"\n",
    "                    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"]:\n",
    "                        cas=\"\"\n",
    "#                    else:\n",
    "                    cellule=classe.capitalize()+nombre.capitalize()+cas.capitalize()\n",
    "                    if cas==\"ERG\":\n",
    "                        erg_genre=classe\n",
    "                        erg_nombre=nombre\n",
    "                        if debug: print \"ERG\",erg_genre, erg_nombre\n",
    "                    elif cas==\"ABS\":\n",
    "                        abs_genre=classe\n",
    "                        abs_nombre=nombre\n",
    "                        if debug: print \"ABS\",abs_genre, abs_nombre\n",
    "                elif categorie in [\"DET\"]:\n",
    "                    det.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                elif categorie in [\"ADJ\"] or (\"ADJ\" in PFM.hierarchieCF.classes and categorie in PFM.hierarchieCF.classes[\"ADJ\"]):\n",
    "                    adj.append(PFM.lexique.formeLexeme[mot][0])\n",
    "                elif categorie==\"PREP\":\t\t\t#Si on trouve une PREP, elle et le reste forment un GP\n",
    "                    gp.append(mot)\n",
    "                    reste=1\n",
    "        else:\t\t\t\t\t\t\t#On a trouvé une PREP, toute la suite va dans GP\n",
    "            gp.append(mot)\n",
    "    if debug: print \"accord :\", tete\n",
    "    if reste==1: gp=faire_gp(gp)\n",
    "    if debug: print \"GP dans le GN : \", gp\n",
    "    if debug: print \"GN sans det ? \", det\n",
    "    if not det: det.append(\"IND\")\n",
    "    tempSyntagme=[]\n",
    "    for mot in det:\n",
    "        (casDet,nombreDet)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Cas\"]:\n",
    "            casDet=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Nombre\"]:\n",
    "            nombreDet=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"DET\"] or not boolAttribut[\"DET\"][\"Genre\"]:\n",
    "            classeDet=\"\"\n",
    "        else:\n",
    "            classeDet=[classeElement for classeElement in classesNom if classeElement in gloses[\"DET\"][\"Genre\"]][0]\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        for attributDet in morphosyntax[\"Attributs\"][\"DET\"]:\n",
    "            if attributDet==\"Cas\":\n",
    "                ref+=casDet.capitalize()\n",
    "            elif attributDet==\"Nombre\":\n",
    "                ref+=nombreDet.capitalize()\n",
    "            elif attributDet==\"Genre\":\n",
    "                ref+=classeDet.capitalize()\n",
    "        tempSyntagme.append(ref)\n",
    "        texte.append(ref)\n",
    "    structureSyntagme[\"DET\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"DET\"),separateurMots.join(structureSyntagme[\"DET\"]))\n",
    "    tempSyntagme=[]\n",
    "    for mot in gp: \n",
    "#        mots.append(mot)\n",
    "        tempSyntagme.append(mot)\n",
    "    structureSyntagme[\"GP\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GP\"),structureSyntagme[\"GP\"])\n",
    "    tempSyntagme=[]\n",
    "    for mot in adj:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "        (casAdj,nombreAdj)=(cas,nombre)\n",
    "        if not \"Cas\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Cas\"]:\n",
    "            casAdj=\"\"\n",
    "        if not \"Nombre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Nombre\"]:\n",
    "            nombreAdj=\"\"\n",
    "        if not \"Genre\" in boolAttribut[\"ADJ\"] or not boolAttribut[\"ADJ\"][\"Genre\"]:\n",
    "            classeAdj=\"\"\n",
    "        else:\n",
    "            classeAdj=[classeElement for classeElement in classesNom if classeElement in gloses[\"ADJ\"][\"Genre\"]][0]\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+classeAdj.capitalize()+nombreAdj.capitalize()+casAdj.capitalize()\n",
    "#        mots.append(ref)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"GADJ\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"GADJ\"),structureSyntagme[\"GADJ\"])\n",
    "    tempSyntagme=[]\n",
    "#    print \"classe,nombre,cas\", classe, nombre, cas\n",
    "    for mot in nom:\n",
    "#\t\tglose=faire_glose(mot,classe,type,nombre)\n",
    "\n",
    "        noligMot=mot.split(\".\")[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "        if mot.istitle():\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent)+cellule\n",
    "        else:\n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).lower()+cellule\n",
    "#        mots.append(ref)\n",
    "        texte.append(ref)\n",
    "        tempSyntagme.append(ref)\n",
    "    structureSyntagme[\"NOM\"]=tempSyntagme\n",
    "    mots.insert(syntagmes['GN'].index(\"NOM\"),structureSyntagme[\"NOM\"])\n",
    "    listeMots=[]\n",
    "    for element in syntagmes['GN']:\n",
    "        listeMots+=structureSyntagme[element]\n",
    "    return (listeMots,(classesNom,nombre,cas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_gp(groupe_prep,fonction=\"\"):\n",
    "    mots=[]\n",
    "    groupe_prep=etendre_contraction(groupe_prep)\n",
    "    if debug: print \"faire_gp\", groupe_prep\n",
    "    formePreposition=groupe_prep[0]\n",
    "    if debug: print [formePreposition], formePreposition\n",
    "    preposition=PFM.lexique.formeLexeme[formePreposition][0]\n",
    "#    if preposition!=\"à\" or typeCas==\"NoCas\":\n",
    "    if not \"Cas\" in boolAttribut[\"NOM\"] or not boolAttribut[\"NOM\"][\"Cas\"] or fonction!=\"IND\":\n",
    "        if debug: print u\"fonction!=IND\",[groupe_prep[0],u\"à\"]\n",
    "\n",
    "        noligMot=groupe_prep[0]\n",
    "        for ligature in deligatures:\n",
    "            noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "\n",
    "        ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "        if debug: print ref\n",
    "        if casSyntagmes and preposition in casPreposition:\n",
    "            if debug: \n",
    "                print casPreposition, casPreposition[preposition]\n",
    "            cas=casPreposition[preposition]            \n",
    "            if \"+\" in casPreposition[preposition]:\n",
    "                cas=cas.strip(\"+\")\n",
    "                mots.append(ref)\n",
    "                texte.append(ref)\n",
    "        else:\n",
    "            if debug: print \"pas de Cas\"\n",
    "            cas=\"\"\n",
    "            mots.append(ref)\n",
    "            texte.append(ref)\n",
    "        if debug:\n",
    "            print \"groupe prep :\", groupe_prep\n",
    "            print ref\n",
    "        if len(groupe_prep)>1:\n",
    "            groupe_nom=groupe_prep[1:]\n",
    "            if debug: print groupe_nom[0]\n",
    "            #\n",
    "            # Choisir le cas en fonction de la préposition\n",
    "            #\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "            mots.insert(syntagmes['GP'].index(\"GN\"),localMots)\n",
    "        if debug: \n",
    "            print groupe_prep, cas, mots\n",
    "        return mots\n",
    "    elif fonction==\"IND\":\n",
    "        groupe_nom=groupe_prep[1:]\n",
    "        cas=casSyntagmes[\"IND\"]\n",
    "        if \"+\" in casSyntagmes[\"IND\"]:\n",
    "            \n",
    "            noligMot=groupe_prep[0]\n",
    "            for ligature in deligatures:\n",
    "                noligMot=noligMot.replace(ligature,deligatures[ligature])\n",
    "            \n",
    "            ref=\"\\\\\"+recoder(noligMot,deaccent).upper()\n",
    "            cas=cas.strip(\"+\")\n",
    "            mots.append(ref)\n",
    "            texte.append(ref)\n",
    "        if debug: print \"faire_gn\", groupe_nom, faire_gn(groupe_nom,cas)\n",
    "        (localMots,(localClasses,localNombre,localCas))=faire_gn(groupe_nom,cas)\n",
    "        mots.append(localMots)\n",
    "        return mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def etendre_contraction(liste):\n",
    "    result=[]\n",
    "    if liste[0] in contractions.keys():\n",
    "        if debug: print \"EXT : \", liste, contractions[liste[0]],liste[1:] \n",
    "        result.extend(contractions[liste[0]])\n",
    "        result.extend(liste[1:])\n",
    "    else:\n",
    "        result=liste\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printflat(liste,suffixe=\"\",prefixe=\"\"):\n",
    "    if debug: print \"printflat\", liste\n",
    "    if not isinstance(liste, basestring):\n",
    "        for element in liste:\n",
    "            accumulerMots(prefixe)\n",
    "            printflat(element,suffixe)\n",
    "    else: \n",
    "        accumulerMots(prefixe)\n",
    "        accumulerMots(liste+suffixe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#\n",
    "#\tINITIALISATION DES VARIABLES\n",
    "#\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    __IPYTHON__ \n",
    "    ipython=True\n",
    "except: \n",
    "    ipython=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%% version : __file__\n",
      "%% traitement : 160904-2043\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "#\n",
    "# LECTURE DU FICHIER DE LEXEMES\n",
    "#\n",
    "#\t\tLES LIGNES QUI COMMENCENT PAR # SONT IGNOREES\n",
    "#\n",
    "################\n",
    "print \"%% version : \"+version\n",
    "print \"%% traitement : \"+time_stamp\n",
    "\n",
    "if ipython or True:\n",
    "#    lexeme_nom=serie+\"Lexemes.txt\"\n",
    "#    phrase_nom=serie+\"Phrases.txt\"\n",
    "    phrase_nom=serie+complementPhrases+\"Phrases.csv\"\n",
    "    traduction_nom=serie+complementPhrases+\"Traductions.csv\"\n",
    "    cloze_nom=serie+complementPhrases+\"Clozes.txt\"\n",
    "else:\n",
    "    parser=optparse.OptionParser()\n",
    "    parser.add_option(\"-o\", \"--out\", dest=\"outfile\", action=\"store_true\", help=\"write to FILE\")\n",
    "    parser.add_option(\"-c\", \"--cloze\", dest=\"print_cloze\", action=\"store_true\", help=\"write a CLOZE FILE\")\n",
    "    parser.add_option(\"-l\", \"--lexicon\", dest=\"print_lexique\", action=\"store_true\", help=\"append a lexicon\")\n",
    "    parser.add_option(\"-r\", \"--roots\", dest=\"print_racines\", action=\"store_true\", help=\"append a root list\")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    lexeme_nom=args[0]\n",
    "    phrase_nom=args[1]\n",
    "    if len(args)>=3:\n",
    "        traduction_nom=args[2]\n",
    "    else:\n",
    "        traduction_nom=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ouverture du fichier lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accentedIn = unicode(phonology[\"translations\"][\"deaccent\"][\"in\"])\n",
    "deaccentIn = [ord(char) for char in accentedIn]\n",
    "deaccentOut = unicode(phonology[\"translations\"][\"deaccent\"][\"out\"])\n",
    "deaccent = dict(zip(deaccentIn, deaccentOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tipaIn = unicode(phonology[\"translations\"][\"ipa\"][\"in\"])\n",
    "ipaIn = [ord(char) for char in tipaIn]\n",
    "ipaOut = unicode(phonology[\"translations\"][\"ipa\"][\"out\"])\n",
    "toipa = dict(zip(ipaIn, ipaOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "##\n",
    "##\n",
    "##\tFAIRE LE TRI DES FORMES UTILISEES DANS LES PHRASES\n",
    "##\tAFFICHER DANS LES TABLEAUX SEULEMENT CES FORMES\n",
    "##\n",
    "##\n",
    "#################################################\n",
    "################################################\n",
    "#\n",
    "#\n",
    "#\tFAIRE LA LISTE DES PHRASES AVEC LES 4 LIGNES\n",
    "#\t\tGRAPHO, PHONO, GLOSE, TRAD\n",
    "#\n",
    "#\n",
    "################################################\n",
    "texte=[]\n",
    "#graphies={}\n",
    "#abs_genre=\"\"\n",
    "#abs_nombre=\"\"\n",
    "#PFM.lexique.formeLexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faire_phrases(phrase_file,sortieLatex=True):\n",
    "    if sortieLatex:\n",
    "        finLigne=\"\\\\\\\\\"\n",
    "    else:\n",
    "        finLigne=\"\\n\"\n",
    "    if print_phrases:\n",
    "        comment=\"\"\n",
    "    else:\n",
    "        comment=\"%\"\n",
    "    if sortieLatex: ajouterExemple(\"\\\\begin{phrases}\")\n",
    "    for nPhrase,line in enumerate(phrase_file):\n",
    "        phrase=[0 for i in range(len(syntagmes['Phrase']))]\n",
    "        tampon=(line.strip().rstrip('.')).replace(\"'\",\" \").split(\"\\t\")\n",
    "    #    print tampon[0],type(tampon[0])\n",
    "        if debug: print line\n",
    "        if not tampon[0].startswith(\"#\"):\n",
    "            verbe=tampon[1].split(\" \")\n",
    "            verbeForme=verbe[0]\n",
    "            if len(PFM.lexique.formeLexeme[verbeForme])!=1:\n",
    "                print \"FORME AMBIGUË\", PFM.lexique.formeLexeme[verbeForme]\n",
    "            verbeLexeme=PFM.lexique.formeLexeme[verbeForme][0]\n",
    "            temp=verbeLexeme.split(\".\")\n",
    "            if debug or 0: print temp\n",
    "            formeCitation=temp[0]\n",
    "            for element in temp[1:]:\n",
    "                if element in attributsFlexVerbe:\n",
    "                    formeCitation+=element.capitalize()\n",
    "            typeVerbe=temp[1]\n",
    "            classeVerbe=\"\"\n",
    "            nombreVerbe=\"\"\n",
    "            nombrePersonne=\"\"\n",
    "    #        print verbeLexeme, formeCitation,typeVerbe\n",
    "            verbeLemme=\"%s%s\"%(formeCitation,typeVerbe.capitalize())\n",
    "            verbeFormeIndex=PFM.lexique.lexemes[verbeLexeme].formes.index(verbeForme)\n",
    "            if debug: print \"verbe :\", verbe\n",
    "    #        if verbeLexeme.endswith(\"VI\"):\n",
    "            if casSyntagmes and \"SUJ\" in casSyntagmes and \"Erg\" in casSyntagmes[\"SUJ\"]:\n",
    "                if \".VI\" in verbeLexeme:            \n",
    "    #                suj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Abs\"\n",
    "                    klbSujet=\"SUJ\"\n",
    "                else:\n",
    "    #                suj_cas=\"Erg\"\n",
    "    #                obj_cas=\"Abs\"\n",
    "                    frSujetCas=\"Erg\"\n",
    "                    frObjetCas=\"Abs\"\n",
    "                    klbSujet=\"OBJ\"\n",
    "            elif casSyntagmes and \"SUJ\" in casSyntagmes and \"Nom\" in casSyntagmes[\"SUJ\"]:\n",
    "                frSujetCas=casSyntagmes[\"SUJ\"]\n",
    "                frObjetCas=casSyntagmes[\"OBJ\"]\n",
    "                klbSujet=\"SUJ\"\n",
    "            else:\n",
    "                frSujetCas=\"\"\n",
    "                frObjetCas=\"\"\n",
    "                klbSujet=\"SUJ\"\n",
    "            suj_genre=valAttributs[\"Genre\"][0]\n",
    "            suj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            obj_genre=valAttributs[\"Genre\"][0]\n",
    "            obj_nombre=valAttributs[\"Nombre\"][0]\n",
    "            abs_genre=valAttributs[\"Genre\"][0]\n",
    "            abs_nombre=valAttributs[\"Nombre\"][0]\n",
    "            sujet=tampon[0].strip().split(\" \")\n",
    "            (localMots,(localClasses,localNombre,localCas))=faire_gn(sujet,frSujetCas)\n",
    "            if (debug or 0) and nPhrase==0: print (localMots,(localClasses,localNombre,localCas))\n",
    "            phrase[syntagmes['Phrase'].index('SUJ')]=localMots\n",
    "            if debug: print localCas\n",
    "            if not localCas or localCas in sujetVerbe:\n",
    "                if localClasses and \"Genre\" in gloses[\"VER\"]:\n",
    "                    localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                else:\n",
    "                    localClasse=\"\"\n",
    "                classeVerbe=localClasse\n",
    "                nombreVerbe=localNombre\n",
    "                nombrePersonne=localNombre\n",
    "                casVerbe=localCas\n",
    "                if (debug or 0) and nPhrase==0: print \"frSuj\",nombrePersonne\n",
    "            if debug: print \"sujet :\",phrase[1]\n",
    "            if len(tampon)>=3:\n",
    "                if tampon[2] and tampon[2].startswith(\",\"):\n",
    "                    tampon[2]=tampon[2][1:]\n",
    "                objet=tampon[2].split(\" \")\n",
    "                if debug: print \"objet : \",objet\n",
    "                if objet!=['']: \n",
    "                    (localMots,(localClasses,localNombre,localCas))=faire_gn(objet,frObjetCas)\n",
    "                    if (debug or 0) and nPhrase==0: print (\"frObj\",(localClasses,localNombre,localCas),line)\n",
    "                    phrase[syntagmes['Phrase'].index('OBJ')]=localMots\n",
    "                    if debug or 0: print (\"obj :\",localCas, sujetVerbe)\n",
    "                    if localCas in sujetVerbe:\n",
    "                        if localClasses:\n",
    "                            localClasse=[classeElement for classeElement in localClasses if classeElement in gloses[\"VER\"][\"Genre\"]][0]\n",
    "                        else:\n",
    "                            localClasse=\"\"\n",
    "                        classeVerbe=localClasse\n",
    "                        nombreVerbe=localNombre\n",
    "                        nombrePersonne=localNombre\n",
    "                        casVerbe=localCas\n",
    "                        if (debug or 0) and nPhrase==0: print (\"cas\",nombrePersonne, line)\n",
    "                elif klbSujet==\"OBJ\":\n",
    "                    if boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                        classeVerbe=morphosyntax[\"Defauts\"][\"Genre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                        nombreVerbe=morphosyntax[\"Defauts\"][\"Nombre\"]\n",
    "                    if boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                        nombrePersonne=morphosyntax[\"Defauts\"][\"NbPers\"]\n",
    "                    \n",
    "            if len(tampon)>=4:\n",
    "                if tampon[3] and tampon[3].startswith(\",\"):\n",
    "                    tampon[3]=tampon[3][1:]\n",
    "                indirect=tampon[3].split(\" \")\n",
    "                if debug: print \"indirect : \",indirect\n",
    "                if indirect!=['']: phrase[syntagmes['Phrase'].index('IND')]=faire_gp(indirect,\"IND\")\n",
    "            if len(tampon)>=5:\n",
    "                if tampon[4] and tampon[4].startswith(\",\"):\n",
    "                    tampon[4]=tampon[4][1:]\n",
    "                comp=tampon[4].split(\" \")\n",
    "                if comp!=['']:\n",
    "                    phrase[syntagmes['Phrase'].index('COMP')]=faire_gp(comp)\n",
    "            if len(tampon)>=6:\n",
    "                if tampon[5] and tampon[5].startswith(\",\"):\n",
    "                    tampon[5]=tampon[5][1:]\n",
    "                ajout=tampon[5].split(\" \")\n",
    "                phrase[syntagmes['Phrase'].index('AJOUT')]=faire_gp(ajout)\n",
    "            if not boolAttribut[\"VER\"][\"Genre\"]:\n",
    "                classeVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Nombre\"]:\n",
    "                nombreVerbe=\"\"\n",
    "            if not boolAttribut[\"VER\"][\"Pers\"]:\n",
    "                nombrePersonne=\"\"\n",
    "            else:\n",
    "                nombrePersonne=\"Trois\"+nombrePersonne.capitalize()\n",
    "            if (debug or 0) and nPhrase==0: print \"accord Verbe\",nombreVerbe, classeVerbe, sujetVerbe, line\n",
    "\n",
    "            noligFormeCitation=formeCitation\n",
    "            for ligature in deligatures:\n",
    "                noligFormeCitation=noligFormeCitation.replace(ligature,deligatures[ligature])\n",
    "\n",
    "            glose=\"\\\\\"+recoder(noligFormeCitation,deaccent)\\\n",
    "                +morphosyntax[\"VER\"][\"FormesBase\"][verbeFormeIndex].capitalize()\\\n",
    "                +nombrePersonne\\\n",
    "                +classeVerbe.capitalize()\\\n",
    "                +nombreVerbe.capitalize()\n",
    "            if (debug or 0) and nPhrase<200: print \"glose Verbe\",glose\n",
    "            phrase[syntagmes['Phrase'].index('VER')]=glose\n",
    "            texte.append(glose)\n",
    "            if sortieLatex: \n",
    "                ajouterExemple(\"\\\\ex\")\n",
    "                if print_glose and print_phono and print_ortho:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "                elif print_glose+print_ortho+print_phono==2:\n",
    "                    ajouterExemple(comment+\"\\\\gloses\")\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"{}\")\n",
    "            if print_ortho:\n",
    "                prefixe=\"\"\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0:\n",
    "                    printflat(mot,\"P{}\")\n",
    "            if print_phono:\n",
    "                prefixe=\"\"\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            for mot in phrase:\n",
    "                if mot!=0 and sortieLatex:\n",
    "                    printflat(mot,\"G{}\")\n",
    "            if print_glose:\n",
    "                prefixe=\"\"\n",
    "            else:\n",
    "                prefixe=marqueurCommentaire\n",
    "            if sortieLatex: ajouterExemple(prefixe+separateurMots.join(accumulateur)+finLigne)\n",
    "            if \",\" in line:\n",
    "                consts=line.split(\"\\t\")\n",
    "                disloc=[]\n",
    "                canon=[]\n",
    "                for const in consts:\n",
    "                    if const.startswith(\",\"):\n",
    "                        disloc.append(const[1:])\n",
    "                    else:\n",
    "                        canon.append(const)\n",
    "                line=\",\\t\".join(disloc).strip()+\", \"+\"\\t\".join(canon)\n",
    "                        \n",
    "            traduction=(line.strip().rstrip('.')).split()\n",
    "            start=1\n",
    "            for element in traduction:\t\t\t# convertir les S majuscules à la finale des mots en minuscules\n",
    "                element=element.strip(\"#\")\n",
    "                if element!=\"\":\n",
    "                    if start:\n",
    "                        start=0\n",
    "                        element=element.capitalize()\n",
    "                    caracteres=element\n",
    "                    if len(caracteres)>1 and caracteres!=caracteres.lower() and caracteres!=caracteres.capitalize():\n",
    "                        caracteres=list(caracteres[0]+caracteres[1:].lower())\n",
    "#                    accumulerMots(\"\".join(caracteres).encode('utf8'))\n",
    "                    accumulerMots(\"\".join(caracteres))\n",
    "            if sortieLatex: \n",
    "                ajouterExemple(taches()+\" \".join(accumulateur)+\".\")\n",
    "            else:\n",
    "                if debug: print accumulateur\n",
    "                ajouterExemple(\" \".join(accumulateur)+\".\")\n",
    "            del accumulateur[:]\n",
    "            if sortieLatex and print_coffee and random.randint(1,4)==1:\n",
    "                stain=random.choice([\"A\",\"B\",\"C\",\"D\"])\n",
    "                stain=random.choice([\"A\",\"B\",\"C\"])\n",
    "                alpha=random.random()/1.5\n",
    "                angle=random.randint(0,360)\n",
    "                xoff=random.randint(-200,0)\n",
    "#                ajouterExemple('\\\\\\\\\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "                ajouterExemple('\\\\hspace{-.35\\\\textwidth}\\\\cofe%sm{%.3f}{1}{%d}{%d}{0}' % (stain,alpha,angle,xoff))\n",
    "\n",
    "    if sortieLatex: ajouterExemple(\"\\\\end{phrases}\")\n",
    "    if sortieLatex:\n",
    "        if ('options' in globals() and options.print_cloze) or print_lexique:\n",
    "            tab=(head,tail,\"\")\n",
    "        else:\n",
    "            tab=(head,tail,\"%\")\n",
    "#        prononciationExtrait=[]\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\begin{itemize}\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item NOMS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"NOM\"][\"cols\"],tableaux[\"NOM\"],texte,dimensionsTableaux[\"NOM\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item ADJECTIFS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"ADJ\"][\"cols\"],tableaux[\"ADJ\"],texte,dimensionsTableaux[\"ADJ\"][\"long\"],tab,False)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\item VERBES\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"VER\"][\"cols\"],tableaux[\"VER\"],texte,dimensionsTableaux[\"VER\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"VER\"],texte,20,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item DÉTERMINANTS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"DET\"][\"cols\"],tableaux[\"DET\"],texte,dimensionsTableaux[\"DET\"][\"long\"],tab,False)\n",
    "#        print_tableaux(3,tableaux[\"DET\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\Needspace{8\\\\baselineskip}%\")\n",
    "        ajouterVocabulaire(tab[2]+u\"\\\\item PRÉPOSITIONS\\\\\\\\[-3ex]\")\n",
    "        print_tableaux(dimensionsTableaux[\"PREP\"][\"cols\"],tableaux[\"PREP\"],texte,dimensionsTableaux[\"PREP\"][\"long\"],tab,False)\n",
    "#        print_tableaux(2,tableaux[\"PREP\"],texte,0,tab)\n",
    "        ajouterVocabulaire(tab[2]+\"\\\\end{itemize}\")\n",
    "\n",
    "        if 1:\n",
    "            with codecs.open(serie+complementPhrases+\"Exemples\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for exemple in exemples:\n",
    "                    output.write(exemple+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Vocabulaire\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for vocable in vocabulaire:\n",
    "    #                print [vocable]\n",
    "                    output.write(vocable+\"\\n\")\n",
    "\n",
    "            with codecs.open(serie+complementPhrases+\"Prononciation\"+variante+\".tex\", 'wb',encoding=\"utf8\") as output:\n",
    "                for ligne in prononciationBegin+prononciationExtrait+prononciationEnd:\n",
    "                    output.write(ligne+\"\\n\")\n",
    "    else:\n",
    "        clozeTraductions=[]\n",
    "        for orthoLigne,phonoLigne,tradLigne in zip(*[iter(exemples)]*3):\n",
    "            phonoMots=phonoLigne.strip().split(\"{}\")\n",
    "            phonoPhrase=[]\n",
    "            for element in phonoMots:\n",
    "                cleElement=element.strip().strip(\"\\\\{}\")[:-1]\n",
    "#                print element,cleElement\n",
    "                if cleElement:\n",
    "                    if not cleElement in traductions: print cleElement,phonoMots\n",
    "                    phonoPhrase.append(traductions[cleElement])\n",
    "            if separateurPhonoCloze==\"\" : suppLigne=\";\"+\" \".join(phonoPhrase)\n",
    "            else: suppLigne=\"\"\n",
    "            result=separateurPhonoCloze.join(phonoPhrase)+\";\"+tradLigne+suppLigne\n",
    "            clozeTraductions.append(result)\n",
    "        with codecs.open(serie+complementPhrases+\"Traductions\"+\".txt\", 'wb',encoding=\"utf8\") as output:\n",
    "            for ligne in clozeTraductions:\n",
    "                output.write(ligne+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement du fichier phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print os.path.realpath(phrase_nom)\n",
    "try:\n",
    "    phrase_file = codecs.open((phrase_nom),\"r\",\"utf8\")\n",
    "except IOError:\n",
    "    print 'I could not open the sentence file', phrase_nom\n",
    "    sys.exit()\n",
    "exemples=[]\n",
    "accumulateur=[]\n",
    "vocabulaire=[]\n",
    "prononciationExtrait=[]\n",
    "faire_phrases(phrase_file)\n",
    "phrase_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nomTableaux=\"Tableaux.yaml\"\n",
    "with open(serie+nomTableaux, 'r') as stream:\n",
    "    tableaux=yaml.load(stream)\n",
    "if traduction_nom.endswith(\"csv\"):\n",
    "    try:\n",
    "        traduction_file = codecs.open(traduction_nom,\"r\",\"utf8\")\n",
    "    except IOError:\n",
    "        print 'I could not open the sentence file', traduction_nom\n",
    "        sys.exit()      \n",
    "    else:\n",
    "        try:\n",
    "            cloze_file = codecs.open(cloze_nom,\"r\",\"utf8\")\n",
    "        except IOError:\n",
    "            print 'I could not open the sentence file', cloze_nom\n",
    "            sys.exit()\n",
    "        else:\n",
    "            traductions={}\n",
    "            for line in cloze_file.readlines():\n",
    "                line=line.strip()\n",
    "                if not line.startswith(\"#\"):\n",
    "                    elementsCloze=line.split(\";\")\n",
    "                    traductions[elementsCloze[0]]=elementsCloze[3]\n",
    "            cloze_file.close()\n",
    "            exemples=[]\n",
    "            accumulateur=[]\n",
    "            vocabulaire=[]\n",
    "#            prononciationExtrait=[]\n",
    "            faire_phrases(traduction_file,False)\n",
    "            traduction_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\\\KalebADuAbs & \\\\KalebADuAbsP & \\\\KalebADuAbsG \\\\\\\\',\n",
       " '\\\\KalebADuDat & \\\\KalebADuDatP & \\\\KalebADuDatG \\\\\\\\',\n",
       " '\\\\KalebADuErg & \\\\KalebADuErgP & \\\\KalebADuErgG \\\\\\\\',\n",
       " '\\\\KalebADuObl & \\\\KalebADuOblP & \\\\KalebADuOblG \\\\\\\\',\n",
       " '\\\\KalebAPlAbs & \\\\KalebAPlAbsP & \\\\KalebAPlAbsG \\\\\\\\',\n",
       " '\\\\KalebAPlDat & \\\\KalebAPlDatP & \\\\KalebAPlDatG \\\\\\\\',\n",
       " '\\\\KalebAPlErg & \\\\KalebAPlErgP & \\\\KalebAPlErgG \\\\\\\\',\n",
       " '\\\\KalebAPlObl & \\\\KalebAPlOblP & \\\\KalebAPlOblG \\\\\\\\',\n",
       " '\\\\KalebASgAbs & \\\\KalebASgAbsP & \\\\KalebASgAbsG \\\\\\\\',\n",
       " '\\\\KalebASgDat & \\\\KalebASgDatP & \\\\KalebASgDatG \\\\\\\\',\n",
       " '\\\\KalebASgErg & \\\\KalebASgErgP & \\\\KalebASgErgG \\\\\\\\',\n",
       " '\\\\KalebASgObl & \\\\KalebASgOblP & \\\\KalebASgOblG \\\\\\\\',\n",
       " '\\\\MahiraCDuAbs & \\\\MahiraCDuAbsP & \\\\MahiraCDuAbsG \\\\\\\\',\n",
       " '\\\\MahiraCDuDat & \\\\MahiraCDuDatP & \\\\MahiraCDuDatG \\\\\\\\',\n",
       " '\\\\MahiraCDuErg & \\\\MahiraCDuErgP & \\\\MahiraCDuErgG \\\\\\\\',\n",
       " '\\\\MahiraCDuObl & \\\\MahiraCDuOblP & \\\\MahiraCDuOblG \\\\\\\\',\n",
       " '\\\\MahiraCPlAbs & \\\\MahiraCPlAbsP & \\\\MahiraCPlAbsG \\\\\\\\',\n",
       " '\\\\MahiraCPlDat & \\\\MahiraCPlDatP & \\\\MahiraCPlDatG \\\\\\\\',\n",
       " '\\\\MahiraCPlErg & \\\\MahiraCPlErgP & \\\\MahiraCPlErgG \\\\\\\\',\n",
       " '\\\\MahiraCPlObl & \\\\MahiraCPlOblP & \\\\MahiraCPlOblG \\\\\\\\',\n",
       " '\\\\MahiraCSgAbs & \\\\MahiraCSgAbsP & \\\\MahiraCSgAbsG \\\\\\\\',\n",
       " '\\\\MahiraCSgDat & \\\\MahiraCSgDatP & \\\\MahiraCSgDatG \\\\\\\\',\n",
       " '\\\\MahiraCSgErg & \\\\MahiraCSgErgP & \\\\MahiraCSgErgG \\\\\\\\',\n",
       " '\\\\MahiraCSgObl & \\\\MahiraCSgOblP & \\\\MahiraCSgOblG \\\\\\\\',\n",
       " '\\\\VioletteBDuAbs & \\\\VioletteBDuAbsP & \\\\VioletteBDuAbsG \\\\\\\\',\n",
       " '\\\\VioletteBDuDat & \\\\VioletteBDuDatP & \\\\VioletteBDuDatG \\\\\\\\',\n",
       " '\\\\VioletteBDuErg & \\\\VioletteBDuErgP & \\\\VioletteBDuErgG \\\\\\\\',\n",
       " '\\\\VioletteBDuObl & \\\\VioletteBDuOblP & \\\\VioletteBDuOblG \\\\\\\\',\n",
       " '\\\\VioletteBPlAbs & \\\\VioletteBPlAbsP & \\\\VioletteBPlAbsG \\\\\\\\',\n",
       " '\\\\VioletteBPlDat & \\\\VioletteBPlDatP & \\\\VioletteBPlDatG \\\\\\\\',\n",
       " '\\\\VioletteBPlErg & \\\\VioletteBPlErgP & \\\\VioletteBPlErgG \\\\\\\\',\n",
       " '\\\\VioletteBPlObl & \\\\VioletteBPlOblP & \\\\VioletteBPlOblG \\\\\\\\',\n",
       " '\\\\VioletteBSgAbs & \\\\VioletteBSgAbsP & \\\\VioletteBSgAbsG \\\\\\\\',\n",
       " '\\\\VioletteBSgDat & \\\\VioletteBSgDatP & \\\\VioletteBSgDatG \\\\\\\\',\n",
       " '\\\\VioletteBSgErg & \\\\VioletteBSgErgP & \\\\VioletteBSgErgG \\\\\\\\',\n",
       " '\\\\VioletteBSgObl & \\\\VioletteBSgOblP & \\\\VioletteBSgOblG \\\\\\\\',\n",
       " '\\\\arbreBDuAbs & \\\\arbreBDuAbsP & \\\\arbreBDuAbsG \\\\\\\\',\n",
       " '\\\\arbreBDuDat & \\\\arbreBDuDatP & \\\\arbreBDuDatG \\\\\\\\',\n",
       " '\\\\arbreBDuErg & \\\\arbreBDuErgP & \\\\arbreBDuErgG \\\\\\\\',\n",
       " '\\\\arbreBDuObl & \\\\arbreBDuOblP & \\\\arbreBDuOblG \\\\\\\\',\n",
       " '\\\\arbreBPlAbs & \\\\arbreBPlAbsP & \\\\arbreBPlAbsG \\\\\\\\',\n",
       " '\\\\arbreBPlDat & \\\\arbreBPlDatP & \\\\arbreBPlDatG \\\\\\\\',\n",
       " '\\\\arbreBPlErg & \\\\arbreBPlErgP & \\\\arbreBPlErgG \\\\\\\\',\n",
       " '\\\\arbreBPlObl & \\\\arbreBPlOblP & \\\\arbreBPlOblG \\\\\\\\',\n",
       " '\\\\arbreBSgAbs & \\\\arbreBSgAbsP & \\\\arbreBSgAbsG \\\\\\\\',\n",
       " '\\\\arbreBSgDat & \\\\arbreBSgDatP & \\\\arbreBSgDatG \\\\\\\\',\n",
       " '\\\\arbreBSgErg & \\\\arbreBSgErgP & \\\\arbreBSgErgG \\\\\\\\',\n",
       " '\\\\arbreBSgObl & \\\\arbreBSgOblP & \\\\arbreBSgOblG \\\\\\\\',\n",
       " '\\\\blessureADuAbs & \\\\blessureADuAbsP & \\\\blessureADuAbsG \\\\\\\\',\n",
       " '\\\\blessureADuDat & \\\\blessureADuDatP & \\\\blessureADuDatG \\\\\\\\',\n",
       " '\\\\blessureADuErg & \\\\blessureADuErgP & \\\\blessureADuErgG \\\\\\\\',\n",
       " '\\\\blessureADuObl & \\\\blessureADuOblP & \\\\blessureADuOblG \\\\\\\\',\n",
       " '\\\\blessureAPlAbs & \\\\blessureAPlAbsP & \\\\blessureAPlAbsG \\\\\\\\',\n",
       " '\\\\blessureAPlDat & \\\\blessureAPlDatP & \\\\blessureAPlDatG \\\\\\\\',\n",
       " '\\\\blessureAPlErg & \\\\blessureAPlErgP & \\\\blessureAPlErgG \\\\\\\\',\n",
       " '\\\\blessureAPlObl & \\\\blessureAPlOblP & \\\\blessureAPlOblG \\\\\\\\',\n",
       " '\\\\blessureASgAbs & \\\\blessureASgAbsP & \\\\blessureASgAbsG \\\\\\\\',\n",
       " '\\\\blessureASgDat & \\\\blessureASgDatP & \\\\blessureASgDatG \\\\\\\\',\n",
       " '\\\\blessureASgErg & \\\\blessureASgErgP & \\\\blessureASgErgG \\\\\\\\',\n",
       " '\\\\blessureASgObl & \\\\blessureASgOblP & \\\\blessureASgOblG \\\\\\\\',\n",
       " '\\\\chefDDuAbs & \\\\chefDDuAbsP & \\\\chefDDuAbsG \\\\\\\\',\n",
       " '\\\\chefDDuDat & \\\\chefDDuDatP & \\\\chefDDuDatG \\\\\\\\',\n",
       " '\\\\chefDDuErg & \\\\chefDDuErgP & \\\\chefDDuErgG \\\\\\\\',\n",
       " '\\\\chefDDuObl & \\\\chefDDuOblP & \\\\chefDDuOblG \\\\\\\\',\n",
       " '\\\\chefDPlAbs & \\\\chefDPlAbsP & \\\\chefDPlAbsG \\\\\\\\',\n",
       " '\\\\chefDPlDat & \\\\chefDPlDatP & \\\\chefDPlDatG \\\\\\\\',\n",
       " '\\\\chefDPlErg & \\\\chefDPlErgP & \\\\chefDPlErgG \\\\\\\\',\n",
       " '\\\\chefDPlObl & \\\\chefDPlOblP & \\\\chefDPlOblG \\\\\\\\',\n",
       " '\\\\chefDSgAbs & \\\\chefDSgAbsP & \\\\chefDSgAbsG \\\\\\\\',\n",
       " '\\\\chefDSgDat & \\\\chefDSgDatP & \\\\chefDSgDatG \\\\\\\\',\n",
       " '\\\\chefDSgErg & \\\\chefDSgErgP & \\\\chefDSgErgG \\\\\\\\',\n",
       " '\\\\chefDSgObl & \\\\chefDSgOblP & \\\\chefDSgOblG \\\\\\\\',\n",
       " '\\\\colereBDuAbs & \\\\colereBDuAbsP & \\\\colereBDuAbsG \\\\\\\\',\n",
       " '\\\\colereBDuDat & \\\\colereBDuDatP & \\\\colereBDuDatG \\\\\\\\',\n",
       " '\\\\colereBDuErg & \\\\colereBDuErgP & \\\\colereBDuErgG \\\\\\\\',\n",
       " '\\\\colereBDuObl & \\\\colereBDuOblP & \\\\colereBDuOblG \\\\\\\\',\n",
       " '\\\\colereBPlAbs & \\\\colereBPlAbsP & \\\\colereBPlAbsG \\\\\\\\',\n",
       " '\\\\colereBPlDat & \\\\colereBPlDatP & \\\\colereBPlDatG \\\\\\\\',\n",
       " '\\\\colereBPlErg & \\\\colereBPlErgP & \\\\colereBPlErgG \\\\\\\\',\n",
       " '\\\\colereBPlObl & \\\\colereBPlOblP & \\\\colereBPlOblG \\\\\\\\',\n",
       " '\\\\colereBSgAbs & \\\\colereBSgAbsP & \\\\colereBSgAbsG \\\\\\\\',\n",
       " '\\\\colereBSgDat & \\\\colereBSgDatP & \\\\colereBSgDatG \\\\\\\\',\n",
       " '\\\\colereBSgErg & \\\\colereBSgErgP & \\\\colereBSgErgG \\\\\\\\',\n",
       " '\\\\colereBSgObl & \\\\colereBSgOblP & \\\\colereBSgOblG \\\\\\\\',\n",
       " '\\\\combatBDuAbs & \\\\combatBDuAbsP & \\\\combatBDuAbsG \\\\\\\\',\n",
       " '\\\\combatBDuDat & \\\\combatBDuDatP & \\\\combatBDuDatG \\\\\\\\',\n",
       " '\\\\combatBDuErg & \\\\combatBDuErgP & \\\\combatBDuErgG \\\\\\\\',\n",
       " '\\\\combatBDuObl & \\\\combatBDuOblP & \\\\combatBDuOblG \\\\\\\\',\n",
       " '\\\\combatBPlAbs & \\\\combatBPlAbsP & \\\\combatBPlAbsG \\\\\\\\',\n",
       " '\\\\combatBPlDat & \\\\combatBPlDatP & \\\\combatBPlDatG \\\\\\\\',\n",
       " '\\\\combatBPlErg & \\\\combatBPlErgP & \\\\combatBPlErgG \\\\\\\\',\n",
       " '\\\\combatBPlObl & \\\\combatBPlOblP & \\\\combatBPlOblG \\\\\\\\',\n",
       " '\\\\combatBSgAbs & \\\\combatBSgAbsP & \\\\combatBSgAbsG \\\\\\\\',\n",
       " '\\\\combatBSgDat & \\\\combatBSgDatP & \\\\combatBSgDatG \\\\\\\\',\n",
       " '\\\\combatBSgErg & \\\\combatBSgErgP & \\\\combatBSgErgG \\\\\\\\',\n",
       " '\\\\combatBSgObl & \\\\combatBSgOblP & \\\\combatBSgOblG \\\\\\\\',\n",
       " '\\\\combattantBDuAbs & \\\\combattantBDuAbsP & \\\\combattantBDuAbsG \\\\\\\\',\n",
       " '\\\\combattantBDuDat & \\\\combattantBDuDatP & \\\\combattantBDuDatG \\\\\\\\',\n",
       " '\\\\combattantBDuErg & \\\\combattantBDuErgP & \\\\combattantBDuErgG \\\\\\\\',\n",
       " '\\\\combattantBDuObl & \\\\combattantBDuOblP & \\\\combattantBDuOblG \\\\\\\\',\n",
       " '\\\\combattantBPlAbs & \\\\combattantBPlAbsP & \\\\combattantBPlAbsG \\\\\\\\',\n",
       " '\\\\combattantBPlDat & \\\\combattantBPlDatP & \\\\combattantBPlDatG \\\\\\\\',\n",
       " '\\\\combattantBPlErg & \\\\combattantBPlErgP & \\\\combattantBPlErgG \\\\\\\\',\n",
       " '\\\\combattantBPlObl & \\\\combattantBPlOblP & \\\\combattantBPlOblG \\\\\\\\',\n",
       " '\\\\combattantBSgAbs & \\\\combattantBSgAbsP & \\\\combattantBSgAbsG \\\\\\\\',\n",
       " '\\\\combattantBSgDat & \\\\combattantBSgDatP & \\\\combattantBSgDatG \\\\\\\\',\n",
       " '\\\\combattantBSgErg & \\\\combattantBSgErgP & \\\\combattantBSgErgG \\\\\\\\',\n",
       " '\\\\combattantBSgObl & \\\\combattantBSgOblP & \\\\combattantBSgOblG \\\\\\\\',\n",
       " '\\\\corpsDDuAbs & \\\\corpsDDuAbsP & \\\\corpsDDuAbsG \\\\\\\\',\n",
       " '\\\\corpsDDuDat & \\\\corpsDDuDatP & \\\\corpsDDuDatG \\\\\\\\',\n",
       " '\\\\corpsDDuErg & \\\\corpsDDuErgP & \\\\corpsDDuErgG \\\\\\\\',\n",
       " '\\\\corpsDDuObl & \\\\corpsDDuOblP & \\\\corpsDDuOblG \\\\\\\\',\n",
       " '\\\\corpsDPlAbs & \\\\corpsDPlAbsP & \\\\corpsDPlAbsG \\\\\\\\',\n",
       " '\\\\corpsDPlDat & \\\\corpsDPlDatP & \\\\corpsDPlDatG \\\\\\\\',\n",
       " '\\\\corpsDPlErg & \\\\corpsDPlErgP & \\\\corpsDPlErgG \\\\\\\\',\n",
       " '\\\\corpsDPlObl & \\\\corpsDPlOblP & \\\\corpsDPlOblG \\\\\\\\',\n",
       " '\\\\corpsDSgAbs & \\\\corpsDSgAbsP & \\\\corpsDSgAbsG \\\\\\\\',\n",
       " '\\\\corpsDSgDat & \\\\corpsDSgDatP & \\\\corpsDSgDatG \\\\\\\\',\n",
       " '\\\\corpsDSgErg & \\\\corpsDSgErgP & \\\\corpsDSgErgG \\\\\\\\',\n",
       " '\\\\corpsDSgObl & \\\\corpsDSgOblP & \\\\corpsDSgOblG \\\\\\\\',\n",
       " '\\\\coupADuAbs & \\\\coupADuAbsP & \\\\coupADuAbsG \\\\\\\\',\n",
       " '\\\\coupADuDat & \\\\coupADuDatP & \\\\coupADuDatG \\\\\\\\',\n",
       " '\\\\coupADuErg & \\\\coupADuErgP & \\\\coupADuErgG \\\\\\\\',\n",
       " '\\\\coupADuObl & \\\\coupADuOblP & \\\\coupADuOblG \\\\\\\\',\n",
       " '\\\\coupAPlAbs & \\\\coupAPlAbsP & \\\\coupAPlAbsG \\\\\\\\',\n",
       " '\\\\coupAPlDat & \\\\coupAPlDatP & \\\\coupAPlDatG \\\\\\\\',\n",
       " '\\\\coupAPlErg & \\\\coupAPlErgP & \\\\coupAPlErgG \\\\\\\\',\n",
       " '\\\\coupAPlObl & \\\\coupAPlOblP & \\\\coupAPlOblG \\\\\\\\',\n",
       " '\\\\coupASgAbs & \\\\coupASgAbsP & \\\\coupASgAbsG \\\\\\\\',\n",
       " '\\\\coupASgDat & \\\\coupASgDatP & \\\\coupASgDatG \\\\\\\\',\n",
       " '\\\\coupASgErg & \\\\coupASgErgP & \\\\coupASgErgG \\\\\\\\',\n",
       " '\\\\coupASgObl & \\\\coupASgOblP & \\\\coupASgOblG \\\\\\\\',\n",
       " '\\\\couteauDDuAbs & \\\\couteauDDuAbsP & \\\\couteauDDuAbsG \\\\\\\\',\n",
       " '\\\\couteauDDuDat & \\\\couteauDDuDatP & \\\\couteauDDuDatG \\\\\\\\',\n",
       " '\\\\couteauDDuErg & \\\\couteauDDuErgP & \\\\couteauDDuErgG \\\\\\\\',\n",
       " '\\\\couteauDDuObl & \\\\couteauDDuOblP & \\\\couteauDDuOblG \\\\\\\\',\n",
       " '\\\\couteauDPlAbs & \\\\couteauDPlAbsP & \\\\couteauDPlAbsG \\\\\\\\',\n",
       " '\\\\couteauDPlDat & \\\\couteauDPlDatP & \\\\couteauDPlDatG \\\\\\\\',\n",
       " '\\\\couteauDPlErg & \\\\couteauDPlErgP & \\\\couteauDPlErgG \\\\\\\\',\n",
       " '\\\\couteauDPlObl & \\\\couteauDPlOblP & \\\\couteauDPlOblG \\\\\\\\',\n",
       " '\\\\couteauDSgAbs & \\\\couteauDSgAbsP & \\\\couteauDSgAbsG \\\\\\\\',\n",
       " '\\\\couteauDSgDat & \\\\couteauDSgDatP & \\\\couteauDSgDatG \\\\\\\\',\n",
       " '\\\\couteauDSgErg & \\\\couteauDSgErgP & \\\\couteauDSgErgG \\\\\\\\',\n",
       " '\\\\couteauDSgObl & \\\\couteauDSgOblP & \\\\couteauDSgOblG \\\\\\\\',\n",
       " '\\\\criCDuAbs & \\\\criCDuAbsP & \\\\criCDuAbsG \\\\\\\\',\n",
       " '\\\\criCDuDat & \\\\criCDuDatP & \\\\criCDuDatG \\\\\\\\',\n",
       " '\\\\criCDuErg & \\\\criCDuErgP & \\\\criCDuErgG \\\\\\\\',\n",
       " '\\\\criCDuObl & \\\\criCDuOblP & \\\\criCDuOblG \\\\\\\\',\n",
       " '\\\\criCPlAbs & \\\\criCPlAbsP & \\\\criCPlAbsG \\\\\\\\',\n",
       " '\\\\criCPlDat & \\\\criCPlDatP & \\\\criCPlDatG \\\\\\\\',\n",
       " '\\\\criCPlErg & \\\\criCPlErgP & \\\\criCPlErgG \\\\\\\\',\n",
       " '\\\\criCPlObl & \\\\criCPlOblP & \\\\criCPlOblG \\\\\\\\',\n",
       " '\\\\criCSgAbs & \\\\criCSgAbsP & \\\\criCSgAbsG \\\\\\\\',\n",
       " '\\\\criCSgDat & \\\\criCSgDatP & \\\\criCSgDatG \\\\\\\\',\n",
       " '\\\\criCSgErg & \\\\criCSgErgP & \\\\criCSgErgG \\\\\\\\',\n",
       " '\\\\criCSgObl & \\\\criCSgOblP & \\\\criCSgOblG \\\\\\\\',\n",
       " '\\\\crocBDuAbs & \\\\crocBDuAbsP & \\\\crocBDuAbsG \\\\\\\\',\n",
       " '\\\\crocBDuDat & \\\\crocBDuDatP & \\\\crocBDuDatG \\\\\\\\',\n",
       " '\\\\crocBDuErg & \\\\crocBDuErgP & \\\\crocBDuErgG \\\\\\\\',\n",
       " '\\\\crocBDuObl & \\\\crocBDuOblP & \\\\crocBDuOblG \\\\\\\\',\n",
       " '\\\\crocBPlAbs & \\\\crocBPlAbsP & \\\\crocBPlAbsG \\\\\\\\',\n",
       " '\\\\crocBPlDat & \\\\crocBPlDatP & \\\\crocBPlDatG \\\\\\\\',\n",
       " '\\\\crocBPlErg & \\\\crocBPlErgP & \\\\crocBPlErgG \\\\\\\\',\n",
       " '\\\\crocBPlObl & \\\\crocBPlOblP & \\\\crocBPlOblG \\\\\\\\',\n",
       " '\\\\crocBSgAbs & \\\\crocBSgAbsP & \\\\crocBSgAbsG \\\\\\\\',\n",
       " '\\\\crocBSgDat & \\\\crocBSgDatP & \\\\crocBSgDatG \\\\\\\\',\n",
       " '\\\\crocBSgErg & \\\\crocBSgErgP & \\\\crocBSgErgG \\\\\\\\',\n",
       " '\\\\crocBSgObl & \\\\crocBSgOblP & \\\\crocBSgOblG \\\\\\\\',\n",
       " '\\\\demonDDuAbs & \\\\demonDDuAbsP & \\\\demonDDuAbsG \\\\\\\\',\n",
       " '\\\\demonDDuDat & \\\\demonDDuDatP & \\\\demonDDuDatG \\\\\\\\',\n",
       " '\\\\demonDDuErg & \\\\demonDDuErgP & \\\\demonDDuErgG \\\\\\\\',\n",
       " '\\\\demonDDuObl & \\\\demonDDuOblP & \\\\demonDDuOblG \\\\\\\\',\n",
       " '\\\\demonDPlAbs & \\\\demonDPlAbsP & \\\\demonDPlAbsG \\\\\\\\',\n",
       " '\\\\demonDPlDat & \\\\demonDPlDatP & \\\\demonDPlDatG \\\\\\\\',\n",
       " '\\\\demonDPlErg & \\\\demonDPlErgP & \\\\demonDPlErgG \\\\\\\\',\n",
       " '\\\\demonDPlObl & \\\\demonDPlOblP & \\\\demonDPlOblG \\\\\\\\',\n",
       " '\\\\demonDSgAbs & \\\\demonDSgAbsP & \\\\demonDSgAbsG \\\\\\\\',\n",
       " '\\\\demonDSgDat & \\\\demonDSgDatP & \\\\demonDSgDatG \\\\\\\\',\n",
       " '\\\\demonDSgErg & \\\\demonDSgErgP & \\\\demonDSgErgG \\\\\\\\',\n",
       " '\\\\demonDSgObl & \\\\demonDSgOblP & \\\\demonDSgOblG \\\\\\\\',\n",
       " '\\\\enfantADuAbs & \\\\enfantADuAbsP & \\\\enfantADuAbsG \\\\\\\\',\n",
       " '\\\\enfantADuDat & \\\\enfantADuDatP & \\\\enfantADuDatG \\\\\\\\',\n",
       " '\\\\enfantADuErg & \\\\enfantADuErgP & \\\\enfantADuErgG \\\\\\\\',\n",
       " '\\\\enfantADuObl & \\\\enfantADuOblP & \\\\enfantADuOblG \\\\\\\\',\n",
       " '\\\\enfantAPlAbs & \\\\enfantAPlAbsP & \\\\enfantAPlAbsG \\\\\\\\',\n",
       " '\\\\enfantAPlDat & \\\\enfantAPlDatP & \\\\enfantAPlDatG \\\\\\\\',\n",
       " '\\\\enfantAPlErg & \\\\enfantAPlErgP & \\\\enfantAPlErgG \\\\\\\\',\n",
       " '\\\\enfantAPlObl & \\\\enfantAPlOblP & \\\\enfantAPlOblG \\\\\\\\',\n",
       " '\\\\enfantASgAbs & \\\\enfantASgAbsP & \\\\enfantASgAbsG \\\\\\\\',\n",
       " '\\\\enfantASgDat & \\\\enfantASgDatP & \\\\enfantASgDatG \\\\\\\\',\n",
       " '\\\\enfantASgErg & \\\\enfantASgErgP & \\\\enfantASgErgG \\\\\\\\',\n",
       " '\\\\enfantASgObl & \\\\enfantASgOblP & \\\\enfantASgOblG \\\\\\\\',\n",
       " '\\\\enfantBDuAbs & \\\\enfantBDuAbsP & \\\\enfantBDuAbsG \\\\\\\\',\n",
       " '\\\\enfantBDuDat & \\\\enfantBDuDatP & \\\\enfantBDuDatG \\\\\\\\',\n",
       " '\\\\enfantBDuErg & \\\\enfantBDuErgP & \\\\enfantBDuErgG \\\\\\\\',\n",
       " '\\\\enfantBDuObl & \\\\enfantBDuOblP & \\\\enfantBDuOblG \\\\\\\\',\n",
       " '\\\\enfantBPlAbs & \\\\enfantBPlAbsP & \\\\enfantBPlAbsG \\\\\\\\',\n",
       " '\\\\enfantBPlDat & \\\\enfantBPlDatP & \\\\enfantBPlDatG \\\\\\\\',\n",
       " '\\\\enfantBPlErg & \\\\enfantBPlErgP & \\\\enfantBPlErgG \\\\\\\\',\n",
       " '\\\\enfantBPlObl & \\\\enfantBPlOblP & \\\\enfantBPlOblG \\\\\\\\',\n",
       " '\\\\enfantBSgAbs & \\\\enfantBSgAbsP & \\\\enfantBSgAbsG \\\\\\\\',\n",
       " '\\\\enfantBSgDat & \\\\enfantBSgDatP & \\\\enfantBSgDatG \\\\\\\\',\n",
       " '\\\\enfantBSgErg & \\\\enfantBSgErgP & \\\\enfantBSgErgG \\\\\\\\',\n",
       " '\\\\enfantBSgObl & \\\\enfantBSgOblP & \\\\enfantBSgOblG \\\\\\\\',\n",
       " '\\\\filleADuAbs & \\\\filleADuAbsP & \\\\filleADuAbsG \\\\\\\\',\n",
       " '\\\\filleADuDat & \\\\filleADuDatP & \\\\filleADuDatG \\\\\\\\',\n",
       " '\\\\filleADuErg & \\\\filleADuErgP & \\\\filleADuErgG \\\\\\\\',\n",
       " '\\\\filleADuObl & \\\\filleADuOblP & \\\\filleADuOblG \\\\\\\\',\n",
       " '\\\\filleAPlAbs & \\\\filleAPlAbsP & \\\\filleAPlAbsG \\\\\\\\',\n",
       " '\\\\filleAPlDat & \\\\filleAPlDatP & \\\\filleAPlDatG \\\\\\\\',\n",
       " '\\\\filleAPlErg & \\\\filleAPlErgP & \\\\filleAPlErgG \\\\\\\\',\n",
       " '\\\\filleAPlObl & \\\\filleAPlOblP & \\\\filleAPlOblG \\\\\\\\',\n",
       " '\\\\filleASgAbs & \\\\filleASgAbsP & \\\\filleASgAbsG \\\\\\\\',\n",
       " '\\\\filleASgDat & \\\\filleASgDatP & \\\\filleASgDatG \\\\\\\\',\n",
       " '\\\\filleASgErg & \\\\filleASgErgP & \\\\filleASgErgG \\\\\\\\',\n",
       " '\\\\filleASgObl & \\\\filleASgOblP & \\\\filleASgOblG \\\\\\\\',\n",
       " '\\\\foretADuAbs & \\\\foretADuAbsP & \\\\foretADuAbsG \\\\\\\\',\n",
       " '\\\\foretADuDat & \\\\foretADuDatP & \\\\foretADuDatG \\\\\\\\',\n",
       " '\\\\foretADuErg & \\\\foretADuErgP & \\\\foretADuErgG \\\\\\\\',\n",
       " '\\\\foretADuObl & \\\\foretADuOblP & \\\\foretADuOblG \\\\\\\\',\n",
       " '\\\\foretAPlAbs & \\\\foretAPlAbsP & \\\\foretAPlAbsG \\\\\\\\',\n",
       " '\\\\foretAPlDat & \\\\foretAPlDatP & \\\\foretAPlDatG \\\\\\\\',\n",
       " '\\\\foretAPlErg & \\\\foretAPlErgP & \\\\foretAPlErgG \\\\\\\\',\n",
       " '\\\\foretAPlObl & \\\\foretAPlOblP & \\\\foretAPlOblG \\\\\\\\',\n",
       " '\\\\foretASgAbs & \\\\foretASgAbsP & \\\\foretASgAbsG \\\\\\\\',\n",
       " '\\\\foretASgDat & \\\\foretASgDatP & \\\\foretASgDatG \\\\\\\\',\n",
       " '\\\\foretASgErg & \\\\foretASgErgP & \\\\foretASgErgG \\\\\\\\',\n",
       " '\\\\foretASgObl & \\\\foretASgOblP & \\\\foretASgOblG \\\\\\\\',\n",
       " '\\\\gorgeCDuAbs & \\\\gorgeCDuAbsP & \\\\gorgeCDuAbsG \\\\\\\\',\n",
       " '\\\\gorgeCDuDat & \\\\gorgeCDuDatP & \\\\gorgeCDuDatG \\\\\\\\',\n",
       " '\\\\gorgeCDuErg & \\\\gorgeCDuErgP & \\\\gorgeCDuErgG \\\\\\\\',\n",
       " '\\\\gorgeCDuObl & \\\\gorgeCDuOblP & \\\\gorgeCDuOblG \\\\\\\\',\n",
       " '\\\\gorgeCPlAbs & \\\\gorgeCPlAbsP & \\\\gorgeCPlAbsG \\\\\\\\',\n",
       " '\\\\gorgeCPlDat & \\\\gorgeCPlDatP & \\\\gorgeCPlDatG \\\\\\\\',\n",
       " '\\\\gorgeCPlErg & \\\\gorgeCPlErgP & \\\\gorgeCPlErgG \\\\\\\\',\n",
       " '\\\\gorgeCPlObl & \\\\gorgeCPlOblP & \\\\gorgeCPlOblG \\\\\\\\',\n",
       " '\\\\gorgeCSgAbs & \\\\gorgeCSgAbsP & \\\\gorgeCSgAbsG \\\\\\\\',\n",
       " '\\\\gorgeCSgDat & \\\\gorgeCSgDatP & \\\\gorgeCSgDatG \\\\\\\\',\n",
       " '\\\\gorgeCSgErg & \\\\gorgeCSgErgP & \\\\gorgeCSgErgG \\\\\\\\',\n",
       " '\\\\gorgeCSgObl & \\\\gorgeCSgOblP & \\\\gorgeCSgOblG \\\\\\\\',\n",
       " '\\\\hommeDDuAbs & \\\\hommeDDuAbsP & \\\\hommeDDuAbsG \\\\\\\\',\n",
       " '\\\\hommeDDuDat & \\\\hommeDDuDatP & \\\\hommeDDuDatG \\\\\\\\',\n",
       " '\\\\hommeDDuErg & \\\\hommeDDuErgP & \\\\hommeDDuErgG \\\\\\\\',\n",
       " '\\\\hommeDDuObl & \\\\hommeDDuOblP & \\\\hommeDDuOblG \\\\\\\\',\n",
       " '\\\\hommeDPlAbs & \\\\hommeDPlAbsP & \\\\hommeDPlAbsG \\\\\\\\',\n",
       " '\\\\hommeDPlDat & \\\\hommeDPlDatP & \\\\hommeDPlDatG \\\\\\\\',\n",
       " '\\\\hommeDPlErg & \\\\hommeDPlErgP & \\\\hommeDPlErgG \\\\\\\\',\n",
       " '\\\\hommeDPlObl & \\\\hommeDPlOblP & \\\\hommeDPlOblG \\\\\\\\',\n",
       " '\\\\hommeDSgAbs & \\\\hommeDSgAbsP & \\\\hommeDSgAbsG \\\\\\\\',\n",
       " '\\\\hommeDSgDat & \\\\hommeDSgDatP & \\\\hommeDSgDatG \\\\\\\\',\n",
       " '\\\\hommeDSgErg & \\\\hommeDSgErgP & \\\\hommeDSgErgG \\\\\\\\',\n",
       " '\\\\hommeDSgObl & \\\\hommeDSgOblP & \\\\hommeDSgOblG \\\\\\\\',\n",
       " '\\\\lanceCDuAbs & \\\\lanceCDuAbsP & \\\\lanceCDuAbsG \\\\\\\\',\n",
       " '\\\\lanceCDuDat & \\\\lanceCDuDatP & \\\\lanceCDuDatG \\\\\\\\',\n",
       " '\\\\lanceCDuErg & \\\\lanceCDuErgP & \\\\lanceCDuErgG \\\\\\\\',\n",
       " '\\\\lanceCDuObl & \\\\lanceCDuOblP & \\\\lanceCDuOblG \\\\\\\\',\n",
       " '\\\\lanceCPlAbs & \\\\lanceCPlAbsP & \\\\lanceCPlAbsG \\\\\\\\',\n",
       " '\\\\lanceCPlDat & \\\\lanceCPlDatP & \\\\lanceCPlDatG \\\\\\\\',\n",
       " '\\\\lanceCPlErg & \\\\lanceCPlErgP & \\\\lanceCPlErgG \\\\\\\\',\n",
       " '\\\\lanceCPlObl & \\\\lanceCPlOblP & \\\\lanceCPlOblG \\\\\\\\',\n",
       " '\\\\lanceCSgAbs & \\\\lanceCSgAbsP & \\\\lanceCSgAbsG \\\\\\\\',\n",
       " '\\\\lanceCSgDat & \\\\lanceCSgDatP & \\\\lanceCSgDatG \\\\\\\\',\n",
       " '\\\\lanceCSgErg & \\\\lanceCSgErgP & \\\\lanceCSgErgG \\\\\\\\',\n",
       " '\\\\lanceCSgObl & \\\\lanceCSgOblP & \\\\lanceCSgOblG \\\\\\\\',\n",
       " '\\\\loupADuAbs & \\\\loupADuAbsP & \\\\loupADuAbsG \\\\\\\\',\n",
       " '\\\\loupADuDat & \\\\loupADuDatP & \\\\loupADuDatG \\\\\\\\',\n",
       " '\\\\loupADuErg & \\\\loupADuErgP & \\\\loupADuErgG \\\\\\\\',\n",
       " '\\\\loupADuObl & \\\\loupADuOblP & \\\\loupADuOblG \\\\\\\\',\n",
       " '\\\\loupAPlAbs & \\\\loupAPlAbsP & \\\\loupAPlAbsG \\\\\\\\',\n",
       " '\\\\loupAPlDat & \\\\loupAPlDatP & \\\\loupAPlDatG \\\\\\\\',\n",
       " '\\\\loupAPlErg & \\\\loupAPlErgP & \\\\loupAPlErgG \\\\\\\\',\n",
       " '\\\\loupAPlObl & \\\\loupAPlOblP & \\\\loupAPlOblG \\\\\\\\',\n",
       " '\\\\loupASgAbs & \\\\loupASgAbsP & \\\\loupASgAbsG \\\\\\\\',\n",
       " '\\\\loupASgDat & \\\\loupASgDatP & \\\\loupASgDatG \\\\\\\\',\n",
       " '\\\\loupASgErg & \\\\loupASgErgP & \\\\loupASgErgG \\\\\\\\',\n",
       " '\\\\loupASgObl & \\\\loupASgOblP & \\\\loupASgOblG \\\\\\\\',\n",
       " '\\\\louveBDuAbs & \\\\louveBDuAbsP & \\\\louveBDuAbsG \\\\\\\\',\n",
       " '\\\\louveBDuDat & \\\\louveBDuDatP & \\\\louveBDuDatG \\\\\\\\',\n",
       " '\\\\louveBDuErg & \\\\louveBDuErgP & \\\\louveBDuErgG \\\\\\\\',\n",
       " '\\\\louveBDuObl & \\\\louveBDuOblP & \\\\louveBDuOblG \\\\\\\\',\n",
       " '\\\\louveBPlAbs & \\\\louveBPlAbsP & \\\\louveBPlAbsG \\\\\\\\',\n",
       " '\\\\louveBPlDat & \\\\louveBPlDatP & \\\\louveBPlDatG \\\\\\\\',\n",
       " '\\\\louveBPlErg & \\\\louveBPlErgP & \\\\louveBPlErgG \\\\\\\\',\n",
       " '\\\\louveBPlObl & \\\\louveBPlOblP & \\\\louveBPlOblG \\\\\\\\',\n",
       " '\\\\louveBSgAbs & \\\\louveBSgAbsP & \\\\louveBSgAbsG \\\\\\\\',\n",
       " '\\\\louveBSgDat & \\\\louveBSgDatP & \\\\louveBSgDatG \\\\\\\\',\n",
       " '\\\\louveBSgErg & \\\\louveBSgErgP & \\\\louveBSgErgG \\\\\\\\',\n",
       " '\\\\louveBSgObl & \\\\louveBSgOblP & \\\\louveBSgOblG \\\\\\\\',\n",
       " '\\\\lueurCDuAbs & \\\\lueurCDuAbsP & \\\\lueurCDuAbsG \\\\\\\\',\n",
       " '\\\\lueurCDuDat & \\\\lueurCDuDatP & \\\\lueurCDuDatG \\\\\\\\',\n",
       " '\\\\lueurCDuErg & \\\\lueurCDuErgP & \\\\lueurCDuErgG \\\\\\\\',\n",
       " '\\\\lueurCDuObl & \\\\lueurCDuOblP & \\\\lueurCDuOblG \\\\\\\\',\n",
       " '\\\\lueurCPlAbs & \\\\lueurCPlAbsP & \\\\lueurCPlAbsG \\\\\\\\',\n",
       " '\\\\lueurCPlDat & \\\\lueurCPlDatP & \\\\lueurCPlDatG \\\\\\\\',\n",
       " '\\\\lueurCPlErg & \\\\lueurCPlErgP & \\\\lueurCPlErgG \\\\\\\\',\n",
       " '\\\\lueurCPlObl & \\\\lueurCPlOblP & \\\\lueurCPlOblG \\\\\\\\',\n",
       " '\\\\lueurCSgAbs & \\\\lueurCSgAbsP & \\\\lueurCSgAbsG \\\\\\\\',\n",
       " '\\\\lueurCSgDat & \\\\lueurCSgDatP & \\\\lueurCSgDatG \\\\\\\\',\n",
       " '\\\\lueurCSgErg & \\\\lueurCSgErgP & \\\\lueurCSgErgG \\\\\\\\',\n",
       " '\\\\lueurCSgObl & \\\\lueurCSgOblP & \\\\lueurCSgOblG \\\\\\\\',\n",
       " '\\\\luneADuAbs & \\\\luneADuAbsP & \\\\luneADuAbsG \\\\\\\\',\n",
       " '\\\\luneADuDat & \\\\luneADuDatP & \\\\luneADuDatG \\\\\\\\',\n",
       " '\\\\luneADuErg & \\\\luneADuErgP & \\\\luneADuErgG \\\\\\\\',\n",
       " '\\\\luneADuObl & \\\\luneADuOblP & \\\\luneADuOblG \\\\\\\\',\n",
       " '\\\\luneAPlAbs & \\\\luneAPlAbsP & \\\\luneAPlAbsG \\\\\\\\',\n",
       " '\\\\luneAPlDat & \\\\luneAPlDatP & \\\\luneAPlDatG \\\\\\\\',\n",
       " '\\\\luneAPlErg & \\\\luneAPlErgP & \\\\luneAPlErgG \\\\\\\\',\n",
       " '\\\\luneAPlObl & \\\\luneAPlOblP & \\\\luneAPlOblG \\\\\\\\',\n",
       " '\\\\luneASgAbs & \\\\luneASgAbsP & \\\\luneASgAbsG \\\\\\\\',\n",
       " '\\\\luneASgDat & \\\\luneASgDatP & \\\\luneASgDatG \\\\\\\\',\n",
       " '\\\\luneASgErg & \\\\luneASgErgP & \\\\luneASgErgG \\\\\\\\',\n",
       " '\\\\luneASgObl & \\\\luneASgOblP & \\\\luneASgOblG \\\\\\\\',\n",
       " '\\\\mainBDuAbs & \\\\mainBDuAbsP & \\\\mainBDuAbsG \\\\\\\\',\n",
       " '\\\\mainBDuDat & \\\\mainBDuDatP & \\\\mainBDuDatG \\\\\\\\',\n",
       " '\\\\mainBDuErg & \\\\mainBDuErgP & \\\\mainBDuErgG \\\\\\\\',\n",
       " '\\\\mainBDuObl & \\\\mainBDuOblP & \\\\mainBDuOblG \\\\\\\\',\n",
       " '\\\\mainBPlAbs & \\\\mainBPlAbsP & \\\\mainBPlAbsG \\\\\\\\',\n",
       " '\\\\mainBPlDat & \\\\mainBPlDatP & \\\\mainBPlDatG \\\\\\\\',\n",
       " '\\\\mainBPlErg & \\\\mainBPlErgP & \\\\mainBPlErgG \\\\\\\\',\n",
       " '\\\\mainBPlObl & \\\\mainBPlOblP & \\\\mainBPlOblG \\\\\\\\',\n",
       " '\\\\mainBSgAbs & \\\\mainBSgAbsP & \\\\mainBSgAbsG \\\\\\\\',\n",
       " '\\\\mainBSgDat & \\\\mainBSgDatP & \\\\mainBSgDatG \\\\\\\\',\n",
       " '\\\\mainBSgErg & \\\\mainBSgErgP & \\\\mainBSgErgG \\\\\\\\',\n",
       " '\\\\mainBSgObl & \\\\mainBSgOblP & \\\\mainBSgOblG \\\\\\\\',\n",
       " '\\\\maisonCDuAbs & \\\\maisonCDuAbsP & \\\\maisonCDuAbsG \\\\\\\\',\n",
       " '\\\\maisonCDuDat & \\\\maisonCDuDatP & \\\\maisonCDuDatG \\\\\\\\',\n",
       " '\\\\maisonCDuErg & \\\\maisonCDuErgP & \\\\maisonCDuErgG \\\\\\\\',\n",
       " '\\\\maisonCDuObl & \\\\maisonCDuOblP & \\\\maisonCDuOblG \\\\\\\\',\n",
       " '\\\\maisonCPlAbs & \\\\maisonCPlAbsP & \\\\maisonCPlAbsG \\\\\\\\',\n",
       " '\\\\maisonCPlDat & \\\\maisonCPlDatP & \\\\maisonCPlDatG \\\\\\\\',\n",
       " '\\\\maisonCPlErg & \\\\maisonCPlErgP & \\\\maisonCPlErgG \\\\\\\\',\n",
       " '\\\\maisonCPlObl & \\\\maisonCPlOblP & \\\\maisonCPlOblG \\\\\\\\',\n",
       " '\\\\maisonCSgAbs & \\\\maisonCSgAbsP & \\\\maisonCSgAbsG \\\\\\\\',\n",
       " '\\\\maisonCSgDat & \\\\maisonCSgDatP & \\\\maisonCSgDatG \\\\\\\\',\n",
       " '\\\\maisonCSgErg & \\\\maisonCSgErgP & \\\\maisonCSgErgG \\\\\\\\',\n",
       " '\\\\maisonCSgObl & \\\\maisonCSgOblP & \\\\maisonCSgOblG \\\\\\\\',\n",
       " '\\\\milieuBDuAbs & \\\\milieuBDuAbsP & \\\\milieuBDuAbsG \\\\\\\\',\n",
       " '\\\\milieuBDuDat & \\\\milieuBDuDatP & \\\\milieuBDuDatG \\\\\\\\',\n",
       " '\\\\milieuBDuErg & \\\\milieuBDuErgP & \\\\milieuBDuErgG \\\\\\\\',\n",
       " '\\\\milieuBDuObl & \\\\milieuBDuOblP & \\\\milieuBDuOblG \\\\\\\\',\n",
       " '\\\\milieuBPlAbs & \\\\milieuBPlAbsP & \\\\milieuBPlAbsG \\\\\\\\',\n",
       " '\\\\milieuBPlDat & \\\\milieuBPlDatP & \\\\milieuBPlDatG \\\\\\\\',\n",
       " '\\\\milieuBPlErg & \\\\milieuBPlErgP & \\\\milieuBPlErgG \\\\\\\\',\n",
       " '\\\\milieuBPlObl & \\\\milieuBPlOblP & \\\\milieuBPlOblG \\\\\\\\',\n",
       " '\\\\milieuBSgAbs & \\\\milieuBSgAbsP & \\\\milieuBSgAbsG \\\\\\\\',\n",
       " '\\\\milieuBSgDat & \\\\milieuBSgDatP & \\\\milieuBSgDatG \\\\\\\\',\n",
       " '\\\\milieuBSgErg & \\\\milieuBSgErgP & \\\\milieuBSgErgG \\\\\\\\',\n",
       " '\\\\milieuBSgObl & \\\\milieuBSgOblP & \\\\milieuBSgOblG \\\\\\\\',\n",
       " '\\\\mortBDuAbs & \\\\mortBDuAbsP & \\\\mortBDuAbsG \\\\\\\\',\n",
       " '\\\\mortBDuDat & \\\\mortBDuDatP & \\\\mortBDuDatG \\\\\\\\',\n",
       " '\\\\mortBDuErg & \\\\mortBDuErgP & \\\\mortBDuErgG \\\\\\\\',\n",
       " '\\\\mortBDuObl & \\\\mortBDuOblP & \\\\mortBDuOblG \\\\\\\\',\n",
       " '\\\\mortBPlAbs & \\\\mortBPlAbsP & \\\\mortBPlAbsG \\\\\\\\',\n",
       " '\\\\mortBPlDat & \\\\mortBPlDatP & \\\\mortBPlDatG \\\\\\\\',\n",
       " '\\\\mortBPlErg & \\\\mortBPlErgP & \\\\mortBPlErgG \\\\\\\\',\n",
       " '\\\\mortBPlObl & \\\\mortBPlOblP & \\\\mortBPlOblG \\\\\\\\',\n",
       " '\\\\mortBSgAbs & \\\\mortBSgAbsP & \\\\mortBSgAbsG \\\\\\\\',\n",
       " '\\\\mortBSgDat & \\\\mortBSgDatP & \\\\mortBSgDatG \\\\\\\\',\n",
       " '\\\\mortBSgErg & \\\\mortBSgErgP & \\\\mortBSgErgG \\\\\\\\',\n",
       " '\\\\mortBSgObl & \\\\mortBSgOblP & \\\\mortBSgOblG \\\\\\\\',\n",
       " '\\\\nuitDDuAbs & \\\\nuitDDuAbsP & \\\\nuitDDuAbsG \\\\\\\\',\n",
       " '\\\\nuitDDuDat & \\\\nuitDDuDatP & \\\\nuitDDuDatG \\\\\\\\',\n",
       " '\\\\nuitDDuErg & \\\\nuitDDuErgP & \\\\nuitDDuErgG \\\\\\\\',\n",
       " '\\\\nuitDDuObl & \\\\nuitDDuOblP & \\\\nuitDDuOblG \\\\\\\\',\n",
       " '\\\\nuitDPlAbs & \\\\nuitDPlAbsP & \\\\nuitDPlAbsG \\\\\\\\',\n",
       " '\\\\nuitDPlDat & \\\\nuitDPlDatP & \\\\nuitDPlDatG \\\\\\\\',\n",
       " '\\\\nuitDPlErg & \\\\nuitDPlErgP & \\\\nuitDPlErgG \\\\\\\\',\n",
       " '\\\\nuitDPlObl & \\\\nuitDPlOblP & \\\\nuitDPlOblG \\\\\\\\',\n",
       " '\\\\nuitDSgAbs & \\\\nuitDSgAbsP & \\\\nuitDSgAbsG \\\\\\\\',\n",
       " '\\\\nuitDSgDat & \\\\nuitDSgDatP & \\\\nuitDSgDatG \\\\\\\\',\n",
       " '\\\\nuitDSgErg & \\\\nuitDSgErgP & \\\\nuitDSgErgG \\\\\\\\',\n",
       " '\\\\nuitDSgObl & \\\\nuitDSgOblP & \\\\nuitDSgOblG \\\\\\\\',\n",
       " '\\\\ombreADuAbs & \\\\ombreADuAbsP & \\\\ombreADuAbsG \\\\\\\\',\n",
       " '\\\\ombreADuDat & \\\\ombreADuDatP & \\\\ombreADuDatG \\\\\\\\',\n",
       " '\\\\ombreADuErg & \\\\ombreADuErgP & \\\\ombreADuErgG \\\\\\\\',\n",
       " '\\\\ombreADuObl & \\\\ombreADuOblP & \\\\ombreADuOblG \\\\\\\\',\n",
       " '\\\\ombreAPlAbs & \\\\ombreAPlAbsP & \\\\ombreAPlAbsG \\\\\\\\',\n",
       " '\\\\ombreAPlDat & \\\\ombreAPlDatP & \\\\ombreAPlDatG \\\\\\\\',\n",
       " '\\\\ombreAPlErg & \\\\ombreAPlErgP & \\\\ombreAPlErgG \\\\\\\\',\n",
       " '\\\\ombreAPlObl & \\\\ombreAPlOblP & \\\\ombreAPlOblG \\\\\\\\',\n",
       " '\\\\ombreASgAbs & \\\\ombreASgAbsP & \\\\ombreASgAbsG \\\\\\\\',\n",
       " '\\\\ombreASgDat & \\\\ombreASgDatP & \\\\ombreASgDatG \\\\\\\\',\n",
       " '\\\\ombreASgErg & \\\\ombreASgErgP & \\\\ombreASgErgG \\\\\\\\',\n",
       " '\\\\ombreASgObl & \\\\ombreASgOblP & \\\\ombreASgOblG \\\\\\\\',\n",
       " '\\\\serpentCDuAbs & \\\\serpentCDuAbsP & \\\\serpentCDuAbsG \\\\\\\\',\n",
       " '\\\\serpentCDuDat & \\\\serpentCDuDatP & \\\\serpentCDuDatG \\\\\\\\',\n",
       " '\\\\serpentCDuErg & \\\\serpentCDuErgP & \\\\serpentCDuErgG \\\\\\\\',\n",
       " '\\\\serpentCDuObl & \\\\serpentCDuOblP & \\\\serpentCDuOblG \\\\\\\\',\n",
       " '\\\\serpentCPlAbs & \\\\serpentCPlAbsP & \\\\serpentCPlAbsG \\\\\\\\',\n",
       " '\\\\serpentCPlDat & \\\\serpentCPlDatP & \\\\serpentCPlDatG \\\\\\\\',\n",
       " '\\\\serpentCPlErg & \\\\serpentCPlErgP & \\\\serpentCPlErgG \\\\\\\\',\n",
       " '\\\\serpentCPlObl & \\\\serpentCPlOblP & \\\\serpentCPlOblG \\\\\\\\',\n",
       " '\\\\serpentCSgAbs & \\\\serpentCSgAbsP & \\\\serpentCSgAbsG \\\\\\\\',\n",
       " '\\\\serpentCSgDat & \\\\serpentCSgDatP & \\\\serpentCSgDatG \\\\\\\\',\n",
       " '\\\\serpentCSgErg & \\\\serpentCSgErgP & \\\\serpentCSgErgG \\\\\\\\',\n",
       " '\\\\serpentCSgObl & \\\\serpentCSgOblP & \\\\serpentCSgOblG \\\\\\\\',\n",
       " '\\\\soeurDDuAbs & \\\\soeurDDuAbsP & \\\\soeurDDuAbsG \\\\\\\\',\n",
       " '\\\\soeurDDuDat & \\\\soeurDDuDatP & \\\\soeurDDuDatG \\\\\\\\',\n",
       " '\\\\soeurDDuErg & \\\\soeurDDuErgP & \\\\soeurDDuErgG \\\\\\\\',\n",
       " '\\\\soeurDDuObl & \\\\soeurDDuOblP & \\\\soeurDDuOblG \\\\\\\\',\n",
       " '\\\\soeurDPlAbs & \\\\soeurDPlAbsP & \\\\soeurDPlAbsG \\\\\\\\',\n",
       " '\\\\soeurDPlDat & \\\\soeurDPlDatP & \\\\soeurDPlDatG \\\\\\\\',\n",
       " '\\\\soeurDPlErg & \\\\soeurDPlErgP & \\\\soeurDPlErgG \\\\\\\\',\n",
       " '\\\\soeurDPlObl & \\\\soeurDPlOblP & \\\\soeurDPlOblG \\\\\\\\',\n",
       " '\\\\soeurDSgAbs & \\\\soeurDSgAbsP & \\\\soeurDSgAbsG \\\\\\\\',\n",
       " '\\\\soeurDSgDat & \\\\soeurDSgDatP & \\\\soeurDSgDatG \\\\\\\\',\n",
       " '\\\\soeurDSgErg & \\\\soeurDSgErgP & \\\\soeurDSgErgG \\\\\\\\',\n",
       " '\\\\soeurDSgObl & \\\\soeurDSgOblP & \\\\soeurDSgOblG \\\\\\\\',\n",
       " '\\\\sortADuAbs & \\\\sortADuAbsP & \\\\sortADuAbsG \\\\\\\\',\n",
       " '\\\\sortADuDat & \\\\sortADuDatP & \\\\sortADuDatG \\\\\\\\',\n",
       " '\\\\sortADuErg & \\\\sortADuErgP & \\\\sortADuErgG \\\\\\\\',\n",
       " '\\\\sortADuObl & \\\\sortADuOblP & \\\\sortADuOblG \\\\\\\\',\n",
       " '\\\\sortAPlAbs & \\\\sortAPlAbsP & \\\\sortAPlAbsG \\\\\\\\',\n",
       " '\\\\sortAPlDat & \\\\sortAPlDatP & \\\\sortAPlDatG \\\\\\\\',\n",
       " '\\\\sortAPlErg & \\\\sortAPlErgP & \\\\sortAPlErgG \\\\\\\\',\n",
       " '\\\\sortAPlObl & \\\\sortAPlOblP & \\\\sortAPlOblG \\\\\\\\',\n",
       " '\\\\sortASgAbs & \\\\sortASgAbsP & \\\\sortASgAbsG \\\\\\\\',\n",
       " '\\\\sortASgDat & \\\\sortASgDatP & \\\\sortASgDatG \\\\\\\\',\n",
       " '\\\\sortASgErg & \\\\sortASgErgP & \\\\sortASgErgG \\\\\\\\',\n",
       " '\\\\sortASgObl & \\\\sortASgOblP & \\\\sortASgOblG \\\\\\\\',\n",
       " '\\\\souffranceCDuAbs & \\\\souffranceCDuAbsP & \\\\souffranceCDuAbsG \\\\\\\\',\n",
       " '\\\\souffranceCDuDat & \\\\souffranceCDuDatP & \\\\souffranceCDuDatG \\\\\\\\',\n",
       " '\\\\souffranceCDuErg & \\\\souffranceCDuErgP & \\\\souffranceCDuErgG \\\\\\\\',\n",
       " '\\\\souffranceCDuObl & \\\\souffranceCDuOblP & \\\\souffranceCDuOblG \\\\\\\\',\n",
       " '\\\\souffranceCPlAbs & \\\\souffranceCPlAbsP & \\\\souffranceCPlAbsG \\\\\\\\',\n",
       " '\\\\souffranceCPlDat & \\\\souffranceCPlDatP & \\\\souffranceCPlDatG \\\\\\\\',\n",
       " '\\\\souffranceCPlErg & \\\\souffranceCPlErgP & \\\\souffranceCPlErgG \\\\\\\\',\n",
       " '\\\\souffranceCPlObl & \\\\souffranceCPlOblP & \\\\souffranceCPlOblG \\\\\\\\',\n",
       " '\\\\souffranceCSgAbs & \\\\souffranceCSgAbsP & \\\\souffranceCSgAbsG \\\\\\\\',\n",
       " '\\\\souffranceCSgDat & \\\\souffranceCSgDatP & \\\\souffranceCSgDatG \\\\\\\\',\n",
       " '\\\\souffranceCSgErg & \\\\souffranceCSgErgP & \\\\souffranceCSgErgG \\\\\\\\',\n",
       " '\\\\souffranceCSgObl & \\\\souffranceCSgOblP & \\\\souffranceCSgOblG \\\\\\\\',\n",
       " '\\\\villageCDuAbs & \\\\villageCDuAbsP & \\\\villageCDuAbsG \\\\\\\\',\n",
       " '\\\\villageCDuDat & \\\\villageCDuDatP & \\\\villageCDuDatG \\\\\\\\',\n",
       " '\\\\villageCDuErg & \\\\villageCDuErgP & \\\\villageCDuErgG \\\\\\\\',\n",
       " '\\\\villageCDuObl & \\\\villageCDuOblP & \\\\villageCDuOblG \\\\\\\\',\n",
       " '\\\\villageCPlAbs & \\\\villageCPlAbsP & \\\\villageCPlAbsG \\\\\\\\',\n",
       " '\\\\villageCPlDat & \\\\villageCPlDatP & \\\\villageCPlDatG \\\\\\\\',\n",
       " '\\\\villageCPlErg & \\\\villageCPlErgP & \\\\villageCPlErgG \\\\\\\\',\n",
       " '\\\\villageCPlObl & \\\\villageCPlOblP & \\\\villageCPlOblG \\\\\\\\',\n",
       " '\\\\villageCSgAbs & \\\\villageCSgAbsP & \\\\villageCSgAbsG \\\\\\\\',\n",
       " '\\\\villageCSgDat & \\\\villageCSgDatP & \\\\villageCSgDatG \\\\\\\\',\n",
       " '\\\\villageCSgErg & \\\\villageCSgErgP & \\\\villageCSgErgG \\\\\\\\',\n",
       " '\\\\villageCSgObl & \\\\villageCSgOblP & \\\\villageCSgOblG \\\\\\\\',\n",
       " '\\\\villageoisCDuAbs & \\\\villageoisCDuAbsP & \\\\villageoisCDuAbsG \\\\\\\\',\n",
       " '\\\\villageoisCDuDat & \\\\villageoisCDuDatP & \\\\villageoisCDuDatG \\\\\\\\',\n",
       " '\\\\villageoisCDuErg & \\\\villageoisCDuErgP & \\\\villageoisCDuErgG \\\\\\\\',\n",
       " '\\\\villageoisCDuObl & \\\\villageoisCDuOblP & \\\\villageoisCDuOblG \\\\\\\\',\n",
       " '\\\\villageoisCPlAbs & \\\\villageoisCPlAbsP & \\\\villageoisCPlAbsG \\\\\\\\',\n",
       " '\\\\villageoisCPlDat & \\\\villageoisCPlDatP & \\\\villageoisCPlDatG \\\\\\\\',\n",
       " '\\\\villageoisCPlErg & \\\\villageoisCPlErgP & \\\\villageoisCPlErgG \\\\\\\\',\n",
       " '\\\\villageoisCPlObl & \\\\villageoisCPlOblP & \\\\villageoisCPlOblG \\\\\\\\',\n",
       " '\\\\villageoisCSgAbs & \\\\villageoisCSgAbsP & \\\\villageoisCSgAbsG \\\\\\\\',\n",
       " '\\\\villageoisCSgDat & \\\\villageoisCSgDatP & \\\\villageoisCSgDatG \\\\\\\\',\n",
       " '\\\\villageoisCSgErg & \\\\villageoisCSgErgP & \\\\villageoisCSgErgG \\\\\\\\',\n",
       " '\\\\villageoisCSgObl & \\\\villageoisCSgOblP & \\\\villageoisCSgOblG \\\\\\\\',\n",
       " '\\\\villageoiseDDuAbs & \\\\villageoiseDDuAbsP & \\\\villageoiseDDuAbsG \\\\\\\\',\n",
       " '\\\\villageoiseDDuDat & \\\\villageoiseDDuDatP & \\\\villageoiseDDuDatG \\\\\\\\',\n",
       " '\\\\villageoiseDDuErg & \\\\villageoiseDDuErgP & \\\\villageoiseDDuErgG \\\\\\\\',\n",
       " '\\\\villageoiseDDuObl & \\\\villageoiseDDuOblP & \\\\villageoiseDDuOblG \\\\\\\\',\n",
       " '\\\\villageoiseDPlAbs & \\\\villageoiseDPlAbsP & \\\\villageoiseDPlAbsG \\\\\\\\',\n",
       " '\\\\villageoiseDPlDat & \\\\villageoiseDPlDatP & \\\\villageoiseDPlDatG \\\\\\\\',\n",
       " '\\\\villageoiseDPlErg & \\\\villageoiseDPlErgP & \\\\villageoiseDPlErgG \\\\\\\\',\n",
       " '\\\\villageoiseDPlObl & \\\\villageoiseDPlOblP & \\\\villageoiseDPlOblG \\\\\\\\',\n",
       " '\\\\villageoiseDSgAbs & \\\\villageoiseDSgAbsP & \\\\villageoiseDSgAbsG \\\\\\\\',\n",
       " '\\\\villageoiseDSgDat & \\\\villageoiseDSgDatP & \\\\villageoiseDSgDatG \\\\\\\\',\n",
       " '\\\\villageoiseDSgErg & \\\\villageoiseDSgErgP & \\\\villageoiseDSgErgG \\\\\\\\',\n",
       " '\\\\villageoiseDSgObl & \\\\villageoiseDSgOblP & \\\\villageoiseDSgOblG \\\\\\\\',\n",
       " '\\\\visageDDuAbs & \\\\visageDDuAbsP & \\\\visageDDuAbsG \\\\\\\\',\n",
       " '\\\\visageDDuDat & \\\\visageDDuDatP & \\\\visageDDuDatG \\\\\\\\',\n",
       " '\\\\visageDDuErg & \\\\visageDDuErgP & \\\\visageDDuErgG \\\\\\\\',\n",
       " '\\\\visageDDuObl & \\\\visageDDuOblP & \\\\visageDDuOblG \\\\\\\\',\n",
       " '\\\\visageDPlAbs & \\\\visageDPlAbsP & \\\\visageDPlAbsG \\\\\\\\',\n",
       " '\\\\visageDPlDat & \\\\visageDPlDatP & \\\\visageDPlDatG \\\\\\\\',\n",
       " '\\\\visageDPlErg & \\\\visageDPlErgP & \\\\visageDPlErgG \\\\\\\\',\n",
       " '\\\\visageDPlObl & \\\\visageDPlOblP & \\\\visageDPlOblG \\\\\\\\',\n",
       " '\\\\visageDSgAbs & \\\\visageDSgAbsP & \\\\visageDSgAbsG \\\\\\\\',\n",
       " '\\\\visageDSgDat & \\\\visageDSgDatP & \\\\visageDSgDatG \\\\\\\\',\n",
       " '\\\\visageDSgErg & \\\\visageDSgErgP & \\\\visageDSgErgG \\\\\\\\',\n",
       " '\\\\visageDSgObl & \\\\visageDSgOblP & \\\\visageDSgOblG \\\\\\\\'}"
      ]
     },
     "execution_count": 1656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PFM.hierarchieCF.classes\n",
    "#discrimineur\n",
    "tableaux[\"NOM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
